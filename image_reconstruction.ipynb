{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from torchsummary import torchsummary\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Local\n",
    "\n",
    "ORIGINAL_IMAGE = 'E:/dataSets/NDI_images/20220725/20220725/Observed_Crop_200x200pix'\n",
    "TARGET_IMAGE = 'E:/dataSets/NDI_images/20220725/20220725/Calculated_200x200/grayscale'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "binarized_path = Path.joinpath(Path(TARGET_IMAGE), 'binarized')\n",
    "file_names = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "for file_name in file_names:\n",
    "    file_stem = file_name.name\n",
    "    img = cv2.imread(str(file_name), cv2.IMREAD_UNCHANGED)\n",
    "    threshold, result = cv2.threshold(img, 90, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imwrite(str(Path.joinpath(binarized_path, file_stem)), result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class NDIDatasetReconstruction(Dataset):\n",
    "    def __init__(self):\n",
    "        super(NDIDatasetReconstruction, self).__init__()\n",
    "        original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "        origins, targets = [], []\n",
    "        to_tensor_func = torchvision.transforms.ToTensor()\n",
    "        for original_image in original_images:\n",
    "            origins.append(to_tensor_func(Image.open(str(original_image))))\n",
    "            targets.append(to_tensor_func(Image.open(str(Path.joinpath(binarized_path, original_image.name.split('_')[0] + '.jpg')))).type(torch.long).squeeze(0))\n",
    "        random_index = np.random.permutation(len(origins))\n",
    "        self.origins, self.targets = [], []\n",
    "        for index in random_index:\n",
    "            self.origins.append(origins[index])\n",
    "            self.targets.append(targets[index])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.origins[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from Unet_model import UNet, dice_loss\n",
    "\n",
    "\n",
    "model = UNet(1, 2, use_BN=True)\n",
    "device = torch.device('cuda:0')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-5, weight_decay=1e-8, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, epochs, device):\n",
    "    net.cuda(device)\n",
    "    train_iter = DataLoader(NDIDatasetReconstruction(), batch_size=8, shuffle=True, drop_last=True)\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        for origin, target in train_iter:\n",
    "            origin, target = origin.cuda(device), target.cuda(device)\n",
    "            assert origin.shape[1] == net.n_channels\n",
    "            masks_pred = net(origin)\n",
    "            loss = criterion(masks_pred, target) + dice_loss(f.softmax(masks_pred, dim=1).float(), f.one_hot(target, net.n_classes).permute(0, 3, 1, 2).float(), multiclass=True)\n",
    "            epoch_loss += loss.item()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss {epoch_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 9.419089198112488\n",
      "Epoch 2, Loss 7.825797915458679\n",
      "Epoch 3, Loss 6.613701105117798\n",
      "Epoch 4, Loss 5.989596426486969\n",
      "Epoch 5, Loss 5.642834305763245\n",
      "Epoch 6, Loss 5.453350901603699\n",
      "Epoch 7, Loss 5.297598838806152\n",
      "Epoch 8, Loss 5.179667294025421\n",
      "Epoch 9, Loss 5.084425330162048\n",
      "Epoch 10, Loss 5.019053936004639\n",
      "Epoch 11, Loss 4.949221611022949\n",
      "Epoch 12, Loss 4.887756288051605\n",
      "Epoch 13, Loss 4.834590494632721\n",
      "Epoch 14, Loss 4.7789976596832275\n",
      "Epoch 15, Loss 4.751592755317688\n",
      "Epoch 16, Loss 4.743165194988251\n",
      "Epoch 17, Loss 4.6976786851882935\n",
      "Epoch 18, Loss 4.639142990112305\n",
      "Epoch 19, Loss 4.580848932266235\n",
      "Epoch 20, Loss 4.524388492107391\n",
      "Epoch 21, Loss 4.473062694072723\n",
      "Epoch 22, Loss 4.43853622674942\n",
      "Epoch 23, Loss 4.395389378070831\n",
      "Epoch 24, Loss 4.3832796812057495\n",
      "Epoch 25, Loss 4.356720566749573\n",
      "Epoch 26, Loss 4.322990596294403\n",
      "Epoch 27, Loss 4.287537753582001\n",
      "Epoch 28, Loss 4.251213788986206\n",
      "Epoch 29, Loss 4.215823292732239\n",
      "Epoch 30, Loss 4.184724807739258\n",
      "Epoch 31, Loss 4.158915221691132\n",
      "Epoch 32, Loss 4.1329933404922485\n",
      "Epoch 33, Loss 4.1063233613967896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [63]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [62]\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(net, criterion, optimizer, epochs, device)\u001B[0m\n\u001B[0;32m      6\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m origin, target \u001B[38;5;129;01min\u001B[39;00m train_iter:\n\u001B[1;32m----> 8\u001B[0m     origin, target \u001B[38;5;241m=\u001B[39m \u001B[43morigin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m, target\u001B[38;5;241m.\u001B[39mcuda(device)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m origin\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m net\u001B[38;5;241m.\u001B[39mn_channels\n\u001B[0;32m     10\u001B[0m     masks_pred \u001B[38;5;241m=\u001B[39m net(origin)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, 50, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 200, 200])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "to_tensor_func = torchvision.transforms.ToTensor()\n",
    "to_image_func = torchvision.transforms.ToPILImage()\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "origin = to_tensor_func(Image.open(str(np.random.choice(original_images)))).unsqueeze(0)\n",
    "result = model(origin)\n",
    "torch.argmax(result, dim=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def reconstruction_test(net, origin, target):\n",
    "    to_image_func = torchvision.transforms.ToPILImage()\n",
    "    preds = net(origin)\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "    preds = to_image_func(preds.type(torch.float))\n",
    "    target = to_image_func(target)\n",
    "    preds = cv2.cvtColor(np.asarray(preds), cv2.COLOR_RGB2BGR)\n",
    "    target = cv2.cvtColor(np.asarray(target), cv2.COLOR_RGB2BGR)\n",
    "    stacked_image = np.hstack([target, preds])\n",
    "    cv2.imshow('stacked', stacked_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "original_image = np.random.choice(original_images)\n",
    "print(original_image.name.split('_')[0])\n",
    "origin_data = to_tensor_func(Image.open(str(original_image))).unsqueeze(0)\n",
    "target_data = to_tensor_func(Image.open(str(Path.joinpath(Path(binarized_path), original_image.name.split('_')[0] + '.jpg'))))\n",
    "reconstruction_test(model, origin, target_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}