{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE = '/import/mqhome/duanct/dataSets/NDI_images/20220725/20220725/Observed_Crop_200x200pix'\n",
    "TARGET_IMAGE = '/import/mqhome/duanct/dataSets/NDI_images/20220725/20220725/Calculated_200x200/grayscale'\n",
    "POSITIVE_RATIO = 0.1\n",
    "BATCH_SIZE = 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CosineEmbeddingLoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class NDI_dataset(Dataset):\n",
    "    def __init__(self, positive_ratio=0.5, times=10):\n",
    "        original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "        target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "        self.origins, self.targets, self.label = [], [], []\n",
    "        for original_image in original_images:\n",
    "            self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "            self.targets.append(torchvision.io.read_image(str(Path.joinpath(Path(TARGET_IMAGE), original_image.name.split('_')[0] + '.jpg'))))\n",
    "            self.label.append(torch.tensor(1))\n",
    "        for _ in range(times):\n",
    "            for original_image in original_images:\n",
    "                self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "                self.targets.append(torchvision.io.read_image(str(np.random.choice(target_images))))\n",
    "                self.label.append(torch.tensor(-1))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.origins[idx], self.targets[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_iter = DataLoader(NDI_dataset(POSITIVE_RATIO), BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(512, 256)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,136\n",
      "       BatchNorm2d-2         [-1, 64, 100, 100]             128\n",
      "              ReLU-3         [-1, 64, 100, 100]               0\n",
      "         MaxPool2d-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 50, 50]             128\n",
      "              ReLU-7           [-1, 64, 50, 50]               0\n",
      "            Conv2d-8           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 50, 50]             128\n",
      "             ReLU-10           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-11           [-1, 64, 50, 50]               0\n",
      "           Conv2d-12           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 50, 50]             128\n",
      "             ReLU-14           [-1, 64, 50, 50]               0\n",
      "           Conv2d-15           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 50, 50]             128\n",
      "             ReLU-17           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-18           [-1, 64, 50, 50]               0\n",
      "           Conv2d-19          [-1, 128, 25, 25]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 25, 25]             256\n",
      "             ReLU-21          [-1, 128, 25, 25]               0\n",
      "           Conv2d-22          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 25, 25]             256\n",
      "           Conv2d-24          [-1, 128, 25, 25]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 25, 25]             256\n",
      "             ReLU-26          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-27          [-1, 128, 25, 25]               0\n",
      "           Conv2d-28          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 25, 25]             256\n",
      "             ReLU-30          [-1, 128, 25, 25]               0\n",
      "           Conv2d-31          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 25, 25]             256\n",
      "             ReLU-33          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-34          [-1, 128, 25, 25]               0\n",
      "           Conv2d-35          [-1, 256, 13, 13]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 13, 13]             512\n",
      "             ReLU-37          [-1, 256, 13, 13]               0\n",
      "           Conv2d-38          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 13, 13]             512\n",
      "           Conv2d-40          [-1, 256, 13, 13]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 13, 13]             512\n",
      "             ReLU-42          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-43          [-1, 256, 13, 13]               0\n",
      "           Conv2d-44          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 13, 13]             512\n",
      "             ReLU-46          [-1, 256, 13, 13]               0\n",
      "           Conv2d-47          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 13, 13]             512\n",
      "             ReLU-49          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-50          [-1, 256, 13, 13]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "================================================================\n",
      "Total params: 11,301,568\n",
      "Trainable params: 11,301,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 51.07\n",
      "Params size (MB): 43.11\n",
      "Estimated Total Size (MB): 94.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import torchsummary\n",
    "\n",
    "torchsummary.summary(model, input_size=(1, 200, 200), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Ave. Loss: 0.5940\n",
      "Epoch: 2, Ave. Loss: 0.5952\n",
      "Epoch: 3, Ave. Loss: 0.5944\n",
      "Epoch: 4, Ave. Loss: 0.5929\n",
      "Epoch: 5, Ave. Loss: 0.5938\n",
      "Epoch: 6, Ave. Loss: 0.5953\n",
      "Epoch: 7, Ave. Loss: 0.5931\n",
      "Epoch: 8, Ave. Loss: 0.5945\n",
      "Epoch: 9, Ave. Loss: 0.5908\n",
      "Epoch: 10, Ave. Loss: 0.5949\n",
      "Epoch: 11, Ave. Loss: 0.5910\n",
      "Epoch: 12, Ave. Loss: 0.5936\n",
      "Epoch: 13, Ave. Loss: 0.5947\n",
      "Epoch: 14, Ave. Loss: 0.5938\n",
      "Epoch: 15, Ave. Loss: 0.5946\n",
      "Epoch: 16, Ave. Loss: 0.5942\n",
      "Epoch: 17, Ave. Loss: 0.5944\n",
      "Epoch: 18, Ave. Loss: 0.5940\n",
      "Epoch: 19, Ave. Loss: 0.5937\n",
      "Epoch: 20, Ave. Loss: 0.5939\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "lr = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "loss = nn.CosineEmbeddingLoss(margin=0.3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "train_iter = DataLoader(NDI_dataset(POSITIVE_RATIO), BATCH_SIZE, shuffle=True)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for origin, target, label in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        origin, target = origin.float(), target.float()\n",
    "        origin, target, label = origin.to(device), target.to(device), label.to(device)\n",
    "        origin_feature = model(origin)\n",
    "        target_feature = model(target)\n",
    "        l = loss(origin_feature, target_feature, label)\n",
    "        l.backward()\n",
    "        total_loss += l\n",
    "    print(f'Epoch: {epoch + 1}, Ave. Loss: {total_loss / len(train_iter):.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9949], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "model.to('cpu')\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "original_image_name = np.random.choice(original_images)\n",
    "original_image = torchvision.io.read_image(str(original_image_name)).unsqueeze_(0).float()\n",
    "target_image = torchvision.io.read_image(str(Path.joinpath(Path(TARGET_IMAGE), original_image_name.name.split('_')[0] + '.jpg'))).unsqueeze_(0).float()\n",
    "print(nn.CosineSimilarity()(model(original_image), model(target_image)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9946], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "original_image_name = np.random.choice(original_images)\n",
    "target_image_name = np.random.choice(target_images)\n",
    "original_image = torchvision.io.read_image(str(original_image_name)).unsqueeze_(0).float()\n",
    "target_image = torchvision.io.read_image(str(target_image_name)).unsqueeze_(0).float()\n",
    "print(nn.CosineSimilarity()(model(original_image), model(target_image)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7585])"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = 512\n",
    "a = torch.rand((1, dimensions))\n",
    "b = torch.rand((1, dimensions))\n",
    "nn.CosineSimilarity()(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}