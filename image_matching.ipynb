{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from torchsummary import torchsummary\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE = 'E:/dataSets/NDI_images/20220725/20220725/Observed_Crop_200x200pix'\n",
    "TARGET_IMAGE = 'E:/dataSets/NDI_images/20220725/20220725/Calculated_200x200/grayscale'\n",
    "POSITIVE_RATIO = 0.1\n",
    "BATCH_SIZE = 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ORIGINAL_IMAGE = '/import/mqhome/duanct/dataSets/NDI_images/20220725/20220725/Observed_Crop_200x200pix'\n",
    "TARGET_IMAGE = '/import/mqhome/duanct/dataSets/NDI_images/20220725/20220725/Calculated_200x200/grayscale'\n",
    "POSITIVE_RATIO = 0.1\n",
    "BATCH_SIZE = 8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CosineEmbeddingLoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class NDI_dataset(Dataset):\n",
    "    def __init__(self, positive_ratio=0.5, times=10):\n",
    "        original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "        target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "        self.origins, self.targets, self.label = [], [], []\n",
    "        for original_image in original_images:\n",
    "            self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "            self.targets.append(torchvision.io.read_image(str(Path.joinpath(Path(TARGET_IMAGE), original_image.name.split('_')[0] + '.jpg'))))\n",
    "            self.label.append(torch.tensor(1))\n",
    "        for _ in range(times):\n",
    "            for original_image in original_images:\n",
    "                self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "                self.targets.append(torchvision.io.read_image(str(np.random.choice(target_images))))\n",
    "                self.label.append(torch.tensor(-1))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.origins[idx], self.targets[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_iter = DataLoader(NDI_dataset(POSITIVE_RATIO), BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(512, 256)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,136\n",
      "       BatchNorm2d-2         [-1, 64, 100, 100]             128\n",
      "              ReLU-3         [-1, 64, 100, 100]               0\n",
      "         MaxPool2d-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 50, 50]             128\n",
      "              ReLU-7           [-1, 64, 50, 50]               0\n",
      "            Conv2d-8           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 50, 50]             128\n",
      "             ReLU-10           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-11           [-1, 64, 50, 50]               0\n",
      "           Conv2d-12           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 50, 50]             128\n",
      "             ReLU-14           [-1, 64, 50, 50]               0\n",
      "           Conv2d-15           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 50, 50]             128\n",
      "             ReLU-17           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-18           [-1, 64, 50, 50]               0\n",
      "           Conv2d-19          [-1, 128, 25, 25]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 25, 25]             256\n",
      "             ReLU-21          [-1, 128, 25, 25]               0\n",
      "           Conv2d-22          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 25, 25]             256\n",
      "           Conv2d-24          [-1, 128, 25, 25]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 25, 25]             256\n",
      "             ReLU-26          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-27          [-1, 128, 25, 25]               0\n",
      "           Conv2d-28          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 25, 25]             256\n",
      "             ReLU-30          [-1, 128, 25, 25]               0\n",
      "           Conv2d-31          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 25, 25]             256\n",
      "             ReLU-33          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-34          [-1, 128, 25, 25]               0\n",
      "           Conv2d-35          [-1, 256, 13, 13]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 13, 13]             512\n",
      "             ReLU-37          [-1, 256, 13, 13]               0\n",
      "           Conv2d-38          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 13, 13]             512\n",
      "           Conv2d-40          [-1, 256, 13, 13]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 13, 13]             512\n",
      "             ReLU-42          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-43          [-1, 256, 13, 13]               0\n",
      "           Conv2d-44          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 13, 13]             512\n",
      "             ReLU-46          [-1, 256, 13, 13]               0\n",
      "           Conv2d-47          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 13, 13]             512\n",
      "             ReLU-49          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-50          [-1, 256, 13, 13]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "================================================================\n",
      "Total params: 11,301,568\n",
      "Trainable params: 11,301,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 51.07\n",
      "Params size (MB): 43.11\n",
      "Estimated Total Size (MB): 94.34\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=(1, 200, 200), device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Ave. Loss: 0.5940\n",
      "Epoch: 2, Ave. Loss: 0.5952\n",
      "Epoch: 3, Ave. Loss: 0.5944\n",
      "Epoch: 4, Ave. Loss: 0.5929\n",
      "Epoch: 5, Ave. Loss: 0.5938\n",
      "Epoch: 6, Ave. Loss: 0.5953\n",
      "Epoch: 7, Ave. Loss: 0.5931\n",
      "Epoch: 8, Ave. Loss: 0.5945\n",
      "Epoch: 9, Ave. Loss: 0.5908\n",
      "Epoch: 10, Ave. Loss: 0.5949\n",
      "Epoch: 11, Ave. Loss: 0.5910\n",
      "Epoch: 12, Ave. Loss: 0.5936\n",
      "Epoch: 13, Ave. Loss: 0.5947\n",
      "Epoch: 14, Ave. Loss: 0.5938\n",
      "Epoch: 15, Ave. Loss: 0.5946\n",
      "Epoch: 16, Ave. Loss: 0.5942\n",
      "Epoch: 17, Ave. Loss: 0.5944\n",
      "Epoch: 18, Ave. Loss: 0.5940\n",
      "Epoch: 19, Ave. Loss: 0.5937\n",
      "Epoch: 20, Ave. Loss: 0.5939\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "lr = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "loss = nn.CosineEmbeddingLoss(margin=0.3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "train_iter = DataLoader(NDI_dataset(POSITIVE_RATIO), BATCH_SIZE, shuffle=True)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for origin, target, label in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        origin, target = origin.float(), target.float()\n",
    "        origin, target, label = origin.to(device), target.to(device), label.to(device)\n",
    "        origin_feature = model(origin)\n",
    "        target_feature = model(target)\n",
    "        l = loss(origin_feature, target_feature, label)\n",
    "        l.backward()\n",
    "        total_loss += l\n",
    "    print(f'Epoch: {epoch + 1}, Ave. Loss: {total_loss / len(train_iter):.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9949], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "model.to('cpu')\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "original_image_name = np.random.choice(original_images)\n",
    "original_image = torchvision.io.read_image(str(original_image_name)).unsqueeze_(0).float()\n",
    "target_image = torchvision.io.read_image(str(Path.joinpath(Path(TARGET_IMAGE), original_image_name.name.split('_')[0] + '.jpg'))).unsqueeze_(0).float()\n",
    "print(nn.CosineSimilarity()(model(original_image), model(target_image)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9946], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "original_image_name = np.random.choice(original_images)\n",
    "target_image_name = np.random.choice(target_images)\n",
    "original_image = torchvision.io.read_image(str(original_image_name)).unsqueeze_(0).float()\n",
    "target_image = torchvision.io.read_image(str(target_image_name)).unsqueeze_(0).float()\n",
    "print(nn.CosineSimilarity()(model(original_image), model(target_image)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7585])"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = 512\n",
    "a = torch.rand((1, dimensions))\n",
    "b = torch.rand((1, dimensions))\n",
    "nn.CosineSimilarity()(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Binary Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 512])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((8, 512))\n",
    "b = torch.rand((8, 512))\n",
    "torch.cat([a, b], dim=).size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.backbone = torchvision.models.resnet18(pretrained=False)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone.fc = nn.Linear(512, 256)\n",
    "        self.classifier = nn.Linear(512, 2)\n",
    "    def forward(self, origin, target):\n",
    "        origin_feature = f.relu(self.backbone(origin))\n",
    "        target_feature = f.relu(self.backbone(target))\n",
    "        return self.classifier(torch.cat([origin_feature, target_feature], dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class NDI_dataset_classifier(Dataset):\n",
    "    def __init__(self, positive_ratio=0.5, times=10):\n",
    "        original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "        target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "        self.origins, self.targets, self.label = [], [], []\n",
    "        for original_image in original_images:\n",
    "            self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "            self.targets.append(torchvision.io.read_image(str(Path.joinpath(Path(TARGET_IMAGE), original_image.name.split('_')[0] + '.jpg'))))\n",
    "            self.label.append(torch.tensor(1, dtype=torch.long))\n",
    "        for _ in range(times):\n",
    "            for original_image in original_images:\n",
    "                self.origins.append(torchvision.io.read_image(str(original_image)))\n",
    "                self.targets.append(torchvision.io.read_image(str(np.random.choice(target_images))))\n",
    "                self.label.append(torch.tensor(0, dtype=torch.long))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.origins[idx], self.targets[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,136\n",
      "       BatchNorm2d-2         [-1, 64, 100, 100]             128\n",
      "              ReLU-3         [-1, 64, 100, 100]               0\n",
      "         MaxPool2d-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 50, 50]             128\n",
      "              ReLU-7           [-1, 64, 50, 50]               0\n",
      "            Conv2d-8           [-1, 64, 50, 50]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 50, 50]             128\n",
      "             ReLU-10           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-11           [-1, 64, 50, 50]               0\n",
      "           Conv2d-12           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 50, 50]             128\n",
      "             ReLU-14           [-1, 64, 50, 50]               0\n",
      "           Conv2d-15           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 50, 50]             128\n",
      "             ReLU-17           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-18           [-1, 64, 50, 50]               0\n",
      "           Conv2d-19          [-1, 128, 25, 25]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 25, 25]             256\n",
      "             ReLU-21          [-1, 128, 25, 25]               0\n",
      "           Conv2d-22          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 25, 25]             256\n",
      "           Conv2d-24          [-1, 128, 25, 25]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 25, 25]             256\n",
      "             ReLU-26          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-27          [-1, 128, 25, 25]               0\n",
      "           Conv2d-28          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 25, 25]             256\n",
      "             ReLU-30          [-1, 128, 25, 25]               0\n",
      "           Conv2d-31          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 25, 25]             256\n",
      "             ReLU-33          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-34          [-1, 128, 25, 25]               0\n",
      "           Conv2d-35          [-1, 256, 13, 13]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 13, 13]             512\n",
      "             ReLU-37          [-1, 256, 13, 13]               0\n",
      "           Conv2d-38          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 13, 13]             512\n",
      "           Conv2d-40          [-1, 256, 13, 13]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 13, 13]             512\n",
      "             ReLU-42          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-43          [-1, 256, 13, 13]               0\n",
      "           Conv2d-44          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 13, 13]             512\n",
      "             ReLU-46          [-1, 256, 13, 13]               0\n",
      "           Conv2d-47          [-1, 256, 13, 13]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 13, 13]             512\n",
      "             ReLU-49          [-1, 256, 13, 13]               0\n",
      "       BasicBlock-50          [-1, 256, 13, 13]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "           ResNet-69                  [-1, 256]               0\n",
      "           Conv2d-70         [-1, 64, 100, 100]           3,136\n",
      "      BatchNorm2d-71         [-1, 64, 100, 100]             128\n",
      "             ReLU-72         [-1, 64, 100, 100]               0\n",
      "        MaxPool2d-73           [-1, 64, 50, 50]               0\n",
      "           Conv2d-74           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-75           [-1, 64, 50, 50]             128\n",
      "             ReLU-76           [-1, 64, 50, 50]               0\n",
      "           Conv2d-77           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-78           [-1, 64, 50, 50]             128\n",
      "             ReLU-79           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-80           [-1, 64, 50, 50]               0\n",
      "           Conv2d-81           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-82           [-1, 64, 50, 50]             128\n",
      "             ReLU-83           [-1, 64, 50, 50]               0\n",
      "           Conv2d-84           [-1, 64, 50, 50]          36,864\n",
      "      BatchNorm2d-85           [-1, 64, 50, 50]             128\n",
      "             ReLU-86           [-1, 64, 50, 50]               0\n",
      "       BasicBlock-87           [-1, 64, 50, 50]               0\n",
      "           Conv2d-88          [-1, 128, 25, 25]          73,728\n",
      "      BatchNorm2d-89          [-1, 128, 25, 25]             256\n",
      "             ReLU-90          [-1, 128, 25, 25]               0\n",
      "           Conv2d-91          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-92          [-1, 128, 25, 25]             256\n",
      "           Conv2d-93          [-1, 128, 25, 25]           8,192\n",
      "      BatchNorm2d-94          [-1, 128, 25, 25]             256\n",
      "             ReLU-95          [-1, 128, 25, 25]               0\n",
      "       BasicBlock-96          [-1, 128, 25, 25]               0\n",
      "           Conv2d-97          [-1, 128, 25, 25]         147,456\n",
      "      BatchNorm2d-98          [-1, 128, 25, 25]             256\n",
      "             ReLU-99          [-1, 128, 25, 25]               0\n",
      "          Conv2d-100          [-1, 128, 25, 25]         147,456\n",
      "     BatchNorm2d-101          [-1, 128, 25, 25]             256\n",
      "            ReLU-102          [-1, 128, 25, 25]               0\n",
      "      BasicBlock-103          [-1, 128, 25, 25]               0\n",
      "          Conv2d-104          [-1, 256, 13, 13]         294,912\n",
      "     BatchNorm2d-105          [-1, 256, 13, 13]             512\n",
      "            ReLU-106          [-1, 256, 13, 13]               0\n",
      "          Conv2d-107          [-1, 256, 13, 13]         589,824\n",
      "     BatchNorm2d-108          [-1, 256, 13, 13]             512\n",
      "          Conv2d-109          [-1, 256, 13, 13]          32,768\n",
      "     BatchNorm2d-110          [-1, 256, 13, 13]             512\n",
      "            ReLU-111          [-1, 256, 13, 13]               0\n",
      "      BasicBlock-112          [-1, 256, 13, 13]               0\n",
      "          Conv2d-113          [-1, 256, 13, 13]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 13, 13]             512\n",
      "            ReLU-115          [-1, 256, 13, 13]               0\n",
      "          Conv2d-116          [-1, 256, 13, 13]         589,824\n",
      "     BatchNorm2d-117          [-1, 256, 13, 13]             512\n",
      "            ReLU-118          [-1, 256, 13, 13]               0\n",
      "      BasicBlock-119          [-1, 256, 13, 13]               0\n",
      "          Conv2d-120            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-121            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-122            [-1, 512, 7, 7]               0\n",
      "          Conv2d-123            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-124            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-125            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-126            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-127            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-128            [-1, 512, 7, 7]               0\n",
      "          Conv2d-129            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-130            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-131            [-1, 512, 7, 7]               0\n",
      "          Conv2d-132            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-133            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-134            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-135            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-136            [-1, 512, 1, 1]               0\n",
      "          Linear-137                  [-1, 256]         131,328\n",
      "          ResNet-138                  [-1, 256]               0\n",
      "          Linear-139                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 22,604,162\n",
      "Trainable params: 22,604,162\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6103.52\n",
      "Forward/backward pass size (MB): 102.15\n",
      "Params size (MB): 86.23\n",
      "Estimated Total Size (MB): 6291.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel()\n",
    "torchsummary.summary(model, input_size=[(1, 200, 200), (1, 200, 200)], device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "lr = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "train_iter = DataLoader(NDI_dataset(POSITIVE_RATIO), BATCH_SIZE, shuffle=True)\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for origin, target, label in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        origin, target = origin.float(), target.float()\n",
    "        origin, target, label = origin.to(device), target.to(device), label.to(device)\n",
    "        origin_feature = model(origin)\n",
    "        target_feature = model(target)\n",
    "        l = loss(origin_feature, target_feature, label)\n",
    "        l.backward()\n",
    "        total_loss += l\n",
    "    print(f'Epoch: {epoch + 1}, Ave. Loss: {total_loss / len(train_iter):.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "x = torch.rand((1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x).type(x.dtype).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.6341])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset = torchvision.datasets.FashionMNIST(root='../data', train=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()]), download=True)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=32, shuffle=True)\n",
    "for x, y in mnist_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([[0.7490, 0.9333, 0.8863, 0.8824, 0.8784, 0.8196, 0.8078, 0.8510, 0.8941,\n         0.9647, 0.9176, 1.0000, 0.8588, 0.9216, 0.9294, 0.9882, 0.9882, 0.9882,\n         0.9843, 0.9765, 0.9451, 0.9843, 0.9843, 0.9412, 0.8627, 0.9020, 0.8431,\n         0.6902]]),\nindices=tensor([[13, 15, 10, 16,  6, 18, 18,  7,  7, 19, 19, 19, 20,  9,  9,  6, 18, 18,\n         18, 18, 18, 21, 21,  8, 21, 19, 19, 22]]))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x[0], dim=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class NDIDatasetContrastiveLearning(Dataset):\n",
    "    def __init__(self):\n",
    "        super(NDIDatasetContrastiveLearning, self).__init__()\n",
    "        original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "        origins, targets = [], []\n",
    "        to_tensor_func = torchvision.transforms.ToTensor()\n",
    "        for original_image in original_images:\n",
    "            origins.append(to_tensor_func(Image.open(str(original_image))))\n",
    "            targets.append(to_tensor_func(Image.open(str(Path.joinpath(Path(TARGET_IMAGE), original_image.name.split('_')[0] + '.jpg')))))\n",
    "        random_index = np.random.permutation(len(origins))\n",
    "        self.origins, self.targets = [], []\n",
    "        for index in random_index:\n",
    "            self.origins.append(origins[index])\n",
    "            self.targets.append(targets[index])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.origins[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "from moco_model import MoCo\n",
    "\n",
    "\n",
    "model = MoCo(torchvision.models.resnet18, dim=128, K=48)\n",
    "device = torch.device('cuda:0')\n",
    "criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def train_moco(net, criterion, optimizer, epochs, device):\n",
    "    train_iter = DataLoader(NDIDatasetContrastiveLearning(), batch_size=8, shuffle=True, drop_last=True)\n",
    "    model.cuda(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for origin, target in train_iter:\n",
    "            origin, target = origin.cuda(device), target.cuda(device)\n",
    "            output, labels = net(origin, target)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss {total_loss / len(train_iter)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 2.5478965307144485\n",
      "Epoch 2, Loss 3.8372589349746704\n",
      "Epoch 3, Loss 3.6488163073857627\n",
      "Epoch 4, Loss 3.4865161577860513\n",
      "Epoch 5, Loss 3.177033305168152\n",
      "Epoch 6, Loss 3.2050740321477256\n",
      "Epoch 7, Loss 3.020328919092814\n",
      "Epoch 8, Loss 3.082185745239258\n",
      "Epoch 9, Loss 2.824070692062378\n",
      "Epoch 10, Loss 2.7290110190709433\n",
      "Epoch 11, Loss 2.962373971939087\n",
      "Epoch 12, Loss 2.529419183731079\n",
      "Epoch 13, Loss 2.5628720919291177\n",
      "Epoch 14, Loss 2.4155572255452475\n",
      "Epoch 15, Loss 2.3799455563227334\n",
      "Epoch 16, Loss 2.3157723347345986\n",
      "Epoch 17, Loss 2.179949184258779\n",
      "Epoch 18, Loss 2.2039785782496133\n",
      "Epoch 19, Loss 2.0526958306630454\n",
      "Epoch 20, Loss 2.06346728404363\n",
      "Epoch 21, Loss 2.0119340817133584\n",
      "Epoch 22, Loss 1.9778805375099182\n",
      "Epoch 23, Loss 1.8880394498507183\n",
      "Epoch 24, Loss 1.9622933467229207\n",
      "Epoch 25, Loss 1.756432831287384\n",
      "Epoch 26, Loss 1.8690356214841206\n",
      "Epoch 27, Loss 1.8484575748443604\n",
      "Epoch 28, Loss 1.7700023452440898\n",
      "Epoch 29, Loss 1.6966349085172017\n",
      "Epoch 30, Loss 1.7569868365923564\n",
      "Epoch 31, Loss 1.7595654527346294\n",
      "Epoch 32, Loss 1.631648321946462\n",
      "Epoch 33, Loss 1.545429766178131\n",
      "Epoch 34, Loss 1.5481981039047241\n",
      "Epoch 35, Loss 1.5899022817611694\n",
      "Epoch 36, Loss 1.5056854685147603\n",
      "Epoch 37, Loss 1.441978434721629\n",
      "Epoch 38, Loss 1.4727519154548645\n",
      "Epoch 39, Loss 1.4838272134462993\n",
      "Epoch 40, Loss 1.3781432509422302\n",
      "Epoch 41, Loss 1.4654327034950256\n",
      "Epoch 42, Loss 1.3087953726450603\n",
      "Epoch 43, Loss 1.362623115380605\n",
      "Epoch 44, Loss 1.4573571880658467\n",
      "Epoch 45, Loss 1.3201951185862224\n",
      "Epoch 46, Loss 1.329410970211029\n",
      "Epoch 47, Loss 1.2494672338167827\n",
      "Epoch 48, Loss 1.2362672090530396\n",
      "Epoch 49, Loss 1.2126329739888508\n",
      "Epoch 50, Loss 1.2450488209724426\n"
     ]
    }
   ],
   "source": [
    "# 把K设置成48还算成功，在queue不大的情况下\n",
    "\n",
    "train_moco(model, criterion, optimizer, 50, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 2.673976675757634\n",
      "Epoch 2, Loss 3.931485931078593\n",
      "Epoch 3, Loss 3.8541926542917886\n",
      "Epoch 4, Loss 3.6459306478500366\n",
      "Epoch 5, Loss 3.407223383585612\n",
      "Epoch 6, Loss 3.105238596598307\n",
      "Epoch 7, Loss 3.1296446720759072\n",
      "Epoch 8, Loss 3.1514963706334433\n",
      "Epoch 9, Loss 3.053861141204834\n",
      "Epoch 10, Loss 2.6810205380121865\n",
      "Epoch 11, Loss 2.705527981122335\n",
      "Epoch 12, Loss 2.632307688395182\n",
      "Epoch 13, Loss 2.4753270546595254\n",
      "Epoch 14, Loss 2.3976933558781943\n",
      "Epoch 15, Loss 2.333985129992167\n",
      "Epoch 16, Loss 2.2366109689076743\n",
      "Epoch 17, Loss 2.1844319701194763\n",
      "Epoch 18, Loss 2.2525221506754556\n",
      "Epoch 19, Loss 2.1583401759465537\n",
      "Epoch 20, Loss 2.0467366774876914\n",
      "Epoch 21, Loss 2.0968031088511148\n",
      "Epoch 22, Loss 2.081486225128174\n",
      "Epoch 23, Loss 2.047618548075358\n",
      "Epoch 24, Loss 1.9676475127538045\n",
      "Epoch 25, Loss 1.9295819004376729\n",
      "Epoch 26, Loss 1.8663320342699687\n",
      "Epoch 27, Loss 1.8291430870691936\n",
      "Epoch 28, Loss 1.789828399817149\n",
      "Epoch 29, Loss 1.7487680315971375\n",
      "Epoch 30, Loss 1.7118704319000244\n",
      "Epoch 31, Loss 1.761828859647115\n",
      "Epoch 32, Loss 1.7304572860399883\n",
      "Epoch 33, Loss 1.703533907731374\n",
      "Epoch 34, Loss 1.552752415339152\n",
      "Epoch 35, Loss 1.698424796263377\n",
      "Epoch 36, Loss 1.6368554035822551\n",
      "Epoch 37, Loss 1.6863943934440613\n",
      "Epoch 38, Loss 1.5227134029070537\n",
      "Epoch 39, Loss 1.5379104018211365\n",
      "Epoch 40, Loss 1.5471089084943135\n",
      "Epoch 41, Loss 1.547522524992625\n",
      "Epoch 42, Loss 1.439075231552124\n",
      "Epoch 43, Loss 1.495581865310669\n",
      "Epoch 44, Loss 1.424798885981242\n",
      "Epoch 45, Loss 1.386127809683482\n",
      "Epoch 46, Loss 1.3655091325441997\n",
      "Epoch 47, Loss 1.366443653901418\n",
      "Epoch 48, Loss 1.3557376265525818\n",
      "Epoch 49, Loss 1.3533420364061992\n",
      "Epoch 50, Loss 1.2456497550010681\n"
     ]
    }
   ],
   "source": [
    "# 尝试把K设置成56\n",
    "\n",
    "model = MoCo(torchvision.models.resnet18, dim=128, K=56)\n",
    "device = torch.device('cuda:0')\n",
    "criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=1e-4)\n",
    "train_moco(model, criterion, optimizer, 50, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def image_pair_matching(net, original_image, matching_image):\n",
    "    net.cpu()\n",
    "    net.eval()\n",
    "    q = net.encoder_q(original_image)\n",
    "    q = f.normalize(q, dim=1)\n",
    "    k = net.encoder_k(matching_image)\n",
    "    k = f.normalize(k, dim=1)\n",
    "    logits = torch.mm(q, k.T)\n",
    "    return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# 取总共大小小于K的queue来试，成功\n",
    "\n",
    "model.cpu()\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "to_tensor_func = torchvision.transforms.ToTensor()\n",
    "original_image = np.random.choice(original_images)\n",
    "original_tensor = to_tensor_func(Image.open(str(original_image))).unsqueeze(0)\n",
    "target_images_candidates = np.random.choice(target_images, 40)\n",
    "target_tensor = []\n",
    "for i in range(20):\n",
    "    target_tensor.append(to_tensor_func(Image.open(str(target_images_candidates[i]))).unsqueeze(0))\n",
    "target_tensor.append(to_tensor_func(Image.open(str(Path.joinpath(Path(TARGET_IMAGE), original_image.name.split('_')[0] + '.jpg')))).unsqueeze(0))\n",
    "for i in range(20, 40):\n",
    "    target_tensor.append(to_tensor_func(Image.open(str(target_images_candidates[i]))).unsqueeze(0))\n",
    "target_tensor = torch.cat(target_tensor, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.2281,  0.1505,  0.0759,  0.3091,  0.0944,  0.3091, -0.0131,  0.1535,\n          0.0576,  0.1025,  0.0797,  0.1233,  0.1377,  0.0640,  0.1535,  0.0891,\n         -0.0098,  0.0383,  0.2141, -0.0383,  0.3091,  0.0969,  0.0739,  0.0576,\n          0.1209,  0.1377,  0.0891,  0.1424,  0.0175,  0.1025,  0.1732,  0.0883,\n          0.0811,  0.0613,  0.1233, -0.0235,  0.1025,  0.0883,  0.0738,  0.2119,\n          0.0383]], grad_fn=<MmBackward>)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_pair_matching(model, original_tensor, target_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# 取所有比对图片\n",
    "\n",
    "model.cpu()\n",
    "original_images = list(Path(ORIGINAL_IMAGE).glob('*.jpg'))\n",
    "target_images = list(Path(TARGET_IMAGE).glob('*.jpg'))\n",
    "to_tensor_func = torchvision.transforms.ToTensor()\n",
    "original_image = np.random.choice(original_images)\n",
    "original_tensor = to_tensor_func(Image.open(str(original_image))).unsqueeze(0)\n",
    "target_tensor = []\n",
    "for i in range(1, 55):\n",
    "    target_tensor.append(to_tensor_func(Image.open(str(Path.joinpath(Path(TARGET_IMAGE), f'{i}.jpg')))).unsqueeze(0))\n",
    "target_tensor = torch.cat(target_tensor, dim=0)\n",
    "print(str(original_image.name).split('_')[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4565e-01,  1.1097e-01,  3.9617e-02,  1.2304e-01,  1.0800e-01,\n",
      "          1.1116e-01,  1.9075e-01,  1.6977e-01,  7.8928e-02,  2.5626e-01,\n",
      "          9.6446e-02,  1.6837e-01,  8.6016e-02,  1.0304e-01,  9.4899e-02,\n",
      "          3.0067e-02,  8.0622e-02,  1.3401e-01,  8.8296e-02, -1.2011e-03,\n",
      "          4.0938e-01,  5.5814e-02,  1.7832e-01,  6.8754e-02,  3.9356e-01,\n",
      "          3.9356e-01,  2.4748e-01, -9.8140e-02, -9.8763e-02,  1.2288e-01,\n",
      "          1.8330e-01,  1.7046e-01,  7.5117e-02,  1.4688e-01,  1.3979e-01,\n",
      "          1.2716e-04,  1.2593e-01,  7.9922e-02,  3.0441e-01,  3.9980e-02,\n",
      "          2.0772e-02,  1.7252e-01,  1.3889e-01,  3.5146e-03,  3.6427e-02,\n",
      "          1.8339e-01,  8.3577e-02,  5.3283e-02,  1.7072e-01,  1.6657e-01,\n",
      "          1.9643e-01,  5.9414e-02,  5.9414e-02,  1.3753e-01]],\n",
      "       grad_fn=<MmBackward>)\n",
      "tensor(20)\n"
     ]
    }
   ],
   "source": [
    "logits = image_pair_matching(model, original_tensor, target_tensor)\n",
    "print(logits)\n",
    "print(torch.argmax(logits))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}