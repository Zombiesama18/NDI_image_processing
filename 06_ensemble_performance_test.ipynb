{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from train import *\n",
    "from utils import torch_fix_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_fix_seed(19981303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_candidates = (20, 30, 40)\n",
    "k = 7\n",
    "temps = 0.7\n",
    "momentums = 0.99\n",
    "k_value = 64\n",
    "\n",
    "def get_self_pretrain_model(index=1000):\n",
    "    base_encoder = torchvision.models.resnet50(weights=None)\n",
    "    base_encoder.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    origin_dim_mlp = base_encoder.fc.in_features\n",
    "    base_encoder.fc = None\n",
    "    temp = torch.load(f'./checkpoints/CEM_ALL_CHECK_{index}_Epoch.pth')['state_dict']\n",
    "    state_dict = {}\n",
    "    for k, v in temp.items():\n",
    "        if 'encoder_q' in k:\n",
    "            if 'fc' not in k:\n",
    "                state_dict['.'.join(k.split('.')[1:])] = v\n",
    "    base_encoder.load_state_dict(state_dict)\n",
    "    base_encoder.fc = torch.nn.Linear(origin_dim_mlp, 512)\n",
    "    return base_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'pretrain_model': ['self_pretrained']}\n",
    "train_metrics = HistoryRecorder(['Train Loss', 'Train Acc', 'Val Loss', 'Val Acc'], list(parameters.keys()))\n",
    "\n",
    "parameters = list(itertools.product(*parameters.values()))\n",
    "\n",
    "for parameter in parameters:\n",
    "\n",
    "    ### custom part to get parameters\n",
    "    pretrain_model = parameter[0]\n",
    "    ### END\n",
    "    \n",
    "    for images in k_fold_train_validation_split(ORIGINAL_IMAGE, TARGET_IMAGE, k):\n",
    "        train_dataset = SingleChannelNDIDatasetContrastiveLearningWithAug(images, False)\n",
    "        val_dataset = SingleChannelNDIDatasetContrastiveLearningWithAug(images, True)\n",
    "        train_iter = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "        val_iter = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "\n",
    "        model = get_model(pretrain_model)\n",
    "        if pretrain_model in ['self_pretrained', 'CEM']:\n",
    "            base_params = list(filter(lambda kv: 'fc' not in kv[0], model.encoder_q.named_parameters()))\n",
    "            base_params = [v for k, v in base_params]\n",
    "            fc_params = list(filter(lambda kv: 'fc' in kv[0], model.encoder_q.named_parameters()))\n",
    "            fc_params = [v for k, v in fc_params]\n",
    "            params = [{'params': base_params, 'lr': 0.02 * 0.5}, {'params': fc_params, 'lr': 0.02}]\n",
    "        else:\n",
    "            params = [{'params': model.parameters(), 'lr': 0.02}]\n",
    "            \n",
    "        device = torch.device('cuda:0')\n",
    "        criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "        optimizer = torch.optim.SGD(params=params, momentum=0.9, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "        start_time = time.time()\n",
    "        metrics = train_moco_return_metrics_top_k(model, train_iter, val_iter, criterion, optimizer, 20, device,\n",
    "                                                    tested_parameter=parameter, k_candidates=top_k_candidates, scheduler=scheduler)\n",
    "        end_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4e980a27e930b9ff5731385d4bd44946951fe20aeacecd4aa5a8f48401c490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
