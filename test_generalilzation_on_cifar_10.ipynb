{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import collections\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from moco_model import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_DIR = 'E:/Mine/亲手/Python/Pytorch/动手学深度学习v2/data/cifar-10-batches-py/train'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def image_pair_matching(net, original_image, matching_image, mode='training'):\n",
    "    if mode == 'training':\n",
    "        q = net.encoder_q(original_image)\n",
    "        q = f.normalize(q, dim=1)\n",
    "        k = net.encoder_k(matching_image)\n",
    "        k = f.normalize(k, dim=1)\n",
    "        logits = torch.einsum('nc,ck->nk', [q, k.T])\n",
    "        return logits\n",
    "\n",
    "def cal_accuracy(preds, label):\n",
    "    return float(torch.sum(torch.argmax(preds, dim=1).type_as(label) == label))\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class HistoryRecorder:\n",
    "    def __init__(self, names):\n",
    "        self.data = {name: [] for name in names}\n",
    "        self.names = names\n",
    "\n",
    "    def add(self, *args):\n",
    "        for name, value in zip(self.names, args):\n",
    "            self.data[name].append(value)\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = {name: [] for name in self.names}\n",
    "\n",
    "    def __getitem__(self, name):\n",
    "        return self.data[name]\n",
    "\n",
    "def train_moco_return_metrics(net, criterion, optimizer, epochs, device):\n",
    "    train_metrics = HistoryRecorder(['Train Loss', 'Train Acc', 'Val Loss', 'Val Acc'])\n",
    "    idx_to_label_queue = torch.ones((1, net.K), device=device) * -1\n",
    "    queue_pointer = torch.ones(1, dtype=torch.long)\n",
    "    for epoch in range(epochs):\n",
    "        net.cuda(device)\n",
    "        total_loss = 0\n",
    "        training_correct = 0\n",
    "        training_size = 0\n",
    "        for origin, target, label in train_iter:\n",
    "            net.train()\n",
    "            origin, target, label = origin.cuda(device), target.cuda(device), label.cuda(device)\n",
    "            pointer = int(queue_pointer)\n",
    "            idx_to_label_queue[pointer: pointer + origin[0].shape[0]] = label\n",
    "            queue_pointer[0] = (pointer + origin[0].shape[0]) % net.K\n",
    "            output, labels = net(origin, target)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                training_correct += cal_accuracy(image_pair_matching(net, origin, idx_to_label_queue), label)\n",
    "                training_size += origin.shape[0]\n",
    "        net.eval()\n",
    "        val_loss = 0\n",
    "        for origin, target, label in val_iter:\n",
    "            origin, target, label = origin.cuda(device), target.cuda(device), label.cuda(device)\n",
    "            output, labels = net(origin, target, evaluate=True)\n",
    "            val_loss += f.cross_entropy(output, labels).item()\n",
    "            val_correct = cal_accuracy(image_pair_matching(net, origin, target_tensor), label)\n",
    "        val_acc = val_correct / origin.shape[0]\n",
    "        train_metrics.add(total_loss / len(train_iter), training_correct / training_size, val_loss / len(val_iter), val_acc)\n",
    "        print(f'Epoch {epoch + 1}, Loss {total_loss / len(train_iter)}, Train_acc {training_correct / training_size}, Val_loss {val_loss / len(val_iter)}, Val_acc {val_acc}')\n",
    "    return train_metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'airplane_10029'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_images = list(Path(DATA_DIR).rglob('*.jpg'))\n",
    "len(original_images)\n",
    "original_images[0].name.split('.')[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class CIFAR10ContrastiveLearning(Dataset):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10ContrastiveLearning, self).__init__()\n",
    "        original_images = list(Path(DATA_DIR).rglob('*.jpg'))\n",
    "        self.origins = []\n",
    "        normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        augmentation = [torchvision.transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "                        torchvision.transforms.RandomApply([torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "                        torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                        torchvision.transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "                        torchvision.transforms.RandomHorizontalFlip(),\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        normalize\n",
    "        ]\n",
    "        compose = torchvision.transforms.Compose(augmentation)\n",
    "        self.transform = TwoCropsTransform(compose)\n",
    "        label_counter = 0\n",
    "        for original_image in original_images:\n",
    "            self.origins.append((str(original_image), label_counter))\n",
    "            label_counter += 1\n",
    "        # random_index = np.random.permutation(len(origins))\n",
    "        # self.origins, self.targets, self.labels = [], [], []\n",
    "        # for index in random_index:\n",
    "        #     self.origins.append(origins[index])\n",
    "        #     self.targets.append(targets[index])\n",
    "        #     self.labels.append(labels[index])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.origins[idx]\n",
    "        with open(path, 'rb') as f:\n",
    "            sample = Image.open(f)\n",
    "            sample = sample.convert('RGB')\n",
    "        origin = self.transform(sample)\n",
    "        target = self.transform(sample)\n",
    "        return origin, target, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.origins)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "dataset = CIFAR10ContrastiveLearning()\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [42500, 7500])\n",
    "train_iter = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_iter = DataLoader(val_dataset, batch_size=256, drop_last=True, pin_memory=True)\n",
    "metrics = {}\n",
    "k_values = [16384]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 224, 224])\n",
      "torch.Size([256, 3, 224, 224])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for origin, target, label in train_iter:\n",
    "    print(origin[0].shape)\n",
    "    print(target[0].shape)\n",
    "    print(label.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
