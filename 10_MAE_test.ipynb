{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import Block, PatchEmbed\n",
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SinCos编码  \n",
    "$$PE(pos, 2i) = \\sin{\\frac{pos}{10000^{2i/d_{model}}}}$$\n",
    "$$PE(pos, 2i + 1) = \\cos{\\frac{pos}{10000^{2i/d_{model}}}}$$\n",
    "引入位置信息：相隔 k 个词的两个位置 pos 和 pos+k 的位置编码是由 k 和pos的位置编码定义的一个线性变换  \n",
    "$$PE(pos + k, 2i) = PE(pos, 2i)PE(k, 2i + 1) + PE(pos, 2i + 1)PE(k, 2i)$$\n",
    "$$PE(pos + k, 2i + 1) = PE(pos, 2i + 1)PE(k, 2i + 1) - PE(pos, 2i)PE(k, 2i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)\n",
    "    grid = np.stack(grid, axis=0)\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])\n",
    "    pos_embed = np.concatenate([emb_h, emb_w], axis=1)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000 ** omega\n",
    "    pos = pos.reshape(-1)\n",
    "    out = np.einsum('m,d->md', pos, omega)\n",
    "    emb_sin = np.sin(out)\n",
    "    emb_cos = np.cos(out)\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_model import MaskedAutoEncoderViT, VisionTransformer\n",
    "\n",
    "\n",
    "MAE_model = MaskedAutoEncoderViT()\n",
    "ViT_model = VisionTransformer()\n",
    "\n",
    "mae_name_param_size = dict()\n",
    "vit_name_param_size = dict()\n",
    "\n",
    "for name, param in MAE_model.named_parameters():\n",
    "    mae_name_param_size[name] = param.shape\n",
    "for name, param in ViT_model.named_parameters():\n",
    "    vit_name_param_size[name] = param.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cls_token', 'pos_embed', 'mask_token', 'decoder_pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'enc_blocks.0.norm1.weight', 'enc_blocks.0.norm1.bias', 'enc_blocks.0.attn.qkv.weight', 'enc_blocks.0.attn.qkv.bias', 'enc_blocks.0.attn.proj.weight', 'enc_blocks.0.attn.proj.bias', 'enc_blocks.0.norm2.weight', 'enc_blocks.0.norm2.bias', 'enc_blocks.0.mlp.fc1.weight', 'enc_blocks.0.mlp.fc1.bias', 'enc_blocks.0.mlp.fc2.weight', 'enc_blocks.0.mlp.fc2.bias', 'enc_blocks.1.norm1.weight', 'enc_blocks.1.norm1.bias', 'enc_blocks.1.attn.qkv.weight', 'enc_blocks.1.attn.qkv.bias', 'enc_blocks.1.attn.proj.weight', 'enc_blocks.1.attn.proj.bias', 'enc_blocks.1.norm2.weight', 'enc_blocks.1.norm2.bias', 'enc_blocks.1.mlp.fc1.weight', 'enc_blocks.1.mlp.fc1.bias', 'enc_blocks.1.mlp.fc2.weight', 'enc_blocks.1.mlp.fc2.bias', 'enc_blocks.2.norm1.weight', 'enc_blocks.2.norm1.bias', 'enc_blocks.2.attn.qkv.weight', 'enc_blocks.2.attn.qkv.bias', 'enc_blocks.2.attn.proj.weight', 'enc_blocks.2.attn.proj.bias', 'enc_blocks.2.norm2.weight', 'enc_blocks.2.norm2.bias', 'enc_blocks.2.mlp.fc1.weight', 'enc_blocks.2.mlp.fc1.bias', 'enc_blocks.2.mlp.fc2.weight', 'enc_blocks.2.mlp.fc2.bias', 'enc_blocks.3.norm1.weight', 'enc_blocks.3.norm1.bias', 'enc_blocks.3.attn.qkv.weight', 'enc_blocks.3.attn.qkv.bias', 'enc_blocks.3.attn.proj.weight', 'enc_blocks.3.attn.proj.bias', 'enc_blocks.3.norm2.weight', 'enc_blocks.3.norm2.bias', 'enc_blocks.3.mlp.fc1.weight', 'enc_blocks.3.mlp.fc1.bias', 'enc_blocks.3.mlp.fc2.weight', 'enc_blocks.3.mlp.fc2.bias', 'enc_blocks.4.norm1.weight', 'enc_blocks.4.norm1.bias', 'enc_blocks.4.attn.qkv.weight', 'enc_blocks.4.attn.qkv.bias', 'enc_blocks.4.attn.proj.weight', 'enc_blocks.4.attn.proj.bias', 'enc_blocks.4.norm2.weight', 'enc_blocks.4.norm2.bias', 'enc_blocks.4.mlp.fc1.weight', 'enc_blocks.4.mlp.fc1.bias', 'enc_blocks.4.mlp.fc2.weight', 'enc_blocks.4.mlp.fc2.bias', 'enc_blocks.5.norm1.weight', 'enc_blocks.5.norm1.bias', 'enc_blocks.5.attn.qkv.weight', 'enc_blocks.5.attn.qkv.bias', 'enc_blocks.5.attn.proj.weight', 'enc_blocks.5.attn.proj.bias', 'enc_blocks.5.norm2.weight', 'enc_blocks.5.norm2.bias', 'enc_blocks.5.mlp.fc1.weight', 'enc_blocks.5.mlp.fc1.bias', 'enc_blocks.5.mlp.fc2.weight', 'enc_blocks.5.mlp.fc2.bias', 'enc_blocks.6.norm1.weight', 'enc_blocks.6.norm1.bias', 'enc_blocks.6.attn.qkv.weight', 'enc_blocks.6.attn.qkv.bias', 'enc_blocks.6.attn.proj.weight', 'enc_blocks.6.attn.proj.bias', 'enc_blocks.6.norm2.weight', 'enc_blocks.6.norm2.bias', 'enc_blocks.6.mlp.fc1.weight', 'enc_blocks.6.mlp.fc1.bias', 'enc_blocks.6.mlp.fc2.weight', 'enc_blocks.6.mlp.fc2.bias', 'enc_blocks.7.norm1.weight', 'enc_blocks.7.norm1.bias', 'enc_blocks.7.attn.qkv.weight', 'enc_blocks.7.attn.qkv.bias', 'enc_blocks.7.attn.proj.weight', 'enc_blocks.7.attn.proj.bias', 'enc_blocks.7.norm2.weight', 'enc_blocks.7.norm2.bias', 'enc_blocks.7.mlp.fc1.weight', 'enc_blocks.7.mlp.fc1.bias', 'enc_blocks.7.mlp.fc2.weight', 'enc_blocks.7.mlp.fc2.bias', 'enc_blocks.8.norm1.weight', 'enc_blocks.8.norm1.bias', 'enc_blocks.8.attn.qkv.weight', 'enc_blocks.8.attn.qkv.bias', 'enc_blocks.8.attn.proj.weight', 'enc_blocks.8.attn.proj.bias', 'enc_blocks.8.norm2.weight', 'enc_blocks.8.norm2.bias', 'enc_blocks.8.mlp.fc1.weight', 'enc_blocks.8.mlp.fc1.bias', 'enc_blocks.8.mlp.fc2.weight', 'enc_blocks.8.mlp.fc2.bias', 'enc_blocks.9.norm1.weight', 'enc_blocks.9.norm1.bias', 'enc_blocks.9.attn.qkv.weight', 'enc_blocks.9.attn.qkv.bias', 'enc_blocks.9.attn.proj.weight', 'enc_blocks.9.attn.proj.bias', 'enc_blocks.9.norm2.weight', 'enc_blocks.9.norm2.bias', 'enc_blocks.9.mlp.fc1.weight', 'enc_blocks.9.mlp.fc1.bias', 'enc_blocks.9.mlp.fc2.weight', 'enc_blocks.9.mlp.fc2.bias', 'enc_blocks.10.norm1.weight', 'enc_blocks.10.norm1.bias', 'enc_blocks.10.attn.qkv.weight', 'enc_blocks.10.attn.qkv.bias', 'enc_blocks.10.attn.proj.weight', 'enc_blocks.10.attn.proj.bias', 'enc_blocks.10.norm2.weight', 'enc_blocks.10.norm2.bias', 'enc_blocks.10.mlp.fc1.weight', 'enc_blocks.10.mlp.fc1.bias', 'enc_blocks.10.mlp.fc2.weight', 'enc_blocks.10.mlp.fc2.bias', 'enc_blocks.11.norm1.weight', 'enc_blocks.11.norm1.bias', 'enc_blocks.11.attn.qkv.weight', 'enc_blocks.11.attn.qkv.bias', 'enc_blocks.11.attn.proj.weight', 'enc_blocks.11.attn.proj.bias', 'enc_blocks.11.norm2.weight', 'enc_blocks.11.norm2.bias', 'enc_blocks.11.mlp.fc1.weight', 'enc_blocks.11.mlp.fc1.bias', 'enc_blocks.11.mlp.fc2.weight', 'enc_blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'decoder_embed.weight', 'decoder_embed.bias', 'dec_blocks.0.norm1.weight', 'dec_blocks.0.norm1.bias', 'dec_blocks.0.attn.qkv.weight', 'dec_blocks.0.attn.qkv.bias', 'dec_blocks.0.attn.proj.weight', 'dec_blocks.0.attn.proj.bias', 'dec_blocks.0.norm2.weight', 'dec_blocks.0.norm2.bias', 'dec_blocks.0.mlp.fc1.weight', 'dec_blocks.0.mlp.fc1.bias', 'dec_blocks.0.mlp.fc2.weight', 'dec_blocks.0.mlp.fc2.bias', 'dec_blocks.1.norm1.weight', 'dec_blocks.1.norm1.bias', 'dec_blocks.1.attn.qkv.weight', 'dec_blocks.1.attn.qkv.bias', 'dec_blocks.1.attn.proj.weight', 'dec_blocks.1.attn.proj.bias', 'dec_blocks.1.norm2.weight', 'dec_blocks.1.norm2.bias', 'dec_blocks.1.mlp.fc1.weight', 'dec_blocks.1.mlp.fc1.bias', 'dec_blocks.1.mlp.fc2.weight', 'dec_blocks.1.mlp.fc2.bias', 'dec_blocks.2.norm1.weight', 'dec_blocks.2.norm1.bias', 'dec_blocks.2.attn.qkv.weight', 'dec_blocks.2.attn.qkv.bias', 'dec_blocks.2.attn.proj.weight', 'dec_blocks.2.attn.proj.bias', 'dec_blocks.2.norm2.weight', 'dec_blocks.2.norm2.bias', 'dec_blocks.2.mlp.fc1.weight', 'dec_blocks.2.mlp.fc1.bias', 'dec_blocks.2.mlp.fc2.weight', 'dec_blocks.2.mlp.fc2.bias', 'dec_blocks.3.norm1.weight', 'dec_blocks.3.norm1.bias', 'dec_blocks.3.attn.qkv.weight', 'dec_blocks.3.attn.qkv.bias', 'dec_blocks.3.attn.proj.weight', 'dec_blocks.3.attn.proj.bias', 'dec_blocks.3.norm2.weight', 'dec_blocks.3.norm2.bias', 'dec_blocks.3.mlp.fc1.weight', 'dec_blocks.3.mlp.fc1.bias', 'dec_blocks.3.mlp.fc2.weight', 'dec_blocks.3.mlp.fc2.bias', 'dec_blocks.4.norm1.weight', 'dec_blocks.4.norm1.bias', 'dec_blocks.4.attn.qkv.weight', 'dec_blocks.4.attn.qkv.bias', 'dec_blocks.4.attn.proj.weight', 'dec_blocks.4.attn.proj.bias', 'dec_blocks.4.norm2.weight', 'dec_blocks.4.norm2.bias', 'dec_blocks.4.mlp.fc1.weight', 'dec_blocks.4.mlp.fc1.bias', 'dec_blocks.4.mlp.fc2.weight', 'dec_blocks.4.mlp.fc2.bias', 'dec_blocks.5.norm1.weight', 'dec_blocks.5.norm1.bias', 'dec_blocks.5.attn.qkv.weight', 'dec_blocks.5.attn.qkv.bias', 'dec_blocks.5.attn.proj.weight', 'dec_blocks.5.attn.proj.bias', 'dec_blocks.5.norm2.weight', 'dec_blocks.5.norm2.bias', 'dec_blocks.5.mlp.fc1.weight', 'dec_blocks.5.mlp.fc1.bias', 'dec_blocks.5.mlp.fc2.weight', 'dec_blocks.5.mlp.fc2.bias', 'dec_blocks.6.norm1.weight', 'dec_blocks.6.norm1.bias', 'dec_blocks.6.attn.qkv.weight', 'dec_blocks.6.attn.qkv.bias', 'dec_blocks.6.attn.proj.weight', 'dec_blocks.6.attn.proj.bias', 'dec_blocks.6.norm2.weight', 'dec_blocks.6.norm2.bias', 'dec_blocks.6.mlp.fc1.weight', 'dec_blocks.6.mlp.fc1.bias', 'dec_blocks.6.mlp.fc2.weight', 'dec_blocks.6.mlp.fc2.bias', 'dec_blocks.7.norm1.weight', 'dec_blocks.7.norm1.bias', 'dec_blocks.7.attn.qkv.weight', 'dec_blocks.7.attn.qkv.bias', 'dec_blocks.7.attn.proj.weight', 'dec_blocks.7.attn.proj.bias', 'dec_blocks.7.norm2.weight', 'dec_blocks.7.norm2.bias', 'dec_blocks.7.mlp.fc1.weight', 'dec_blocks.7.mlp.fc1.bias', 'dec_blocks.7.mlp.fc2.weight', 'dec_blocks.7.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.weight', 'decoder_pred.bias'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mae, vit in zip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4e980a27e930b9ff5731385d4bd44946951fe20aeacecd4aa5a8f48401c490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
