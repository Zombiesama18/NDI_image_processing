{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from dataset import *\n",
    "from train import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_fix_seed(19981303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_self_pretrain_model(index=1000):\n",
    "    base_encoder = torchvision.models.resnet50(weights=None)\n",
    "    base_encoder.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    origin_dim_mlp = base_encoder.fc.in_features\n",
    "    base_encoder.fc = None\n",
    "    temp = torch.load(f'./checkpoints/CEM_ALL_CHECK_{index}_Epoch.pth')['state_dict']\n",
    "    state_dict = {}\n",
    "    for k, v in temp.items():\n",
    "        if 'encoder_q' in k:\n",
    "            if 'fc' not in k:\n",
    "                state_dict['.'.join(k.split('.')[1:])] = v\n",
    "    base_encoder.load_state_dict(state_dict)\n",
    "    base_encoder.fc = torch.nn.Linear(origin_dim_mlp, 512)\n",
    "    return base_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train_Loss 3.929688286781311, Val_loss 4.187676906585693\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.116767692565918, Val_loss 4.1739501953125\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.08\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.062369060516358, Val_loss 4.148848056793213\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.93734986782074, Val_loss 4.0801100730896\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.04\t\n",
      "Epoch 5, Train_Loss 3.844912815093994, Val_loss 4.004388332366943\n",
      "Train_acc_top_20 0.175\tTrain_acc_top_30 0.2437\tTrain_acc_top_40 0.2812\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.747133708000183, Val_loss 3.8979103565216064\n",
      "Train_acc_top_20 0.3187\tTrain_acc_top_30 0.4562\tTrain_acc_top_40 0.5625\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.661601758003235, Val_loss 3.714705228805542\n",
      "Train_acc_top_20 0.5625\tTrain_acc_top_30 0.725\tTrain_acc_top_40 0.8438\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.596157956123352, Val_loss 3.687349557876587\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5592527866363524, Val_loss 3.6207618713378906\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.4915127038955687, Val_loss 3.6264970302581787\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.451988697052002, Val_loss 3.6012697219848633\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.453506827354431, Val_loss 3.585850715637207\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 13, Train_Loss 3.3985690593719484, Val_loss 3.5679495334625244\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3678945302963257, Val_loss 3.627129554748535\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3216050624847413, Val_loss 3.5422189235687256\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.3132129669189454, Val_loss 3.5363357067108154\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.2923108100891114, Val_loss 3.489250898361206\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.2856690883636475, Val_loss 3.516794204711914\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2559381484985352, Val_loss 3.5218846797943115\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.2692321300506593, Val_loss 3.528956413269043\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2282854557037353, Val_loss 3.563647985458374\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.250846791267395, Val_loss 3.4830620288848877\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.221308469772339, Val_loss 3.528780221939087\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.246222639083862, Val_loss 3.603710174560547\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.2027917861938477, Val_loss 3.5156290531158447\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.201266574859619, Val_loss 3.5628139972686768\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.2035760641098023, Val_loss 3.5136606693267822\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.216354560852051, Val_loss 3.547856569290161\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.203145384788513, Val_loss 3.671388626098633\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.182514262199402, Val_loss 3.4763681888580322\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.170681524276733, Val_loss 3.5359113216400146\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1807724475860595, Val_loss 3.6169722080230713\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.1600473642349245, Val_loss 3.5361297130584717\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.157625365257263, Val_loss 3.54121470451355\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.153596806526184, Val_loss 3.5249698162078857\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.155872178077698, Val_loss 3.4719581604003906\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1745710134506226, Val_loss 3.6105339527130127\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1896633386611937, Val_loss 3.528122663497925\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.148179626464844, Val_loss 3.5734012126922607\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.14782874584198, Val_loss 3.5429418087005615\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.165984296798706, Val_loss 3.514850616455078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.140773606300354, Val_loss 3.594958543777466\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.13269464969635, Val_loss 3.59470534324646\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.144817924499512, Val_loss 3.5621166229248047\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.132323217391968, Val_loss 3.552557945251465\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1309119701385497, Val_loss 3.5688750743865967\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.12474045753479, Val_loss 3.6173999309539795\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1314593315124513, Val_loss 3.5463979244232178\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1445215940475464, Val_loss 3.510128974914551\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1219889402389525, Val_loss 3.5577666759490967\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1338661670684815, Val_loss 3.563591241836548\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.118548345565796, Val_loss 3.615380048751831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.108931541442871, Val_loss 3.515713930130005\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1353947162628173, Val_loss 3.543452501296997\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1234522104263305, Val_loss 3.5625903606414795\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1293335914611817, Val_loss 3.5496528148651123\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1107969760894774, Val_loss 3.535188913345337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.1118358612060546, Val_loss 3.5793468952178955\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.131295609474182, Val_loss 3.578967332839966\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1232720613479614, Val_loss 3.5073158740997314\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1252935409545897, Val_loss 3.5494887828826904\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.1042415857315064, Val_loss 3.5535755157470703\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.1052635431289675, Val_loss 3.556445837020874\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.1218371629714965, Val_loss 3.6106436252593994\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.105792999267578, Val_loss 3.5397212505340576\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.1129818677902223, Val_loss 3.575089693069458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.102324604988098, Val_loss 3.5618531703948975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.0963606595993043, Val_loss 3.5527923107147217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.09889702796936, Val_loss 3.5888149738311768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.1147854804992674, Val_loss 3.5993435382843018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.096716356277466, Val_loss 3.631211996078491\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.0924513816833494, Val_loss 3.6079447269439697\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0951372146606446, Val_loss 3.564140558242798\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0842637062072753, Val_loss 3.59125018119812\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.099187135696411, Val_loss 3.5837371349334717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.091294026374817, Val_loss 3.56493878364563\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.108487033843994, Val_loss 3.5964584350585938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0856699466705324, Val_loss 3.559326171875\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.103108859062195, Val_loss 3.587146759033203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1115349769592284, Val_loss 3.5979816913604736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.0811172246932985, Val_loss 3.569131851196289\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1094626903533937, Val_loss 3.5699520111083984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.098779082298279, Val_loss 3.559312105178833\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0915324211120607, Val_loss 3.564255714416504\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.109942102432251, Val_loss 3.564035177230835\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0970289945602416, Val_loss 3.5911824703216553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.091099262237549, Val_loss 3.541494369506836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.078480529785156, Val_loss 3.5619382858276367\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.0861144065856934, Val_loss 3.6011760234832764\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0949928522109986, Val_loss 3.544553756713867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.098444414138794, Val_loss 3.565640687942505\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0906373500823974, Val_loss 3.572697877883911\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.083617091178894, Val_loss 3.576554298400879\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.084106111526489, Val_loss 3.575625419616699\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.081669783592224, Val_loss 3.5936012268066406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0926632642745973, Val_loss 3.5851352214813232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.094763469696045, Val_loss 3.5709800720214844\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.103084897994995, Val_loss 3.602165937423706\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.10305769443512, Val_loss 3.557466745376587\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.089535641670227, Val_loss 3.593496322631836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9274500370025636, Val_loss 4.21019983291626\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.103702020645142, Val_loss 4.1687445640563965\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.029853510856628, Val_loss 4.134355545043945\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9049696207046507, Val_loss 4.078310489654541\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.810220980644226, Val_loss 3.9975674152374268\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.721152353286743, Val_loss 3.818732976913452\n",
      "Train_acc_top_20 0.2812\tTrain_acc_top_30 0.4375\tTrain_acc_top_40 0.5813\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.6852174520492555, Val_loss 3.7351553440093994\n",
      "Train_acc_top_20 0.6\tTrain_acc_top_30 0.7875\tTrain_acc_top_40 0.8688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.590159463882446, Val_loss 3.725142240524292\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5538172721862793, Val_loss 3.6937482357025146\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.529628801345825, Val_loss 3.7392196655273438\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.4471671342849732, Val_loss 3.716473340988159\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.404368185997009, Val_loss 3.6570231914520264\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.3902215003967284, Val_loss 3.751811981201172\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 14, Train_Loss 3.3636264324188234, Val_loss 3.730257272720337\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.321448016166687, Val_loss 3.6604204177856445\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3362723350524903, Val_loss 3.642659902572632\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.30933256149292, Val_loss 3.6682302951812744\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.286857509613037, Val_loss 3.6894893646240234\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.278934097290039, Val_loss 3.6243932247161865\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.269397473335266, Val_loss 3.62372088432312\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.250375986099243, Val_loss 3.5801448822021484\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.216509294509888, Val_loss 3.6341001987457275\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.212651777267456, Val_loss 3.6566686630249023\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2102235078811647, Val_loss 3.621886968612671\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.206077742576599, Val_loss 3.667759895324707\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.1871960878372194, Val_loss 3.598928451538086\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.1822999000549315, Val_loss 3.5851869583129883\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.206725263595581, Val_loss 3.5871143341064453\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.1746808290481567, Val_loss 3.562260627746582\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1585229873657226, Val_loss 3.5902345180511475\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.182084584236145, Val_loss 3.6069085597991943\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.163541293144226, Val_loss 3.629682779312134\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.156896543502808, Val_loss 3.610107183456421\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.150135850906372, Val_loss 3.5873115062713623\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.139531874656677, Val_loss 3.6020166873931885\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1588914155960084, Val_loss 3.5700571537017822\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.144632840156555, Val_loss 3.5804338455200195\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1512501001358033, Val_loss 3.5685226917266846\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.1497400522232057, Val_loss 3.632239580154419\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.1383037090301515, Val_loss 3.5750768184661865\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1480209589004517, Val_loss 3.564749002456665\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.132035160064697, Val_loss 3.5533506870269775\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1253323793411254, Val_loss 3.5983848571777344\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1439875841140745, Val_loss 3.592184066772461\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1354813098907472, Val_loss 3.639612913131714\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.155259037017822, Val_loss 3.5848348140716553\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1283588886260985, Val_loss 3.595845937728882\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.131729793548584, Val_loss 3.5819578170776367\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1201037168502808, Val_loss 3.5612754821777344\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1316880702972414, Val_loss 3.530383825302124\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1127492427825927, Val_loss 3.5385401248931885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.110975956916809, Val_loss 3.5567493438720703\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.109110474586487, Val_loss 3.563192129135132\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 54, Train_Loss 3.1284048557281494, Val_loss 3.5487709045410156\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1125863075256346, Val_loss 3.5379040241241455\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.132147693634033, Val_loss 3.5534427165985107\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1316220998764037, Val_loss 3.5350239276885986\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.117224168777466, Val_loss 3.5613858699798584\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.109299564361572, Val_loss 3.5277414321899414\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1211013078689573, Val_loss 3.5754966735839844\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.124959707260132, Val_loss 3.5580132007598877\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.105689597129822, Val_loss 3.5571720600128174\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.120827555656433, Val_loss 3.5675876140594482\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.094674801826477, Val_loss 3.5694539546966553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.1014625072479247, Val_loss 3.562612295150757\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.119100642204285, Val_loss 3.54306960105896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.124045181274414, Val_loss 3.5741398334503174\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.0897255420684813, Val_loss 3.545513153076172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0930174589157104, Val_loss 3.5390377044677734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.094126892089844, Val_loss 3.5550386905670166\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.0993462800979614, Val_loss 3.5716092586517334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0871204137802124, Val_loss 3.543233871459961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.1073662281036376, Val_loss 3.554216146469116\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.104711079597473, Val_loss 3.554036855697632\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.092769002914429, Val_loss 3.5441925525665283\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.1010016441345214, Val_loss 3.5436830520629883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.0991169929504396, Val_loss 3.570995330810547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.0972060680389406, Val_loss 3.559854507446289\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.094357204437256, Val_loss 3.552452802658081\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.1120251178741456, Val_loss 3.5845632553100586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.1031768321990967, Val_loss 3.5582549571990967\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.084765672683716, Val_loss 3.548868179321289\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.0993780374526976, Val_loss 3.55464768409729\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.1021061658859255, Val_loss 3.5758116245269775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.093184232711792, Val_loss 3.5553951263427734\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.103859210014343, Val_loss 3.5513973236083984\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.1065165758132935, Val_loss 3.5569944381713867\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.0991317987442017, Val_loss 3.5702028274536133\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.1071505308151246, Val_loss 3.5478334426879883\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1159862279891968, Val_loss 3.559265375137329\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.104251766204834, Val_loss 3.5855627059936523\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0942161798477175, Val_loss 3.5452613830566406\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.1053033590316774, Val_loss 3.5649726390838623\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.0952417850494385, Val_loss 3.569610834121704\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.0971121549606324, Val_loss 3.573345184326172\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.0879651308059692, Val_loss 3.5600039958953857\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.1290841341018676, Val_loss 3.597822427749634\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.098037314414978, Val_loss 3.5720064640045166\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.10290265083313, Val_loss 3.5874130725860596\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.0896975994110107, Val_loss 3.5561978816986084\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9282751083374023, Val_loss 4.135512828826904\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.104268026351929, Val_loss 4.114707946777344\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 3, Train_Loss 4.023036026954651, Val_loss 4.081290245056152\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.9007959365844727, Val_loss 3.93882155418396\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.802072858810425, Val_loss 3.8634283542633057\n",
      "Train_acc_top_20 0.1688\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.2625\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 6, Train_Loss 3.7310341596603394, Val_loss 3.8624799251556396\n",
      "Train_acc_top_20 0.3375\tTrain_acc_top_30 0.4375\tTrain_acc_top_40 0.5687\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.6281407833099366, Val_loss 3.829183578491211\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.8313\tTrain_acc_top_40 0.9125\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.604932737350464, Val_loss 3.8505008220672607\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5427403450012207, Val_loss 3.814689874649048\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.4599796772003173, Val_loss 3.7751424312591553\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4123600244522097, Val_loss 3.7817952632904053\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.4606467485427856, Val_loss 3.9722368717193604\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.58\t\n",
      "Epoch 13, Train_Loss 3.36042058467865, Val_loss 3.8328773975372314\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3480770111083986, Val_loss 3.71899151802063\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3194435358047487, Val_loss 3.6756668090820312\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.297703242301941, Val_loss 3.8077452182769775\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.62\t\n",
      "Epoch 17, Train_Loss 3.2785593986511232, Val_loss 3.7151498794555664\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.276160192489624, Val_loss 3.6682701110839844\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.2496554136276243, Val_loss 3.7686545848846436\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2736666440963744, Val_loss 3.797374963760376\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.2161311149597167, Val_loss 3.651384115219116\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.2649249792099, Val_loss 3.6291277408599854\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2067568063735963, Val_loss 3.756704330444336\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.193655562400818, Val_loss 3.752870798110962\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.2162213802337645, Val_loss 3.705747604370117\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 26, Train_Loss 3.204226565361023, Val_loss 3.7058048248291016\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.1757844924926757, Val_loss 3.6846866607666016\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 28, Train_Loss 3.169125485420227, Val_loss 3.737572431564331\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 29, Train_Loss 3.1995550632476806, Val_loss 3.7312495708465576\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 30, Train_Loss 3.1903602361679075, Val_loss 3.7431862354278564\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 31, Train_Loss 3.1560471773147585, Val_loss 3.703700065612793\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 32, Train_Loss 3.1537272214889525, Val_loss 3.689880132675171\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.1496266603469847, Val_loss 3.703251838684082\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.1536905765533447, Val_loss 3.678485631942749\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 35, Train_Loss 3.1658518075942994, Val_loss 3.7063019275665283\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.1522108554840087, Val_loss 3.6923129558563232\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.164119529724121, Val_loss 3.667714834213257\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.17210533618927, Val_loss 3.743398904800415\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 39, Train_Loss 3.1438451766967774, Val_loss 3.7305068969726562\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.1343214750289916, Val_loss 3.7118730545043945\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 41, Train_Loss 3.135788631439209, Val_loss 3.6770009994506836\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.1305403232574465, Val_loss 3.6584415435791016\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1242008924484255, Val_loss 3.7361361980438232\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.1312357425689696, Val_loss 3.6585748195648193\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 45, Train_Loss 3.152710747718811, Val_loss 3.6341474056243896\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1260441303253175, Val_loss 3.730264663696289\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 47, Train_Loss 3.1354365825653074, Val_loss 3.6385624408721924\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.1115371704101564, Val_loss 3.6598803997039795\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.1161490440368653, Val_loss 3.7297465801239014\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.1195698499679567, Val_loss 3.648456335067749\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.115051436424255, Val_loss 3.676647186279297\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.141214156150818, Val_loss 3.620237350463867\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.1082971811294557, Val_loss 3.700901746749878\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.1150726079940796, Val_loss 3.677483320236206\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 55, Train_Loss 3.1135082483291625, Val_loss 3.6876699924468994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 56, Train_Loss 3.0948308229446413, Val_loss 3.7163631916046143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 57, Train_Loss 3.102646899223328, Val_loss 3.709286689758301\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.0936782121658326, Val_loss 3.7104880809783936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.102927231788635, Val_loss 3.7046358585357666\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 60, Train_Loss 3.086189365386963, Val_loss 3.6387274265289307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.0818487882614134, Val_loss 3.683194160461426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 62, Train_Loss 3.089833378791809, Val_loss 3.6454927921295166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.0895844459533692, Val_loss 3.683198928833008\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.103097105026245, Val_loss 3.666990041732788\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.0921828508377076, Val_loss 3.690359354019165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.0946545362472535, Val_loss 3.6788151264190674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 67, Train_Loss 3.0900473833084106, Val_loss 3.703350782394409\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.0991132736206053, Val_loss 3.7067108154296875\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 69, Train_Loss 3.080597686767578, Val_loss 3.7096121311187744\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.0810016632080077, Val_loss 3.7015416622161865\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 71, Train_Loss 3.0908931255340577, Val_loss 3.6369495391845703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 72, Train_Loss 3.0908108711242677, Val_loss 3.7170493602752686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.101386570930481, Val_loss 3.7680065631866455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.085559582710266, Val_loss 3.666477918624878\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.089495038986206, Val_loss 3.696890115737915\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.0865322589874267, Val_loss 3.73232102394104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 77, Train_Loss 3.126845598220825, Val_loss 3.6571645736694336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.107351565361023, Val_loss 3.6812915802001953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.0924317121505736, Val_loss 3.6545698642730713\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.093876504898071, Val_loss 3.659971237182617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.0741625308990477, Val_loss 3.689822196960449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 82, Train_Loss 3.0696844100952148, Val_loss 3.6672909259796143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.08437340259552, Val_loss 3.727281332015991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.079471969604492, Val_loss 3.6834421157836914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 85, Train_Loss 3.0756075382232666, Val_loss 3.675124168395996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.071378707885742, Val_loss 3.6851556301116943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.0720885753631593, Val_loss 3.680516481399536\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 88, Train_Loss 3.050504207611084, Val_loss 3.692307710647583\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 89, Train_Loss 3.070679187774658, Val_loss 3.6833086013793945\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.08274827003479, Val_loss 3.6898181438446045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.0662521600723265, Val_loss 3.6731622219085693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.068574047088623, Val_loss 3.6673362255096436\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.0830708503723145, Val_loss 3.701793670654297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.0847098350524904, Val_loss 3.7184059619903564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 95, Train_Loss 3.074394774436951, Val_loss 3.7226483821868896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 96, Train_Loss 3.0910808086395263, Val_loss 3.6926326751708984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.084040141105652, Val_loss 3.6829261779785156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.0636518955230714, Val_loss 3.677971601486206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.106023073196411, Val_loss 3.7044384479522705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.0717823028564455, Val_loss 3.6821625232696533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9216530323028564, Val_loss 4.1725544929504395\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.42\t\n",
      "Epoch 2, Train_Loss 4.113060379028321, Val_loss 4.157045364379883\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.036309814453125, Val_loss 4.083799362182617\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.9209102630615233, Val_loss 3.9994728565216064\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 5, Train_Loss 3.857151675224304, Val_loss 3.9074888229370117\n",
      "Train_acc_top_20 0.1562\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2812\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.21\tVal_acc_top_40 0.46\t\n",
      "Epoch 6, Train_Loss 3.7284552574157717, Val_loss 3.9241693019866943\n",
      "Train_acc_top_20 0.3375\tTrain_acc_top_30 0.4813\tTrain_acc_top_40 0.55\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.6491010189056396, Val_loss 3.9020636081695557\n",
      "Train_acc_top_20 0.6312\tTrain_acc_top_30 0.8063\tTrain_acc_top_40 0.875\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.46\t\n",
      "Epoch 8, Train_Loss 3.5873425722122194, Val_loss 3.8616788387298584\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.58\t\n",
      "Epoch 9, Train_Loss 3.5448126792907715, Val_loss 3.814448356628418\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 10, Train_Loss 3.484368896484375, Val_loss 3.830367088317871\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.426210308074951, Val_loss 3.818225860595703\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 12, Train_Loss 3.382993197441101, Val_loss 3.7596752643585205\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.4165786504745483, Val_loss 3.779700517654419\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.336919903755188, Val_loss 3.7935755252838135\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.342862629890442, Val_loss 3.7783749103546143\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.38\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.3177585363388062, Val_loss 3.774909257888794\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 17, Train_Loss 3.320476746559143, Val_loss 3.7367007732391357\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.2673369646072388, Val_loss 3.758221387863159\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.2511736392974853, Val_loss 3.8252344131469727\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.33\tVal_acc_top_40 0.5\t\n",
      "Epoch 20, Train_Loss 3.2441127777099608, Val_loss 3.7356936931610107\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.264025115966797, Val_loss 3.8136589527130127\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.220621132850647, Val_loss 3.726943254470825\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.62\t\n",
      "Epoch 23, Train_Loss 3.219410538673401, Val_loss 3.755528211593628\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.1876512289047243, Val_loss 3.69071888923645\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.205629515647888, Val_loss 3.7308061122894287\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.2224267721176147, Val_loss 3.742841958999634\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 27, Train_Loss 3.2000873565673826, Val_loss 3.7262144088745117\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1758867263793946, Val_loss 3.7389698028564453\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 29, Train_Loss 3.180817890167236, Val_loss 3.7116377353668213\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.2254499435424804, Val_loss 3.743812322616577\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.2094350814819337, Val_loss 3.7481191158294678\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 32, Train_Loss 3.18537323474884, Val_loss 3.7062880992889404\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.2040668725967407, Val_loss 3.8070783615112305\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.1753241062164306, Val_loss 3.723741292953491\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.156542992591858, Val_loss 3.6533243656158447\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.169709062576294, Val_loss 3.7847611904144287\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.1603506565093995, Val_loss 3.665989875793457\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.149107551574707, Val_loss 3.8301961421966553\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.33\tVal_acc_top_40 0.54\t\n",
      "Epoch 39, Train_Loss 3.1475795030593874, Val_loss 3.694552421569824\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.1480394840240478, Val_loss 3.8046560287475586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 41, Train_Loss 3.156063938140869, Val_loss 3.699432373046875\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.133356714248657, Val_loss 3.724820852279663\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.140470290184021, Val_loss 3.7007243633270264\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1308585166931153, Val_loss 3.7532119750976562\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 45, Train_Loss 3.1250075578689573, Val_loss 3.6960904598236084\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1537795782089235, Val_loss 3.773979902267456\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 47, Train_Loss 3.1281700849533083, Val_loss 3.67301082611084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.138030242919922, Val_loss 3.781696319580078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.123641514778137, Val_loss 3.736100435256958\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.1363447427749636, Val_loss 3.737240791320801\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1356689453125, Val_loss 3.721731424331665\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1345389604568483, Val_loss 3.6855573654174805\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1252562284469603, Val_loss 3.7173044681549072\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 54, Train_Loss 3.1305968284606935, Val_loss 3.6715803146362305\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.146609568595886, Val_loss 3.715179204940796\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1291082382202147, Val_loss 3.6989710330963135\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1317062854766844, Val_loss 3.713761568069458\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.116168236732483, Val_loss 3.684002637863159\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1484338521957396, Val_loss 3.7831761837005615\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 60, Train_Loss 3.130090594291687, Val_loss 3.6801908016204834\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.120955157279968, Val_loss 3.738412857055664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.126646876335144, Val_loss 3.7690794467926025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 63, Train_Loss 3.102487087249756, Val_loss 3.7190473079681396\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.1221473693847654, Val_loss 3.768235445022583\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.114599370956421, Val_loss 3.7453272342681885\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 66, Train_Loss 3.121936321258545, Val_loss 3.7930727005004883\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 67, Train_Loss 3.1154311418533327, Val_loss 3.7374632358551025\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.123243737220764, Val_loss 3.737382650375366\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.1112218379974363, Val_loss 3.7480905055999756\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.0994564294815063, Val_loss 3.7590668201446533\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 71, Train_Loss 3.090779519081116, Val_loss 3.7034571170806885\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 72, Train_Loss 3.1264188051223756, Val_loss 3.782780885696411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.1094585180282595, Val_loss 3.7518978118896484\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 74, Train_Loss 3.0967496156692507, Val_loss 3.7320899963378906\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.0963688135147094, Val_loss 3.7858030796051025\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.100641369819641, Val_loss 3.746828079223633\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.111103081703186, Val_loss 3.7730791568756104\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.093129873275757, Val_loss 3.7335283756256104\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.1135711908340453, Val_loss 3.7071361541748047\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.090571641921997, Val_loss 3.7406699657440186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.094064140319824, Val_loss 3.7879486083984375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 82, Train_Loss 3.1047391414642336, Val_loss 3.733398675918579\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.110614800453186, Val_loss 3.762322425842285\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.1173463821411134, Val_loss 3.764836072921753\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 85, Train_Loss 3.106045436859131, Val_loss 3.7777230739593506\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 86, Train_Loss 3.086473083496094, Val_loss 3.7768754959106445\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.127063179016113, Val_loss 3.775796890258789\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 88, Train_Loss 3.098734188079834, Val_loss 3.7530300617218018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 89, Train_Loss 3.107109022140503, Val_loss 3.7582390308380127\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.076969933509827, Val_loss 3.756990432739258\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.0824904680252074, Val_loss 3.783135175704956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 92, Train_Loss 3.0902589321136475, Val_loss 3.7740228176116943\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.0840603828430178, Val_loss 3.7574288845062256\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.085957717895508, Val_loss 3.7703187465667725\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.1035534858703615, Val_loss 3.769566535949707\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 96, Train_Loss 3.09385290145874, Val_loss 3.780487298965454\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.0798136472702025, Val_loss 3.7620484828948975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.095322823524475, Val_loss 3.767944097518921\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.0927504777908323, Val_loss 3.7755277156829834\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 100, Train_Loss 3.0793269157409666, Val_loss 3.759554624557495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 1, Train_Loss 3.929978847503662, Val_loss 4.174858570098877\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.11739068031311, Val_loss 4.11490535736084\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.059519481658936, Val_loss 4.051237106323242\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.948193073272705, Val_loss 4.041097640991211\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 5, Train_Loss 3.850594234466553, Val_loss 3.997971534729004\n",
      "Train_acc_top_20 0.175\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.3125\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.38\t\n",
      "Epoch 6, Train_Loss 3.7794212102890015, Val_loss 3.813767671585083\n",
      "Train_acc_top_20 0.325\tTrain_acc_top_30 0.4813\tTrain_acc_top_40 0.6188\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 7, Train_Loss 3.7146854400634766, Val_loss 3.6853160858154297\n",
      "Train_acc_top_20 0.6125\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.636903762817383, Val_loss 3.649850606918335\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5647114515304565, Val_loss 3.628587484359741\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.5558079957962034, Val_loss 3.5852577686309814\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 11, Train_Loss 3.4677833795547484, Val_loss 3.6026365756988525\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.450701665878296, Val_loss 3.567263603210449\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 13, Train_Loss 3.421028256416321, Val_loss 3.5791549682617188\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.395721745491028, Val_loss 3.516453504562378\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 15, Train_Loss 3.419351005554199, Val_loss 3.5781078338623047\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.371377205848694, Val_loss 3.5791454315185547\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.323388147354126, Val_loss 3.527742624282837\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.288276529312134, Val_loss 3.5264694690704346\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 19, Train_Loss 3.315877366065979, Val_loss 3.5334577560424805\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 20, Train_Loss 3.29035005569458, Val_loss 3.5383269786834717\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 21, Train_Loss 3.270136523246765, Val_loss 3.4900290966033936\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 22, Train_Loss 3.2943994998931885, Val_loss 3.5545551776885986\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 23, Train_Loss 3.250718879699707, Val_loss 3.496180772781372\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 24, Train_Loss 3.232545256614685, Val_loss 3.511306047439575\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.2024224519729616, Val_loss 3.5110270977020264\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 26, Train_Loss 3.2388543128967284, Val_loss 3.55713152885437\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 27, Train_Loss 3.202165961265564, Val_loss 3.5160367488861084\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 28, Train_Loss 3.20468692779541, Val_loss 3.4940555095672607\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 29, Train_Loss 3.2104016304016114, Val_loss 3.608157157897949\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.1742222547531127, Val_loss 3.5406558513641357\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1630218267440795, Val_loss 3.5257561206817627\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1913257122039793, Val_loss 3.5481338500976562\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1831517696380613, Val_loss 3.501258134841919\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.184701108932495, Val_loss 3.524688482284546\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1740509510040282, Val_loss 3.4834840297698975\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.166740131378174, Val_loss 3.5215394496917725\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 37, Train_Loss 3.156307506561279, Val_loss 3.5287744998931885\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.1577335357666017, Val_loss 3.5318996906280518\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.169321584701538, Val_loss 3.6083250045776367\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1855928897857666, Val_loss 3.605389356613159\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.147764205932617, Val_loss 3.532313346862793\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.165986943244934, Val_loss 3.5419795513153076\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.1468520402908324, Val_loss 3.616992235183716\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.1353241205215454, Val_loss 3.548400640487671\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.157985973358154, Val_loss 3.600398063659668\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1408014059066773, Val_loss 3.5321950912475586\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.1133561372756957, Val_loss 3.5582637786865234\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.145405960083008, Val_loss 3.5597751140594482\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1357635498046874, Val_loss 3.5352346897125244\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.157348656654358, Val_loss 3.5291450023651123\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.161013603210449, Val_loss 3.499885320663452\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1281182050704954, Val_loss 3.561786651611328\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.1413866519927978, Val_loss 3.598649024963379\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.121353507041931, Val_loss 3.5551674365997314\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.130208230018616, Val_loss 3.534891366958618\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.1144022941589355, Val_loss 3.5784738063812256\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.117531895637512, Val_loss 3.6606998443603516\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.114668583869934, Val_loss 3.543266534805298\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.1427522897720337, Val_loss 3.5620734691619873\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.1226537942886354, Val_loss 3.5822503566741943\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.119610595703125, Val_loss 3.6213042736053467\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.110342764854431, Val_loss 3.554201126098633\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1060771465301515, Val_loss 3.5398919582366943\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.1240866661071776, Val_loss 3.5428707599639893\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.156893587112427, Val_loss 3.611560821533203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.106921124458313, Val_loss 3.6169307231903076\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 67, Train_Loss 3.136685872077942, Val_loss 3.6022679805755615\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.104619359970093, Val_loss 3.5646591186523438\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0992696046829225, Val_loss 3.60158634185791\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.0924085140228272, Val_loss 3.597978353500366\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.08480544090271, Val_loss 3.5719759464263916\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.1112754106521607, Val_loss 3.6485002040863037\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.079095387458801, Val_loss 3.6369874477386475\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 74, Train_Loss 3.108015537261963, Val_loss 3.599929094314575\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.105188989639282, Val_loss 3.6374757289886475\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.113855767250061, Val_loss 3.594707489013672\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.105460596084595, Val_loss 3.5971031188964844\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.1069615840911866, Val_loss 3.6736106872558594\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.1392723321914673, Val_loss 3.6034088134765625\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0886740684509277, Val_loss 3.6104183197021484\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.0895126819610597, Val_loss 3.5757625102996826\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.0921797275543215, Val_loss 3.5840835571289062\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.1311964273452757, Val_loss 3.638108968734741\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0844088792800903, Val_loss 3.6034481525421143\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.102645254135132, Val_loss 3.6149587631225586\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.0843665838241576, Val_loss 3.5972681045532227\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.094963788986206, Val_loss 3.61519455909729\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.1260676860809324, Val_loss 3.6391820907592773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.089034342765808, Val_loss 3.600322961807251\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.084377956390381, Val_loss 3.6014387607574463\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 91, Train_Loss 3.0811956882476808, Val_loss 3.6139910221099854\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.106837582588196, Val_loss 3.5914306640625\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.1052431583404543, Val_loss 3.621565103530884\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.1000303745269777, Val_loss 3.5828607082366943\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.0884348154067993, Val_loss 3.606126546859741\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.1032662630081176, Val_loss 3.6304140090942383\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.1017765283584593, Val_loss 3.618227243423462\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.0957275152206423, Val_loss 3.6128833293914795\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0997790336608886, Val_loss 3.6060667037963867\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.114309310913086, Val_loss 3.6066300868988037\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.924021768569946, Val_loss 4.165503978729248\n",
      "Train_acc_top_20 0.075\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.46\t\n",
      "Epoch 2, Train_Loss 4.119659042358398, Val_loss 4.111972332000732\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 3, Train_Loss 4.061303758621216, Val_loss 4.061730861663818\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.950589919090271, Val_loss 4.017059803009033\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1125\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.855931043624878, Val_loss 4.00532865524292\n",
      "Train_acc_top_20 0.15\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.25\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7964231252670286, Val_loss 3.8637492656707764\n",
      "Train_acc_top_20 0.3375\tTrain_acc_top_30 0.4437\tTrain_acc_top_40 0.6\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 7, Train_Loss 3.7192745208740234, Val_loss 3.7682225704193115\n",
      "Train_acc_top_20 0.575\tTrain_acc_top_30 0.7688\tTrain_acc_top_40 0.8625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.665044093132019, Val_loss 3.720841646194458\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.8562\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.593641662597656, Val_loss 3.6835575103759766\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.5430014371871947, Val_loss 3.653285264968872\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4964653491973876, Val_loss 3.660304307937622\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.459626007080078, Val_loss 3.632181406021118\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.4069934606552126, Val_loss 3.612881898880005\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.40421781539917, Val_loss 3.640428304672241\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3246649742126464, Val_loss 3.6151340007781982\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.325496292114258, Val_loss 3.6248109340667725\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.3027220010757445, Val_loss 3.6656720638275146\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 18, Train_Loss 3.3036471605300903, Val_loss 3.6763064861297607\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.294551157951355, Val_loss 3.5798380374908447\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2619245767593386, Val_loss 3.724203109741211\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 21, Train_Loss 3.253051233291626, Val_loss 3.642876386642456\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.224187135696411, Val_loss 3.595637559890747\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.223598289489746, Val_loss 3.602604866027832\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.193159890174866, Val_loss 3.551039934158325\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2176466941833497, Val_loss 3.647597551345825\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 26, Train_Loss 3.188992476463318, Val_loss 3.620309829711914\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.1846501350402834, Val_loss 3.6612555980682373\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 28, Train_Loss 3.1745189666748046, Val_loss 3.591381072998047\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.2021199464797974, Val_loss 3.7060439586639404\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 30, Train_Loss 3.163980317115784, Val_loss 3.6447761058807373\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.1519814014434813, Val_loss 3.632643699645996\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1912125825881956, Val_loss 3.6172430515289307\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.160250759124756, Val_loss 3.6126937866210938\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.163300371170044, Val_loss 3.6220133304595947\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.150953769683838, Val_loss 3.601980447769165\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.14709734916687, Val_loss 3.6074554920196533\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 37, Train_Loss 3.1931724548339844, Val_loss 3.666475296020508\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.152380132675171, Val_loss 3.6562821865081787\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 39, Train_Loss 3.1528042554855347, Val_loss 3.6608774662017822\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.133350944519043, Val_loss 3.5770256519317627\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.150776720046997, Val_loss 3.635017156600952\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 42, Train_Loss 3.122835063934326, Val_loss 3.6316936016082764\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 43, Train_Loss 3.141456651687622, Val_loss 3.6576106548309326\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.126180553436279, Val_loss 3.5828723907470703\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1386207580566405, Val_loss 3.694687843322754\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 46, Train_Loss 3.121064472198486, Val_loss 3.5548908710479736\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.140391778945923, Val_loss 3.6937360763549805\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 48, Train_Loss 3.1180699110031127, Val_loss 3.6032874584198\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.133683967590332, Val_loss 3.652531862258911\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 50, Train_Loss 3.117786979675293, Val_loss 3.584327459335327\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.157655620574951, Val_loss 3.7173054218292236\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 52, Train_Loss 3.1284626483917237, Val_loss 3.7286922931671143\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 53, Train_Loss 3.11598002910614, Val_loss 3.6497809886932373\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 54, Train_Loss 3.1022990703582765, Val_loss 3.6434803009033203\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 55, Train_Loss 3.0997781991958617, Val_loss 3.597193479537964\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 56, Train_Loss 3.0961017370224, Val_loss 3.6588847637176514\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 57, Train_Loss 3.112640452384949, Val_loss 3.587575674057007\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.1227128744125365, Val_loss 3.655886650085449\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 59, Train_Loss 3.090149760246277, Val_loss 3.6159069538116455\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 60, Train_Loss 3.093500518798828, Val_loss 3.638833999633789\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 61, Train_Loss 3.123699760437012, Val_loss 3.669051170349121\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 62, Train_Loss 3.100154662132263, Val_loss 3.66939377784729\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 63, Train_Loss 3.113844704627991, Val_loss 3.65195631980896\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.108933424949646, Val_loss 3.682783842086792\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 65, Train_Loss 3.1010146141052246, Val_loss 3.638524055480957\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 66, Train_Loss 3.0901240587234495, Val_loss 3.6771934032440186\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 67, Train_Loss 3.108878564834595, Val_loss 3.7105414867401123\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 68, Train_Loss 3.1078604221343995, Val_loss 3.6529080867767334\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 69, Train_Loss 3.0816070318222044, Val_loss 3.631922960281372\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 70, Train_Loss 3.1121315956115723, Val_loss 3.7143146991729736\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 71, Train_Loss 3.102797293663025, Val_loss 3.689955949783325\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 72, Train_Loss 3.0779449224472044, Val_loss 3.6543447971343994\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 73, Train_Loss 3.0909815788269044, Val_loss 3.619053602218628\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0679706573486327, Val_loss 3.6429975032806396\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.1102635145187376, Val_loss 3.7080252170562744\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 76, Train_Loss 3.084857368469238, Val_loss 3.63728928565979\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 77, Train_Loss 3.0843238115310667, Val_loss 3.646235227584839\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 78, Train_Loss 3.0745574712753294, Val_loss 3.6537513732910156\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 79, Train_Loss 3.077969264984131, Val_loss 3.627220392227173\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 80, Train_Loss 3.093559217453003, Val_loss 3.6459779739379883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 81, Train_Loss 3.0712491273880005, Val_loss 3.644749641418457\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 82, Train_Loss 3.0846713542938233, Val_loss 3.684941291809082\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 83, Train_Loss 3.075954055786133, Val_loss 3.666435956954956\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 84, Train_Loss 3.070026683807373, Val_loss 3.6695778369903564\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 85, Train_Loss 3.0638752698898317, Val_loss 3.632636785507202\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 86, Train_Loss 3.1139691352844237, Val_loss 3.6660006046295166\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 87, Train_Loss 3.087114453315735, Val_loss 3.647841453552246\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 88, Train_Loss 3.0675127506256104, Val_loss 3.663642168045044\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 89, Train_Loss 3.0723748445510863, Val_loss 3.65765643119812\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 90, Train_Loss 3.0866578578948975, Val_loss 3.6826038360595703\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 91, Train_Loss 3.0780677318573, Val_loss 3.6612253189086914\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 92, Train_Loss 3.0959964990615845, Val_loss 3.6696090698242188\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 93, Train_Loss 3.083714723587036, Val_loss 3.6740643978118896\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 94, Train_Loss 3.0836322784423826, Val_loss 3.6636531352996826\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 95, Train_Loss 3.0743717908859254, Val_loss 3.644859552383423\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 96, Train_Loss 3.093174457550049, Val_loss 3.657249689102173\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 97, Train_Loss 3.070086431503296, Val_loss 3.6401426792144775\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 98, Train_Loss 3.092910408973694, Val_loss 3.63667893409729\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 99, Train_Loss 3.095111536979675, Val_loss 3.6748733520507812\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 100, Train_Loss 3.072889471054077, Val_loss 3.640615463256836\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 1, Train_Loss 3.9294864177703857, Val_loss 4.175761699676514\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.116934537887573, Val_loss 4.11179780960083\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.061142802238464, Val_loss 4.03611946105957\n",
      "Train_acc_top_20 0.075\tTrain_acc_top_30 0.0938\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.33\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9498643398284914, Val_loss 3.958139181137085\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 5, Train_Loss 3.854162645339966, Val_loss 3.9333431720733643\n",
      "Train_acc_top_20 0.1562\tTrain_acc_top_30 0.2188\tTrain_acc_top_40 0.3063\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.42\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.777218461036682, Val_loss 3.8021113872528076\n",
      "Train_acc_top_20 0.3063\tTrain_acc_top_30 0.45\tTrain_acc_top_40 0.55\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 7, Train_Loss 3.6890970945358275, Val_loss 3.767054796218872\n",
      "Train_acc_top_20 0.6125\tTrain_acc_top_30 0.8187\tTrain_acc_top_40 0.8875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.644160771369934, Val_loss 3.6942501068115234\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5744152784347536, Val_loss 3.6647398471832275\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.5202962875366213, Val_loss 3.608724355697632\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.47219922542572, Val_loss 3.6304943561553955\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.4273339033126833, Val_loss 3.6053240299224854\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.4235766887664796, Val_loss 3.586944341659546\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.345646786689758, Val_loss 3.6225545406341553\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.352143669128418, Val_loss 3.634850263595581\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3460072755813597, Val_loss 3.6611557006835938\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.3097695112228394, Val_loss 3.655167579650879\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.2743115425109863, Val_loss 3.61896014213562\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2552576780319216, Val_loss 3.6211488246917725\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.2879875183105467, Val_loss 3.6150543689727783\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.245101547241211, Val_loss 3.5809717178344727\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2386289834976196, Val_loss 3.6524946689605713\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 23, Train_Loss 3.200805997848511, Val_loss 3.6312313079833984\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.2197360754013062, Val_loss 3.620896577835083\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.224657940864563, Val_loss 3.6181535720825195\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 26, Train_Loss 3.2072506189346313, Val_loss 3.701559066772461\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.2116329431533814, Val_loss 3.6182711124420166\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.190595507621765, Val_loss 3.612537384033203\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.1727645635604858, Val_loss 3.638051748275757\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 30, Train_Loss 3.189194178581238, Val_loss 3.632788896560669\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1666421413421633, Val_loss 3.584378480911255\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.158180046081543, Val_loss 3.6096184253692627\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.194881725311279, Val_loss 3.5779154300689697\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1584620237350465, Val_loss 3.6008269786834717\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1405980587005615, Val_loss 3.6015450954437256\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1634064435958864, Val_loss 3.6288681030273438\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.1547657012939454, Val_loss 3.600288152694702\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1630287885665895, Val_loss 3.602689027786255\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.115705060958862, Val_loss 3.6045186519622803\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.1470715522766115, Val_loss 3.6028287410736084\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1342421531677247, Val_loss 3.6307075023651123\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.126353716850281, Val_loss 3.6366336345672607\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.13824303150177, Val_loss 3.6177051067352295\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.144066405296326, Val_loss 3.6022655963897705\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.125247073173523, Val_loss 3.6514320373535156\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.167250633239746, Val_loss 3.617333173751831\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1340821266174315, Val_loss 3.6017894744873047\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.109056901931763, Val_loss 3.5894105434417725\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1136181592941283, Val_loss 3.611818552017212\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.1093003511428834, Val_loss 3.5884876251220703\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.1137738704681395, Val_loss 3.6432182788848877\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.0923829317092895, Val_loss 3.621194839477539\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.1171027421951294, Val_loss 3.6188628673553467\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.098632836341858, Val_loss 3.577522039413452\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.0993611097335814, Val_loss 3.5940048694610596\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.0865288019180297, Val_loss 3.573406934738159\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.12151038646698, Val_loss 3.6239986419677734\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.088514041900635, Val_loss 3.6376760005950928\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.108169984817505, Val_loss 3.614480972290039\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 60, Train_Loss 3.1236335039138794, Val_loss 3.62311053276062\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.110310769081116, Val_loss 3.6216790676116943\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.097434663772583, Val_loss 3.6274235248565674\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 63, Train_Loss 3.0853904724121093, Val_loss 3.6240322589874268\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.0790005207061766, Val_loss 3.6029040813446045\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.094520354270935, Val_loss 3.620558023452759\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.1254292011260985, Val_loss 3.6304595470428467\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.1064027309417725, Val_loss 3.5446999073028564\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.086601495742798, Val_loss 3.563413619995117\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.090689849853516, Val_loss 3.592022180557251\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.09581618309021, Val_loss 3.618297576904297\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.0974213600158693, Val_loss 3.615248680114746\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.0677757978439333, Val_loss 3.5971949100494385\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.088897633552551, Val_loss 3.620314836502075\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.0822353601455688, Val_loss 3.608274459838867\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.063742518424988, Val_loss 3.5798308849334717\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.096627140045166, Val_loss 3.5675575733184814\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0809465885162353, Val_loss 3.569037675857544\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0897393941879274, Val_loss 3.6163341999053955\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.094670224189758, Val_loss 3.599222421646118\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.101255512237549, Val_loss 3.5883028507232666\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.1019526720046997, Val_loss 3.609910249710083\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1084098339080812, Val_loss 3.6132752895355225\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0829852342605593, Val_loss 3.6312644481658936\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.086915397644043, Val_loss 3.608255386352539\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.088111686706543, Val_loss 3.583669900894165\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0855710029602053, Val_loss 3.5860555171966553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.0804315567016602, Val_loss 3.5962703227996826\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.1004030227661135, Val_loss 3.5904791355133057\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.0699894189834596, Val_loss 3.585878372192383\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.08505322933197, Val_loss 3.590404748916626\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.091671586036682, Val_loss 3.5742616653442383\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.092108941078186, Val_loss 3.5726006031036377\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.0651659250259398, Val_loss 3.5656726360321045\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0858601093292237, Val_loss 3.609029531478882\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.0922402858734133, Val_loss 3.581753969192505\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.1043601989746095, Val_loss 3.5935285091400146\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.094606304168701, Val_loss 3.583859443664551\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.109873628616333, Val_loss 3.6277120113372803\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.067540979385376, Val_loss 3.584968328475952\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.093579363822937, Val_loss 3.575268030166626\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9292180061340334, Val_loss 4.230564117431641\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.107052326202393, Val_loss 4.257840633392334\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.02214834690094, Val_loss 4.309884071350098\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.892120051383972, Val_loss 4.186606407165527\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 5, Train_Loss 3.8135191917419435, Val_loss 4.138288974761963\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 6, Train_Loss 3.7370980978012085, Val_loss 3.894740343093872\n",
      "Train_acc_top_20 0.2313\tTrain_acc_top_30 0.3875\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.658005952835083, Val_loss 3.7528398036956787\n",
      "Train_acc_top_20 0.5625\tTrain_acc_top_30 0.7063\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.614664578437805, Val_loss 3.7243034839630127\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.564679670333862, Val_loss 3.709702253341675\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.536758470535278, Val_loss 3.6400091648101807\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.449059844017029, Val_loss 3.6659488677978516\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4405276775360107, Val_loss 3.684431314468384\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.402243161201477, Val_loss 3.6202681064605713\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.386133408546448, Val_loss 3.6027212142944336\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3524922132492065, Val_loss 3.5855166912078857\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.366743326187134, Val_loss 3.562000274658203\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.320675277709961, Val_loss 3.6627423763275146\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.3231297016143797, Val_loss 3.6461994647979736\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2889394521713258, Val_loss 3.565098524093628\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2648798704147337, Val_loss 3.599130868911743\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.259034752845764, Val_loss 3.5299875736236572\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.252159094810486, Val_loss 3.6007869243621826\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2239476442337036, Val_loss 3.5570735931396484\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.2312451124191286, Val_loss 3.5583126544952393\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.2140622615814207, Val_loss 3.6103827953338623\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.206123876571655, Val_loss 3.5602540969848633\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.1910492420196532, Val_loss 3.6022720336914062\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.188708233833313, Val_loss 3.551689863204956\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.2026202201843263, Val_loss 3.6163103580474854\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.2169037103652953, Val_loss 3.563974142074585\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.18436975479126, Val_loss 3.574819564819336\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1908761262893677, Val_loss 3.5681049823760986\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.181785750389099, Val_loss 3.597641944885254\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.1543949604034425, Val_loss 3.571169853210449\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1502296686172486, Val_loss 3.561251640319824\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.17962646484375, Val_loss 3.5716826915740967\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.2086344003677367, Val_loss 3.749469518661499\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1764575004577638, Val_loss 3.4998104572296143\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1756951332092287, Val_loss 3.5703842639923096\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 40, Train_Loss 3.1890954971313477, Val_loss 3.532874345779419\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.1525967597961424, Val_loss 3.5572006702423096\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1429358959197997, Val_loss 3.5887959003448486\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.1380987405776977, Val_loss 3.5945682525634766\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1552062034606934, Val_loss 3.5483551025390625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.122771954536438, Val_loss 3.52718448638916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1376452922821043, Val_loss 3.5972251892089844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1495726346969604, Val_loss 3.536635637283325\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.118462252616882, Val_loss 3.5209503173828125\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1380393505096436, Val_loss 3.558037519454956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1111985445022583, Val_loss 3.5645458698272705\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1134623289108276, Val_loss 3.5782177448272705\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1161673069000244, Val_loss 3.5295121669769287\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.144930124282837, Val_loss 3.5574090480804443\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1295918464660644, Val_loss 3.6042394638061523\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1515050888061524, Val_loss 3.5540246963500977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1216269016265867, Val_loss 3.5699355602264404\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1234824419021607, Val_loss 3.5827839374542236\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.099544048309326, Val_loss 3.5358312129974365\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1085061550140383, Val_loss 3.5779430866241455\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.0896025896072388, Val_loss 3.576120376586914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1311210870742796, Val_loss 3.5534000396728516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.0910828828811647, Val_loss 3.564493179321289\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.109752917289734, Val_loss 3.5579159259796143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.120777416229248, Val_loss 3.6288845539093018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.0971463680267335, Val_loss 3.5423481464385986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.0886916160583495, Val_loss 3.615492582321167\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.0915014266967775, Val_loss 3.5206892490386963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.093088412284851, Val_loss 3.5685901641845703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.1023128747940065, Val_loss 3.587254285812378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1012622833251955, Val_loss 3.6150591373443604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.1204426765441893, Val_loss 3.5833632946014404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.088988184928894, Val_loss 3.581387519836426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0988796234130858, Val_loss 3.5755159854888916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.1218696355819704, Val_loss 3.624293565750122\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0826215505599976, Val_loss 3.5952298641204834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.083751392364502, Val_loss 3.5772361755371094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0938372373580934, Val_loss 3.542970895767212\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.074738359451294, Val_loss 3.5761795043945312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.086884021759033, Val_loss 3.55533766746521\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1276745319366457, Val_loss 3.5495965480804443\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.1065932273864747, Val_loss 3.5692031383514404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1158732175827026, Val_loss 3.571949005126953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.099115514755249, Val_loss 3.573237419128418\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0819759607315063, Val_loss 3.5207722187042236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.0975934982299806, Val_loss 3.5657527446746826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0876653671264647, Val_loss 3.5369956493377686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.0633503913879396, Val_loss 3.5145957469940186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.106972885131836, Val_loss 3.5273396968841553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.1033881664276124, Val_loss 3.551588773727417\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0921600341796873, Val_loss 3.5209646224975586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.127773666381836, Val_loss 3.5273799896240234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.0983179330825807, Val_loss 3.5800492763519287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.079178237915039, Val_loss 3.5840561389923096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0895768642425536, Val_loss 3.549539804458618\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.0890594482421876, Val_loss 3.5249836444854736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.081370806694031, Val_loss 3.594558000564575\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.1009494066238403, Val_loss 3.5729305744171143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.080246663093567, Val_loss 3.5497524738311768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0906162738800047, Val_loss 3.549372911453247\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.089677572250366, Val_loss 3.5641708374023438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9338965892791746, Val_loss 4.275838851928711\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.111823654174804, Val_loss 4.21068811416626\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.032766199111938, Val_loss 4.2353997230529785\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9048988819122314, Val_loss 4.182181358337402\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.831185483932495, Val_loss 4.114320278167725\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7178651094436646, Val_loss 3.8600780963897705\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.6686740159988402, Val_loss 3.72339129447937\n",
      "Train_acc_top_20 0.6062\tTrain_acc_top_30 0.8125\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.6190608024597166, Val_loss 3.6691315174102783\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5432215213775633, Val_loss 3.6756229400634766\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.489026951789856, Val_loss 3.6665236949920654\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.462666153907776, Val_loss 3.6268444061279297\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4335000038146974, Val_loss 3.604503631591797\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.413517117500305, Val_loss 3.5790092945098877\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.351331090927124, Val_loss 3.575995445251465\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.351616907119751, Val_loss 3.5884151458740234\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.345713758468628, Val_loss 3.567781686782837\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.306549644470215, Val_loss 3.626398801803589\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.3142003297805784, Val_loss 3.608527421951294\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2654903888702393, Val_loss 3.6670753955841064\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.2798712253570557, Val_loss 3.545992851257324\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 21, Train_Loss 3.2809720754623415, Val_loss 3.4996166229248047\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.2442442178726196, Val_loss 3.581719160079956\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.2260656118392945, Val_loss 3.5614969730377197\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.219114971160889, Val_loss 3.5912437438964844\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.20404691696167, Val_loss 3.6555774211883545\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.2480335235595703, Val_loss 3.7813479900360107\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 27, Train_Loss 3.2363790035247804, Val_loss 3.566045045852661\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.2047607421875, Val_loss 3.573808431625366\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.219905972480774, Val_loss 3.531277894973755\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.180967926979065, Val_loss 3.5173110961914062\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.228518486022949, Val_loss 3.584470510482788\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.161049556732178, Val_loss 3.529071569442749\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.183439350128174, Val_loss 3.5433151721954346\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.211056852340698, Val_loss 3.523202657699585\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.185360908508301, Val_loss 3.561882257461548\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.17674343585968, Val_loss 3.6006851196289062\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.1529255867004395, Val_loss 3.5278520584106445\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1184903144836427, Val_loss 3.518922805786133\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.1343071699142455, Val_loss 3.5997257232666016\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1322510719299315, Val_loss 3.5147058963775635\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1607351779937742, Val_loss 3.513021469116211\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1403619050979614, Val_loss 3.611893653869629\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1571853876113893, Val_loss 3.5077362060546875\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1504733324050904, Val_loss 3.5510520935058594\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.1319576501846313, Val_loss 3.5424392223358154\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.128455114364624, Val_loss 3.587707281112671\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1308089017868044, Val_loss 3.5421924591064453\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.154226851463318, Val_loss 3.5867464542388916\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.1112751007080077, Val_loss 3.567098379135132\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1148098707199097, Val_loss 3.502927780151367\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.0928316593170164, Val_loss 3.530872344970703\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.105062961578369, Val_loss 3.484243392944336\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1321707487106325, Val_loss 3.5381860733032227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.122551107406616, Val_loss 3.6066277027130127\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.09769983291626, Val_loss 3.551602363586426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.118198299407959, Val_loss 3.5511722564697266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1055209159851076, Val_loss 3.4696810245513916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.1248159170150758, Val_loss 3.5263354778289795\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.10553297996521, Val_loss 3.5099494457244873\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.131695771217346, Val_loss 3.5641982555389404\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.096696972846985, Val_loss 3.4618098735809326\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0761759996414186, Val_loss 3.489924669265747\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.1051047325134276, Val_loss 3.512964963912964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.089088773727417, Val_loss 3.4919593334198\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.1059261083602907, Val_loss 3.5641841888427734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.08455171585083, Val_loss 3.527959108352661\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0648895263671876, Val_loss 3.495608329772949\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.079389977455139, Val_loss 3.5704457759857178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0932505130767822, Val_loss 3.551647424697876\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1237088680267333, Val_loss 3.522944211959839\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0724554300308227, Val_loss 3.5141334533691406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.069325089454651, Val_loss 3.57384991645813\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.1103177785873415, Val_loss 3.5345475673675537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.0799188137054445, Val_loss 3.5252323150634766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.109720516204834, Val_loss 3.5239927768707275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.104630208015442, Val_loss 3.500565767288208\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.1009028911590577, Val_loss 3.556382417678833\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0647918462753294, Val_loss 3.5046446323394775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.1801520347595216, Val_loss 3.5769035816192627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1044681549072264, Val_loss 3.548051595687866\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.069008135795593, Val_loss 3.5173161029815674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1094084978103638, Val_loss 3.5428783893585205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0914912939071657, Val_loss 3.549105405807495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.1139818906784056, Val_loss 3.553751230239868\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.074267292022705, Val_loss 3.514523506164551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.085721969604492, Val_loss 3.545616865158081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.0805683851242067, Val_loss 3.556304931640625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.0999969720840452, Val_loss 3.5175178050994873\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.054493808746338, Val_loss 3.5357186794281006\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.1245744943618776, Val_loss 3.557239532470703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.090037536621094, Val_loss 3.526273012161255\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0890156984329225, Val_loss 3.521517038345337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.1092284679412843, Val_loss 3.542689323425293\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0786516189575197, Val_loss 3.5373828411102295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.0700634956359862, Val_loss 3.5003855228424072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.125260901451111, Val_loss 3.5627822875976562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.0937346458435058, Val_loss 3.5200328826904297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.082360291481018, Val_loss 3.504894256591797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.1044333457946776, Val_loss 3.5160939693450928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0847630977630613, Val_loss 3.5597259998321533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9345412731170653, Val_loss 4.264009475708008\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.0847595691680905, Val_loss 4.255735397338867\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 3.9944068431854247, Val_loss 4.222360134124756\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.868571710586548, Val_loss 4.077879905700684\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.7503139972686768, Val_loss 3.870725393295288\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.46\t\n",
      "Epoch 6, Train_Loss 3.688395547866821, Val_loss 3.816450357437134\n",
      "Train_acc_top_20 0.3187\tTrain_acc_top_30 0.4562\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.6028538942337036, Val_loss 3.8626558780670166\n",
      "Train_acc_top_20 0.6125\tTrain_acc_top_30 0.7562\tTrain_acc_top_40 0.8562\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.25\tVal_acc_top_40 0.54\t\n",
      "Epoch 8, Train_Loss 3.5695029973983763, Val_loss 3.8618619441986084\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.527642273902893, Val_loss 3.827483892440796\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.38\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.461487317085266, Val_loss 3.7005977630615234\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.40076162815094, Val_loss 3.7440948486328125\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.3971011638641357, Val_loss 3.7597815990448\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.33\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.412963128089905, Val_loss 3.83307147026062\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.58\t\n",
      "Epoch 14, Train_Loss 3.3473863124847414, Val_loss 3.775928258895874\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3071760177612304, Val_loss 3.736513137817383\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.2911768198013305, Val_loss 3.7394027709960938\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.276764249801636, Val_loss 3.797724485397339\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.244399166107178, Val_loss 3.6841886043548584\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.243388843536377, Val_loss 3.7325239181518555\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2355815887451174, Val_loss 3.669743537902832\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.223840832710266, Val_loss 3.7787024974823\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.209628677368164, Val_loss 3.6671416759490967\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.197685956954956, Val_loss 3.690046548843384\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.1922037601470947, Val_loss 3.6618900299072266\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.168582034111023, Val_loss 3.672635316848755\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.225243401527405, Val_loss 3.6169049739837646\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.1857430219650267, Val_loss 3.6476948261260986\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.201060390472412, Val_loss 3.691387176513672\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1754143476486205, Val_loss 3.620384454727173\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.170058989524841, Val_loss 3.618971824645996\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.196252465248108, Val_loss 3.6806933879852295\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.163566541671753, Val_loss 3.6320760250091553\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.14235463142395, Val_loss 3.6917641162872314\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1743947982788088, Val_loss 3.57438588142395\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.152502250671387, Val_loss 3.6138131618499756\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1475495100021362, Val_loss 3.6657841205596924\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1399083137512207, Val_loss 3.574517011642456\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.1568591594696045, Val_loss 3.6658802032470703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.131931257247925, Val_loss 3.617121458053589\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.122886633872986, Val_loss 3.653932571411133\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1338378190994263, Val_loss 3.6538305282592773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1177740335464477, Val_loss 3.6498124599456787\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.121318244934082, Val_loss 3.64398193359375\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1492778301239013, Val_loss 3.583454132080078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.1230206727981566, Val_loss 3.6062605381011963\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1135470867156982, Val_loss 3.617380380630493\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.1278636932373045, Val_loss 3.6702373027801514\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.105236554145813, Val_loss 3.6289665699005127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.165643072128296, Val_loss 3.67514705657959\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1126615047454833, Val_loss 3.5915515422821045\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1706491231918337, Val_loss 3.7121448516845703\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.122196316719055, Val_loss 3.639683961868286\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.111105704307556, Val_loss 3.641019821166992\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1126527309417726, Val_loss 3.636535406112671\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.102850842475891, Val_loss 3.6644604206085205\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.1360653162002565, Val_loss 3.638232469558716\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.118803882598877, Val_loss 3.6820003986358643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.105311870574951, Val_loss 3.658585786819458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.110944986343384, Val_loss 3.6091859340667725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.0917187213897703, Val_loss 3.6079063415527344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1344413280487062, Val_loss 3.710543394088745\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.086847114562988, Val_loss 3.579143762588501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.1318708658218384, Val_loss 3.644683837890625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.1283127546310423, Val_loss 3.7317187786102295\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.104616403579712, Val_loss 3.6239845752716064\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.149549722671509, Val_loss 3.7055795192718506\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.125489115715027, Val_loss 3.7406394481658936\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1382444381713865, Val_loss 3.6471593379974365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.112498235702515, Val_loss 3.7184970378875732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.094185709953308, Val_loss 3.6993353366851807\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.1096217393875123, Val_loss 3.6423709392547607\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0803800582885743, Val_loss 3.6572487354278564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.127018117904663, Val_loss 3.670842409133911\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0927496194839477, Val_loss 3.657761812210083\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.0832571506500246, Val_loss 3.640613555908203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.0856831550598143, Val_loss 3.6222381591796875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0873692512512205, Val_loss 3.6322009563446045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.082275462150574, Val_loss 3.6413259506225586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.1138923168182373, Val_loss 3.6380836963653564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0909369230270385, Val_loss 3.662461996078491\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.098105549812317, Val_loss 3.6468896865844727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1100273609161375, Val_loss 3.669114351272583\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.0966545581817626, Val_loss 3.663531541824341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.0963571786880495, Val_loss 3.64559006690979\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.077085590362549, Val_loss 3.6403777599334717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.099947285652161, Val_loss 3.6378707885742188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.098534107208252, Val_loss 3.669461965560913\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.127488541603088, Val_loss 3.682269811630249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.0703948974609374, Val_loss 3.622546434402466\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.106401228904724, Val_loss 3.6540639400482178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.1075577259063722, Val_loss 3.6576497554779053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.095487093925476, Val_loss 3.6575193405151367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.081525754928589, Val_loss 3.6422317028045654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0966521501541138, Val_loss 3.647359609603882\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.077453279495239, Val_loss 3.6509971618652344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.10602388381958, Val_loss 3.630690574645996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.1036521196365356, Val_loss 3.651435136795044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0951090097427367, Val_loss 3.6522152423858643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.0718202114105226, Val_loss 3.673349380493164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.078132700920105, Val_loss 3.635744094848633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9286442756652833, Val_loss 4.268982410430908\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.100858402252197, Val_loss 4.248992443084717\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.01938374042511, Val_loss 4.207960605621338\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.907621645927429, Val_loss 4.1408467292785645\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.7832529067993166, Val_loss 4.004033088684082\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.6876033782958983, Val_loss 3.8377740383148193\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.375\tTrain_acc_top_40 0.4625\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.6333983898162843, Val_loss 3.7965028285980225\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.8562\tTrain_acc_top_40 0.9125\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.5901341915130613, Val_loss 3.7916011810302734\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5233869314193726, Val_loss 3.7291300296783447\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5016965866088867, Val_loss 3.7624053955078125\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.4482493877410887, Val_loss 3.760467767715454\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.419493007659912, Val_loss 3.6646502017974854\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 13, Train_Loss 3.3584912538528444, Val_loss 3.700110673904419\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.337470555305481, Val_loss 3.6570358276367188\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.92\t\n",
      "Epoch 15, Train_Loss 3.2909283876419066, Val_loss 3.6574954986572266\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.2814895153045653, Val_loss 3.6524274349212646\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.2504645347595216, Val_loss 3.6716203689575195\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.256960129737854, Val_loss 3.608140230178833\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.231673073768616, Val_loss 3.640895128250122\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.2160946130752563, Val_loss 3.64007568359375\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2121516466140747, Val_loss 3.6440696716308594\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.207220697402954, Val_loss 3.673760175704956\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.195127272605896, Val_loss 3.6293551921844482\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 24, Train_Loss 3.214595580101013, Val_loss 3.5825679302215576\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.1844731330871583, Val_loss 3.590380907058716\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.2142380475997925, Val_loss 3.6669740676879883\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.1781248092651366, Val_loss 3.6343777179718018\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1895257472991942, Val_loss 3.6625282764434814\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.1677283525466917, Val_loss 3.6051933765411377\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.1612574100494384, Val_loss 3.6934516429901123\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1655641555786134, Val_loss 3.5847702026367188\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1499139308929442, Val_loss 3.600084066390991\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.1585606575012206, Val_loss 3.653209686279297\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 34, Train_Loss 3.159394645690918, Val_loss 3.6381261348724365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.1456544160842896, Val_loss 3.621394157409668\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.138916325569153, Val_loss 3.6087844371795654\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.1397837162017823, Val_loss 3.609144926071167\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.14144549369812, Val_loss 3.6501619815826416\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1733707904815676, Val_loss 3.5673513412475586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.160877323150635, Val_loss 3.6466434001922607\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.157481479644775, Val_loss 3.6581437587738037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.1326691150665282, Val_loss 3.637907028198242\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 43, Train_Loss 3.1412368535995485, Val_loss 3.610112428665161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1208366632461546, Val_loss 3.6096818447113037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.1207977771759032, Val_loss 3.6408779621124268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1292562246322633, Val_loss 3.6131839752197266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1332834243774412, Val_loss 3.6456682682037354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.13597252368927, Val_loss 3.6532437801361084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1224538326263427, Val_loss 3.5685739517211914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1098434209823607, Val_loss 3.622636556625366\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1275105714797973, Val_loss 3.6601407527923584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.141505265235901, Val_loss 3.604717969894409\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1082307577133177, Val_loss 3.6043641567230225\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.119315266609192, Val_loss 3.664356231689453\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.122491192817688, Val_loss 3.626464605331421\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.1183454513549806, Val_loss 3.594980478286743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.099641275405884, Val_loss 3.599090814590454\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.118953013420105, Val_loss 3.6587088108062744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.108223795890808, Val_loss 3.599414825439453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1155385971069336, Val_loss 3.586414098739624\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.1168326854705812, Val_loss 3.6117727756500244\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1168187618255616, Val_loss 3.6310195922851562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1128743410110475, Val_loss 3.574575662612915\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.127554678916931, Val_loss 3.6431591510772705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.120822548866272, Val_loss 3.645428419113159\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.1290255069732664, Val_loss 3.6277472972869873\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0911415100097654, Val_loss 3.612595558166504\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.099808120727539, Val_loss 3.596792459487915\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.081838011741638, Val_loss 3.5981523990631104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1543391942977905, Val_loss 3.608752489089966\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.1005816221237184, Val_loss 3.5938560962677\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.1005764245986938, Val_loss 3.606983184814453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0852991580963134, Val_loss 3.596613645553589\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.091639757156372, Val_loss 3.6124181747436523\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.108079123497009, Val_loss 3.6140012741088867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.110810160636902, Val_loss 3.6308786869049072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0915515184402467, Val_loss 3.615804672241211\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.098452401161194, Val_loss 3.5972578525543213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.1473942756652833, Val_loss 3.5790014266967773\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.1385835886001585, Val_loss 3.6086618900299072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.080273461341858, Val_loss 3.5977580547332764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.1019171714782714, Val_loss 3.598693609237671\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.120226001739502, Val_loss 3.6025075912475586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.095654916763306, Val_loss 3.599660873413086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.094343066215515, Val_loss 3.5833933353424072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.0821142911911013, Val_loss 3.5960121154785156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.88\t\n",
      "Epoch 87, Train_Loss 3.068374228477478, Val_loss 3.60980486869812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.0869378805160523, Val_loss 3.602654457092285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.077992630004883, Val_loss 3.585401773452759\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0610698461532593, Val_loss 3.5941689014434814\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.089610195159912, Val_loss 3.5729563236236572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.111083817481995, Val_loss 3.594822645187378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.1297549962997437, Val_loss 3.583245038986206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.0544988393783568, Val_loss 3.6167385578155518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.0795322179794313, Val_loss 3.592789888381958\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.067517399787903, Val_loss 3.587836503982544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.097016787528992, Val_loss 3.601025342941284\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.109730911254883, Val_loss 3.588144540786743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.0794114589691164, Val_loss 3.5823724269866943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.1069881200790403, Val_loss 3.5796451568603516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.935027289390564, Val_loss 4.217776775360107\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.108693265914917, Val_loss 4.157595157623291\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.026819086074829, Val_loss 4.160614013671875\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.8936390399932863, Val_loss 4.117769718170166\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.8040343284606934, Val_loss 4.136344909667969\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7153425216674805, Val_loss 3.819112777709961\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.4437\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 7, Train_Loss 3.6481115102767943, Val_loss 3.6475722789764404\n",
      "Train_acc_top_20 0.6\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 8, Train_Loss 3.581599259376526, Val_loss 3.59275221824646\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.52964506149292, Val_loss 3.5916643142700195\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5079763889312745, Val_loss 3.539642333984375\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 11, Train_Loss 3.4811858177185058, Val_loss 3.542757749557495\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.4383612871170044, Val_loss 3.539600372314453\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 13, Train_Loss 3.3894560813903807, Val_loss 3.4987783432006836\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 14, Train_Loss 3.367330551147461, Val_loss 3.516481399536133\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.351830315589905, Val_loss 3.528561592102051\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.3448792934417724, Val_loss 3.5096216201782227\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.3574943780899047, Val_loss 3.510014533996582\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.301072597503662, Val_loss 3.5233230590820312\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2947730302810667, Val_loss 3.57303524017334\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.248347306251526, Val_loss 3.4814302921295166\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.25578453540802, Val_loss 3.428119659423828\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 22, Train_Loss 3.2170812606811525, Val_loss 3.442777395248413\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 23, Train_Loss 3.2171053886413574, Val_loss 3.479022741317749\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 24, Train_Loss 3.192353391647339, Val_loss 3.456062078475952\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.214207339286804, Val_loss 3.483241319656372\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 26, Train_Loss 3.1853253126144407, Val_loss 3.4450206756591797\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 27, Train_Loss 3.184274673461914, Val_loss 3.465731382369995\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 28, Train_Loss 3.1863241672515867, Val_loss 3.4569146633148193\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 29, Train_Loss 3.1546823024749755, Val_loss 3.4393370151519775\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 30, Train_Loss 3.169239854812622, Val_loss 3.4744584560394287\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 31, Train_Loss 3.1769567251205446, Val_loss 3.435591459274292\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 32, Train_Loss 3.135677361488342, Val_loss 3.4584004878997803\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1480852603912353, Val_loss 3.4815709590911865\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.1770124197006226, Val_loss 3.410676956176758\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 35, Train_Loss 3.139381241798401, Val_loss 3.4822092056274414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 36, Train_Loss 3.1450976610183714, Val_loss 3.4098927974700928\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 37, Train_Loss 3.1665672063827515, Val_loss 3.4713027477264404\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.126171016693115, Val_loss 3.4531009197235107\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 39, Train_Loss 3.142424130439758, Val_loss 3.462454080581665\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.159083938598633, Val_loss 3.543367385864258\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.167726826667786, Val_loss 3.4758644104003906\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.142510414123535, Val_loss 3.421637773513794\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 43, Train_Loss 3.124614930152893, Val_loss 3.5009686946868896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.1332871437072756, Val_loss 3.482905626296997\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 45, Train_Loss 3.1551202535629272, Val_loss 3.4691226482391357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.96\t\n",
      "Epoch 46, Train_Loss 3.1597993850708006, Val_loss 3.5946104526519775\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1838905572891236, Val_loss 3.4581496715545654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 48, Train_Loss 3.166423726081848, Val_loss 3.497514009475708\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.110478091239929, Val_loss 3.430715322494507\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.132262110710144, Val_loss 3.471806287765503\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.1395689964294435, Val_loss 3.4683587551116943\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 52, Train_Loss 3.1178487062454225, Val_loss 3.5272181034088135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.1030646562576294, Val_loss 3.4624099731445312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 54, Train_Loss 3.144899106025696, Val_loss 3.48679256439209\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.1236826181411743, Val_loss 3.447493314743042\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.145032262802124, Val_loss 3.54474139213562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1371217489242555, Val_loss 3.4744741916656494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.111320424079895, Val_loss 3.4634640216827393\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 59, Train_Loss 3.1116100549697876, Val_loss 3.49455189704895\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.099278378486633, Val_loss 3.4369394779205322\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.1143322229385375, Val_loss 3.4973297119140625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1178966760635376, Val_loss 3.4809205532073975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.111916947364807, Val_loss 3.4816439151763916\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.0818480253219604, Val_loss 3.489600419998169\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 65, Train_Loss 3.0766531944274904, Val_loss 3.4750068187713623\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.1082455635070803, Val_loss 3.518592596054077\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.0986730813980103, Val_loss 3.4791653156280518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 68, Train_Loss 3.0852726459503175, Val_loss 3.4605159759521484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 69, Train_Loss 3.1025847434997558, Val_loss 3.481820821762085\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.1101152896881104, Val_loss 3.4807040691375732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 71, Train_Loss 3.136540150642395, Val_loss 3.4704501628875732\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.132630968093872, Val_loss 3.468735694885254\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.1490629434585573, Val_loss 3.4692633152008057\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.116218113899231, Val_loss 3.4753363132476807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 75, Train_Loss 3.1318853855133058, Val_loss 3.4594554901123047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.110029101371765, Val_loss 3.4816501140594482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.093660259246826, Val_loss 3.4594507217407227\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 78, Train_Loss 3.1259567499160767, Val_loss 3.4755916595458984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 79, Train_Loss 3.1307544469833375, Val_loss 3.473712682723999\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1002102375030516, Val_loss 3.4907066822052\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.111379528045654, Val_loss 3.4771499633789062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 82, Train_Loss 3.1306263208389282, Val_loss 3.4907636642456055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 83, Train_Loss 3.1115877866744994, Val_loss 3.5015926361083984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.097513508796692, Val_loss 3.4863641262054443\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 85, Train_Loss 3.1068019390106203, Val_loss 3.4846887588500977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.183989095687866, Val_loss 3.4906671047210693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.1087156772613525, Val_loss 3.4780073165893555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 88, Train_Loss 3.1042370796203613, Val_loss 3.4743669033050537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 89, Train_Loss 3.1087719678878782, Val_loss 3.4854118824005127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.091380262374878, Val_loss 3.48281192779541\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.0915087699890136, Val_loss 3.4687235355377197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.1372355937957765, Val_loss 3.5040693283081055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.123610329627991, Val_loss 3.5161361694335938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.108756446838379, Val_loss 3.5005428791046143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.0892377614974977, Val_loss 3.4827890396118164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.1044320344924925, Val_loss 3.4833486080169678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.087567687034607, Val_loss 3.46777081489563\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.1143540143966675, Val_loss 3.482555627822876\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 99, Train_Loss 3.126771640777588, Val_loss 3.494464874267578\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.091563415527344, Val_loss 3.4796388149261475\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 1, Train_Loss 3.9315017223358155, Val_loss 4.270338535308838\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.112086391448974, Val_loss 4.217347621917725\n",
      "Train_acc_top_20 0.1437\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.059237146377564, Val_loss 4.183107376098633\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9201892852783202, Val_loss 4.095198631286621\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8464769601821898, Val_loss 4.022175312042236\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7922845602035524, Val_loss 3.8516037464141846\n",
      "Train_acc_top_20 0.225\tTrain_acc_top_30 0.325\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.6878660202026365, Val_loss 3.774752616882324\n",
      "Train_acc_top_20 0.5813\tTrain_acc_top_30 0.7375\tTrain_acc_top_40 0.8438\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.621912956237793, Val_loss 3.7087793350219727\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5720835447311403, Val_loss 3.689664840698242\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.549485278129578, Val_loss 3.705718755722046\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4985739469528196, Val_loss 3.720585584640503\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.4409954071044924, Val_loss 3.7211754322052\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.395940399169922, Val_loss 3.7056713104248047\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.3711091041564942, Val_loss 3.604945421218872\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3297927379608154, Val_loss 3.6405694484710693\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3199378728866575, Val_loss 3.6872005462646484\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.2644510507583617, Val_loss 3.625490427017212\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.327604818344116, Val_loss 3.614248275756836\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.3133352518081667, Val_loss 4.010341167449951\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 20, Train_Loss 3.266566300392151, Val_loss 3.6040585041046143\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.244015431404114, Val_loss 3.576605796813965\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.210546064376831, Val_loss 3.5900490283966064\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2090531826019286, Val_loss 3.5941531658172607\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2122365713119505, Val_loss 3.5968682765960693\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.187536597251892, Val_loss 3.574659585952759\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.221906328201294, Val_loss 3.8914661407470703\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 27, Train_Loss 3.1881020307540893, Val_loss 3.5921742916107178\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.17039692401886, Val_loss 3.5482447147369385\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.165052652359009, Val_loss 3.549989938735962\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1640302181243896, Val_loss 3.5755460262298584\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1495057582855224, Val_loss 3.560856580734253\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.157990598678589, Val_loss 3.628422498703003\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1646979570388796, Val_loss 3.609273910522461\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.1338686466217043, Val_loss 3.5761988162994385\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1523553133010864, Val_loss 3.590970039367676\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1236066818237305, Val_loss 3.5983190536499023\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.1329152822494506, Val_loss 3.621539831161499\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.171960783004761, Val_loss 3.7392895221710205\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 39, Train_Loss 3.1478981256484984, Val_loss 3.668015718460083\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1306631088256838, Val_loss 3.646677255630493\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.134748935699463, Val_loss 3.6377334594726562\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.13880877494812, Val_loss 3.6558339595794678\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1279859066009523, Val_loss 3.5813400745391846\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.146004629135132, Val_loss 3.626148223876953\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1008545637130736, Val_loss 3.611567735671997\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.130742049217224, Val_loss 3.7083547115325928\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.116956925392151, Val_loss 3.5868005752563477\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 48, Train_Loss 3.138596534729004, Val_loss 3.7250916957855225\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.117367959022522, Val_loss 3.622257947921753\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1148581504821777, Val_loss 3.7114551067352295\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.135653018951416, Val_loss 3.609686851501465\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1108171463012697, Val_loss 3.6405675411224365\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.0788713455200196, Val_loss 3.657857656478882\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1278489589691163, Val_loss 3.6460626125335693\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1192625045776365, Val_loss 3.6952240467071533\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1081342458724976, Val_loss 3.606382131576538\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1371607303619387, Val_loss 3.601240873336792\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.0882688999176025, Val_loss 3.674314260482788\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1442755222320558, Val_loss 3.6846020221710205\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.1073951005935667, Val_loss 3.630439043045044\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.121574568748474, Val_loss 3.703993558883667\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.1172820806503294, Val_loss 3.5636720657348633\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1194172143936156, Val_loss 3.625822067260742\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0890198945999146, Val_loss 3.653984308242798\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.090295195579529, Val_loss 3.6068828105926514\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.1380895137786866, Val_loss 3.6081762313842773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.109555649757385, Val_loss 3.6256392002105713\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.0796534538269045, Val_loss 3.648341178894043\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0998950958251954, Val_loss 3.6326777935028076\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1365986585617067, Val_loss 3.6462419033050537\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0884193181991577, Val_loss 3.6525070667266846\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.0917373418807985, Val_loss 3.629634141921997\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.100171971321106, Val_loss 3.620821952819824\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.1131248235702516, Val_loss 3.684286117553711\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.083309841156006, Val_loss 3.6432316303253174\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.119953751564026, Val_loss 3.6486656665802\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0979157447814942, Val_loss 3.6541645526885986\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.1047054052352907, Val_loss 3.6376240253448486\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.0930939435958864, Val_loss 3.6013243198394775\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.0951940774917603, Val_loss 3.678476095199585\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.094120669364929, Val_loss 3.637345314025879\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.1208909034729, Val_loss 3.616452217102051\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0909889459609987, Val_loss 3.6684436798095703\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.110735034942627, Val_loss 3.5749151706695557\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.106733536720276, Val_loss 3.6308085918426514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.1052647829055786, Val_loss 3.6116256713867188\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.1389002799987793, Val_loss 3.6612777709960938\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.0857195377349855, Val_loss 3.6244494915008545\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.124024248123169, Val_loss 3.646786689758301\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.1011291980743407, Val_loss 3.6836135387420654\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.091884732246399, Val_loss 3.6622722148895264\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.1010037660598755, Val_loss 3.6450979709625244\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.1211664199829103, Val_loss 3.6724777221679688\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.085574007034302, Val_loss 3.6483726501464844\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0845550060272218, Val_loss 3.631366729736328\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0882813692092896, Val_loss 3.5975935459136963\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.106734848022461, Val_loss 3.610257863998413\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.1299161434173586, Val_loss 3.6003544330596924\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.0918302059173586, Val_loss 3.612684488296509\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.12441565990448, Val_loss 3.620616912841797\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9359544992446898, Val_loss 4.1994547843933105\n",
      "Train_acc_top_20 0.1437\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.38\tVal_acc_top_40 0.38\t\n",
      "Epoch 2, Train_Loss 4.119712257385254, Val_loss 4.1503424644470215\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.38\t\n",
      "Epoch 3, Train_Loss 4.052887725830078, Val_loss 4.081056118011475\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.33\tVal_acc_top_40 0.38\t\n",
      "Epoch 4, Train_Loss 3.9309002161026, Val_loss 4.048102855682373\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.125\tTrain_acc_top_40 0.1562\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 5, Train_Loss 3.8497657060623167, Val_loss 4.016607284545898\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.7809093713760378, Val_loss 3.697382688522339\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.3812\tTrain_acc_top_40 0.4437\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 7, Train_Loss 3.711077642440796, Val_loss 3.774402618408203\n",
      "Train_acc_top_20 0.5188\tTrain_acc_top_30 0.6813\tTrain_acc_top_40 0.75\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.6329369068145754, Val_loss 3.5965492725372314\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5865357637405397, Val_loss 3.5598647594451904\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5337024450302126, Val_loss 3.539161443710327\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.5099265575408936, Val_loss 3.5529096126556396\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4689627408981325, Val_loss 3.49212908744812\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.406542181968689, Val_loss 3.492438316345215\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.3744673252105715, Val_loss 3.4640557765960693\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.33457772731781, Val_loss 3.4804086685180664\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.3109927654266356, Val_loss 3.4705848693847656\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 17, Train_Loss 3.2931305170059204, Val_loss 3.5542213916778564\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.2689122438430784, Val_loss 3.509457588195801\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2478444576263428, Val_loss 3.480015993118286\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.247526669502258, Val_loss 3.582404375076294\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.2142998218536376, Val_loss 3.4942824840545654\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2178414821624757, Val_loss 3.524367332458496\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 23, Train_Loss 3.199379396438599, Val_loss 3.5114030838012695\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.184161567687988, Val_loss 3.5487194061279297\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2322504043579103, Val_loss 3.5774013996124268\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.181505012512207, Val_loss 3.5070788860321045\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.182800817489624, Val_loss 3.5293941497802734\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.17772581577301, Val_loss 3.489879846572876\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.1479812383651735, Val_loss 3.530658721923828\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.16672682762146, Val_loss 3.530632734298706\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.164046287536621, Val_loss 3.5478715896606445\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.140076208114624, Val_loss 3.5527780055999756\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.155739426612854, Val_loss 3.516979932785034\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.164975666999817, Val_loss 3.546201467514038\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1549301624298094, Val_loss 3.5166311264038086\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.13066725730896, Val_loss 3.492708206176758\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 37, Train_Loss 3.131147336959839, Val_loss 3.5351638793945312\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.1444238424301147, Val_loss 3.5427935123443604\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1416585206985475, Val_loss 3.578977584838867\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.102617335319519, Val_loss 3.5737879276275635\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.119409513473511, Val_loss 3.5390195846557617\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.1249917268753054, Val_loss 3.5726985931396484\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.0938228607177733, Val_loss 3.5656626224517822\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.129405641555786, Val_loss 3.5637452602386475\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.162159466743469, Val_loss 3.561046838760376\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.120458388328552, Val_loss 3.54738450050354\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1428045988082887, Val_loss 3.5337135791778564\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.102497911453247, Val_loss 3.508357286453247\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.1282596349716187, Val_loss 3.54650616645813\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.118972063064575, Val_loss 3.5367190837860107\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.127740168571472, Val_loss 3.4996635913848877\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1594976663589476, Val_loss 3.5506889820098877\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.0994625329971313, Val_loss 3.559516191482544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.1056852102279664, Val_loss 3.5384225845336914\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.1295592308044435, Val_loss 3.5721404552459717\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.124085235595703, Val_loss 3.5594675540924072\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1094002723693848, Val_loss 3.518925905227661\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.0986830472946165, Val_loss 3.572131872177124\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.155858111381531, Val_loss 3.4866249561309814\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.126289796829224, Val_loss 3.5363476276397705\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.125971961021423, Val_loss 3.4954183101654053\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1136252164840696, Val_loss 3.5172994136810303\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1236153841018677, Val_loss 3.5116281509399414\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.098063850402832, Val_loss 3.545140504837036\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.089441728591919, Val_loss 3.5809967517852783\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.105832004547119, Val_loss 3.553335189819336\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0539957761764525, Val_loss 3.5373809337615967\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1173823833465577, Val_loss 3.4947690963745117\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.123057007789612, Val_loss 3.552771806716919\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.114658737182617, Val_loss 3.5881118774414062\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.1169286012649535, Val_loss 3.50551700592041\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.140483355522156, Val_loss 3.5760889053344727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.1138604640960694, Val_loss 3.534602403640747\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.122286009788513, Val_loss 3.555730104446411\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0990978717803954, Val_loss 3.561711072921753\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.0966906785964965, Val_loss 3.5478928089141846\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0979613065719604, Val_loss 3.524531126022339\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.1210261583328247, Val_loss 3.5395822525024414\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.115931677818298, Val_loss 3.5294735431671143\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.102746772766113, Val_loss 3.5257742404937744\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.110183095932007, Val_loss 3.5354483127593994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.103699231147766, Val_loss 3.560039520263672\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.098302388191223, Val_loss 3.532733678817749\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0894078254699706, Val_loss 3.5512237548828125\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.1104357481002807, Val_loss 3.5438201427459717\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.1179465770721437, Val_loss 3.5768258571624756\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.103861403465271, Val_loss 3.5560100078582764\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.0966832876205443, Val_loss 3.53943133354187\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.081946301460266, Val_loss 3.5368287563323975\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.1459641218185426, Val_loss 3.5285282135009766\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.124475336074829, Val_loss 3.5395727157592773\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.095197319984436, Val_loss 3.5418691635131836\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.0947521686553956, Val_loss 3.5767576694488525\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.107201910018921, Val_loss 3.516339063644409\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.108022141456604, Val_loss 3.5336034297943115\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0943045616149902, Val_loss 3.535263776779175\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.1709607362747194, Val_loss 3.549846649169922\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.13180091381073, Val_loss 3.5456650257110596\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.1389738082885743, Val_loss 3.5611674785614014\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.089965987205505, Val_loss 3.5733087062835693\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9314075708389282, Val_loss 4.310108661651611\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.08\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.105152273178101, Val_loss 4.293125629425049\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.014740729331971, Val_loss 4.33308744430542\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.8669721126556396, Val_loss 4.291305065155029\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 5, Train_Loss 3.7853111743927004, Val_loss 4.110072612762451\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 6, Train_Loss 3.6913771867752074, Val_loss 3.819807767868042\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.375\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 7, Train_Loss 3.6414567708969114, Val_loss 3.6771020889282227\n",
      "Train_acc_top_20 0.6\tTrain_acc_top_30 0.75\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.5970014333724976, Val_loss 3.731896162033081\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.553603506088257, Val_loss 3.687181234359741\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.50102858543396, Val_loss 3.6028597354888916\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4844546556472777, Val_loss 3.6553542613983154\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 12, Train_Loss 3.4537372827529906, Val_loss 3.628568410873413\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.390540337562561, Val_loss 3.7056891918182373\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3736650943756104, Val_loss 3.56796932220459\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.374541711807251, Val_loss 3.5435822010040283\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.326542592048645, Val_loss 3.6359779834747314\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.3003941774368286, Val_loss 3.6685421466827393\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.296533465385437, Val_loss 3.5410327911376953\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2635859489440917, Val_loss 3.6608283519744873\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.268363285064697, Val_loss 3.5906264781951904\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.260981225967407, Val_loss 3.609158515930176\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.218190550804138, Val_loss 3.610067367553711\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.204275441169739, Val_loss 3.594978094100952\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 24, Train_Loss 3.2446141481399535, Val_loss 3.535289764404297\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2107495784759523, Val_loss 3.6263444423675537\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.1923455715179445, Val_loss 3.5536720752716064\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.1936712980270388, Val_loss 3.5315191745758057\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 28, Train_Loss 3.1866933584213255, Val_loss 3.681978940963745\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.1843563318252563, Val_loss 3.5465497970581055\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 30, Train_Loss 3.181458902359009, Val_loss 3.502363920211792\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.1731287479400634, Val_loss 3.524928092956543\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.1556781053543093, Val_loss 3.525284767150879\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.151945209503174, Val_loss 3.5936567783355713\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.1883286237716675, Val_loss 3.5511624813079834\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.175642466545105, Val_loss 3.659046173095703\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1452393770217895, Val_loss 3.5112578868865967\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 37, Train_Loss 3.1482150077819826, Val_loss 3.520836591720581\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.146814203262329, Val_loss 3.570422410964966\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1425143003463747, Val_loss 3.4657304286956787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.152718710899353, Val_loss 3.5082428455352783\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.151247262954712, Val_loss 3.485823392868042\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.1259583950042726, Val_loss 3.493462562561035\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.1334992408752442, Val_loss 3.4885284900665283\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.106109881401062, Val_loss 3.478726625442505\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 45, Train_Loss 3.1386144399642943, Val_loss 3.5624377727508545\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1191155672073365, Val_loss 3.4893085956573486\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.11225802898407, Val_loss 3.5394256114959717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 48, Train_Loss 3.0942829608917237, Val_loss 3.51578688621521\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.1216023683547975, Val_loss 3.526697874069214\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.1007137537002563, Val_loss 3.5681841373443604\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.1239901781082153, Val_loss 3.531801223754883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.1249359130859373, Val_loss 3.508056879043579\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.080739450454712, Val_loss 3.5360543727874756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 54, Train_Loss 3.1042724609375, Val_loss 3.5195696353912354\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.1078211069107056, Val_loss 3.5115432739257812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.09626727104187, Val_loss 3.5085513591766357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1418099403381348, Val_loss 3.5439441204071045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.105424499511719, Val_loss 3.556116819381714\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.107781744003296, Val_loss 3.5241899490356445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.109970045089722, Val_loss 3.510067939758301\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.097476005554199, Val_loss 3.509481191635132\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.114158844947815, Val_loss 3.5382258892059326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.1051172971725465, Val_loss 3.5761730670928955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.104692840576172, Val_loss 3.538106918334961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.1091745376586912, Val_loss 3.5525035858154297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 66, Train_Loss 3.107257103919983, Val_loss 3.5224647521972656\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.112139272689819, Val_loss 3.5025880336761475\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.100269150733948, Val_loss 3.5105552673339844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.108889937400818, Val_loss 3.4898040294647217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.1024137496948243, Val_loss 3.513725996017456\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.0949806451797484, Val_loss 3.5047178268432617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.0916857004165648, Val_loss 3.53076434135437\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.1239196062088013, Val_loss 3.5243513584136963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 74, Train_Loss 3.1153998136520387, Val_loss 3.5151844024658203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 75, Train_Loss 3.1064474105834963, Val_loss 3.5289928913116455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.1016827821731567, Val_loss 3.515167236328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.1202606439590452, Val_loss 3.5277211666107178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.1516157388687134, Val_loss 3.5122196674346924\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.1164611339569093, Val_loss 3.530876874923706\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.0850250244140627, Val_loss 3.5058882236480713\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.116094398498535, Val_loss 3.542710065841675\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.10192334651947, Val_loss 3.5189459323883057\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.0925402879714965, Val_loss 3.4952898025512695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.102445101737976, Val_loss 3.5486831665039062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.094709801673889, Val_loss 3.5330286026000977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.116493248939514, Val_loss 3.513054847717285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.098730540275574, Val_loss 3.5106399059295654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.1108597993850706, Val_loss 3.474755048751831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.099314260482788, Val_loss 3.514636754989624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1111639022827147, Val_loss 3.5041134357452393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.0936752557754517, Val_loss 3.5014753341674805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.117909574508667, Val_loss 3.546809196472168\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.1050641536712646, Val_loss 3.5234880447387695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.1037070751190186, Val_loss 3.499506711959839\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.130012607574463, Val_loss 3.518842935562134\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.104471778869629, Val_loss 3.5115807056427\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.1092319250106812, Val_loss 3.5114848613739014\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.1090869188308714, Val_loss 3.5369033813476562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.0961756706237793, Val_loss 3.5140421390533447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.129986810684204, Val_loss 3.5174577236175537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9279274463653566, Val_loss 4.272980213165283\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.117156648635865, Val_loss 4.240733623504639\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.056381368637085, Val_loss 4.227564334869385\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9254540681838987, Val_loss 4.199410438537598\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8274973154067995, Val_loss 4.110084533691406\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.772789812088013, Val_loss 3.8381128311157227\n",
      "Train_acc_top_20 0.2125\tTrain_acc_top_30 0.35\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.38\t\n",
      "Epoch 7, Train_Loss 3.691558265686035, Val_loss 3.7463343143463135\n",
      "Train_acc_top_20 0.575\tTrain_acc_top_30 0.775\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.585282039642334, Val_loss 3.775266647338867\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5513151407241823, Val_loss 3.6898117065429688\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.5012663841247558, Val_loss 3.6702213287353516\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4576852083206178, Val_loss 3.6590559482574463\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.4190316915512087, Val_loss 3.6135504245758057\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.3841803789138796, Val_loss 3.5805795192718506\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.401156115531921, Val_loss 3.693547248840332\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3604965448379516, Val_loss 3.618483781814575\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.330300521850586, Val_loss 3.5999088287353516\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.318424367904663, Val_loss 3.712135076522827\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.293947672843933, Val_loss 3.599024772644043\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.272483253479004, Val_loss 3.5267298221588135\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.2298879384994508, Val_loss 3.545596122741699\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.2220883846282957, Val_loss 3.52496337890625\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.221272087097168, Val_loss 3.5564699172973633\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.2252952098846435, Val_loss 3.5753469467163086\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.2113134622573853, Val_loss 3.549832344055176\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2318981409072878, Val_loss 3.559297800064087\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.1926409006118774, Val_loss 3.498920202255249\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.19131121635437, Val_loss 3.542769432067871\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1720905542373656, Val_loss 3.438995361328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 29, Train_Loss 3.1747596740722654, Val_loss 3.527318239212036\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.1723886489868165, Val_loss 3.50356388092041\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.155667543411255, Val_loss 3.5070960521698\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1502518892288207, Val_loss 3.490485429763794\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1831578254699706, Val_loss 3.474820852279663\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.1464684009552, Val_loss 3.5009708404541016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.162954092025757, Val_loss 3.452329397201538\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.1580825090408324, Val_loss 3.504845380783081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1481369018554686, Val_loss 3.503891706466675\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.143935775756836, Val_loss 3.487739324569702\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.1554883480072022, Val_loss 3.55981183052063\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1444719791412354, Val_loss 3.4412753582000732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 41, Train_Loss 3.1212067127227785, Val_loss 3.4680440425872803\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.1351898670196534, Val_loss 3.5069923400878906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.114483046531677, Val_loss 3.6000146865844727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.147811222076416, Val_loss 3.5263168811798096\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.117430853843689, Val_loss 3.504582643508911\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.118375611305237, Val_loss 3.5142128467559814\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.121609663963318, Val_loss 3.5121309757232666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.135457229614258, Val_loss 3.5531883239746094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1480321407318117, Val_loss 3.5413239002227783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1088497400283814, Val_loss 3.5046446323394775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.100272059440613, Val_loss 3.45592999458313\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 52, Train_Loss 3.1479129076004027, Val_loss 3.4557220935821533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.09235303401947, Val_loss 3.510436773300171\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1135842561721803, Val_loss 3.517530679702759\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.118147373199463, Val_loss 3.534559965133667\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.1123926639556885, Val_loss 3.5004045963287354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 57, Train_Loss 3.133374834060669, Val_loss 3.528857469558716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.120517683029175, Val_loss 3.505624532699585\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 59, Train_Loss 3.0996322870254516, Val_loss 3.501718759536743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.0929247617721556, Val_loss 3.512471914291382\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.1023690700531006, Val_loss 3.4908370971679688\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.1192574739456176, Val_loss 3.504115343093872\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.0940979719161987, Val_loss 3.489812135696411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.1370564222335817, Val_loss 3.5108213424682617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 65, Train_Loss 3.091868758201599, Val_loss 3.485872983932495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.0929072856903077, Val_loss 3.492497444152832\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 67, Train_Loss 3.1172162771224974, Val_loss 3.4620323181152344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 68, Train_Loss 3.0929621696472167, Val_loss 3.5197975635528564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.097120261192322, Val_loss 3.4750864505767822\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 70, Train_Loss 3.080474352836609, Val_loss 3.468999147415161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 71, Train_Loss 3.1210384130477906, Val_loss 3.486057996749878\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 72, Train_Loss 3.1060558795928954, Val_loss 3.48248553276062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.0789392709732057, Val_loss 3.44278883934021\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.1002612352371215, Val_loss 3.5249826908111572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 75, Train_Loss 3.098795938491821, Val_loss 3.4714908599853516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 76, Train_Loss 3.1029821395874024, Val_loss 3.4848062992095947\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 77, Train_Loss 3.1050860404968263, Val_loss 3.4941303730010986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 78, Train_Loss 3.100307989120483, Val_loss 3.5130388736724854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 79, Train_Loss 3.1182101249694822, Val_loss 3.4997692108154297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 80, Train_Loss 3.101115679740906, Val_loss 3.5058746337890625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 81, Train_Loss 3.0910287857055665, Val_loss 3.4682130813598633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 82, Train_Loss 3.127563452720642, Val_loss 3.4624624252319336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 83, Train_Loss 3.1075186491012574, Val_loss 3.491560935974121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 84, Train_Loss 3.0881357192993164, Val_loss 3.4873430728912354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 85, Train_Loss 3.069499468803406, Val_loss 3.509233236312866\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.100999903678894, Val_loss 3.5091135501861572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.1149038076400757, Val_loss 3.5259406566619873\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 88, Train_Loss 3.1001977205276487, Val_loss 3.48638916015625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 89, Train_Loss 3.088535022735596, Val_loss 3.4950954914093018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 90, Train_Loss 3.1260528564453125, Val_loss 3.4554035663604736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.1127978801727294, Val_loss 3.4904606342315674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 92, Train_Loss 3.1005541563034056, Val_loss 3.491610527038574\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 93, Train_Loss 3.0882095813751222, Val_loss 3.4705677032470703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 94, Train_Loss 3.1085901975631716, Val_loss 3.481001853942871\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 95, Train_Loss 3.0717400550842284, Val_loss 3.4809038639068604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 96, Train_Loss 3.120588517189026, Val_loss 3.474217414855957\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.105235958099365, Val_loss 3.485004186630249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.108405828475952, Val_loss 3.4852936267852783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 99, Train_Loss 3.0886286020278932, Val_loss 3.4769961833953857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 100, Train_Loss 3.11640465259552, Val_loss 3.522618055343628\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 1, Train_Loss 3.9227766513824465, Val_loss 4.22838830947876\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.108712863922119, Val_loss 4.14714241027832\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.026006174087525, Val_loss 4.089544773101807\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.889036679267883, Val_loss 4.062479496002197\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8057701587677, Val_loss 3.918508291244507\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7086527824401854, Val_loss 3.809115409851074\n",
      "Train_acc_top_20 0.2437\tTrain_acc_top_30 0.3375\tTrain_acc_top_40 0.4313\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.669100451469421, Val_loss 3.8767271041870117\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.6813\tTrain_acc_top_40 0.7812\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.25\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.603754472732544, Val_loss 3.848120927810669\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.507952642440796, Val_loss 3.77101731300354\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.456268620491028, Val_loss 3.7413463592529297\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.4292030811309813, Val_loss 3.7756917476654053\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.3943513870239257, Val_loss 3.720984697341919\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.345522975921631, Val_loss 3.775604248046875\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3813965559005736, Val_loss 3.8341662883758545\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.3171088457107545, Val_loss 3.746670722961426\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.2910340070724486, Val_loss 3.73323655128479\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 17, Train_Loss 3.2891351222991942, Val_loss 3.846896171569824\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.5\t\n",
      "Epoch 18, Train_Loss 3.309305119514465, Val_loss 3.7747585773468018\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.281318783760071, Val_loss 3.8004519939422607\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 20, Train_Loss 3.249723768234253, Val_loss 3.7236955165863037\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.2215918064117433, Val_loss 3.7474889755249023\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.2501747369766236, Val_loss 3.6800296306610107\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 23, Train_Loss 3.224772882461548, Val_loss 3.927694082260132\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.38\t\n",
      "Epoch 24, Train_Loss 3.2063956260681152, Val_loss 3.673715353012085\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.218145799636841, Val_loss 3.665285110473633\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.181366467475891, Val_loss 3.7547190189361572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 27, Train_Loss 3.1480260848999024, Val_loss 3.734797477722168\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.168801689147949, Val_loss 3.802612543106079\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.33\tVal_acc_top_40 0.46\t\n",
      "Epoch 29, Train_Loss 3.1901058673858644, Val_loss 3.7888400554656982\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.33\tVal_acc_top_40 0.5\t\n",
      "Epoch 30, Train_Loss 3.154282975196838, Val_loss 3.7481091022491455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.38\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.1874996185302735, Val_loss 3.7862679958343506\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.58\t\n",
      "Epoch 32, Train_Loss 3.172427749633789, Val_loss 3.672410011291504\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.134110856056213, Val_loss 3.7225024700164795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 34, Train_Loss 3.151706576347351, Val_loss 3.6812045574188232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1800716161727904, Val_loss 3.783881425857544\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 36, Train_Loss 3.1573678731918333, Val_loss 3.754342794418335\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 37, Train_Loss 3.1718189239501955, Val_loss 3.665149450302124\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.158523988723755, Val_loss 3.804217576980591\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.38\tVal_acc_top_40 0.54\t\n",
      "Epoch 39, Train_Loss 3.15032057762146, Val_loss 3.6516873836517334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.1532864570617676, Val_loss 3.739018678665161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 41, Train_Loss 3.1520684957504272, Val_loss 3.69931697845459\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.1416558027267456, Val_loss 3.7304115295410156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 43, Train_Loss 3.1227204322814943, Val_loss 3.708300828933716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 44, Train_Loss 3.1985621452331543, Val_loss 3.737257719039917\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 45, Train_Loss 3.1337684392929077, Val_loss 3.7918665409088135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.137581467628479, Val_loss 3.641277551651001\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1200307607650757, Val_loss 3.7470169067382812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 48, Train_Loss 3.1441536426544188, Val_loss 3.706239700317383\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.13917236328125, Val_loss 3.684441328048706\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.136545443534851, Val_loss 3.6807239055633545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1200939178466798, Val_loss 3.6695518493652344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.133487677574158, Val_loss 3.717203378677368\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 53, Train_Loss 3.121356248855591, Val_loss 3.702582597732544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 54, Train_Loss 3.135956382751465, Val_loss 3.659688711166382\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.101725196838379, Val_loss 3.6862411499023438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.1032304525375367, Val_loss 3.6983768939971924\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.1265532970428467, Val_loss 3.761019468307495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.0898333311080934, Val_loss 3.5986502170562744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1383541584014893, Val_loss 3.89672589302063\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 60, Train_Loss 3.1310598850250244, Val_loss 3.64542555809021\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.1091017007827757, Val_loss 3.6530685424804688\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.1141876220703124, Val_loss 3.691331624984741\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 63, Train_Loss 3.12561891078949, Val_loss 3.697896957397461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.1191868782043457, Val_loss 3.6981287002563477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.1090298891067505, Val_loss 3.680689811706543\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.1072804927825928, Val_loss 3.6684885025024414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.1011945486068724, Val_loss 3.644787073135376\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.065771460533142, Val_loss 3.6253702640533447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.120382022857666, Val_loss 3.711315393447876\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.1132102489471434, Val_loss 3.7068698406219482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 71, Train_Loss 3.0972876071929933, Val_loss 3.635603189468384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.0723894596099854, Val_loss 3.641119956970215\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.090425944328308, Val_loss 3.7454025745391846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.1143220186233522, Val_loss 3.6646080017089844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0670310258865356, Val_loss 3.6520745754241943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.109140968322754, Val_loss 3.667675256729126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 77, Train_Loss 3.100913572311401, Val_loss 3.6594083309173584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.0768614292144774, Val_loss 3.6639604568481445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.1093901634216308, Val_loss 3.6882283687591553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.1152682065963746, Val_loss 3.7082319259643555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.08911075592041, Val_loss 3.7329094409942627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.0955939531326293, Val_loss 3.669316291809082\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.070951294898987, Val_loss 3.6816556453704834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.107574772834778, Val_loss 3.672826051712036\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.1228764057159424, Val_loss 3.6654164791107178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.0919375658035277, Val_loss 3.6728620529174805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.1013370990753173, Val_loss 3.674621820449829\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.0652915716171263, Val_loss 3.6606509685516357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.081442928314209, Val_loss 3.6832141876220703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0918164253234863, Val_loss 3.654759168624878\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 91, Train_Loss 3.0997432231903077, Val_loss 3.682504653930664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 92, Train_Loss 3.0973913192749025, Val_loss 3.664358139038086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.0935319900512694, Val_loss 3.6746253967285156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 94, Train_Loss 3.0702900171279905, Val_loss 3.6678504943847656\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.100313687324524, Val_loss 3.6730053424835205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.140032434463501, Val_loss 3.6933858394622803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.0946911334991456, Val_loss 3.6703040599823\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.0930688858032225, Val_loss 3.667323112487793\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.0486222982406614, Val_loss 3.650846242904663\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.12901828289032, Val_loss 3.679274559020996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.935158538818359, Val_loss 4.256383419036865\n",
      "Train_acc_top_20 0.1437\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.25\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.122747468948364, Val_loss 4.233790397644043\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.065371370315551, Val_loss 4.2097697257995605\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.08\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.960449552536011, Val_loss 4.119002342224121\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8548737525939942, Val_loss 4.017153263092041\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.8026532411575316, Val_loss 3.8529531955718994\n",
      "Train_acc_top_20 0.2188\tTrain_acc_top_30 0.3063\tTrain_acc_top_40 0.4125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.25\tVal_acc_top_40 0.33\t\n",
      "Epoch 7, Train_Loss 3.7028107404708863, Val_loss 3.824878692626953\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.7562\tTrain_acc_top_40 0.8375\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.612368440628052, Val_loss 3.8108022212982178\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.563372540473938, Val_loss 3.7736196517944336\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.49901225566864, Val_loss 3.7945244312286377\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4568334817886353, Val_loss 3.7456817626953125\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.399040699005127, Val_loss 3.7226943969726562\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.3690356254577636, Val_loss 3.7292287349700928\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.347616505622864, Val_loss 3.6596298217773438\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.2957393646240236, Val_loss 3.661630630493164\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3015748023986817, Val_loss 3.6588919162750244\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.2731631278991697, Val_loss 3.6687676906585693\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.2589470863342287, Val_loss 3.675732374191284\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.2360460996627807, Val_loss 3.7069075107574463\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.232474517822266, Val_loss 3.664639711380005\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.234556221961975, Val_loss 3.6722593307495117\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.2152840375900267, Val_loss 3.6654212474823\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.223605823516846, Val_loss 3.683945417404175\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.203992509841919, Val_loss 3.653275728225708\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.201395630836487, Val_loss 3.659865617752075\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 26, Train_Loss 3.209601640701294, Val_loss 3.7788965702056885\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.5\t\n",
      "Epoch 27, Train_Loss 3.201094651222229, Val_loss 3.6708076000213623\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.211199903488159, Val_loss 3.712096929550171\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.1847228527069094, Val_loss 3.7001333236694336\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 30, Train_Loss 3.1811519622802735, Val_loss 3.702254056930542\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.184380316734314, Val_loss 3.7547662258148193\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 32, Train_Loss 3.1890338897705077, Val_loss 3.6811325550079346\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 33, Train_Loss 3.161383271217346, Val_loss 3.7058849334716797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.156578850746155, Val_loss 3.6996562480926514\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 35, Train_Loss 3.1386419534683228, Val_loss 3.6538798809051514\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.145677161216736, Val_loss 3.6399405002593994\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.134472441673279, Val_loss 3.7091410160064697\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 38, Train_Loss 3.150390648841858, Val_loss 3.7363064289093018\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 39, Train_Loss 3.137128734588623, Val_loss 3.651834726333618\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.142145347595215, Val_loss 3.6576032638549805\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.135006332397461, Val_loss 3.672792673110962\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.128431224822998, Val_loss 3.6804895401000977\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1318142890930174, Val_loss 3.704756021499634\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.12027850151062, Val_loss 3.6887903213500977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.143815803527832, Val_loss 3.7288668155670166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.110856223106384, Val_loss 3.6999685764312744\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 47, Train_Loss 3.1220845222473144, Val_loss 3.7462856769561768\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 48, Train_Loss 3.141158699989319, Val_loss 3.7189581394195557\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.114556360244751, Val_loss 3.7457468509674072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 50, Train_Loss 3.1271886348724367, Val_loss 3.6840219497680664\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.1164031744003298, Val_loss 3.6678683757781982\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 52, Train_Loss 3.1137337684631348, Val_loss 3.691230535507202\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 53, Train_Loss 3.119371795654297, Val_loss 3.660006523132324\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 54, Train_Loss 3.0934728622436523, Val_loss 3.632936477661133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 55, Train_Loss 3.11521897315979, Val_loss 3.6859452724456787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.104413604736328, Val_loss 3.714257001876831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 57, Train_Loss 3.1355791330337524, Val_loss 3.7112977504730225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.1100267648696898, Val_loss 3.69353985786438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1263676404953005, Val_loss 3.692549467086792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.1003619909286497, Val_loss 3.597913980484009\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.0880352735519407, Val_loss 3.675283432006836\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.123952293395996, Val_loss 3.6952970027923584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 63, Train_Loss 3.1142036437988283, Val_loss 3.6705777645111084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.133261275291443, Val_loss 3.6760776042938232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.127193641662598, Val_loss 3.678020715713501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 66, Train_Loss 3.106944036483765, Val_loss 3.686528444290161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 67, Train_Loss 3.0938577175140383, Val_loss 3.703968048095703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.096739935874939, Val_loss 3.686448812484741\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.1342331409454345, Val_loss 3.6945478916168213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.1089709281921385, Val_loss 3.680182456970215\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.1032645225524904, Val_loss 3.698946952819824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.109047055244446, Val_loss 3.7014853954315186\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.0963650226593016, Val_loss 3.700225591659546\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.1277356147766113, Val_loss 3.6797726154327393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.091381573677063, Val_loss 3.702324867248535\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 76, Train_Loss 3.0925930023193358, Val_loss 3.694709539413452\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.0968712329864503, Val_loss 3.685076951980591\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.081316089630127, Val_loss 3.6744353771209717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.1045109748840334, Val_loss 3.674086332321167\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.1220431566238402, Val_loss 3.662276029586792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.097649908065796, Val_loss 3.669593095779419\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 82, Train_Loss 3.078401780128479, Val_loss 3.683518171310425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.1067505359649656, Val_loss 3.718294858932495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.0905232667922973, Val_loss 3.7074806690216064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.113933825492859, Val_loss 3.7077455520629883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.1092421054840087, Val_loss 3.701420783996582\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.08943772315979, Val_loss 3.6966230869293213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.097540092468262, Val_loss 3.7113819122314453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.107002019882202, Val_loss 3.7134010791778564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.126104784011841, Val_loss 3.691525459289551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 91, Train_Loss 3.1068037033081053, Val_loss 3.688674211502075\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.098433089256287, Val_loss 3.7111473083496094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.118390369415283, Val_loss 3.710252523422241\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.083513951301575, Val_loss 3.6851069927215576\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.1232202768325807, Val_loss 3.718862533569336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 96, Train_Loss 3.1041626930236816, Val_loss 3.7029807567596436\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.083312249183655, Val_loss 3.688643217086792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.095985674858093, Val_loss 3.7204697132110596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.0856966018676757, Val_loss 3.696570634841919\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.083272385597229, Val_loss 3.711542844772339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 1, Train_Loss 3.9243792295455933, Val_loss 4.264375686645508\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.108005809783935, Val_loss 4.219822406768799\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.036473560333252, Val_loss 4.220733165740967\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9173758268356322, Val_loss 4.241465091705322\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.8315016746521, Val_loss 4.198934078216553\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.7500919103622437, Val_loss 3.8289318084716797\n",
      "Train_acc_top_20 0.2\tTrain_acc_top_30 0.3125\tTrain_acc_top_40 0.3875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.6698270559310915, Val_loss 3.6277801990509033\n",
      "Train_acc_top_20 0.5813\tTrain_acc_top_30 0.7375\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 8, Train_Loss 3.6226621866226196, Val_loss 3.624105453491211\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 9, Train_Loss 3.5569323301315308, Val_loss 3.573920249938965\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.5134660243988036, Val_loss 3.532896041870117\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 11, Train_Loss 3.5090997934341432, Val_loss 3.5063717365264893\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 12, Train_Loss 3.427243781089783, Val_loss 3.521606683731079\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 13, Train_Loss 3.4070850372314454, Val_loss 3.537796974182129\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.380969786643982, Val_loss 3.4766550064086914\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.96\t\n",
      "Epoch 15, Train_Loss 3.347481298446655, Val_loss 3.4503390789031982\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.322382664680481, Val_loss 3.4777047634124756\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.3184855222702025, Val_loss 3.40539288520813\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.2957512378692626, Val_loss 3.440436363220215\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 19, Train_Loss 3.271108794212341, Val_loss 3.4743878841400146\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 20, Train_Loss 3.260836935043335, Val_loss 3.45455002784729\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 21, Train_Loss 3.237752318382263, Val_loss 3.430361032485962\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 22, Train_Loss 3.242366671562195, Val_loss 3.4082038402557373\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 23, Train_Loss 3.2077091932296753, Val_loss 3.44446063041687\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 24, Train_Loss 3.184818911552429, Val_loss 3.4091880321502686\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 25, Train_Loss 3.1925943374633787, Val_loss 3.467029571533203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 26, Train_Loss 3.1871259689331053, Val_loss 3.404238700866699\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 27, Train_Loss 3.1707107067108153, Val_loss 3.3872835636138916\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 28, Train_Loss 3.163238525390625, Val_loss 3.5143299102783203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 29, Train_Loss 3.180172872543335, Val_loss 3.436152219772339\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 30, Train_Loss 3.150223445892334, Val_loss 3.3977911472320557\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 31, Train_Loss 3.176682472229004, Val_loss 3.480005979537964\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.1540791034698485, Val_loss 3.4230563640594482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.96\tVal_acc_top_40 1.0\t\n",
      "Epoch 33, Train_Loss 3.1383819341659547, Val_loss 3.396965265274048\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.96\tVal_acc_top_40 1.0\t\n",
      "Epoch 34, Train_Loss 3.1488441228866577, Val_loss 3.4223146438598633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 35, Train_Loss 3.1101974964141847, Val_loss 3.42849063873291\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.130196285247803, Val_loss 3.419017791748047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 37, Train_Loss 3.1667027711868285, Val_loss 3.5756404399871826\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 38, Train_Loss 3.1376752853393555, Val_loss 3.3873050212860107\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 39, Train_Loss 3.1557164669036863, Val_loss 3.4212875366210938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.1163936614990235, Val_loss 3.425328016281128\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 41, Train_Loss 3.132248044013977, Val_loss 3.4225761890411377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 1.0\t\n",
      "Epoch 42, Train_Loss 3.134426164627075, Val_loss 3.49534010887146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 43, Train_Loss 3.129010033607483, Val_loss 3.4919216632843018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 44, Train_Loss 3.127614688873291, Val_loss 3.46612811088562\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 1.0\t\n",
      "Epoch 45, Train_Loss 3.135146450996399, Val_loss 3.4051313400268555\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 46, Train_Loss 3.1283164501190184, Val_loss 3.453500509262085\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 47, Train_Loss 3.1616156816482546, Val_loss 3.54734206199646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 48, Train_Loss 3.115244650840759, Val_loss 3.3653957843780518\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 1.0\t\n",
      "Epoch 49, Train_Loss 3.1160739183425905, Val_loss 3.414708137512207\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 50, Train_Loss 3.09433856010437, Val_loss 3.3948967456817627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 51, Train_Loss 3.1530865907669066, Val_loss 3.4526853561401367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 52, Train_Loss 3.101620054244995, Val_loss 3.452194929122925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 53, Train_Loss 3.1341403245925905, Val_loss 3.483572244644165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 54, Train_Loss 3.1677361011505125, Val_loss 3.4651472568511963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 55, Train_Loss 3.1140366792678833, Val_loss 3.4957826137542725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.1267680168151855, Val_loss 3.440540075302124\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.1302263259887697, Val_loss 3.523026704788208\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.0907398223876954, Val_loss 3.4450435638427734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 59, Train_Loss 3.0805551290512083, Val_loss 3.445481061935425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0926489353179933, Val_loss 3.461559534072876\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 61, Train_Loss 3.115935730934143, Val_loss 3.474703788757324\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.114444947242737, Val_loss 3.4889028072357178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.11095986366272, Val_loss 3.48551082611084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.076028847694397, Val_loss 3.4344825744628906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.0931719064712526, Val_loss 3.4700746536254883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 66, Train_Loss 3.0750394821166993, Val_loss 3.476763963699341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 67, Train_Loss 3.1105576515197755, Val_loss 3.4879329204559326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.1102852821350098, Val_loss 3.5015223026275635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.1229303598403932, Val_loss 3.487147092819214\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.112227535247803, Val_loss 3.4477930068969727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.1079420328140257, Val_loss 3.4656293392181396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.093033766746521, Val_loss 3.4716596603393555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.0758182048797607, Val_loss 3.519803285598755\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 74, Train_Loss 3.1299050092697143, Val_loss 3.4945905208587646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 75, Train_Loss 3.0859379529953004, Val_loss 3.552459716796875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.114083170890808, Val_loss 3.4745991230010986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.1073155879974363, Val_loss 3.479437828063965\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.1262109518051147, Val_loss 3.4833390712738037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.1474986553192137, Val_loss 3.50561785697937\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1049994468688964, Val_loss 3.521878242492676\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.100313138961792, Val_loss 3.5211408138275146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.103276824951172, Val_loss 3.4966928958892822\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.14684202671051, Val_loss 3.5151054859161377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.074845051765442, Val_loss 3.504241943359375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 85, Train_Loss 3.0984493494033813, Val_loss 3.503068208694458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.085679793357849, Val_loss 3.5010998249053955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 87, Train_Loss 3.097109842300415, Val_loss 3.4919729232788086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 88, Train_Loss 3.1414855241775514, Val_loss 3.512347459793091\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 89, Train_Loss 3.089070439338684, Val_loss 3.4996349811553955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.080561971664429, Val_loss 3.5103423595428467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 91, Train_Loss 3.0730352640151977, Val_loss 3.572343587875366\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.0658776998519897, Val_loss 3.4995906352996826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.106367039680481, Val_loss 3.4736673831939697\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.109170341491699, Val_loss 3.508249521255493\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.0781600713729858, Val_loss 3.524913787841797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.056200551986694, Val_loss 3.5289218425750732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.093001365661621, Val_loss 3.4799106121063232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.077444815635681, Val_loss 3.492537260055542\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.0891369581222534, Val_loss 3.506509780883789\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.0899311304092407, Val_loss 3.5005130767822266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.9300289154052734, Val_loss 4.265695095062256\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.1087975025177, Val_loss 4.268412113189697\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.028562402725219, Val_loss 4.212911605834961\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.901613640785217, Val_loss 4.132178783416748\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8102205753326417, Val_loss 4.045590877532959\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.72587103843689, Val_loss 3.853862762451172\n",
      "Train_acc_top_20 0.225\tTrain_acc_top_30 0.3688\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.666425085067749, Val_loss 3.778257369995117\n",
      "Train_acc_top_20 0.6438\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.6179347038269043, Val_loss 3.7395429611206055\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.5323298454284666, Val_loss 3.736175298690796\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.4942707300186155, Val_loss 3.7377169132232666\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.487140488624573, Val_loss 3.811056137084961\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 12, Train_Loss 3.4259174346923826, Val_loss 3.745615243911743\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 13, Train_Loss 3.3999807119369505, Val_loss 3.75410532951355\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.354827117919922, Val_loss 3.6799795627593994\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.335954117774963, Val_loss 3.659311294555664\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3129656076431275, Val_loss 3.784592390060425\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 17, Train_Loss 3.2858604431152343, Val_loss 3.6409552097320557\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.268903398513794, Val_loss 3.7015535831451416\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.2462997913360594, Val_loss 3.63474440574646\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2376754760742186, Val_loss 3.8201749324798584\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 21, Train_Loss 3.2523030281066894, Val_loss 3.7648918628692627\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 22, Train_Loss 3.2397765159606933, Val_loss 3.6346395015716553\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.2070481538772584, Val_loss 3.6590652465820312\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.2120272159576415, Val_loss 3.5935451984405518\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.18850781917572, Val_loss 3.618506669998169\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.199499320983887, Val_loss 3.6200008392333984\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.214748501777649, Val_loss 3.6380503177642822\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.1889437437057495, Val_loss 3.734748125076294\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.183518886566162, Val_loss 3.6123247146606445\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.2097466945648194, Val_loss 3.641632318496704\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.188073921203613, Val_loss 3.5968663692474365\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.178019714355469, Val_loss 3.64310622215271\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.177957367897034, Val_loss 3.5527894496917725\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1616983652114867, Val_loss 3.5942652225494385\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1623409748077393, Val_loss 3.612792730331421\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.137265944480896, Val_loss 3.5509393215179443\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1426806449890137, Val_loss 3.6298961639404297\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.132346248626709, Val_loss 3.5690650939941406\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1475992679595945, Val_loss 3.6330432891845703\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1307119369506835, Val_loss 3.593816041946411\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1638835191726686, Val_loss 3.6641786098480225\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1459303855895997, Val_loss 3.592026472091675\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1543691158294678, Val_loss 3.5950210094451904\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1399320125579835, Val_loss 3.607889413833618\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1329650402069094, Val_loss 3.5788488388061523\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1525609254837037, Val_loss 3.599778175354004\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1424281120300295, Val_loss 3.5662572383880615\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.1632089853286742, Val_loss 3.539463758468628\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.130413365364075, Val_loss 3.5221548080444336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.123192048072815, Val_loss 3.575352907180786\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.114765191078186, Val_loss 3.4952542781829834\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.1341853618621824, Val_loss 3.5373055934906006\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1023851156234743, Val_loss 3.5863826274871826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.126582479476929, Val_loss 3.5615234375\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1086588859558106, Val_loss 3.578092336654663\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.109111762046814, Val_loss 3.5248851776123047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.0775605201721192, Val_loss 3.53267502784729\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.100654864311218, Val_loss 3.577455520629883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.102095103263855, Val_loss 3.5529117584228516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1124776124954225, Val_loss 3.5703811645507812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.12652382850647, Val_loss 3.614288330078125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.0984524726867675, Val_loss 3.567153215408325\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.066747522354126, Val_loss 3.5554778575897217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0676959276199343, Val_loss 3.603806734085083\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.086705541610718, Val_loss 3.591627836227417\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.0980491399765016, Val_loss 3.5444564819335938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.0842860460281374, Val_loss 3.5953457355499268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.1116456031799316, Val_loss 3.5527737140655518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.109006881713867, Val_loss 3.5448436737060547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.0870291233062743, Val_loss 3.5516765117645264\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.118802046775818, Val_loss 3.5530786514282227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.1069801092147826, Val_loss 3.5911705493927\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.097701668739319, Val_loss 3.5507538318634033\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.074831223487854, Val_loss 3.557173013687134\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.106640672683716, Val_loss 3.5979702472686768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.088553309440613, Val_loss 3.573099374771118\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0842448711395263, Val_loss 3.5761425495147705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.109221911430359, Val_loss 3.568183660507202\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.113768482208252, Val_loss 3.588364362716675\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.137245798110962, Val_loss 3.5722224712371826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0981372356414796, Val_loss 3.546895742416382\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1208566665649413, Val_loss 3.5661916732788086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0824563026428224, Val_loss 3.5637569427490234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0897816896438597, Val_loss 3.534316301345825\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0967656850814818, Val_loss 3.5411694049835205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0952890872955323, Val_loss 3.5623319149017334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.1020314693450928, Val_loss 3.5669918060302734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.084758257865906, Val_loss 3.584667205810547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.081308364868164, Val_loss 3.5604889392852783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.078940725326538, Val_loss 3.546769857406616\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.091902232170105, Val_loss 3.57085919380188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.094118905067444, Val_loss 3.5531914234161377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.095477080345154, Val_loss 3.552983045578003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0924177169799805, Val_loss 3.5447261333465576\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.088723349571228, Val_loss 3.5674784183502197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0933087825775147, Val_loss 3.5827791690826416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.076766037940979, Val_loss 3.5686252117156982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.1108113288879395, Val_loss 3.57511830329895\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.1149072885513305, Val_loss 3.555739402770996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.132616066932678, Val_loss 3.5870189666748047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.934008574485779, Val_loss 4.230668544769287\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.114554738998413, Val_loss 4.1595940589904785\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.05987582206726, Val_loss 4.147285461425781\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9197499752044678, Val_loss 4.113245487213135\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.25\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.837785315513611, Val_loss 4.033367156982422\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.125\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.33\tVal_acc_top_40 0.38\t\n",
      "Epoch 6, Train_Loss 3.7850009202957153, Val_loss 3.767566680908203\n",
      "Train_acc_top_20 0.2313\tTrain_acc_top_30 0.3375\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 7, Train_Loss 3.6844525814056395, Val_loss 3.6983883380889893\n",
      "Train_acc_top_20 0.6\tTrain_acc_top_30 0.7438\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.6245829343795775, Val_loss 3.5736072063446045\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.62936475276947, Val_loss 3.5548858642578125\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.545360541343689, Val_loss 3.608652114868164\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.533371186256409, Val_loss 3.5829641819000244\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4562732219696044, Val_loss 3.5368576049804688\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.393432927131653, Val_loss 3.5323374271392822\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3767786979675294, Val_loss 3.481600522994995\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3732685327529905, Val_loss 3.462280035018921\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.309572958946228, Val_loss 3.4631965160369873\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.290411877632141, Val_loss 3.4718821048736572\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.2727214813232424, Val_loss 3.4673349857330322\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.270382595062256, Val_loss 3.4819881916046143\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.2572740077972413, Val_loss 3.5044424533843994\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.230454182624817, Val_loss 3.472412109375\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.211556839942932, Val_loss 3.447813034057617\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2023092985153196, Val_loss 3.53458309173584\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.198761010169983, Val_loss 3.4714291095733643\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.215949773788452, Val_loss 3.50422739982605\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.1774266719818116, Val_loss 3.5417892932891846\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.225288224220276, Val_loss 3.4053685665130615\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 28, Train_Loss 3.189036560058594, Val_loss 3.5216360092163086\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.19029495716095, Val_loss 3.4910335540771484\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.1935039520263673, Val_loss 3.4229419231414795\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.157076048851013, Val_loss 3.4901368618011475\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1521583557128907, Val_loss 3.5895633697509766\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.127903389930725, Val_loss 3.536224126815796\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.16150438785553, Val_loss 3.460150957107544\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.147666907310486, Val_loss 3.4624011516571045\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.144372248649597, Val_loss 3.494805097579956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1450632095336912, Val_loss 3.507011651992798\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1291866302490234, Val_loss 3.5960426330566406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 39, Train_Loss 3.129321336746216, Val_loss 3.5553395748138428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1407732486724855, Val_loss 3.5367748737335205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1209622621536255, Val_loss 3.5286312103271484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.124715876579285, Val_loss 3.556598424911499\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1358206987380983, Val_loss 3.524585723876953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.133383560180664, Val_loss 3.5453646183013916\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1207435607910154, Val_loss 3.5543620586395264\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1360220193862913, Val_loss 3.523602247238159\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1271990060806276, Val_loss 3.526409149169922\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.108416700363159, Val_loss 3.5139551162719727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.0972607851028444, Val_loss 3.5292139053344727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1058847427368166, Val_loss 3.534735918045044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1241995811462404, Val_loss 3.45635986328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1321304559707643, Val_loss 3.4452133178710938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.0974627494812013, Val_loss 3.477078437805176\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1266182899475097, Val_loss 3.5116958618164062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1146908521652223, Val_loss 3.4549472332000732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.140803575515747, Val_loss 3.5725231170654297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1386823654174805, Val_loss 3.5590221881866455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.0973997592926024, Val_loss 3.5116183757781982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.0747212171554565, Val_loss 3.5369699001312256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.1476208686828615, Val_loss 3.5268075466156006\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1272674560546876, Val_loss 3.4713966846466064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1010435819625854, Val_loss 3.5216846466064453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.14718234539032, Val_loss 3.4712793827056885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1273253917694093, Val_loss 3.5142173767089844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.1171029567718507, Val_loss 3.551302909851074\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.0785362482070924, Val_loss 3.5149614810943604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.0984513998031615, Val_loss 3.5537688732147217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1230061054229736, Val_loss 3.51870059967041\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.084004282951355, Val_loss 3.504033327102661\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.0840914726257322, Val_loss 3.5331008434295654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.119126796722412, Val_loss 3.5131208896636963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.0973352909088137, Val_loss 3.4974663257598877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.1537081956863404, Val_loss 3.500957727432251\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.107623648643494, Val_loss 3.5093777179718018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.1297711610794066, Val_loss 3.535022735595703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.113984227180481, Val_loss 3.5175037384033203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0920780181884764, Val_loss 3.5164263248443604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0851511478424074, Val_loss 3.531338930130005\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.074169731140137, Val_loss 3.541048049926758\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1032701969146728, Val_loss 3.504868268966675\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.1261176586151125, Val_loss 3.4895877838134766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.108121085166931, Val_loss 3.493939161300659\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.1208603620529174, Val_loss 3.495811700820923\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.066401648521423, Val_loss 3.5308942794799805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.063620758056641, Val_loss 3.5431911945343018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.069102430343628, Val_loss 3.5038959980010986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.1252092838287355, Val_loss 3.51788592338562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.116385078430176, Val_loss 3.5356006622314453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.0956592082977297, Val_loss 3.5352611541748047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.12531464099884, Val_loss 3.516054153442383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.082690143585205, Val_loss 3.521043539047241\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.115046811103821, Val_loss 3.5107314586639404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.1248040437698363, Val_loss 3.5080597400665283\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.08742835521698, Val_loss 3.532238006591797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.104210305213928, Val_loss 3.476489305496216\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0979443788528442, Val_loss 3.5060176849365234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.084176468849182, Val_loss 3.53015398979187\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.1091246128082277, Val_loss 3.505093574523926\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.1069472074508666, Val_loss 3.4926071166992188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.082977557182312, Val_loss 3.5128822326660156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.932823657989502, Val_loss 4.2617411613464355\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.08\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.117830657958985, Val_loss 4.259832382202148\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.058852434158325, Val_loss 4.290037155151367\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.9461677074432373, Val_loss 4.228208065032959\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 5, Train_Loss 3.835718774795532, Val_loss 3.9763565063476562\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7715630531311035, Val_loss 3.8189990520477295\n",
      "Train_acc_top_20 0.2375\tTrain_acc_top_30 0.3438\tTrain_acc_top_40 0.4\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.6939804553985596, Val_loss 3.771669626235962\n",
      "Train_acc_top_20 0.475\tTrain_acc_top_30 0.65\tTrain_acc_top_40 0.7438\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.639003324508667, Val_loss 3.73148512840271\n",
      "Train_acc_top_20 0.625\tTrain_acc_top_30 0.7937\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5721051931381225, Val_loss 3.709256887435913\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.537624144554138, Val_loss 3.652615547180176\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.496501994132996, Val_loss 3.676457643508911\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.4665814876556396, Val_loss 3.66156268119812\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4289878606796265, Val_loss 3.607685089111328\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.4221758365631105, Val_loss 3.6856729984283447\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.4035929679870605, Val_loss 3.755364418029785\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.3802310943603517, Val_loss 3.706941604614258\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.3551940441131594, Val_loss 3.642374277114868\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.341199278831482, Val_loss 3.6382532119750977\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 19, Train_Loss 3.317518782615662, Val_loss 3.6625120639801025\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.286291980743408, Val_loss 3.5807230472564697\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2571707725524903, Val_loss 3.5893867015838623\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2342272996902466, Val_loss 3.5829427242279053\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.263751435279846, Val_loss 3.6897518634796143\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 24, Train_Loss 3.2402145862579346, Val_loss 3.5457913875579834\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.2200363636016847, Val_loss 3.631991386413574\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.2357362031936647, Val_loss 3.6633288860321045\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.204158329963684, Val_loss 3.6656551361083984\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.247987246513367, Val_loss 3.6549577713012695\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 29, Train_Loss 3.2134572982788088, Val_loss 3.7072722911834717\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 30, Train_Loss 3.204294466972351, Val_loss 3.546217918395996\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.1782551527023317, Val_loss 3.518359422683716\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.192340040206909, Val_loss 3.579927682876587\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1650209188461305, Val_loss 3.5807526111602783\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.17994601726532, Val_loss 3.632033109664917\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1528635263442992, Val_loss 3.694659471511841\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.1816118240356444, Val_loss 3.6042118072509766\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1262475490570067, Val_loss 3.505488634109497\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1706430673599244, Val_loss 3.6059818267822266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.16417977809906, Val_loss 3.6501235961914062\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1316194772720336, Val_loss 3.6185929775238037\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.111062455177307, Val_loss 3.468316078186035\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.1515459299087523, Val_loss 3.549247980117798\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1163601636886598, Val_loss 3.5462646484375\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1794769287109377, Val_loss 3.58284592628479\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.1175493478775023, Val_loss 3.4754409790039062\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.0955156564712523, Val_loss 3.6157572269439697\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.147706079483032, Val_loss 3.4506921768188477\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.1179938554763793, Val_loss 3.5322062969207764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.187657380104065, Val_loss 3.5560576915740967\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.125844049453735, Val_loss 3.5315914154052734\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.1041552305221556, Val_loss 3.5747807025909424\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.1165002584457397, Val_loss 3.5629310607910156\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.105255436897278, Val_loss 3.6244943141937256\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.145778274536133, Val_loss 3.5400378704071045\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1446962118148805, Val_loss 3.5189828872680664\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1647985219955443, Val_loss 3.5518782138824463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1276020765304566, Val_loss 3.5458364486694336\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.1694078922271727, Val_loss 3.532119035720825\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.105094623565674, Val_loss 3.5225906372070312\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 60, Train_Loss 3.1520050525665284, Val_loss 3.5105020999908447\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 61, Train_Loss 3.126901316642761, Val_loss 3.4858481884002686\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.0981003046035767, Val_loss 3.5242300033569336\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.080366063117981, Val_loss 3.5040080547332764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.0771984815597535, Val_loss 3.51517653465271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.087276577949524, Val_loss 3.550564765930176\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.1239859819412232, Val_loss 3.5606260299682617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.1000674962997437, Val_loss 3.5272104740142822\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 68, Train_Loss 3.103130078315735, Val_loss 3.48734450340271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0679131507873536, Val_loss 3.5803661346435547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1362031936645507, Val_loss 3.5469110012054443\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.090181517601013, Val_loss 3.5484554767608643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.1234835386276245, Val_loss 3.571545362472534\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.0701460599899293, Val_loss 3.525386095046997\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.1057429790496824, Val_loss 3.514493942260742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.0971410036087037, Val_loss 3.499595880508423\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.092315101623535, Val_loss 3.551539659500122\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.1206766605377196, Val_loss 3.5222771167755127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.0877943515777586, Val_loss 3.517509698867798\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.09174907207489, Val_loss 3.50626277923584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0772073745727537, Val_loss 3.5126636028289795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.086638855934143, Val_loss 3.516244888305664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.1116353988647463, Val_loss 3.5200376510620117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0772627115249636, Val_loss 3.495037794113159\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.085625100135803, Val_loss 3.502662420272827\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.0728426456451414, Val_loss 3.504678726196289\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0905725002288817, Val_loss 3.549341917037964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.085110807418823, Val_loss 3.5072755813598633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.07266743183136, Val_loss 3.566291093826294\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0897411346435546, Val_loss 3.507887601852417\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0740270376205445, Val_loss 3.518993616104126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.085613322257996, Val_loss 3.5478198528289795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.0860573053359985, Val_loss 3.5338146686553955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.0845940113067627, Val_loss 3.541301727294922\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0943332433700563, Val_loss 3.5443317890167236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.090241527557373, Val_loss 3.5140116214752197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.1140464544296265, Val_loss 3.52264404296875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.083289861679077, Val_loss 3.5122873783111572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.046890687942505, Val_loss 3.514724016189575\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0805570602416994, Val_loss 3.5238144397735596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0594906568527223, Val_loss 3.530097723007202\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9325018882751466, Val_loss 4.291745662689209\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.2625\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.115484523773193, Val_loss 4.207035541534424\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.04533429145813, Val_loss 4.201250076293945\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.955938458442688, Val_loss 4.101225852966309\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.827110695838928, Val_loss 4.004821300506592\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.225\tTrain_acc_top_40 0.2812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.25\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.74345543384552, Val_loss 3.785520315170288\n",
      "Train_acc_top_20 0.225\tTrain_acc_top_30 0.3937\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.38\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.6621349334716795, Val_loss 3.7169055938720703\n",
      "Train_acc_top_20 0.575\tTrain_acc_top_30 0.8063\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6006579637527465, Val_loss 3.713312864303589\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.537175154685974, Val_loss 3.6387693881988525\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.51800000667572, Val_loss 3.6230688095092773\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4733388900756834, Val_loss 3.583252191543579\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.4316645860671997, Val_loss 3.654839277267456\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4237704277038574, Val_loss 3.601924180984497\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.392286682128906, Val_loss 3.6417195796966553\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 15, Train_Loss 3.357905316352844, Val_loss 3.613436460494995\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3440338134765626, Val_loss 3.761918783187866\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.314803409576416, Val_loss 3.5931758880615234\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.296047639846802, Val_loss 3.621356248855591\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2606258630752563, Val_loss 3.6149208545684814\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2567150831222533, Val_loss 3.561049699783325\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2590452909469603, Val_loss 3.6175220012664795\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.212709403038025, Val_loss 3.5499629974365234\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.227800393104553, Val_loss 3.5737531185150146\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.2128458976745606, Val_loss 3.624788522720337\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2156837224960326, Val_loss 3.592310905456543\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.2173457860946657, Val_loss 3.6304566860198975\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.257076621055603, Val_loss 3.539652109146118\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.217651057243347, Val_loss 3.6529715061187744\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.1965218782424927, Val_loss 3.5660111904144287\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.176807141304016, Val_loss 3.6195716857910156\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.202108931541443, Val_loss 3.494767427444458\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.246094584465027, Val_loss 3.5624606609344482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.1760838508605955, Val_loss 3.5584847927093506\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.2209030628204345, Val_loss 3.5918941497802734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1583003997802734, Val_loss 3.74051570892334\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.22388231754303, Val_loss 3.6127841472625732\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.170845699310303, Val_loss 3.600604772567749\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.160147762298584, Val_loss 3.651148796081543\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1264559030532837, Val_loss 3.551250457763672\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 40, Train_Loss 3.116928744316101, Val_loss 3.6298844814300537\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1635282039642334, Val_loss 3.556518793106079\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1809691429138183, Val_loss 3.5562000274658203\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.181082582473755, Val_loss 3.5245349407196045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.139524054527283, Val_loss 3.589921236038208\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1531975507736205, Val_loss 3.564357042312622\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1441954374313354, Val_loss 3.533935785293579\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.1035308837890625, Val_loss 3.523238182067871\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1299781084060667, Val_loss 3.5580904483795166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.117111825942993, Val_loss 3.4973318576812744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.115069341659546, Val_loss 3.5401771068573\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.085951089859009, Val_loss 3.529442548751831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1388678312301637, Val_loss 3.5473501682281494\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.1870442390441895, Val_loss 3.5107364654541016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 54, Train_Loss 3.1269795417785646, Val_loss 3.5226962566375732\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.101341485977173, Val_loss 3.5298678874969482\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.168325185775757, Val_loss 3.5238559246063232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.126782488822937, Val_loss 3.5723164081573486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.1316256523132324, Val_loss 3.596167802810669\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1160142183303834, Val_loss 3.4834835529327393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.1089468479156492, Val_loss 3.5154972076416016\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.1247841119766235, Val_loss 3.5696184635162354\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1078014373779297, Val_loss 3.506829023361206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.1475160837173464, Val_loss 3.531536340713501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1356558799743652, Val_loss 3.4852685928344727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.130179286003113, Val_loss 3.535033941268921\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.0842166185379027, Val_loss 3.505415916442871\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 67, Train_Loss 3.0507177352905273, Val_loss 3.4938058853149414\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.116430330276489, Val_loss 3.494004964828491\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.102272319793701, Val_loss 3.5038328170776367\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.1312108516693113, Val_loss 3.5502068996429443\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.1103822946548463, Val_loss 3.4943063259124756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.069136452674866, Val_loss 3.517902135848999\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.144342541694641, Val_loss 3.505021810531616\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 74, Train_Loss 3.101876425743103, Val_loss 3.512681245803833\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0796886682510376, Val_loss 3.510067939758301\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.1041446924209595, Val_loss 3.517524003982544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.1188547611236572, Val_loss 3.5130443572998047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.083099389076233, Val_loss 3.5272181034088135\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.1568566799163817, Val_loss 3.51517653465271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1305829524993896, Val_loss 3.516184091567993\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.0889397144317625, Val_loss 3.5055761337280273\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.080382537841797, Val_loss 3.5050036907196045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.13326952457428, Val_loss 3.5424716472625732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.069952201843262, Val_loss 3.4978582859039307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.0816993713378906, Val_loss 3.490222692489624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.090197038650513, Val_loss 3.5063064098358154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 87, Train_Loss 3.1254028558731077, Val_loss 3.5334157943725586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.1080276489257814, Val_loss 3.5090560913085938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 89, Train_Loss 3.1230807065963746, Val_loss 3.4939534664154053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.0881935119628907, Val_loss 3.4802706241607666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 91, Train_Loss 3.1112804651260375, Val_loss 3.5281355381011963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.107318639755249, Val_loss 3.479377031326294\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.1290838956832885, Val_loss 3.4890711307525635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.0960983276367187, Val_loss 3.5360047817230225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.12058801651001, Val_loss 3.523139715194702\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.086966395378113, Val_loss 3.5271174907684326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.1582174062728883, Val_loss 3.5722875595092773\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0752226591110228, Val_loss 3.4898412227630615\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.100560736656189, Val_loss 3.5155251026153564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.0890653133392334, Val_loss 3.5418665409088135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.91682550907135, Val_loss 4.221767425537109\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.38\t\n",
      "Epoch 2, Train_Loss 4.120505332946777, Val_loss 4.146268367767334\n",
      "Train_acc_top_20 0.0688\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.1625\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.061803412437439, Val_loss 4.165378093719482\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.908772039413452, Val_loss 4.15552282333374\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8454776048660277, Val_loss 3.9873170852661133\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7604464530944823, Val_loss 3.8572580814361572\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.67\t\n",
      "Epoch 7, Train_Loss 3.6772130489349366, Val_loss 3.8382956981658936\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.7125\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.6190678358078, Val_loss 3.8549420833587646\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5974334478378296, Val_loss 3.836005449295044\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.5152515888214113, Val_loss 3.925474166870117\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.4455549240112306, Val_loss 3.9070940017700195\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.58\t\n",
      "Epoch 12, Train_Loss 3.4193856000900267, Val_loss 3.8584775924682617\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 13, Train_Loss 3.361890125274658, Val_loss 3.7698888778686523\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.3749933004379273, Val_loss 3.725738286972046\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.3645193099975588, Val_loss 3.7312707901000977\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3282293558120726, Val_loss 3.734682083129883\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.2872015953063967, Val_loss 3.9066755771636963\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 18, Train_Loss 3.2711975812911986, Val_loss 3.7557880878448486\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 19, Train_Loss 3.253626298904419, Val_loss 3.73500919342041\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.2768863439559937, Val_loss 3.602912664413452\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2245510816574097, Val_loss 3.6906585693359375\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2349726438522337, Val_loss 3.64174485206604\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2377307415008545, Val_loss 3.7093992233276367\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.2264484643936155, Val_loss 3.64949107170105\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2268861532211304, Val_loss 3.7418124675750732\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 26, Train_Loss 3.1856258869171143, Val_loss 3.7727878093719482\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 27, Train_Loss 3.200880193710327, Val_loss 3.6347568035125732\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.1808653354644774, Val_loss 3.6398887634277344\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.1611709356307984, Val_loss 3.563797950744629\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1644994497299193, Val_loss 3.6670618057250977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 31, Train_Loss 3.178946828842163, Val_loss 3.6147468090057373\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1535747051239014, Val_loss 3.745554208755493\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 33, Train_Loss 3.153534507751465, Val_loss 3.671428918838501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 34, Train_Loss 3.1219449996948243, Val_loss 3.58211612701416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.12900173664093, Val_loss 3.6668612957000732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.1368947267532348, Val_loss 3.5964510440826416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.160542941093445, Val_loss 3.7124693393707275\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.140742802619934, Val_loss 3.5386297702789307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.145100498199463, Val_loss 3.6601455211639404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.1914832830429076, Val_loss 3.6073801517486572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.1349507331848145, Val_loss 3.6507091522216797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1336644649505616, Val_loss 3.6468312740325928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 43, Train_Loss 3.1429062843322755, Val_loss 3.588430643081665\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.122190737724304, Val_loss 3.651937484741211\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 45, Train_Loss 3.111164927482605, Val_loss 3.737405776977539\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 46, Train_Loss 3.1305724382400513, Val_loss 3.5545461177825928\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1527215003967286, Val_loss 3.714313507080078\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 48, Train_Loss 3.1405627489089967, Val_loss 3.594019651412964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1295754671096803, Val_loss 3.6089580059051514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.122266936302185, Val_loss 3.62805438041687\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.122090220451355, Val_loss 3.637200117111206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.087985706329346, Val_loss 3.622410535812378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.1201386213302613, Val_loss 3.5773861408233643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.0878670692443846, Val_loss 3.578218460083008\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.1268208265304565, Val_loss 3.596181631088257\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.0952636003494263, Val_loss 3.586273431777954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.154314947128296, Val_loss 3.5796737670898438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.106882643699646, Val_loss 3.57183575630188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1081387042999267, Val_loss 3.5819644927978516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.106800079345703, Val_loss 3.666084051132202\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.086753082275391, Val_loss 3.591174840927124\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.0899392127990724, Val_loss 3.5594635009765625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.091244697570801, Val_loss 3.5994207859039307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0693581104278564, Val_loss 3.57621693611145\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.0976236343383787, Val_loss 3.632932662963867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.1303060054779053, Val_loss 3.6142537593841553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0792112588882445, Val_loss 3.521489381790161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.075674366950989, Val_loss 3.5696372985839844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0735105991363527, Val_loss 3.589916944503784\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.088396501541138, Val_loss 3.5898454189300537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.0379438400268555, Val_loss 3.6236236095428467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.100341463088989, Val_loss 3.6503257751464844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 73, Train_Loss 3.052707576751709, Val_loss 3.5952045917510986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0860023736953734, Val_loss 3.5863046646118164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0795169830322267, Val_loss 3.6126320362091064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.074071455001831, Val_loss 3.6008012294769287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.115541911125183, Val_loss 3.587712049484253\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.054166841506958, Val_loss 3.5427017211914062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.109195852279663, Val_loss 3.5944159030914307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0736437320709227, Val_loss 3.602191925048828\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.1143152952194213, Val_loss 3.5965330600738525\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.0722394466400145, Val_loss 3.594762086868286\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0643110513687133, Val_loss 3.578443765640259\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0759077787399294, Val_loss 3.5818684101104736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.066360282897949, Val_loss 3.5717058181762695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0915629386901857, Val_loss 3.594219923019409\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.090824007987976, Val_loss 3.5984153747558594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.0901318550109864, Val_loss 3.5887677669525146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.077669787406921, Val_loss 3.6075992584228516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.081848978996277, Val_loss 3.600187301635742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.071409797668457, Val_loss 3.592867612838745\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0805349111557008, Val_loss 3.5709800720214844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.086234784126282, Val_loss 3.6112687587738037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0438454389572143, Val_loss 3.5645334720611572\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.046573305130005, Val_loss 3.5663034915924072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.067772316932678, Val_loss 3.5764894485473633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.0430266857147217, Val_loss 3.568877935409546\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.070859670639038, Val_loss 3.5952980518341064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0973623275756834, Val_loss 3.5913288593292236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.090594005584717, Val_loss 3.5831058025360107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9279749155044557, Val_loss 4.2903594970703125\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.125970840454102, Val_loss 4.228647232055664\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.069672584533691, Val_loss 4.19948148727417\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.951895523071289, Val_loss 4.130279064178467\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 5, Train_Loss 3.8627172708511353, Val_loss 3.9968366622924805\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.38\t\n",
      "Epoch 6, Train_Loss 3.764694166183472, Val_loss 3.8659141063690186\n",
      "Train_acc_top_20 0.2437\tTrain_acc_top_30 0.3875\tTrain_acc_top_40 0.4625\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.6799625873565676, Val_loss 3.8708858489990234\n",
      "Train_acc_top_20 0.6062\tTrain_acc_top_30 0.7937\tTrain_acc_top_40 0.8438\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6209999084472657, Val_loss 3.8045310974121094\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5802657842636108, Val_loss 3.8145062923431396\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.5033791065216064, Val_loss 3.738149642944336\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.462779712677002, Val_loss 3.7715847492218018\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.4383709907531737, Val_loss 3.709580421447754\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.3859121084213255, Val_loss 3.710819959640503\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 14, Train_Loss 3.349173974990845, Val_loss 3.7125585079193115\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.309356117248535, Val_loss 3.7246434688568115\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.337451934814453, Val_loss 3.7050621509552\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.2851106405258177, Val_loss 3.668853521347046\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.2609857082366944, Val_loss 3.6040849685668945\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.260370302200317, Val_loss 3.6733694076538086\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2570972204208375, Val_loss 3.6468169689178467\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.275514101982117, Val_loss 3.762460947036743\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.228894090652466, Val_loss 3.612072229385376\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.2227084159851076, Val_loss 3.6627798080444336\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 24, Train_Loss 3.213437867164612, Val_loss 3.6157381534576416\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.213359236717224, Val_loss 3.645504951477051\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.2083009243011475, Val_loss 3.626680374145508\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 27, Train_Loss 3.1693739175796507, Val_loss 3.6022818088531494\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1817676782608033, Val_loss 3.632263422012329\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.1731684923172, Val_loss 3.6380484104156494\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 30, Train_Loss 3.2038751363754274, Val_loss 3.5935916900634766\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1854206800460814, Val_loss 3.6389036178588867\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1848203897476197, Val_loss 3.7142446041107178\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.2127465486526487, Val_loss 3.6199848651885986\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.1830838203430174, Val_loss 3.619476556777954\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1495558500289915, Val_loss 3.686586380004883\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1643868684768677, Val_loss 3.68241024017334\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.1367247104644775, Val_loss 3.6648752689361572\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.131463575363159, Val_loss 3.6294658184051514\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.124255919456482, Val_loss 3.622708559036255\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.1311964988708496, Val_loss 3.7162578105926514\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1422963619232176, Val_loss 3.5860421657562256\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1394993543624876, Val_loss 3.626244306564331\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.1323112726211546, Val_loss 3.6372783184051514\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1147257804870607, Val_loss 3.6667299270629883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.152550292015076, Val_loss 3.645881414413452\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.1314244747161863, Val_loss 3.619823455810547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.1015694379806518, Val_loss 3.629415512084961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.1094231367111207, Val_loss 3.628495216369629\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1444050073623657, Val_loss 3.657594919204712\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.1212971210479736, Val_loss 3.729140043258667\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.0963091373443605, Val_loss 3.7201318740844727\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.084359955787659, Val_loss 3.6438963413238525\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.0911886215209963, Val_loss 3.688913345336914\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1371634721755983, Val_loss 3.700709581375122\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.082889175415039, Val_loss 3.6731748580932617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.16032931804657, Val_loss 3.6866865158081055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.0697864294052124, Val_loss 3.695035934448242\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.098677968978882, Val_loss 3.6764535903930664\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.0822864055633543, Val_loss 3.7210264205932617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.152441668510437, Val_loss 3.748056650161743\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 61, Train_Loss 3.0654656887054443, Val_loss 3.6574184894561768\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0814961433410644, Val_loss 3.6935746669769287\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.0869803428649902, Val_loss 3.725095510482788\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 64, Train_Loss 3.116611933708191, Val_loss 3.7221524715423584\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.1164557456970217, Val_loss 3.681819200515747\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.054416561126709, Val_loss 3.6636874675750732\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 67, Train_Loss 3.103840470314026, Val_loss 3.7336952686309814\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.1160154342651367, Val_loss 3.739288091659546\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.0870461225509644, Val_loss 3.6506786346435547\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.065787601470947, Val_loss 3.6929829120635986\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.0787925720214844, Val_loss 3.694244146347046\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 72, Train_Loss 3.122077488899231, Val_loss 3.729292869567871\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.102928304672241, Val_loss 3.717705011367798\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 74, Train_Loss 3.08440523147583, Val_loss 3.6817798614501953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.068357467651367, Val_loss 3.7126786708831787\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 76, Train_Loss 3.0192328214645388, Val_loss 3.6898345947265625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.09306423664093, Val_loss 3.7217447757720947\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.071743297576904, Val_loss 3.682494878768921\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 79, Train_Loss 3.0993234872817994, Val_loss 3.6996097564697266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.061747431755066, Val_loss 3.6980340480804443\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.0328338861465456, Val_loss 3.6752612590789795\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 82, Train_Loss 3.068937349319458, Val_loss 3.712712049484253\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.095175361633301, Val_loss 3.703240156173706\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.12873752117157, Val_loss 3.714886426925659\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 85, Train_Loss 3.0715740442276003, Val_loss 3.7012860774993896\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 86, Train_Loss 3.048780417442322, Val_loss 3.727482795715332\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 87, Train_Loss 3.0808408498764037, Val_loss 3.7071263790130615\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 88, Train_Loss 3.0374046564102173, Val_loss 3.7141687870025635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 89, Train_Loss 3.0621175289154055, Val_loss 3.7224113941192627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 90, Train_Loss 3.0697429180145264, Val_loss 3.715254068374634\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 91, Train_Loss 3.089029097557068, Val_loss 3.674553632736206\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 92, Train_Loss 3.0850797414779665, Val_loss 3.725970983505249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.133496642112732, Val_loss 3.6996514797210693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.087395358085632, Val_loss 3.6596519947052\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.049861288070679, Val_loss 3.729560136795044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 96, Train_Loss 3.057144284248352, Val_loss 3.689234495162964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 97, Train_Loss 3.0608912467956544, Val_loss 3.7128283977508545\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 98, Train_Loss 3.0580803632736204, Val_loss 3.6631813049316406\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 99, Train_Loss 3.080100393295288, Val_loss 3.726562261581421\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 100, Train_Loss 3.055791473388672, Val_loss 3.7132568359375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 1, Train_Loss 3.9163909435272215, Val_loss 4.238255977630615\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.10776948928833, Val_loss 4.184908866882324\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.033892107009888, Val_loss 4.215027332305908\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9116971254348756, Val_loss 4.214972972869873\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.818316912651062, Val_loss 4.117016315460205\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.765316128730774, Val_loss 3.7830753326416016\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.35\tTrain_acc_top_40 0.45\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.6911699056625364, Val_loss 3.678500175476074\n",
      "Train_acc_top_20 0.5813\tTrain_acc_top_30 0.7688\tTrain_acc_top_40 0.8375\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 8, Train_Loss 3.6318962812423705, Val_loss 3.6116955280303955\n",
      "Train_acc_top_20 0.7\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 9, Train_Loss 3.5622554779052735, Val_loss 3.6024887561798096\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.504906415939331, Val_loss 3.607013463973999\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 11, Train_Loss 3.507839226722717, Val_loss 3.6262056827545166\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4799888134002686, Val_loss 3.6653244495391846\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.4002028465270997, Val_loss 3.476210355758667\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 14, Train_Loss 3.3887338638305664, Val_loss 3.6708014011383057\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.370877981185913, Val_loss 3.5294313430786133\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.32535035610199, Val_loss 3.6041953563690186\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 17, Train_Loss 3.377078318595886, Val_loss 3.6838619709014893\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.295057940483093, Val_loss 3.542752981185913\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2846818208694457, Val_loss 3.5839693546295166\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 20, Train_Loss 3.2809202432632447, Val_loss 3.5268640518188477\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2679811000823973, Val_loss 3.4636285305023193\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 22, Train_Loss 3.2510913848876952, Val_loss 3.629060983657837\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2797184705734255, Val_loss 3.5841989517211914\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.236455535888672, Val_loss 3.552535057067871\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.2493441581726072, Val_loss 3.5435619354248047\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 26, Train_Loss 3.2095010757446287, Val_loss 3.5326578617095947\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.196665573120117, Val_loss 3.559492826461792\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.2277950763702394, Val_loss 3.520932912826538\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 29, Train_Loss 3.213223361968994, Val_loss 3.507338762283325\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 30, Train_Loss 3.1878642797470094, Val_loss 3.536412000656128\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.1805129289627074, Val_loss 3.5315887928009033\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 32, Train_Loss 3.173579287528992, Val_loss 3.4973974227905273\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 33, Train_Loss 3.1434526681900024, Val_loss 3.5544636249542236\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.1790070295333863, Val_loss 3.499208688735962\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1762038230895997, Val_loss 3.515047073364258\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1438332557678224, Val_loss 3.449469566345215\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 37, Train_Loss 3.1504998445510863, Val_loss 3.5674755573272705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.1566487073898317, Val_loss 3.527778387069702\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.92\t\n",
      "Epoch 39, Train_Loss 3.165754294395447, Val_loss 3.501323938369751\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 40, Train_Loss 3.1469631433486938, Val_loss 3.6208393573760986\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.165481615066528, Val_loss 3.51755690574646\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.1462355852127075, Val_loss 3.4980251789093018\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.161580729484558, Val_loss 3.5309016704559326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.1381466388702393, Val_loss 3.5349462032318115\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1261269569396974, Val_loss 3.578904151916504\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.139249801635742, Val_loss 3.5758533477783203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.119069504737854, Val_loss 3.5028791427612305\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 48, Train_Loss 3.1352716445922852, Val_loss 3.5597658157348633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.1232841491699217, Val_loss 3.554046869277954\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1519814252853395, Val_loss 3.4843082427978516\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.13866765499115, Val_loss 3.5147650241851807\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1018380165100097, Val_loss 3.499462366104126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.130232834815979, Val_loss 3.5156171321868896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 54, Train_Loss 3.101792740821838, Val_loss 3.527189016342163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.109142303466797, Val_loss 3.553013563156128\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.167141914367676, Val_loss 3.5427348613739014\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1240954637527465, Val_loss 3.4657437801361084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.111313319206238, Val_loss 3.501009225845337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 59, Train_Loss 3.1267544746398928, Val_loss 3.53301739692688\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.110967254638672, Val_loss 3.509753942489624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.083856153488159, Val_loss 3.5228404998779297\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1009238958358765, Val_loss 3.5135345458984375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.117738056182861, Val_loss 3.4827539920806885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.076238679885864, Val_loss 3.502122640609741\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.1109923839569094, Val_loss 3.535003662109375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.088072633743286, Val_loss 3.4901082515716553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.1284605979919435, Val_loss 3.504929304122925\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.09418625831604, Val_loss 3.5731871128082275\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.103965973854065, Val_loss 3.5180318355560303\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.0892600059509276, Val_loss 3.552783250808716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.091478419303894, Val_loss 3.5435798168182373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.1116544008255005, Val_loss 3.5204076766967773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.1199562788009643, Val_loss 3.5527877807617188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0808850288391114, Val_loss 3.508892774581909\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.086431884765625, Val_loss 3.5245110988616943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.1057233095169066, Val_loss 3.547866106033325\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.070658302307129, Val_loss 3.5264394283294678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.0625619411468508, Val_loss 3.5342814922332764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.099904775619507, Val_loss 3.521906852722168\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.102989339828491, Val_loss 3.5715749263763428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.1192350149154664, Val_loss 3.530763626098633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.051717209815979, Val_loss 3.5308711528778076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.137653088569641, Val_loss 3.5439956188201904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.085974431037903, Val_loss 3.557103157043457\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.086453890800476, Val_loss 3.5435688495635986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.1352532863616944, Val_loss 3.564215660095215\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0847959995269774, Val_loss 3.5126752853393555\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.121539521217346, Val_loss 3.5386645793914795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.081680250167847, Val_loss 3.5487048625946045\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0791309118270873, Val_loss 3.5079479217529297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.1125177145004272, Val_loss 3.531510353088379\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.132469820976257, Val_loss 3.540569543838501\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.124683380126953, Val_loss 3.5280845165252686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.065841555595398, Val_loss 3.5034916400909424\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.097605586051941, Val_loss 3.5335264205932617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.102218675613403, Val_loss 3.521576166152954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.1135793924331665, Val_loss 3.5342319011688232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.10522940158844, Val_loss 3.5071141719818115\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.1106908321380615, Val_loss 3.5173861980438232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.098553276062012, Val_loss 3.50723934173584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9348374128341677, Val_loss 4.2645416259765625\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.04\t\n",
      "Epoch 2, Train_Loss 4.117933750152588, Val_loss 4.188528537750244\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.08\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.0692285060882565, Val_loss 4.168113708496094\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.963058614730835, Val_loss 4.0899763107299805\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.870697045326233, Val_loss 3.987295150756836\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7869186878204344, Val_loss 3.8469417095184326\n",
      "Train_acc_top_20 0.2375\tTrain_acc_top_30 0.3625\tTrain_acc_top_40 0.4313\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.38\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.7024576663970947, Val_loss 3.774651527404785\n",
      "Train_acc_top_20 0.5563\tTrain_acc_top_30 0.775\tTrain_acc_top_40 0.8625\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.644323492050171, Val_loss 3.796464681625366\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.572979474067688, Val_loss 3.718980550765991\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.506209135055542, Val_loss 3.7063076496124268\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.4728969812393187, Val_loss 3.678072690963745\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 12, Train_Loss 3.4412815809249877, Val_loss 3.712005853652954\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.4245856046676635, Val_loss 3.7773244380950928\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 14, Train_Loss 3.388275718688965, Val_loss 3.8197669982910156\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 15, Train_Loss 3.3690051555633547, Val_loss 3.6499640941619873\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.319085931777954, Val_loss 3.6325910091400146\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.304732084274292, Val_loss 3.638836622238159\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.333880090713501, Val_loss 3.719360589981079\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.2877117872238157, Val_loss 3.690053939819336\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 20, Train_Loss 3.280226492881775, Val_loss 3.6133487224578857\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2483407258987427, Val_loss 3.6735315322875977\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.2255865573883056, Val_loss 3.6450979709625244\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 23, Train_Loss 3.2196616172790526, Val_loss 3.632641077041626\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.214436149597168, Val_loss 3.6666691303253174\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.2092604637145996, Val_loss 3.619182586669922\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 26, Train_Loss 3.1942254066467286, Val_loss 3.5893185138702393\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.1904335260391234, Val_loss 3.648207664489746\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.221894311904907, Val_loss 3.576401710510254\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.183730053901672, Val_loss 3.608003616333008\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.183490180969238, Val_loss 3.595438003540039\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.184778332710266, Val_loss 3.6699953079223633\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1633206844329833, Val_loss 3.6073052883148193\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 33, Train_Loss 3.1686410188674925, Val_loss 3.6782147884368896\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1501280784606935, Val_loss 3.6167237758636475\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1478785991668703, Val_loss 3.610053777694702\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.1208937883377077, Val_loss 3.693460702896118\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.149433946609497, Val_loss 3.6127803325653076\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1504537582397463, Val_loss 3.731153726577759\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.176467204093933, Val_loss 3.6589319705963135\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.1693078517913817, Val_loss 3.604031801223755\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.1676804304122923, Val_loss 3.612128257751465\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.169759202003479, Val_loss 3.6052942276000977\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1804136753082277, Val_loss 3.5834436416625977\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.1324604749679565, Val_loss 3.6027774810791016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1393743991851806, Val_loss 3.6161139011383057\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1398524761199953, Val_loss 3.641326665878296\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.1481513500213625, Val_loss 3.5966501235961914\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 48, Train_Loss 3.1530978679656982, Val_loss 3.607374429702759\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.0985195875167846, Val_loss 3.5769436359405518\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.1571926832199098, Val_loss 3.68942928314209\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.109833002090454, Val_loss 3.561998128890991\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 52, Train_Loss 3.128365159034729, Val_loss 3.611082077026367\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 53, Train_Loss 3.137838840484619, Val_loss 3.6155776977539062\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.1107596158981323, Val_loss 3.575836420059204\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.1065369129180906, Val_loss 3.5552902221679688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.0783479690551756, Val_loss 3.5777628421783447\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.102163529396057, Val_loss 3.5855605602264404\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.0656224966049193, Val_loss 3.5943191051483154\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.138436031341553, Val_loss 3.5970165729522705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.135127139091492, Val_loss 3.5820541381835938\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.1190842390060425, Val_loss 3.556838035583496\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.0814053773880006, Val_loss 3.5525424480438232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.0923341035842897, Val_loss 3.578242063522339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1199411153793335, Val_loss 3.56168532371521\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.12091007232666, Val_loss 3.5871829986572266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.063243293762207, Val_loss 3.5403549671173096\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.125682330131531, Val_loss 3.573160409927368\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.089881682395935, Val_loss 3.5899009704589844\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.1216634273529054, Val_loss 3.5716609954833984\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.149781894683838, Val_loss 3.5774457454681396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.1317734241485597, Val_loss 3.57201886177063\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.0574930191040037, Val_loss 3.556600570678711\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0640760183334352, Val_loss 3.5776309967041016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.1492958545684813, Val_loss 3.5867042541503906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.077785277366638, Val_loss 3.5689163208007812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.114853286743164, Val_loss 3.5782196521759033\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 77, Train_Loss 3.104569435119629, Val_loss 3.557398796081543\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.136289596557617, Val_loss 3.565358877182007\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.044305515289307, Val_loss 3.5617895126342773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0858081102371218, Val_loss 3.5683488845825195\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.1008744716644285, Val_loss 3.56569766998291\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1504027366638185, Val_loss 3.5797111988067627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.1416028499603272, Val_loss 3.5848264694213867\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.074377417564392, Val_loss 3.572155714035034\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.1304984092712402, Val_loss 3.5698413848876953\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.172681713104248, Val_loss 3.5677108764648438\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.15574471950531, Val_loss 3.5819597244262695\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.151351737976074, Val_loss 3.550825834274292\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.0520519018173218, Val_loss 3.55353045463562\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.1016714572906494, Val_loss 3.5527455806732178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.061414670944214, Val_loss 3.5504000186920166\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.064359354972839, Val_loss 3.596088409423828\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.039322257041931, Val_loss 3.575596809387207\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.1025262117385863, Val_loss 3.569648504257202\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0496330738067625, Val_loss 3.615159273147583\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.127638649940491, Val_loss 3.5907185077667236\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.104131984710693, Val_loss 3.551664352416992\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.1169909954071047, Val_loss 3.549206495285034\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.1412606954574587, Val_loss 3.5599777698516846\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.1107073068618774, Val_loss 3.5466222763061523\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9316593647003173, Val_loss 4.212157726287842\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.119331169128418, Val_loss 4.167089939117432\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2625\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.061489057540894, Val_loss 4.129443645477295\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9594043493270874, Val_loss 4.057924747467041\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.38\t\n",
      "Epoch 5, Train_Loss 3.856667160987854, Val_loss 3.9481136798858643\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.33\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.77714319229126, Val_loss 3.781196355819702\n",
      "Train_acc_top_20 0.2188\tTrain_acc_top_30 0.3063\tTrain_acc_top_40 0.4\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.733818531036377, Val_loss 3.6420373916625977\n",
      "Train_acc_top_20 0.5563\tTrain_acc_top_30 0.6625\tTrain_acc_top_40 0.75\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.655761170387268, Val_loss 3.5634851455688477\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8562\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.623194098472595, Val_loss 3.533926248550415\n",
      "Train_acc_top_20 0.7562\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5504777431488037, Val_loss 3.5378940105438232\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.503025031089783, Val_loss 3.483358383178711\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4300326347351073, Val_loss 3.507286310195923\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.401081418991089, Val_loss 3.463488817214966\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 14, Train_Loss 3.3552557229995728, Val_loss 3.4922101497650146\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.333482098579407, Val_loss 3.4843928813934326\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.3033912658691404, Val_loss 3.493541717529297\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.2944153547286987, Val_loss 3.4804575443267822\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 18, Train_Loss 3.264145612716675, Val_loss 3.5336244106292725\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2431368589401246, Val_loss 3.508854627609253\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.234931492805481, Val_loss 3.445781946182251\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.259836745262146, Val_loss 3.6700267791748047\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 22, Train_Loss 3.2276180267333983, Val_loss 3.487730026245117\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.210972309112549, Val_loss 3.4854238033294678\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.2064972162246703, Val_loss 3.4876203536987305\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.1933515310287475, Val_loss 3.506514310836792\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.20472936630249, Val_loss 3.4750778675079346\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.2062066555023194, Val_loss 3.4146976470947266\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.190610098838806, Val_loss 3.660526990890503\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 29, Train_Loss 3.162507677078247, Val_loss 3.5064170360565186\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.182127809524536, Val_loss 3.4773385524749756\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.1491298198699953, Val_loss 3.506953001022339\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1606643199920654, Val_loss 3.5017805099487305\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.1600679636001585, Val_loss 3.5489914417266846\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1637438535690308, Val_loss 3.574521780014038\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1435952186584473, Val_loss 3.583757162094116\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.2048900604248045, Val_loss 3.5283682346343994\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1282186031341555, Val_loss 3.60249400138855\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1262560844421388, Val_loss 3.6214160919189453\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1055099964141846, Val_loss 3.4489614963531494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 40, Train_Loss 3.135455298423767, Val_loss 3.4789907932281494\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.1206902265548706, Val_loss 3.499737024307251\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.1516672372817993, Val_loss 3.4442718029022217\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.168144178390503, Val_loss 3.584374189376831\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.1240137815475464, Val_loss 3.7677395343780518\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 45, Train_Loss 3.1375150203704836, Val_loss 3.556717872619629\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.160649371147156, Val_loss 3.480997085571289\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.1275913238525392, Val_loss 3.5142557621002197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1302324533462524, Val_loss 3.4273507595062256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.133639597892761, Val_loss 3.441774368286133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1156501531600953, Val_loss 3.428419828414917\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1251322507858275, Val_loss 3.549825668334961\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.1141639232635496, Val_loss 3.4514894485473633\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.1409213304519654, Val_loss 3.4130306243896484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.077342963218689, Val_loss 3.5349340438842773\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.1190398216247557, Val_loss 3.5162506103515625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.0909830808639525, Val_loss 3.477457046508789\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.085650587081909, Val_loss 3.41789174079895\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.07914936542511, Val_loss 3.497097969055176\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.127314591407776, Val_loss 3.4950268268585205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0799344301223757, Val_loss 3.420459032058716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.0960530996322633, Val_loss 3.472721815109253\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.102284336090088, Val_loss 3.4508354663848877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1206663846969604, Val_loss 3.4967901706695557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0486679792404177, Val_loss 3.5535728931427\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.0727664470672607, Val_loss 3.478940963745117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.098669481277466, Val_loss 3.4326934814453125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 67, Train_Loss 3.1074887037277223, Val_loss 3.5000054836273193\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.093723249435425, Val_loss 3.545201301574707\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.1379515171051025, Val_loss 3.5416080951690674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.1428958654403685, Val_loss 3.4456894397735596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.1400551080703734, Val_loss 3.5166919231414795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.030395197868347, Val_loss 3.508289337158203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.1341168880462646, Val_loss 3.4799423217773438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0915388107299804, Val_loss 3.5346615314483643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.13060622215271, Val_loss 3.5095174312591553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.1244250535964966, Val_loss 3.446012258529663\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0659735918045046, Val_loss 3.483144998550415\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.053696608543396, Val_loss 3.488412618637085\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.125269079208374, Val_loss 3.521347999572754\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.0974656105041505, Val_loss 3.456406831741333\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.1541908502578737, Val_loss 3.416140556335449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.1085817575454713, Val_loss 3.4357786178588867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.0721643924713136, Val_loss 3.4574058055877686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.1174790143966673, Val_loss 3.4403727054595947\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.1042162418365478, Val_loss 3.48001766204834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0334142684936523, Val_loss 3.4811513423919678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.083590030670166, Val_loss 3.4749374389648438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.095144581794739, Val_loss 3.4872682094573975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.121358275413513, Val_loss 3.456505537033081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.109163212776184, Val_loss 3.4515883922576904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.0766414403915405, Val_loss 3.4507992267608643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.052798056602478, Val_loss 3.478558301925659\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.0762666702270507, Val_loss 3.489489793777466\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.109647250175476, Val_loss 3.4259045124053955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.087448525428772, Val_loss 3.469776153564453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0400822162628174, Val_loss 3.4566125869750977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.0863718509674074, Val_loss 3.4734580516815186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0527377843856813, Val_loss 3.47224497795105\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.0718661308288575, Val_loss 3.4400272369384766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.1342127323150635, Val_loss 3.494399070739746\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9230523347854613, Val_loss 4.289852619171143\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.08\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.119887256622315, Val_loss 4.2619194984436035\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.04\t\n",
      "Epoch 3, Train_Loss 4.070279741287232, Val_loss 4.285672187805176\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.04\t\n",
      "Epoch 4, Train_Loss 3.9434860229492186, Val_loss 4.192702770233154\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 5, Train_Loss 3.821220874786377, Val_loss 4.051638126373291\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.08\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.7390554666519167, Val_loss 3.8554582595825195\n",
      "Train_acc_top_20 0.2562\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.4625\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.657642698287964, Val_loss 3.753253698348999\n",
      "Train_acc_top_20 0.5437\tTrain_acc_top_30 0.725\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.600692129135132, Val_loss 3.700274705886841\n",
      "Train_acc_top_20 0.7125\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5708577394485475, Val_loss 3.677525281906128\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.5057913064956665, Val_loss 3.6678638458251953\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4857624530792237, Val_loss 3.6364309787750244\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.4677009105682375, Val_loss 3.64977765083313\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.4067479610443114, Val_loss 3.61100697517395\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3782359838485716, Val_loss 3.561992645263672\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3391963243484497, Val_loss 3.575134515762329\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.318754720687866, Val_loss 3.54496169090271\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.282395100593567, Val_loss 3.585704803466797\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.3167285442352297, Val_loss 3.5398542881011963\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.320536398887634, Val_loss 3.6615850925445557\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 20, Train_Loss 3.2930591821670534, Val_loss 3.663996696472168\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.2909372568130495, Val_loss 3.551828145980835\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2549479961395265, Val_loss 3.5928757190704346\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.2573999643325804, Val_loss 3.5974369049072266\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 24, Train_Loss 3.213541269302368, Val_loss 3.510322332382202\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.200032639503479, Val_loss 3.46096134185791\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.192812466621399, Val_loss 3.521359443664551\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.1690729379653932, Val_loss 3.506479263305664\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.2035425662994386, Val_loss 3.4163730144500732\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.1942930936813356, Val_loss 3.4548041820526123\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 30, Train_Loss 3.163620448112488, Val_loss 3.533433675765991\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1598968505859375, Val_loss 3.4829397201538086\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1532862186431885, Val_loss 3.6774442195892334\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 33, Train_Loss 3.178281545639038, Val_loss 3.4408786296844482\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.137018632888794, Val_loss 3.440000295639038\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.1725260496139525, Val_loss 3.4713428020477295\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1323617458343507, Val_loss 3.4586715698242188\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.113705348968506, Val_loss 3.433522939682007\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.142485737800598, Val_loss 3.5022852420806885\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1243985891342163, Val_loss 3.4904117584228516\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1478453874588013, Val_loss 3.4805126190185547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.139462447166443, Val_loss 3.5096991062164307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.151303791999817, Val_loss 3.6691954135894775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 43, Train_Loss 3.097621512413025, Val_loss 3.4929325580596924\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1294134140014647, Val_loss 3.5131778717041016\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1261645793914794, Val_loss 3.460930585861206\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.072904944419861, Val_loss 3.4509332180023193\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.121734118461609, Val_loss 3.4921023845672607\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.0986664056777955, Val_loss 3.4451329708099365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.096639370918274, Val_loss 3.4728927612304688\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1164299488067626, Val_loss 3.5082390308380127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1174349069595335, Val_loss 3.4586055278778076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.123095893859863, Val_loss 3.451349973678589\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.0598284006118774, Val_loss 3.4160327911376953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.118349814414978, Val_loss 3.480567216873169\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.0930376768112184, Val_loss 3.450571060180664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.08895366191864, Val_loss 3.4342973232269287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.103608775138855, Val_loss 3.4410221576690674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.1625439882278443, Val_loss 3.4555814266204834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.12507541179657, Val_loss 3.6442432403564453\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.102606201171875, Val_loss 3.4272079467773438\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.0832738399505617, Val_loss 3.4611260890960693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1325880765914915, Val_loss 3.447500228881836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1010019063949583, Val_loss 3.4428396224975586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.06847505569458, Val_loss 3.388404607772827\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.121289038658142, Val_loss 3.506140947341919\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.0726448774337767, Val_loss 3.458338499069214\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.09845712184906, Val_loss 3.3876264095306396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1270087003707885, Val_loss 3.4490082263946533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0956448554992675, Val_loss 3.440305709838867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.072660136222839, Val_loss 3.402339220046997\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0770006656646727, Val_loss 3.452482223510742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.060970973968506, Val_loss 3.399519681930542\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0571978092193604, Val_loss 3.428325891494751\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.097323989868164, Val_loss 3.4475810527801514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.0578028202056884, Val_loss 3.4518353939056396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.0699010133743285, Val_loss 3.4554836750030518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.063873291015625, Val_loss 3.424675703048706\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.090633988380432, Val_loss 3.436638832092285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.057358503341675, Val_loss 3.413496255874634\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0980722427368166, Val_loss 3.4790499210357666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.1224528789520263, Val_loss 3.4237582683563232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0464035749435423, Val_loss 3.444430112838745\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.1120834350585938, Val_loss 3.4733402729034424\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.1069268941879273, Val_loss 3.4639484882354736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.106673812866211, Val_loss 3.4570562839508057\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0233139753341676, Val_loss 3.446261167526245\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.047287034988403, Val_loss 3.3789968490600586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.097525691986084, Val_loss 3.441826581954956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0793790102005003, Val_loss 3.422361135482788\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.1071922540664674, Val_loss 3.4663302898406982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.041052460670471, Val_loss 3.4583797454833984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.0766129732131957, Val_loss 3.424612045288086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.052248811721802, Val_loss 3.4844486713409424\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0653971910476683, Val_loss 3.4198224544525146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0744290590286254, Val_loss 3.401524305343628\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.017078471183777, Val_loss 3.394153594970703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.0544392108917235, Val_loss 3.436453104019165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0486066579818725, Val_loss 3.438753843307495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0722164869308473, Val_loss 3.431098222732544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.118976187705994, Val_loss 3.4373939037323\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9364041805267336, Val_loss 4.265448093414307\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.113490772247315, Val_loss 4.1980366706848145\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.052915716171265, Val_loss 4.2223687171936035\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.952300548553467, Val_loss 4.150259494781494\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8362783432006835, Val_loss 3.989077568054199\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7643004655838013, Val_loss 3.796464204788208\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.3875\tTrain_acc_top_40 0.475\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.7112584114074707, Val_loss 3.8006591796875\n",
      "Train_acc_top_20 0.5062\tTrain_acc_top_30 0.7188\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.633801078796387, Val_loss 3.785320997238159\n",
      "Train_acc_top_20 0.7562\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.591456913948059, Val_loss 3.674913167953491\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.52170877456665, Val_loss 3.6727101802825928\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4764991283416746, Val_loss 3.6453800201416016\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.455722975730896, Val_loss 3.714444398880005\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.47530837059021, Val_loss 3.6161324977874756\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.3925692558288576, Val_loss 3.6150588989257812\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3617895603179933, Val_loss 3.6678550243377686\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 16, Train_Loss 3.3256186723709105, Val_loss 3.6576364040374756\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.3178653955459594, Val_loss 3.5592095851898193\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.307696723937988, Val_loss 3.6171207427978516\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.28751802444458, Val_loss 3.5748367309570312\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.262157344818115, Val_loss 3.538811683654785\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.254355311393738, Val_loss 3.5190610885620117\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.242903971672058, Val_loss 3.4833621978759766\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2224615097045897, Val_loss 3.558917999267578\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.206039309501648, Val_loss 3.5169217586517334\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.207987380027771, Val_loss 3.5370256900787354\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.236755061149597, Val_loss 3.6035478115081787\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.2415136098861694, Val_loss 3.6290628910064697\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 28, Train_Loss 3.2860356330871583, Val_loss 3.5040292739868164\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.224285292625427, Val_loss 3.5344221591949463\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.212381958961487, Val_loss 3.6443681716918945\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.1650745153427122, Val_loss 3.4768903255462646\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1639832973480226, Val_loss 3.4267494678497314\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.176426720619202, Val_loss 3.455004930496216\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.159923768043518, Val_loss 3.51641845703125\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1397619009017945, Val_loss 3.4695050716400146\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1431806325912475, Val_loss 3.54422664642334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1510709285736085, Val_loss 3.5298988819122314\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.252675414085388, Val_loss 3.48478627204895\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.177462100982666, Val_loss 3.438690423965454\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.1979220151901244, Val_loss 3.410146474838257\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.1269384145736696, Val_loss 3.413212537765503\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.1619959831237794, Val_loss 3.4398012161254883\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.1832234382629396, Val_loss 3.401231527328491\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.191636395454407, Val_loss 3.538151741027832\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.16362464427948, Val_loss 3.5518264770507812\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1921910285949706, Val_loss 3.463545799255371\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.140083909034729, Val_loss 3.463146924972534\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 48, Train_Loss 3.1273104667663576, Val_loss 3.4856014251708984\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.114294743537903, Val_loss 3.457636594772339\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1134029626846313, Val_loss 3.411607503890991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.0761959552764893, Val_loss 3.477781057357788\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.174997901916504, Val_loss 3.4196321964263916\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.1622922658920287, Val_loss 3.4800548553466797\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.124271869659424, Val_loss 3.404003143310547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.124433970451355, Val_loss 3.4327595233917236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 56, Train_Loss 3.15935161113739, Val_loss 3.4356849193573\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.1421460151672362, Val_loss 3.3929388523101807\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.1037314414978026, Val_loss 3.3925275802612305\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 59, Train_Loss 3.163256025314331, Val_loss 3.4391181468963623\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 60, Train_Loss 3.145364546775818, Val_loss 3.4130916595458984\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 61, Train_Loss 3.1168082475662233, Val_loss 3.4275808334350586\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 62, Train_Loss 3.1474562644958497, Val_loss 3.4517505168914795\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.0919389724731445, Val_loss 3.3830220699310303\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.1207896947860716, Val_loss 3.4358272552490234\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 65, Train_Loss 3.08276743888855, Val_loss 3.3964507579803467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.097988557815552, Val_loss 3.437260866165161\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.112906336784363, Val_loss 3.4182825088500977\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 68, Train_Loss 3.1503183841705322, Val_loss 3.444622278213501\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 69, Train_Loss 3.1474515914916994, Val_loss 3.4053945541381836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 70, Train_Loss 3.0876941442489625, Val_loss 3.387305974960327\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.1481559038162232, Val_loss 3.4250881671905518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 72, Train_Loss 3.0986457109451293, Val_loss 3.4222145080566406\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.101988410949707, Val_loss 3.4186716079711914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.0730082035064696, Val_loss 3.373680353164673\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 75, Train_Loss 3.09992778301239, Val_loss 3.4013845920562744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 76, Train_Loss 3.1581743001937865, Val_loss 3.45227313041687\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.0880834579467775, Val_loss 3.4368793964385986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.0837720155715944, Val_loss 3.4156503677368164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.0951619148254395, Val_loss 3.4554519653320312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1368895292282106, Val_loss 3.448246717453003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.0602789878845216, Val_loss 3.4254961013793945\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 82, Train_Loss 3.127346992492676, Val_loss 3.4050099849700928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 83, Train_Loss 3.086003875732422, Val_loss 3.404433250427246\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 84, Train_Loss 3.1136932134628297, Val_loss 3.4481565952301025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 85, Train_Loss 3.086962580680847, Val_loss 3.407785654067993\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.1335015296936035, Val_loss 3.432863473892212\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.0896690845489503, Val_loss 3.405716896057129\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 88, Train_Loss 3.1311941146850586, Val_loss 3.4293453693389893\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 89, Train_Loss 3.0891225576400756, Val_loss 3.3860559463500977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 90, Train_Loss 3.1516839504241942, Val_loss 3.3716394901275635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.099202370643616, Val_loss 3.3994691371917725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 92, Train_Loss 3.12755970954895, Val_loss 3.4239542484283447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 93, Train_Loss 3.1191186189651487, Val_loss 3.4189558029174805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 94, Train_Loss 3.0923702239990236, Val_loss 3.386383056640625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 95, Train_Loss 3.14076452255249, Val_loss 3.389742851257324\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 96, Train_Loss 3.0937307357788084, Val_loss 3.3995048999786377\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.089815783500671, Val_loss 3.3973448276519775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.1019665956497193, Val_loss 3.386078119277954\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 99, Train_Loss 3.1060598373413084, Val_loss 3.416006326675415\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 100, Train_Loss 3.0571098804473875, Val_loss 3.369237184524536\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 1, Train_Loss 3.9244120836257936, Val_loss 4.235504150390625\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.126309061050415, Val_loss 4.171175003051758\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 3, Train_Loss 4.078030824661255, Val_loss 4.168074131011963\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9620288848876952, Val_loss 4.04773473739624\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.859028172492981, Val_loss 3.9151570796966553\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.778605318069458, Val_loss 3.873979330062866\n",
      "Train_acc_top_20 0.2562\tTrain_acc_top_30 0.3625\tTrain_acc_top_40 0.45\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 7, Train_Loss 3.6876333713531495, Val_loss 3.848926544189453\n",
      "Train_acc_top_20 0.5\tTrain_acc_top_30 0.6562\tTrain_acc_top_40 0.725\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.6172813892364504, Val_loss 3.8657026290893555\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.8688\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.38\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5571486949920654, Val_loss 3.7895212173461914\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.5263946294784545, Val_loss 3.804307699203491\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.455644726753235, Val_loss 3.763833999633789\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.4100562572479247, Val_loss 3.68267560005188\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.3628254175186156, Val_loss 3.733476400375366\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3622748613357545, Val_loss 3.8020904064178467\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 15, Train_Loss 3.328141379356384, Val_loss 3.777351140975952\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 16, Train_Loss 3.319730591773987, Val_loss 3.7249956130981445\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 17, Train_Loss 3.2786840438842773, Val_loss 3.6921722888946533\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 18, Train_Loss 3.295160746574402, Val_loss 3.6946847438812256\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 19, Train_Loss 3.2318842887878416, Val_loss 3.6934337615966797\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 20, Train_Loss 3.226422595977783, Val_loss 3.629962682723999\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.242503356933594, Val_loss 3.8010997772216797\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 22, Train_Loss 3.2270514249801634, Val_loss 3.8658294677734375\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.54\t\n",
      "Epoch 23, Train_Loss 3.2491249322891234, Val_loss 3.7712507247924805\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.2172275304794313, Val_loss 3.9430782794952393\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 25, Train_Loss 3.2030373096466063, Val_loss 3.7300310134887695\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.252132606506348, Val_loss 3.7882888317108154\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 27, Train_Loss 3.2346048593521117, Val_loss 3.705322265625\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.220201778411865, Val_loss 3.6074330806732178\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.171596550941467, Val_loss 3.688403367996216\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.1909843921661376, Val_loss 3.6798017024993896\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.186595821380615, Val_loss 3.7164647579193115\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 32, Train_Loss 3.165425968170166, Val_loss 3.6979942321777344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.181922936439514, Val_loss 3.6801834106445312\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 34, Train_Loss 3.159128189086914, Val_loss 3.584352731704712\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.154924488067627, Val_loss 3.8674428462982178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.1474168062210084, Val_loss 3.6405227184295654\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1458390235900877, Val_loss 3.6386868953704834\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.113600564002991, Val_loss 3.6732025146484375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 39, Train_Loss 3.132502055168152, Val_loss 3.6813642978668213\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.212653970718384, Val_loss 3.5740411281585693\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.209882712364197, Val_loss 3.6581220626831055\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1788184881210326, Val_loss 3.6533050537109375\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1655219316482546, Val_loss 3.7248001098632812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.121635103225708, Val_loss 3.6368541717529297\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1273372173309326, Val_loss 3.6780576705932617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1060957431793215, Val_loss 3.6337502002716064\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.124347710609436, Val_loss 3.608320951461792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.13507285118103, Val_loss 3.637420654296875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.1141295433044434, Val_loss 3.7462785243988037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.1433979511260985, Val_loss 3.543928861618042\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.139536452293396, Val_loss 3.6393258571624756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1135937213897704, Val_loss 3.616832733154297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1633612155914306, Val_loss 3.7011356353759766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.11467559337616, Val_loss 3.654078245162964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.1138665437698365, Val_loss 3.6362521648406982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1040196418762207, Val_loss 3.657613754272461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1768619060516357, Val_loss 3.707965612411499\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.0891812324523924, Val_loss 3.6795108318328857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.122367334365845, Val_loss 3.629640579223633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.137070155143738, Val_loss 3.6906440258026123\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.0907633781433104, Val_loss 3.685100555419922\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.1097842931747435, Val_loss 3.584587812423706\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.096323108673096, Val_loss 3.639765977859497\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.1036688089370728, Val_loss 3.6906449794769287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.101905941963196, Val_loss 3.624737024307251\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.114658808708191, Val_loss 3.644582986831665\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.11477267742157, Val_loss 3.64249587059021\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.123518872261047, Val_loss 3.6259262561798096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.099150800704956, Val_loss 3.6103689670562744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.052372193336487, Val_loss 3.624058961868286\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.064030337333679, Val_loss 3.622093915939331\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.125649094581604, Val_loss 3.663182497024536\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0781084060668946, Val_loss 3.623039960861206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.0722066164016724, Val_loss 3.653611898422241\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.0888023138046266, Val_loss 3.6334850788116455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.0479771375656126, Val_loss 3.6318466663360596\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0930318593978883, Val_loss 3.6720335483551025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.056367564201355, Val_loss 3.651139497756958\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.116482877731323, Val_loss 3.633119583129883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0668052196502686, Val_loss 3.625654458999634\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.071923851966858, Val_loss 3.65116024017334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.1453274965286253, Val_loss 3.684654951095581\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.127404308319092, Val_loss 3.6884679794311523\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0832772970199587, Val_loss 3.678051233291626\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.1046573877334596, Val_loss 3.63751482963562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.103592109680176, Val_loss 3.6327896118164062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.080271077156067, Val_loss 3.6517083644866943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.094253158569336, Val_loss 3.6828248500823975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.12946355342865, Val_loss 3.6738102436065674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.0623415231704714, Val_loss 3.634772539138794\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.0776660203933717, Val_loss 3.659090042114258\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 92, Train_Loss 3.0581451654434204, Val_loss 3.618602752685547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.1135394096374513, Val_loss 3.6902945041656494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 94, Train_Loss 3.0704588890075684, Val_loss 3.656695604324341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.0625913619995115, Val_loss 3.6347720623016357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.095055627822876, Val_loss 3.6514246463775635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.0838160276412965, Val_loss 3.6514854431152344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.1114417552947997, Val_loss 3.6537716388702393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.068257236480713, Val_loss 3.651975631713867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.086004114151001, Val_loss 3.6818220615386963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9329468488693236, Val_loss 4.262840747833252\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.08\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.125733852386475, Val_loss 4.247836589813232\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.072397613525391, Val_loss 4.230472087860107\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.9440130949020387, Val_loss 4.192174434661865\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.839817762374878, Val_loss 3.99527645111084\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.748965048789978, Val_loss 3.8725178241729736\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.4\tTrain_acc_top_40 0.4875\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.38\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.6959837436676026, Val_loss 3.8098337650299072\n",
      "Train_acc_top_20 0.575\tTrain_acc_top_30 0.7438\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.658782958984375, Val_loss 3.793858528137207\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.6360928535461428, Val_loss 3.718600273132324\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.5596593618392944, Val_loss 3.7189862728118896\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.8625\tTrain_acc_top_40 0.9\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.50508451461792, Val_loss 3.709775686264038\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4321353912353514, Val_loss 3.6893393993377686\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 13, Train_Loss 3.3993680477142334, Val_loss 3.680450439453125\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3649325370788574, Val_loss 3.6094858646392822\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 15, Train_Loss 3.3957743406295777, Val_loss 3.6549034118652344\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.3262282848358153, Val_loss 3.6706812381744385\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.3039279699325563, Val_loss 3.568068504333496\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.2816397190093993, Val_loss 3.565662384033203\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 19, Train_Loss 3.245547914505005, Val_loss 3.604231595993042\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.261337947845459, Val_loss 3.580859899520874\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2284278869628906, Val_loss 3.6438300609588623\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.218136501312256, Val_loss 3.6276400089263916\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2291901826858522, Val_loss 3.538949966430664\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.2297078132629395, Val_loss 3.640726089477539\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.1957207679748536, Val_loss 3.584199905395508\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.2003723859786986, Val_loss 3.590796709060669\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.218528079986572, Val_loss 3.5799710750579834\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.183880877494812, Val_loss 3.591144561767578\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.1951295137405396, Val_loss 3.6426169872283936\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.19104950428009, Val_loss 3.616467237472534\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1788994312286376, Val_loss 3.5893256664276123\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1372531175613405, Val_loss 3.5690183639526367\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.1728243589401246, Val_loss 3.590392827987671\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.1622512578964233, Val_loss 3.6037683486938477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.169205164909363, Val_loss 3.6106226444244385\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1767692089080812, Val_loss 3.71960711479187\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 37, Train_Loss 3.1561413288116453, Val_loss 3.5761022567749023\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.133741545677185, Val_loss 3.6812076568603516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1787630558013915, Val_loss 3.646145820617676\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.1323181629180907, Val_loss 3.641929864883423\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.164458465576172, Val_loss 3.594118356704712\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1671699047088624, Val_loss 3.7285854816436768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1331209182739257, Val_loss 3.5205061435699463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1799363136291503, Val_loss 3.684755325317383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 45, Train_Loss 3.1460551977157594, Val_loss 3.673444986343384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1661017894744874, Val_loss 3.6411139965057373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 47, Train_Loss 3.1048402070999144, Val_loss 3.594803810119629\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.155423069000244, Val_loss 3.687450408935547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 49, Train_Loss 3.1026719331741335, Val_loss 3.71657395362854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 50, Train_Loss 3.13167085647583, Val_loss 3.5986692905426025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1455239057540894, Val_loss 3.679060935974121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 52, Train_Loss 3.1479851484298704, Val_loss 3.6798553466796875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 53, Train_Loss 3.099247121810913, Val_loss 3.639183282852173\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 54, Train_Loss 3.0854151487350463, Val_loss 3.589587926864624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.085181975364685, Val_loss 3.5948219299316406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 56, Train_Loss 3.114444065093994, Val_loss 3.712644577026367\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 57, Train_Loss 3.071587419509888, Val_loss 3.5797994136810303\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.114577794075012, Val_loss 3.5789241790771484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.0497185945510865, Val_loss 3.617922782897949\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.1319327354431152, Val_loss 3.5917303562164307\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.124989080429077, Val_loss 3.5742504596710205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.084284806251526, Val_loss 3.61362624168396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 63, Train_Loss 3.101819968223572, Val_loss 3.6258182525634766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.1712057828903197, Val_loss 3.601608991622925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.1007717132568358, Val_loss 3.6335299015045166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 66, Train_Loss 3.104239845275879, Val_loss 3.597018003463745\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.1681172847747803, Val_loss 3.6091928482055664\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1565393209457397, Val_loss 3.5876264572143555\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.10269718170166, Val_loss 3.5634851455688477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 70, Train_Loss 3.0798041820526123, Val_loss 3.6165921688079834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 71, Train_Loss 3.0884323596954344, Val_loss 3.639239549636841\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 72, Train_Loss 3.0304885387420653, Val_loss 3.647934675216675\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 73, Train_Loss 3.0846728086471558, Val_loss 3.616773843765259\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 74, Train_Loss 3.103369402885437, Val_loss 3.6275408267974854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 75, Train_Loss 3.0924049615859985, Val_loss 3.5904300212860107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.0564275979995728, Val_loss 3.5935757160186768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.093059515953064, Val_loss 3.595909357070923\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 78, Train_Loss 3.076696586608887, Val_loss 3.5815165042877197\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.084038257598877, Val_loss 3.5601589679718018\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.04685525894165, Val_loss 3.589090347290039\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.1304849863052366, Val_loss 3.6340444087982178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.1068613529205322, Val_loss 3.5803110599517822\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0822120904922485, Val_loss 3.628708839416504\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.1181725740432737, Val_loss 3.6253726482391357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.031795692443848, Val_loss 3.6077158451080322\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 86, Train_Loss 3.0624401807785033, Val_loss 3.601896047592163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.1057186126708984, Val_loss 3.585674285888672\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.104103374481201, Val_loss 3.612349271774292\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.1069766998291017, Val_loss 3.6166718006134033\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.1537697315216064, Val_loss 3.5945074558258057\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.1151491165161134, Val_loss 3.618598699569702\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.079133486747742, Val_loss 3.5975663661956787\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 93, Train_Loss 3.0951632261276245, Val_loss 3.6259937286376953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.093188977241516, Val_loss 3.6233928203582764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.037988233566284, Val_loss 3.6007754802703857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0539441108703613, Val_loss 3.580294609069824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 97, Train_Loss 3.0900091886520387, Val_loss 3.6131293773651123\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.0860851049423217, Val_loss 3.63128924369812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.0921860694885255, Val_loss 3.6291239261627197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 100, Train_Loss 3.0764222621917723, Val_loss 3.574841260910034\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.9275843858718873, Val_loss 4.292750835418701\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2625\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.129675579071045, Val_loss 4.222560882568359\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.078100872039795, Val_loss 4.210958957672119\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9668200731277468, Val_loss 4.16133975982666\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.880246305465698, Val_loss 4.117084980010986\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.775513482093811, Val_loss 3.8238754272460938\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.4188\tTrain_acc_top_40 0.525\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 7, Train_Loss 3.7114489555358885, Val_loss 3.695056676864624\n",
      "Train_acc_top_20 0.5875\tTrain_acc_top_30 0.7562\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 8, Train_Loss 3.6435160636901855, Val_loss 3.608579397201538\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 9, Train_Loss 3.5835498094558718, Val_loss 3.5611202716827393\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 10, Train_Loss 3.5553781270980833, Val_loss 3.57906436920166\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 11, Train_Loss 3.5087807893753054, Val_loss 3.533137083053589\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 12, Train_Loss 3.4350302696228026, Val_loss 3.5236072540283203\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 13, Train_Loss 3.4169037103652955, Val_loss 3.54156231880188\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 14, Train_Loss 3.3623536586761475, Val_loss 3.5144691467285156\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.388640832901001, Val_loss 3.732067108154297\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3448724508285523, Val_loss 3.523986577987671\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.3110925197601317, Val_loss 3.6023952960968018\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.305448293685913, Val_loss 3.4227712154388428\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 19, Train_Loss 3.2958165645599364, Val_loss 3.5667736530303955\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 20, Train_Loss 3.2902149200439452, Val_loss 3.53739333152771\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2525235414505005, Val_loss 3.424420118331909\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.214925837516785, Val_loss 3.4833791255950928\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.218129301071167, Val_loss 3.417224168777466\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 24, Train_Loss 3.2116019487380982, Val_loss 3.5027828216552734\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 25, Train_Loss 3.2155603647232054, Val_loss 3.5008842945098877\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.212821364402771, Val_loss 3.449690103530884\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 27, Train_Loss 3.216090369224548, Val_loss 3.4555513858795166\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 28, Train_Loss 3.186401605606079, Val_loss 3.4527204036712646\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.1513241052627565, Val_loss 3.413313627243042\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 30, Train_Loss 3.167554807662964, Val_loss 3.4485044479370117\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 31, Train_Loss 3.1695185899734497, Val_loss 3.3938238620758057\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 32, Train_Loss 3.1522290229797365, Val_loss 3.4530344009399414\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 33, Train_Loss 3.156729745864868, Val_loss 3.523284673690796\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.1465723514556885, Val_loss 3.499032974243164\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 35, Train_Loss 3.143826198577881, Val_loss 3.499054193496704\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 36, Train_Loss 3.14347767829895, Val_loss 3.4579153060913086\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 37, Train_Loss 3.128757691383362, Val_loss 3.448885202407837\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.1069040298461914, Val_loss 3.443464517593384\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 39, Train_Loss 3.1315839767456053, Val_loss 3.467240571975708\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.1388319969177245, Val_loss 3.4217588901519775\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.1448864459991457, Val_loss 3.440627098083496\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 42, Train_Loss 3.1595785856246947, Val_loss 3.4430408477783203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.1098998308181764, Val_loss 3.468552350997925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 1.0\t\n",
      "Epoch 44, Train_Loss 3.1186315774917603, Val_loss 3.5303375720977783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.113486671447754, Val_loss 3.4742648601531982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 46, Train_Loss 3.107931351661682, Val_loss 3.482762098312378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.159476065635681, Val_loss 3.535811185836792\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1283173084259035, Val_loss 3.508429527282715\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.1206227779388427, Val_loss 3.5078961849212646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 50, Train_Loss 3.1248669624328613, Val_loss 3.4788360595703125\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 51, Train_Loss 3.11113817691803, Val_loss 3.4510672092437744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 52, Train_Loss 3.123661828041077, Val_loss 3.447922468185425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 53, Train_Loss 3.078502726554871, Val_loss 3.473931074142456\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 54, Train_Loss 3.1316281080245973, Val_loss 3.499600648880005\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.96\t\n",
      "Epoch 55, Train_Loss 3.0933731317520143, Val_loss 3.5489933490753174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.152573084831238, Val_loss 3.51733660697937\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.094683575630188, Val_loss 3.455646276473999\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.0704294204711915, Val_loss 3.4723799228668213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 59, Train_Loss 3.118368983268738, Val_loss 3.5027236938476562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.173079180717468, Val_loss 3.5448474884033203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.120110201835632, Val_loss 3.4856557846069336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.066870403289795, Val_loss 3.4628236293792725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.10604190826416, Val_loss 3.4991867542266846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.101189064979553, Val_loss 3.4667866230010986\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 65, Train_Loss 3.0641155004501344, Val_loss 3.48344349861145\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 66, Train_Loss 3.0852332592010496, Val_loss 3.4978058338165283\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 67, Train_Loss 3.1154820919036865, Val_loss 3.530186653137207\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.108747410774231, Val_loss 3.475587844848633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 69, Train_Loss 3.091262769699097, Val_loss 3.4603874683380127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 70, Train_Loss 3.101968455314636, Val_loss 3.5062389373779297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.124764919281006, Val_loss 3.4775402545928955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.108440566062927, Val_loss 3.4854094982147217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.1080456256866453, Val_loss 3.505033493041992\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.1179415941238404, Val_loss 3.504993438720703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.1203710794448853, Val_loss 3.5004379749298096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.1120770454406737, Val_loss 3.490788459777832\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.1051934480667116, Val_loss 3.4954631328582764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.0778345823287965, Val_loss 3.4839048385620117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 79, Train_Loss 3.070812296867371, Val_loss 3.480572462081909\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1198816776275633, Val_loss 3.478182792663574\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.113903594017029, Val_loss 3.4916303157806396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.095434141159058, Val_loss 3.4809863567352295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 83, Train_Loss 3.0554211854934694, Val_loss 3.4929401874542236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.104531693458557, Val_loss 3.4886722564697266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 85, Train_Loss 3.0874014616012575, Val_loss 3.490149736404419\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.0847301483154297, Val_loss 3.497032880783081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 87, Train_Loss 3.049619698524475, Val_loss 3.4780092239379883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 88, Train_Loss 3.1393066167831423, Val_loss 3.505305290222168\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.119244360923767, Val_loss 3.5036113262176514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1052801609039307, Val_loss 3.494405746459961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.086136746406555, Val_loss 3.486717939376831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0589420318603517, Val_loss 3.50368332862854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.113468647003174, Val_loss 3.4955437183380127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.1402543067932127, Val_loss 3.523803472518921\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 95, Train_Loss 3.105448770523071, Val_loss 3.517428159713745\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.083402132987976, Val_loss 3.5007998943328857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.1307089567184447, Val_loss 3.489812135696411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.0690613985061646, Val_loss 3.493870496749878\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.1089098930358885, Val_loss 3.483349084854126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.1062944173812865, Val_loss 3.508437156677246\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.9258399486541746, Val_loss 4.332437038421631\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.121115589141846, Val_loss 4.25233793258667\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.077663230895996, Val_loss 4.180671215057373\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.9583510398864745, Val_loss 4.125748634338379\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8574777603149415, Val_loss 4.069314479827881\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.125\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7703530311584474, Val_loss 3.8575656414031982\n",
      "Train_acc_top_20 0.1938\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.4688\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.7106000423431396, Val_loss 3.7806308269500732\n",
      "Train_acc_top_20 0.5062\tTrain_acc_top_30 0.7125\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.6463977336883544, Val_loss 3.716477632522583\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.585713744163513, Val_loss 3.7163593769073486\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 10, Train_Loss 3.532334089279175, Val_loss 3.704024314880371\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.4839264392852782, Val_loss 3.737295389175415\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.435278367996216, Val_loss 3.668910264968872\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.4330035209655763, Val_loss 3.6325929164886475\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.394682741165161, Val_loss 3.616773843765259\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.3704200983047485, Val_loss 3.696178674697876\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.3369672298431396, Val_loss 3.6937243938446045\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 17, Train_Loss 3.3041422367095947, Val_loss 3.5680320262908936\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.2810136318206786, Val_loss 3.6704463958740234\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 19, Train_Loss 3.283977437019348, Val_loss 3.611100912094116\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.2619975328445436, Val_loss 3.589689254760742\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2293482065200805, Val_loss 3.6107699871063232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 22, Train_Loss 3.2061771631240843, Val_loss 3.6413638591766357\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.2270599126815798, Val_loss 3.584735870361328\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2131739616394044, Val_loss 3.5788471698760986\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.1820635318756105, Val_loss 3.5204060077667236\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.218434381484985, Val_loss 3.552569627761841\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.1823975086212157, Val_loss 3.51263165473938\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.160313057899475, Val_loss 3.5657284259796143\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.1983583688735964, Val_loss 3.5265073776245117\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.208287072181702, Val_loss 3.5592496395111084\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1955607414245604, Val_loss 3.588632583618164\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1721362352371214, Val_loss 3.520550489425659\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1459495067596435, Val_loss 3.57287335395813\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.15100998878479, Val_loss 3.502131223678589\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1394174575805662, Val_loss 3.5894935131073\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.2050539016723634, Val_loss 3.5444858074188232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1350474119186402, Val_loss 3.5236473083496094\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1446598052978514, Val_loss 3.518958806991577\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1164047002792357, Val_loss 3.5234689712524414\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.127727437019348, Val_loss 3.5428152084350586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1292487382888794, Val_loss 3.5604753494262695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.1294267654418944, Val_loss 3.5866925716400146\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.156594729423523, Val_loss 3.563439130783081\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.148905563354492, Val_loss 3.5368735790252686\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1486077070236207, Val_loss 3.548516035079956\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1009713411331177, Val_loss 3.640347719192505\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.211409091949463, Val_loss 3.5212395191192627\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.136063241958618, Val_loss 3.5525405406951904\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1156331300735474, Val_loss 3.5187292098999023\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1092095375061035, Val_loss 3.5223071575164795\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1292064905166628, Val_loss 3.5169239044189453\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.163467836380005, Val_loss 3.552847146987915\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.1067297220230103, Val_loss 3.513838529586792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1563536643981935, Val_loss 3.5718953609466553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.081007218360901, Val_loss 3.529771566390991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.144397521018982, Val_loss 3.5380818843841553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1128875970840455, Val_loss 3.573776960372925\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.102198767662048, Val_loss 3.520697832107544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.146529483795166, Val_loss 3.500534772872925\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.146592855453491, Val_loss 3.5092403888702393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1222450494766236, Val_loss 3.54431414604187\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.201786017417908, Val_loss 3.6095974445343018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1264538764953613, Val_loss 3.5307810306549072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.189048981666565, Val_loss 3.5222713947296143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.1485769033432005, Val_loss 3.559704542160034\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.1054288148880005, Val_loss 3.502155303955078\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.1248260736465454, Val_loss 3.520324468612671\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.126707887649536, Val_loss 3.519108533859253\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0256659269332884, Val_loss 3.5248448848724365\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1372774124145506, Val_loss 3.520380735397339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.104119348526001, Val_loss 3.528221845626831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.1776285648345945, Val_loss 3.5361900329589844\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.1311213970184326, Val_loss 3.5292768478393555\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.097671103477478, Val_loss 3.497755765914917\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.0965981006622316, Val_loss 3.5254650115966797\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.1003328561782837, Val_loss 3.487438201904297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0693417310714723, Val_loss 3.503278970718384\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.060969829559326, Val_loss 3.4969546794891357\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.064491128921509, Val_loss 3.5125319957733154\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.0349253177642823, Val_loss 3.512558698654175\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0503750324249266, Val_loss 3.505805015563965\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.089723563194275, Val_loss 3.526563882827759\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.071648645401001, Val_loss 3.4936392307281494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0878026485443115, Val_loss 3.5069329738616943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.1278329849243165, Val_loss 3.523125648498535\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0641040563583375, Val_loss 3.533900022506714\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0365330934524537, Val_loss 3.5495169162750244\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.085168480873108, Val_loss 3.512091875076294\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.067594289779663, Val_loss 3.5047991275787354\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.095721125602722, Val_loss 3.506983518600464\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.1017141819000242, Val_loss 3.4954006671905518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.0696794748306275, Val_loss 3.5003769397735596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.068242001533508, Val_loss 3.5072925090789795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.092698311805725, Val_loss 3.4976930618286133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.1489823341369627, Val_loss 3.517263650894165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.1592117071151735, Val_loss 3.516658067703247\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.134681820869446, Val_loss 3.503004312515259\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.052773427963257, Val_loss 3.505955696105957\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.055358552932739, Val_loss 3.510535478591919\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0429321765899657, Val_loss 3.54553484916687\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.934990882873535, Val_loss 4.271904945373535\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 2, Train_Loss 4.118111038208008, Val_loss 4.203489780426025\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 3, Train_Loss 4.050212264060974, Val_loss 4.155397891998291\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.940162444114685, Val_loss 4.0713090896606445\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.125\tTrain_acc_top_40 0.15\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 5, Train_Loss 3.8511720418930055, Val_loss 4.0306172370910645\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7458027839660644, Val_loss 3.8038854598999023\n",
      "Train_acc_top_20 0.2437\tTrain_acc_top_30 0.3187\tTrain_acc_top_40 0.375\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.693321681022644, Val_loss 3.718873977661133\n",
      "Train_acc_top_20 0.5\tTrain_acc_top_30 0.625\tTrain_acc_top_40 0.7562\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 8, Train_Loss 3.6250845909118654, Val_loss 3.5531513690948486\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.5524041175842287, Val_loss 3.492269515991211\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5168275594711305, Val_loss 3.452587366104126\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.4803876876831055, Val_loss 3.6584625244140625\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.478135585784912, Val_loss 3.54728102684021\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.421405529975891, Val_loss 3.4562222957611084\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 14, Train_Loss 3.411347246170044, Val_loss 3.6507022380828857\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3658559799194334, Val_loss 3.4489095211029053\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.308882999420166, Val_loss 3.539041519165039\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.3262271642684937, Val_loss 3.443331480026245\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 18, Train_Loss 3.2946096897125243, Val_loss 3.5473458766937256\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2907318830490113, Val_loss 3.3745384216308594\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.23667311668396, Val_loss 3.5786991119384766\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2762454986572265, Val_loss 3.4836511611938477\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.2425122261047363, Val_loss 3.4724881649017334\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.175161361694336, Val_loss 3.420006513595581\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.207038426399231, Val_loss 3.5961382389068604\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.1813845872879027, Val_loss 3.663419485092163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.2193315744400026, Val_loss 3.504323959350586\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.1771066427230834, Val_loss 3.593076705932617\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.149738097190857, Val_loss 3.433321714401245\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1769509077072144, Val_loss 3.600397825241089\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.212380814552307, Val_loss 3.425565719604492\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 31, Train_Loss 3.1981282472610473, Val_loss 3.6634018421173096\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1692891836166384, Val_loss 3.706279754638672\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 33, Train_Loss 3.171561074256897, Val_loss 3.6646525859832764\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.23021776676178, Val_loss 3.649644136428833\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1050352334976195, Val_loss 3.6848676204681396\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.1361411094665526, Val_loss 3.392848253250122\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 37, Train_Loss 3.190702223777771, Val_loss 3.6020472049713135\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1456450462341308, Val_loss 3.7669856548309326\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 39, Train_Loss 3.129373049736023, Val_loss 3.559636116027832\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1889673471450806, Val_loss 3.4057321548461914\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.22616765499115, Val_loss 3.63094162940979\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.1727602005004885, Val_loss 3.6986982822418213\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.111915040016174, Val_loss 3.566373109817505\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1895254850387573, Val_loss 3.5676591396331787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.2250970363616944, Val_loss 3.5035622119903564\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.120652508735657, Val_loss 3.524848699569702\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.181070566177368, Val_loss 3.5657246112823486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.1620496988296507, Val_loss 3.438062906265259\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.0970037460327147, Val_loss 3.4088594913482666\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.0537594318389893, Val_loss 3.5387122631073\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1908334255218507, Val_loss 3.5451877117156982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.2113586902618407, Val_loss 3.50408935546875\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.1402003288269045, Val_loss 3.559579610824585\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1455113172531126, Val_loss 3.4734504222869873\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1068695068359373, Val_loss 3.5882747173309326\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.0999557256698607, Val_loss 3.5999186038970947\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1132527589797974, Val_loss 3.5720055103302\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.078108382225037, Val_loss 3.5302727222442627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.0745937824249268, Val_loss 3.5773065090179443\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.1193235397338865, Val_loss 3.5534770488739014\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.0717581510543823, Val_loss 3.4400579929351807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.096229600906372, Val_loss 3.6086013317108154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 63, Train_Loss 3.1373599052429197, Val_loss 3.586886405944824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.1402525186538695, Val_loss 3.524198293685913\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.1287618398666384, Val_loss 3.5095856189727783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.071798801422119, Val_loss 3.4720869064331055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.0103102207183836, Val_loss 3.5495519638061523\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.0754803895950316, Val_loss 3.473717451095581\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.1573541879653932, Val_loss 3.5564613342285156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.0683753728866576, Val_loss 3.5327587127685547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.0542383909225466, Val_loss 3.5399277210235596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.064824366569519, Val_loss 3.5100250244140625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0738640069961547, Val_loss 3.5153276920318604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.1802383184432985, Val_loss 3.497894525527954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.1343881607055666, Val_loss 3.547226905822754\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.073607063293457, Val_loss 3.525585412979126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0990680694580077, Val_loss 3.5176899433135986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.0854147911071776, Val_loss 3.5443942546844482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.0755036592483522, Val_loss 3.55743670463562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.074216890335083, Val_loss 3.5694682598114014\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.0525005578994753, Val_loss 3.5274856090545654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.1054192781448364, Val_loss 3.5191128253936768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0393216371536256, Val_loss 3.507394552230835\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.074377989768982, Val_loss 3.518946409225464\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.06662974357605, Val_loss 3.515023946762085\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.1041906833648683, Val_loss 3.5308005809783936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.1099485874176027, Val_loss 3.5224645137786865\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.051719093322754, Val_loss 3.5515966415405273\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.126944828033447, Val_loss 3.541463851928711\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.0992841482162476, Val_loss 3.5470917224884033\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 91, Train_Loss 3.094113993644714, Val_loss 3.5212910175323486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.12260422706604, Val_loss 3.490039825439453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.04923677444458, Val_loss 3.5425970554351807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 94, Train_Loss 3.0832677841186524, Val_loss 3.5243380069732666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.1056418657302856, Val_loss 3.560150146484375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.0093561887741087, Val_loss 3.53045392036438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.0064791202545167, Val_loss 3.609537363052368\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.0457653999328613, Val_loss 3.5090372562408447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.064987063407898, Val_loss 3.531505584716797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.165181541442871, Val_loss 3.546617269515991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.928855323791504, Val_loss 4.2794718742370605\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.04\tVal_acc_top_40 0.04\t\n",
      "Epoch 2, Train_Loss 4.114695930480957, Val_loss 4.287211894989014\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.056630325317383, Val_loss 4.2963433265686035\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.921940779685974, Val_loss 4.218766689300537\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 5, Train_Loss 3.8296921968460085, Val_loss 4.14411735534668\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.12\t\n",
      "Epoch 6, Train_Loss 3.7509264945983887, Val_loss 3.894144058227539\n",
      "Train_acc_top_20 0.2562\tTrain_acc_top_30 0.3438\tTrain_acc_top_40 0.4188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 7, Train_Loss 3.669373798370361, Val_loss 3.7684710025787354\n",
      "Train_acc_top_20 0.5375\tTrain_acc_top_30 0.6562\tTrain_acc_top_40 0.775\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.614723968505859, Val_loss 3.736952543258667\n",
      "Train_acc_top_20 0.6937\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 9, Train_Loss 3.549178671836853, Val_loss 3.713931083679199\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.5125804424285887, Val_loss 3.6428701877593994\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4692276239395143, Val_loss 3.6553361415863037\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4289034366607667, Val_loss 3.6521542072296143\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.3935924768447876, Val_loss 3.6009724140167236\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 14, Train_Loss 3.395446300506592, Val_loss 3.6050148010253906\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.3597498416900633, Val_loss 3.5932648181915283\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.358043646812439, Val_loss 3.554654836654663\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 17, Train_Loss 3.287517285346985, Val_loss 3.5665409564971924\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.326876735687256, Val_loss 3.530832052230835\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.275889778137207, Val_loss 3.5554001331329346\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.230036759376526, Val_loss 3.5506134033203125\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2538370370864866, Val_loss 3.532364845275879\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2384878396987915, Val_loss 3.529189109802246\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.238611912727356, Val_loss 3.5785443782806396\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.230573844909668, Val_loss 3.704589605331421\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2204791784286497, Val_loss 3.5202529430389404\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.2246912479400636, Val_loss 3.5537633895874023\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.2413562774658202, Val_loss 3.66939377784729\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.214467763900757, Val_loss 3.5098705291748047\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.2065149545669556, Val_loss 3.500988721847534\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.1671518087387085, Val_loss 3.589376449584961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1869706869125367, Val_loss 3.5325729846954346\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1572046756744383, Val_loss 3.503054618835449\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1546020030975344, Val_loss 3.5151281356811523\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.156833815574646, Val_loss 3.507645606994629\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1395227193832396, Val_loss 3.5068321228027344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.183545398712158, Val_loss 3.549156427383423\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.160715174674988, Val_loss 3.4812018871307373\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1346246719360353, Val_loss 3.551908493041992\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.131344175338745, Val_loss 3.4868099689483643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1341826915740967, Val_loss 3.450775384902954\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.1129094839096068, Val_loss 3.457369565963745\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.1515286445617674, Val_loss 3.5333824157714844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.1651453733444215, Val_loss 3.5070812702178955\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.0908599615097048, Val_loss 3.4892990589141846\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.0833537578582764, Val_loss 3.4699699878692627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.117328095436096, Val_loss 3.4524879455566406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.1276668071746827, Val_loss 3.4726359844207764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1104394674301146, Val_loss 3.5067923069000244\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.0802265405654907, Val_loss 3.4659335613250732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.111785411834717, Val_loss 3.5277259349823\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.1001627922058104, Val_loss 3.5082576274871826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1351731061935424, Val_loss 3.5359127521514893\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.096504473686218, Val_loss 3.4631528854370117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.117198276519775, Val_loss 3.5222702026367188\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.1074629068374633, Val_loss 3.4695684909820557\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.0835607051849365, Val_loss 3.4481983184814453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.114658260345459, Val_loss 3.498872756958008\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.0932567358016967, Val_loss 3.434575080871582\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1176329851150513, Val_loss 3.4782803058624268\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.1110265493392943, Val_loss 3.4828920364379883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.0730268716812135, Val_loss 3.4364891052246094\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0246637582778932, Val_loss 3.4545679092407227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.0986512660980225, Val_loss 3.486201047897339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.127460741996765, Val_loss 3.504873514175415\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.094213438034058, Val_loss 3.484757423400879\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.0677796363830567, Val_loss 3.444322347640991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.1341237783432008, Val_loss 3.4676554203033447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.087587523460388, Val_loss 3.4850547313690186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.092814874649048, Val_loss 3.4412033557891846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 70, Train_Loss 3.1076541423797606, Val_loss 3.4893388748168945\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.106770634651184, Val_loss 3.509047269821167\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0855650186538695, Val_loss 3.4682071208953857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.1625935792922975, Val_loss 3.4590003490448\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.0929843187332153, Val_loss 3.4646785259246826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.0750202894210816, Val_loss 3.4644434452056885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.130105209350586, Val_loss 3.441239595413208\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.1045583486557007, Val_loss 3.4488589763641357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.1005114555358886, Val_loss 3.426764726638794\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.1557827949523927, Val_loss 3.47794246673584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.086079454421997, Val_loss 3.4548356533050537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.0748255968093874, Val_loss 3.4585893154144287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.087933611869812, Val_loss 3.4658126831054688\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.092948079109192, Val_loss 3.446589708328247\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.103174567222595, Val_loss 3.4575023651123047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.099825549125671, Val_loss 3.450751543045044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.0940186023712157, Val_loss 3.465202569961548\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.1104694604873657, Val_loss 3.4757659435272217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.0828116655349733, Val_loss 3.452988862991333\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0711395502090455, Val_loss 3.4684507846832275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1059542894363403, Val_loss 3.4741733074188232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.0947863101959228, Val_loss 3.450971841812134\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0906537532806397, Val_loss 3.455371141433716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.06265606880188, Val_loss 3.4571454524993896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.0593416690826416, Val_loss 3.4363796710968018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.0730787992477415, Val_loss 3.443835496902466\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.0926059007644655, Val_loss 3.4549577236175537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.0589717864990233, Val_loss 3.426121473312378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.0862492084503175, Val_loss 3.4843571186065674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.1017308473587035, Val_loss 3.426025152206421\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.078830337524414, Val_loss 3.4822330474853516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.93759765625, Val_loss 4.221142768859863\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.118550777435303, Val_loss 4.219870090484619\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.0737837791442875, Val_loss 4.248101711273193\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9504550218582155, Val_loss 4.231736183166504\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8612344741821287, Val_loss 4.107029438018799\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7727639198303224, Val_loss 3.86387038230896\n",
      "Train_acc_top_20 0.175\tTrain_acc_top_30 0.2625\tTrain_acc_top_40 0.3688\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.33\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.6738754749298095, Val_loss 3.7838704586029053\n",
      "Train_acc_top_20 0.5312\tTrain_acc_top_30 0.6937\tTrain_acc_top_40 0.7688\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 8, Train_Loss 3.6276900291442873, Val_loss 3.7383015155792236\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5461265563964846, Val_loss 3.6793527603149414\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.48349187374115, Val_loss 3.6632726192474365\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4578253746032717, Val_loss 3.6559669971466064\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4202948331832888, Val_loss 3.7045602798461914\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.4224091529846192, Val_loss 3.617018938064575\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.397598910331726, Val_loss 3.5968170166015625\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.3443068504333495, Val_loss 3.7655012607574463\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 16, Train_Loss 3.3250208377838133, Val_loss 3.5549211502075195\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.313392972946167, Val_loss 3.5999250411987305\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.297876715660095, Val_loss 3.5357935428619385\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2783050775527953, Val_loss 3.595867156982422\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.2953353404998778, Val_loss 3.6268599033355713\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 21, Train_Loss 3.2660150289535523, Val_loss 3.5667355060577393\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.2521766662597655, Val_loss 3.502593994140625\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.233733057975769, Val_loss 3.4915030002593994\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 24, Train_Loss 3.1846224308013915, Val_loss 3.540621042251587\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.3142253398895263, Val_loss 3.8610947132110596\n",
      "Train_acc_top_20 0.7188\tTrain_acc_top_30 0.7937\tTrain_acc_top_40 0.8375\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 26, Train_Loss 3.2442116260528566, Val_loss 3.6638832092285156\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 27, Train_Loss 3.2310728788375855, Val_loss 3.7112433910369873\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 28, Train_Loss 3.2285541534423827, Val_loss 3.6314847469329834\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.24551465511322, Val_loss 3.51027774810791\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 30, Train_Loss 3.1731937408447264, Val_loss 3.5502309799194336\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.1978835582733156, Val_loss 3.5979843139648438\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.2041894674301146, Val_loss 3.487553596496582\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1734302043914795, Val_loss 3.439120054244995\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.2139696359634398, Val_loss 3.5021467208862305\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.182647180557251, Val_loss 3.532731056213379\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1709047317504884, Val_loss 3.4769675731658936\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.174162817001343, Val_loss 3.557435989379883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.2085385799407957, Val_loss 3.485821008682251\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.156912088394165, Val_loss 3.4899022579193115\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1187958240509035, Val_loss 3.526503801345825\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.0892244815826415, Val_loss 3.538238525390625\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1190266609191895, Val_loss 3.4892094135284424\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1455859422683714, Val_loss 3.5412724018096924\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.148649072647095, Val_loss 3.5534255504608154\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.129792833328247, Val_loss 3.5089495182037354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.2228523015975954, Val_loss 3.4694788455963135\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1407313346862793, Val_loss 3.503798723220825\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.151319885253906, Val_loss 3.5702056884765625\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.206638956069946, Val_loss 3.473397970199585\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1434194087982177, Val_loss 3.495903730392456\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.1440158605575563, Val_loss 3.5102498531341553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.0950342655181884, Val_loss 3.445208787918091\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.1088854312896728, Val_loss 3.5994346141815186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1328235149383543, Val_loss 3.4825875759124756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.104303789138794, Val_loss 3.4657421112060547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1776179552078245, Val_loss 3.497264862060547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.186114048957825, Val_loss 3.523310422897339\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.100598406791687, Val_loss 3.5240581035614014\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1501631498336793, Val_loss 3.5190627574920654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1211159944534304, Val_loss 3.4778709411621094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.1409198522567747, Val_loss 3.465949773788452\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.095854568481445, Val_loss 3.4701473712921143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.143829107284546, Val_loss 3.462791681289673\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1312500715255736, Val_loss 3.44415545463562\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.134824275970459, Val_loss 3.4535417556762695\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.119104337692261, Val_loss 3.4584968090057373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.1094731092453003, Val_loss 3.455104112625122\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.1111176013946533, Val_loss 3.4655628204345703\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.1065351486206056, Val_loss 3.4859683513641357\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.112744402885437, Val_loss 3.4584577083587646\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.1297484636306763, Val_loss 3.4587554931640625\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0939613580703735, Val_loss 3.458918333053589\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.09964234828949, Val_loss 3.4464263916015625\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.0670771837234496, Val_loss 3.424095392227173\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.12664155960083, Val_loss 3.464434862136841\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.117321228981018, Val_loss 3.4500343799591064\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.0886350870132446, Val_loss 3.4787521362304688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.110566759109497, Val_loss 3.4608211517333984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.139188623428345, Val_loss 3.4358441829681396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.081553101539612, Val_loss 3.4348018169403076\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.0589755535125733, Val_loss 3.425034761428833\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.103577446937561, Val_loss 3.403674364089966\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.087700891494751, Val_loss 3.423151731491089\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.089511752128601, Val_loss 3.406275749206543\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.0834776878356935, Val_loss 3.394146203994751\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.1001432657241823, Val_loss 3.413376808166504\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.122997450828552, Val_loss 3.4138715267181396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.1009686946868897, Val_loss 3.4055449962615967\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0821686029434203, Val_loss 3.3820011615753174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.0807610988616942, Val_loss 3.429729700088501\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.127357006072998, Val_loss 3.442833185195923\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0992859840393066, Val_loss 3.3976736068725586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.0680046558380125, Val_loss 3.4086883068084717\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.128037667274475, Val_loss 3.4446866512298584\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.1464435338973997, Val_loss 3.4546453952789307\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.1165176153182985, Val_loss 3.4378421306610107\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.066164803504944, Val_loss 3.4335403442382812\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.082078957557678, Val_loss 3.4301135540008545\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.11887845993042, Val_loss 3.4282007217407227\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.0817802429199217, Val_loss 3.4376285076141357\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.919161152839661, Val_loss 4.247701168060303\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1187\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.122552108764649, Val_loss 4.189272403717041\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.067166423797607, Val_loss 4.188745021820068\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.937354493141174, Val_loss 4.116757869720459\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8446820735931397, Val_loss 3.979008913040161\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7612854719161986, Val_loss 3.8921568393707275\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.3625\tTrain_acc_top_40 0.4813\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.7054047107696535, Val_loss 3.901988983154297\n",
      "Train_acc_top_20 0.6188\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.825\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.671249175071716, Val_loss 3.84159779548645\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.8375\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.596701502799988, Val_loss 3.8239402770996094\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.5151583909988404, Val_loss 3.8669912815093994\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.463553786277771, Val_loss 3.804769515991211\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.429479193687439, Val_loss 3.766512155532837\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 13, Train_Loss 3.4056740760803224, Val_loss 3.7489054203033447\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 14, Train_Loss 3.364693593978882, Val_loss 3.709569215774536\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.3359691858291627, Val_loss 3.648797035217285\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.331350064277649, Val_loss 3.713947057723999\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.312885546684265, Val_loss 3.6718571186065674\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.287915897369385, Val_loss 3.8380508422851562\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.38\tVal_acc_top_40 0.54\t\n",
      "Epoch 19, Train_Loss 3.3001758813858033, Val_loss 3.8070361614227295\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 20, Train_Loss 3.2472161531448362, Val_loss 3.553149938583374\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2511257410049437, Val_loss 3.7185256481170654\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.2197245597839355, Val_loss 3.7072649002075195\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 23, Train_Loss 3.217172908782959, Val_loss 3.700026512145996\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.1803900003433228, Val_loss 3.6414546966552734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.225667858123779, Val_loss 3.6932296752929688\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.2065161228179933, Val_loss 3.568157434463501\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.2319199323654173, Val_loss 3.6431570053100586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 28, Train_Loss 3.1734526634216307, Val_loss 3.6255998611450195\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1637950897216798, Val_loss 3.6183431148529053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.186598229408264, Val_loss 3.6435155868530273\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.184953212738037, Val_loss 3.5995171070098877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.145887303352356, Val_loss 3.650899887084961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.20128710269928, Val_loss 3.602524518966675\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1880592823028566, Val_loss 3.679651975631714\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1936612367630004, Val_loss 3.6880266666412354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.139022445678711, Val_loss 3.7850005626678467\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.153334546089172, Val_loss 3.6553547382354736\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.133746314048767, Val_loss 3.6224825382232666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.157855176925659, Val_loss 3.660956382751465\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.1631715536117553, Val_loss 3.65468430519104\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1469512224197387, Val_loss 3.6460702419281006\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.0968908309936523, Val_loss 3.651594877243042\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.0779905319213867, Val_loss 3.584052324295044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1342227935791014, Val_loss 3.7771503925323486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1124464511871337, Val_loss 3.5351104736328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.130203366279602, Val_loss 3.650099039077759\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.114982843399048, Val_loss 3.6161959171295166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.120315504074097, Val_loss 3.641742706298828\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1163262605667112, Val_loss 3.602649688720703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.0998234272003176, Val_loss 3.532425880432129\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.087342715263367, Val_loss 3.5818960666656494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.114121103286743, Val_loss 3.6263866424560547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 53, Train_Loss 3.1141130685806275, Val_loss 3.6168320178985596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.107756161689758, Val_loss 3.624488115310669\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.133837270736694, Val_loss 3.611325263977051\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1063639163970946, Val_loss 3.549525022506714\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.0864492654800415, Val_loss 3.596666097640991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.100788450241089, Val_loss 3.7029199600219727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.1019728422164916, Val_loss 3.555506706237793\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1385389804840087, Val_loss 3.662181854248047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.0861568212509156, Val_loss 3.5688846111297607\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1062698364257812, Val_loss 3.613072395324707\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 63, Train_Loss 3.0961906909942627, Val_loss 3.5872793197631836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.1152652502059937, Val_loss 3.6010923385620117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.1029415369033813, Val_loss 3.606065511703491\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.0734506845474243, Val_loss 3.5785598754882812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.0778810739517213, Val_loss 3.5606689453125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.0622326850891115, Val_loss 3.57100510597229\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.100718879699707, Val_loss 3.5920350551605225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.078459858894348, Val_loss 3.6020734310150146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.0742108821868896, Val_loss 3.6209230422973633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.080130362510681, Val_loss 3.5669620037078857\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.045963478088379, Val_loss 3.607297897338867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.0559447526931764, Val_loss 3.5745327472686768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.0955386638641356, Val_loss 3.5759048461914062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.075428318977356, Val_loss 3.5624685287475586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0741151332855225, Val_loss 3.5418622493743896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.1032321453094482, Val_loss 3.561460494995117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.04901008605957, Val_loss 3.5637261867523193\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.072338032722473, Val_loss 3.5538110733032227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.084403705596924, Val_loss 3.5600178241729736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.073364520072937, Val_loss 3.5893142223358154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0502262115478516, Val_loss 3.5741665363311768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0626181840896605, Val_loss 3.5518484115600586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.146949553489685, Val_loss 3.5815086364746094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.076494741439819, Val_loss 3.5856587886810303\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.05188844203949, Val_loss 3.5644853115081787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.0513699769973757, Val_loss 3.5662834644317627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.069959878921509, Val_loss 3.557996988296509\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.067009520530701, Val_loss 3.5715930461883545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.0361493825912476, Val_loss 3.588510751724243\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0505624532699587, Val_loss 3.5513598918914795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.0623082160949706, Val_loss 3.5615322589874268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 94, Train_Loss 3.1046338796615602, Val_loss 3.5706875324249268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.073476243019104, Val_loss 3.572774887084961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.048599696159363, Val_loss 3.5603506565093994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.064892888069153, Val_loss 3.5648317337036133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.046141505241394, Val_loss 3.569911241531372\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0916683197021486, Val_loss 3.5736072063446045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.077396368980408, Val_loss 3.550189733505249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.9235296726226805, Val_loss 4.2300004959106445\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.117221403121948, Val_loss 4.188275337219238\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.05937237739563, Val_loss 4.170932292938232\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9188530683517455, Val_loss 4.096551895141602\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.829445004463196, Val_loss 3.901906728744507\n",
      "Train_acc_top_20 0.15\tTrain_acc_top_30 0.2188\tTrain_acc_top_40 0.2625\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.725416326522827, Val_loss 3.8439505100250244\n",
      "Train_acc_top_20 0.3625\tTrain_acc_top_30 0.4813\tTrain_acc_top_40 0.5563\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.674369287490845, Val_loss 3.7318270206451416\n",
      "Train_acc_top_20 0.6687\tTrain_acc_top_30 0.8313\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.83\t\n",
      "Epoch 8, Train_Loss 3.5986958026885985, Val_loss 3.757905960083008\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.543863320350647, Val_loss 3.7170183658599854\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.48402795791626, Val_loss 3.716825485229492\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.453108024597168, Val_loss 3.703575372695923\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.409011435508728, Val_loss 3.7246315479278564\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 13, Train_Loss 3.396734189987183, Val_loss 3.756619453430176\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3574371337890625, Val_loss 3.6862595081329346\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3329476833343508, Val_loss 3.6509714126586914\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.327087950706482, Val_loss 3.6616132259368896\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.2943505525588987, Val_loss 3.650989532470703\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.269952082633972, Val_loss 3.664031982421875\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.261035656929016, Val_loss 3.635300874710083\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.227853202819824, Val_loss 3.6644747257232666\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2560518741607667, Val_loss 3.67510724067688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2217557191848756, Val_loss 3.6248624324798584\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.218298649787903, Val_loss 3.6411476135253906\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.224109148979187, Val_loss 3.648468255996704\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.225780963897705, Val_loss 3.635073661804199\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.2183117866516113, Val_loss 3.66214656829834\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.190834379196167, Val_loss 3.6638975143432617\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.2304776906967163, Val_loss 3.648597002029419\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.1834567070007322, Val_loss 3.6925907135009766\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.1716373920440675, Val_loss 3.575974464416504\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1705499410629274, Val_loss 3.604632616043091\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1831401586532593, Val_loss 3.6295855045318604\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.1627203941345217, Val_loss 3.651135206222534\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.178419518470764, Val_loss 3.7037088871002197\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 35, Train_Loss 3.1386311769485475, Val_loss 3.743919610977173\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 36, Train_Loss 3.1589440584182737, Val_loss 3.649545907974243\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1749332904815675, Val_loss 3.6200854778289795\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1605016469955443, Val_loss 3.5939958095550537\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.128927206993103, Val_loss 3.6081058979034424\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1549551725387572, Val_loss 3.7205898761749268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.1207323551177977, Val_loss 3.6397202014923096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.1469711542129515, Val_loss 3.6702048778533936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 43, Train_Loss 3.1349023580551147, Val_loss 3.7668960094451904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.1822529554367067, Val_loss 3.687131881713867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1842331171035765, Val_loss 3.7118470668792725\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1215305089950562, Val_loss 3.662175178527832\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 47, Train_Loss 3.1001598596572877, Val_loss 3.620922803878784\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.142307090759277, Val_loss 3.675168752670288\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.114902138710022, Val_loss 3.7108614444732666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.131753420829773, Val_loss 3.633427858352661\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 51, Train_Loss 3.1086600542068483, Val_loss 3.6852283477783203\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.1144243240356446, Val_loss 3.6066091060638428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.109408664703369, Val_loss 3.6910247802734375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.125600075721741, Val_loss 3.674339532852173\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.132457399368286, Val_loss 3.7037134170532227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 56, Train_Loss 3.0849908113479616, Val_loss 3.6595618724823\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.0823199272155763, Val_loss 3.643010377883911\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.109596061706543, Val_loss 3.641955614089966\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.09572172164917, Val_loss 3.648726463317871\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.111485552787781, Val_loss 3.6358954906463623\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.076101851463318, Val_loss 3.653201103210449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 62, Train_Loss 3.106018233299255, Val_loss 3.7256507873535156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.1036221265792845, Val_loss 3.7144620418548584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.0881876230239866, Val_loss 3.6852035522460938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.1118677616119386, Val_loss 3.6708920001983643\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.099845361709595, Val_loss 3.6377785205841064\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.089944839477539, Val_loss 3.656116247177124\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.1237491369247437, Val_loss 3.6867313385009766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 69, Train_Loss 3.0820702075958253, Val_loss 3.68267560005188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 70, Train_Loss 3.067672681808472, Val_loss 3.675466299057007\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 71, Train_Loss 3.1263657093048094, Val_loss 3.6917953491210938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 72, Train_Loss 3.079162907600403, Val_loss 3.673063039779663\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.1080196142196654, Val_loss 3.6934053897857666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 74, Train_Loss 3.118843126296997, Val_loss 3.667560338973999\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 75, Train_Loss 3.0702435255050657, Val_loss 3.6922261714935303\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.0691433906555177, Val_loss 3.701190233230591\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 77, Train_Loss 3.0459855794906616, Val_loss 3.6741158962249756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 78, Train_Loss 3.043427062034607, Val_loss 3.6750361919403076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.0914715766906737, Val_loss 3.6398775577545166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.060810112953186, Val_loss 3.6921281814575195\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.066583180427551, Val_loss 3.624253988265991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 82, Train_Loss 3.0875534772872926, Val_loss 3.630844831466675\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 83, Train_Loss 3.0590813875198366, Val_loss 3.6382248401641846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.0593107461929323, Val_loss 3.704653739929199\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 85, Train_Loss 3.113568925857544, Val_loss 3.65899658203125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.1490497827529906, Val_loss 3.6862478256225586\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.0772406578063967, Val_loss 3.6694304943084717\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 88, Train_Loss 3.102250599861145, Val_loss 3.6774699687957764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.082944369316101, Val_loss 3.6680643558502197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.0977631330490114, Val_loss 3.678892135620117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.0915807247161866, Val_loss 3.65932297706604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.084191417694092, Val_loss 3.6676294803619385\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.060855269432068, Val_loss 3.667041063308716\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.06293523311615, Val_loss 3.671562433242798\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.0763887643814085, Val_loss 3.6889355182647705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 96, Train_Loss 3.0771389245986938, Val_loss 3.6956799030303955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 97, Train_Loss 3.068762254714966, Val_loss 3.669445276260376\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.0339313983917235, Val_loss 3.690577268600464\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 99, Train_Loss 3.0616509914398193, Val_loss 3.6557319164276123\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.0864156007766725, Val_loss 3.6670150756835938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9267802953720095, Val_loss 4.275502681732178\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.129845714569091, Val_loss 4.215414524078369\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.07466197013855, Val_loss 4.242210865020752\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9773675203323364, Val_loss 4.253342151641846\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.868161606788635, Val_loss 4.188267230987549\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.779622268676758, Val_loss 3.8509433269500732\n",
      "Train_acc_top_20 0.2\tTrain_acc_top_30 0.2875\tTrain_acc_top_40 0.4062\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.7139682531356812, Val_loss 3.699735403060913\n",
      "Train_acc_top_20 0.4813\tTrain_acc_top_30 0.6375\tTrain_acc_top_40 0.7625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.6601622819900514, Val_loss 3.633624315261841\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8688\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.6059206247329714, Val_loss 3.61641001701355\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.5330233812332152, Val_loss 3.58886981010437\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.5134230136871336, Val_loss 3.555603265762329\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.4476977825164794, Val_loss 3.568521499633789\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 13, Train_Loss 3.4140211582183837, Val_loss 3.5610761642456055\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 14, Train_Loss 3.399700975418091, Val_loss 3.569340944290161\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.378213357925415, Val_loss 3.469611406326294\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.338063192367554, Val_loss 3.5272395610809326\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 17, Train_Loss 3.328271484375, Val_loss 3.463294744491577\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.334044170379639, Val_loss 3.445634126663208\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.313658094406128, Val_loss 3.563688278198242\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.283227634429932, Val_loss 3.594729423522949\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.256548857688904, Val_loss 3.5033743381500244\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.245093846321106, Val_loss 3.536036252975464\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 23, Train_Loss 3.250307822227478, Val_loss 3.5050718784332275\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.256878900527954, Val_loss 3.456941604614258\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 25, Train_Loss 3.242797875404358, Val_loss 3.4565770626068115\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 26, Train_Loss 3.234895396232605, Val_loss 3.5064165592193604\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.2077143907547, Val_loss 3.496331214904785\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 28, Train_Loss 3.2187706232070923, Val_loss 3.431549310684204\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 29, Train_Loss 3.1802485942840577, Val_loss 3.4908406734466553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 30, Train_Loss 3.186191129684448, Val_loss 3.467883348464966\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 31, Train_Loss 3.196095323562622, Val_loss 3.487177610397339\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.179915356636047, Val_loss 3.4071333408355713\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 33, Train_Loss 3.22227463722229, Val_loss 3.80249285697937\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.238675856590271, Val_loss 3.5888891220092773\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.204459857940674, Val_loss 3.5953521728515625\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.2377075433731077, Val_loss 3.412752151489258\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 37, Train_Loss 3.190129208564758, Val_loss 3.505380630493164\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 38, Train_Loss 3.150282549858093, Val_loss 3.5103073120117188\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.206476068496704, Val_loss 3.514362335205078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.2046438694000243, Val_loss 3.543811082839966\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.2422168254852295, Val_loss 3.817232847213745\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 42, Train_Loss 3.1333889245986937, Val_loss 3.507457971572876\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.134216642379761, Val_loss 3.5455217361450195\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.1850745677948, Val_loss 3.396212577819824\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 45, Train_Loss 3.1579880714416504, Val_loss 3.4555110931396484\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 46, Train_Loss 3.182200241088867, Val_loss 3.4674367904663086\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.1744322776794434, Val_loss 3.4395694732666016\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 48, Train_Loss 3.189226675033569, Val_loss 3.4320738315582275\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.22671377658844, Val_loss 3.6527233123779297\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.150414752960205, Val_loss 3.513552665710449\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.133025312423706, Val_loss 3.5490806102752686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.179274153709412, Val_loss 3.467118978500366\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 53, Train_Loss 3.1121917247772215, Val_loss 3.4891576766967773\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 54, Train_Loss 3.1457109451293945, Val_loss 3.487567186355591\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 55, Train_Loss 3.131507730484009, Val_loss 3.61065411567688\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 56, Train_Loss 3.2361999273300173, Val_loss 3.5136709213256836\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.187060570716858, Val_loss 3.451029062271118\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.1784961938858034, Val_loss 3.4128153324127197\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 59, Train_Loss 3.099214053153992, Val_loss 3.4162228107452393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 60, Train_Loss 3.1405596256256105, Val_loss 3.4823532104492188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.1148666620254515, Val_loss 3.476184129714966\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.0948848009109495, Val_loss 3.4559943675994873\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.1158289432525637, Val_loss 3.444711685180664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.0868052005767823, Val_loss 3.442875623703003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 65, Train_Loss 3.1273576736450197, Val_loss 3.5197761058807373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 66, Train_Loss 3.081694722175598, Val_loss 3.368147611618042\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 67, Train_Loss 3.121111583709717, Val_loss 3.4019880294799805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 68, Train_Loss 3.0581886768341064, Val_loss 3.4757254123687744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 69, Train_Loss 3.1468039751052856, Val_loss 3.400792360305786\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 70, Train_Loss 3.0633453369140624, Val_loss 3.396674871444702\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 71, Train_Loss 3.133899688720703, Val_loss 3.3989956378936768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 72, Train_Loss 3.0694223642349243, Val_loss 3.4617795944213867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.05821635723114, Val_loss 3.420896530151367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.159781312942505, Val_loss 3.447279691696167\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 75, Train_Loss 3.0529035329818726, Val_loss 3.449190378189087\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 76, Train_Loss 3.1136093616485594, Val_loss 3.3766777515411377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 77, Train_Loss 3.1132693767547606, Val_loss 3.413302421569824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 78, Train_Loss 3.0852388620376585, Val_loss 3.424565076828003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 79, Train_Loss 3.086448836326599, Val_loss 3.434570074081421\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 80, Train_Loss 3.0734709978103636, Val_loss 3.496631622314453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.096324610710144, Val_loss 3.3747293949127197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 82, Train_Loss 3.108942484855652, Val_loss 3.3666441440582275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 83, Train_Loss 3.113452363014221, Val_loss 3.3867461681365967\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 84, Train_Loss 3.1297763347625733, Val_loss 3.4282095432281494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 85, Train_Loss 3.0885812520980833, Val_loss 3.4129638671875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.0440690994262694, Val_loss 3.4206316471099854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.1372875928878785, Val_loss 3.4070465564727783\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 88, Train_Loss 3.079072952270508, Val_loss 3.4302818775177\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 89, Train_Loss 3.084248495101929, Val_loss 3.4076011180877686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 90, Train_Loss 3.041658568382263, Val_loss 3.4245176315307617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.1144920349121095, Val_loss 3.420478105545044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 92, Train_Loss 3.084048557281494, Val_loss 3.419757127761841\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 93, Train_Loss 3.117334485054016, Val_loss 3.429319381713867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 94, Train_Loss 3.086749315261841, Val_loss 3.4002506732940674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 95, Train_Loss 3.047779583930969, Val_loss 3.468768358230591\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 96, Train_Loss 3.0376498222351076, Val_loss 3.434818983078003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.061425280570984, Val_loss 3.4541358947753906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.0954226732254027, Val_loss 3.4186480045318604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 99, Train_Loss 3.113402271270752, Val_loss 3.4176101684570312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 100, Train_Loss 3.067841410636902, Val_loss 3.4026811122894287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 1, Train_Loss 3.922189974784851, Val_loss 4.2604193687438965\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.11451153755188, Val_loss 4.26834774017334\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.048032021522522, Val_loss 4.232144832611084\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.906075620651245, Val_loss 4.141409397125244\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.837731385231018, Val_loss 4.022019386291504\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.741882252693176, Val_loss 3.8700358867645264\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.4313\tTrain_acc_top_40 0.4875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.6783692121505736, Val_loss 3.733673334121704\n",
      "Train_acc_top_20 0.5375\tTrain_acc_top_30 0.6937\tTrain_acc_top_40 0.85\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.6100136280059814, Val_loss 3.731384515762329\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.5366717338562013, Val_loss 3.663069009780884\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.4848932027816772, Val_loss 3.6920347213745117\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.429450178146362, Val_loss 3.7753705978393555\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.449569821357727, Val_loss 3.6527204513549805\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.4000503778457642, Val_loss 3.6904714107513428\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.351463770866394, Val_loss 3.6294591426849365\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.293273663520813, Val_loss 3.650118112564087\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.2881839752197264, Val_loss 3.661935567855835\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.2652813673019407, Val_loss 3.5956411361694336\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 18, Train_Loss 3.2528810024261476, Val_loss 3.5948150157928467\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.2400580644607544, Val_loss 3.610769271850586\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2178696632385253, Val_loss 3.574345827102661\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.262710452079773, Val_loss 3.598860740661621\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.238552141189575, Val_loss 3.605510950088501\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.186667823791504, Val_loss 3.573209524154663\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.2040732383728026, Val_loss 3.5986297130584717\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.179180407524109, Val_loss 3.6072323322296143\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.1799026250839235, Val_loss 3.579897880554199\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.201086163520813, Val_loss 3.562304735183716\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.179582190513611, Val_loss 3.5434648990631104\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1918970346450806, Val_loss 3.5242929458618164\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.132507824897766, Val_loss 3.507295846939087\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.138159489631653, Val_loss 3.487574815750122\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1402268171310426, Val_loss 3.5138626098632812\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.141509175300598, Val_loss 3.5026683807373047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.1718321084976195, Val_loss 3.5654919147491455\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.127873945236206, Val_loss 3.46921443939209\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1378203868865966, Val_loss 3.5315351486206055\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.123811388015747, Val_loss 3.4988515377044678\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.137629508972168, Val_loss 3.5400285720825195\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1499765396118162, Val_loss 3.4912049770355225\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1429957151412964, Val_loss 3.5480196475982666\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1581875801086428, Val_loss 3.486926317214966\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.147182035446167, Val_loss 3.5076255798339844\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.140535354614258, Val_loss 3.51479434967041\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.1674319982528685, Val_loss 3.529339551925659\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1601994752883913, Val_loss 3.5399246215820312\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.170073962211609, Val_loss 3.550180196762085\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.125705194473267, Val_loss 3.5615921020507812\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.11550030708313, Val_loss 3.5353593826293945\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1096288442611693, Val_loss 3.501150369644165\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.13157742023468, Val_loss 3.51056170463562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.129971718788147, Val_loss 3.5159122943878174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.098027968406677, Val_loss 3.509533643722534\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.0981264114379883, Val_loss 3.5854175090789795\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.0926345586776733, Val_loss 3.5748443603515625\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1204848527908324, Val_loss 3.5443832874298096\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.1057891130447386, Val_loss 3.524728775024414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.134972643852234, Val_loss 3.492516279220581\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.134718155860901, Val_loss 3.5651073455810547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1331419229507445, Val_loss 3.5341243743896484\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.101133131980896, Val_loss 3.5325863361358643\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1119083881378176, Val_loss 3.5165765285491943\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.115322804450989, Val_loss 3.479938507080078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.1036511659622192, Val_loss 3.526796340942383\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.104174041748047, Val_loss 3.588170051574707\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.123093342781067, Val_loss 3.508408546447754\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.106103277206421, Val_loss 3.562821388244629\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.099478602409363, Val_loss 3.5462872982025146\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.1052200317382814, Val_loss 3.517659902572632\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0766214609146116, Val_loss 3.5328080654144287\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.0729450225830077, Val_loss 3.5258901119232178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.112027406692505, Val_loss 3.4876582622528076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0963510990142824, Val_loss 3.5288679599761963\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0728917121887207, Val_loss 3.5016539096832275\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0627923250198363, Val_loss 3.508847951889038\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.0654465913772584, Val_loss 3.5237486362457275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.116812801361084, Val_loss 3.514387369155884\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0612455129623415, Val_loss 3.501511335372925\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.1013705730438232, Val_loss 3.5135018825531006\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.0531689643859865, Val_loss 3.5429935455322266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.0275004625320436, Val_loss 3.567063093185425\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.051737117767334, Val_loss 3.5698301792144775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.1152544021606445, Val_loss 3.5257608890533447\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.124518609046936, Val_loss 3.5468499660491943\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0452574729919433, Val_loss 3.5416786670684814\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.1084335088729858, Val_loss 3.5285987854003906\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0541367292404176, Val_loss 3.516233444213867\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.081280517578125, Val_loss 3.5345966815948486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.0909902095794677, Val_loss 3.5283210277557373\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0405699014663696, Val_loss 3.5037965774536133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0681076288223266, Val_loss 3.4995439052581787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.067429804801941, Val_loss 3.5062057971954346\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.112242603302002, Val_loss 3.506582260131836\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.0785850048065186, Val_loss 3.5114314556121826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.090087080001831, Val_loss 3.4969234466552734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.096788001060486, Val_loss 3.536830186843872\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.062124490737915, Val_loss 3.52551007270813\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.13702871799469, Val_loss 3.5584876537323\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.1368191719055174, Val_loss 3.547506093978882\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.086048197746277, Val_loss 3.521977663040161\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.135819840431213, Val_loss 3.538792371749878\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.925734305381775, Val_loss 4.290907382965088\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.123836183547974, Val_loss 4.202322483062744\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.38\t\n",
      "Epoch 3, Train_Loss 4.071828413009643, Val_loss 4.168598175048828\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9756250858306883, Val_loss 4.093677997589111\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.38\t\n",
      "Epoch 5, Train_Loss 3.860099530220032, Val_loss 3.9836156368255615\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.7539525985717774, Val_loss 3.8163578510284424\n",
      "Train_acc_top_20 0.275\tTrain_acc_top_30 0.3812\tTrain_acc_top_40 0.4813\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.7034689664840696, Val_loss 3.6011064052581787\n",
      "Train_acc_top_20 0.5312\tTrain_acc_top_30 0.7063\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 8, Train_Loss 3.6455815076828, Val_loss 3.5767037868499756\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.6478470087051393, Val_loss 3.672137975692749\n",
      "Train_acc_top_20 0.7\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.587105393409729, Val_loss 3.6149322986602783\n",
      "Train_acc_top_20 0.7562\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.525524640083313, Val_loss 3.613692045211792\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4654285430908205, Val_loss 3.5591938495635986\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.437615418434143, Val_loss 3.4375016689300537\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 14, Train_Loss 3.417812204360962, Val_loss 3.540743827819824\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3302812814712524, Val_loss 3.4893810749053955\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.3402658224105837, Val_loss 3.590113639831543\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.314111256599426, Val_loss 3.4817399978637695\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.277801847457886, Val_loss 3.557098150253296\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.2423998355865478, Val_loss 3.6378962993621826\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2103505611419676, Val_loss 3.6270408630371094\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.2244436264038088, Val_loss 3.596874475479126\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2954031229019165, Val_loss 3.513444662094116\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.273950481414795, Val_loss 3.679290771484375\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.299856662750244, Val_loss 3.6526987552642822\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.259615755081177, Val_loss 3.602156639099121\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.1934535264968873, Val_loss 3.5810749530792236\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.3314409494400024, Val_loss 3.5432779788970947\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.286185073852539, Val_loss 3.67756724357605\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.243749213218689, Val_loss 3.5099573135375977\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.255938982963562, Val_loss 3.5430285930633545\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.2172584772109984, Val_loss 3.5675723552703857\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.191034507751465, Val_loss 3.5192668437957764\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1780463218688966, Val_loss 3.5804789066314697\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.170123243331909, Val_loss 3.603386163711548\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1922217845916747, Val_loss 3.655994176864624\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.200420355796814, Val_loss 3.681710958480835\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.1588656187057493, Val_loss 3.5741748809814453\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1539756059646606, Val_loss 3.5705630779266357\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.2226668119430544, Val_loss 3.53442120552063\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1891627073287965, Val_loss 3.6232452392578125\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 41, Train_Loss 3.126649808883667, Val_loss 3.668503761291504\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1561986684799193, Val_loss 3.548440933227539\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.187441086769104, Val_loss 3.531492233276367\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1807724952697756, Val_loss 3.52911114692688\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.156011199951172, Val_loss 3.517080307006836\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.1999865055084227, Val_loss 3.5465028285980225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1709311246871947, Val_loss 3.6234378814697266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 48, Train_Loss 3.0942865133285524, Val_loss 3.627019166946411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 49, Train_Loss 3.1815115451812743, Val_loss 3.638360023498535\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 50, Train_Loss 3.1720298290252686, Val_loss 3.640838861465454\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.0437503337860106, Val_loss 3.580034017562866\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.1905173540115355, Val_loss 3.5672051906585693\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.110062050819397, Val_loss 3.5987062454223633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.13004732131958, Val_loss 3.5485823154449463\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.0408578872680665, Val_loss 3.6146047115325928\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 56, Train_Loss 3.0717753648757933, Val_loss 3.58455753326416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.084237813949585, Val_loss 3.6134471893310547\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.063004565238953, Val_loss 3.6126749515533447\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.0463870763778687, Val_loss 3.6116371154785156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.085998797416687, Val_loss 3.596055030822754\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.1157596826553347, Val_loss 3.514930009841919\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.1154593944549562, Val_loss 3.5521106719970703\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 63, Train_Loss 3.10665967464447, Val_loss 3.5439980030059814\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.0742228031158447, Val_loss 3.5471456050872803\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.0576916217803953, Val_loss 3.514622926712036\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.092602324485779, Val_loss 3.55924129486084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.101874089241028, Val_loss 3.5675647258758545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.11168372631073, Val_loss 3.54239821434021\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 69, Train_Loss 3.075096344947815, Val_loss 3.662975549697876\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.102589225769043, Val_loss 3.6088945865631104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 71, Train_Loss 3.1153246641159056, Val_loss 3.6112241744995117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.099603605270386, Val_loss 3.59279465675354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.0375325441360475, Val_loss 3.6092872619628906\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0477765798568726, Val_loss 3.606398820877075\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.177696204185486, Val_loss 3.5162010192871094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.0674856424331667, Val_loss 3.5343074798583984\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.0532458305358885, Val_loss 3.5823848247528076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.0593442916870117, Val_loss 3.6083595752716064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.0937991380691527, Val_loss 3.548328161239624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.058792328834534, Val_loss 3.5754339694976807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.052449870109558, Val_loss 3.5930681228637695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.0446207523345947, Val_loss 3.559988021850586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.087867856025696, Val_loss 3.564875364303589\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.055993127822876, Val_loss 3.5801827907562256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.052766036987305, Val_loss 3.5569629669189453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.089073920249939, Val_loss 3.5863380432128906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.105496621131897, Val_loss 3.565554618835449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.100780963897705, Val_loss 3.55631160736084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0760793924331664, Val_loss 3.7037525177001953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1011223793029785, Val_loss 3.5488500595092773\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.0997101068496704, Val_loss 3.562001943588257\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.058168411254883, Val_loss 3.5603342056274414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.09476215839386, Val_loss 3.5786380767822266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.1052168369293214, Val_loss 3.534552574157715\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0746437311172485, Val_loss 3.545677900314331\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.1568461894989013, Val_loss 3.545868158340454\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.066808295249939, Val_loss 3.5623586177825928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0571092128753663, Val_loss 3.5928993225097656\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.086710071563721, Val_loss 3.5539467334747314\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.047024059295654, Val_loss 3.5690317153930664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.924834728240967, Val_loss 4.331618309020996\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.04\t\n",
      "Epoch 2, Train_Loss 4.1111273765563965, Val_loss 4.3278584480285645\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.040499544143676, Val_loss 4.428839206695557\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.896511197090149, Val_loss 4.357879638671875\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.04\t\n",
      "Epoch 5, Train_Loss 3.8273001194000242, Val_loss 4.032727241516113\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.7254861116409304, Val_loss 3.8056113719940186\n",
      "Train_acc_top_20 0.325\tTrain_acc_top_30 0.4875\tTrain_acc_top_40 0.5188\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 7, Train_Loss 3.6757756233215333, Val_loss 3.753002405166626\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.7375\tTrain_acc_top_40 0.8187\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.6098657846450806, Val_loss 3.669078826904297\n",
      "Train_acc_top_20 0.6937\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9125\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5839245557785033, Val_loss 3.751131296157837\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.52480628490448, Val_loss 3.628021001815796\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.495024085044861, Val_loss 3.7096216678619385\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.43639657497406, Val_loss 3.5897581577301025\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.425869679450989, Val_loss 3.6300175189971924\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3828897953033445, Val_loss 3.5652599334716797\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3526836395263673, Val_loss 3.659022331237793\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.351701045036316, Val_loss 3.627260208129883\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 17, Train_Loss 3.340140962600708, Val_loss 3.5798442363739014\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.313385343551636, Val_loss 3.583669424057007\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.2863998889923094, Val_loss 3.6423397064208984\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2790152788162232, Val_loss 3.5564000606536865\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.244078254699707, Val_loss 3.5560896396636963\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.259827899932861, Val_loss 3.553809404373169\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.264202833175659, Val_loss 3.6653826236724854\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.282443976402283, Val_loss 3.458875894546509\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2147855281829836, Val_loss 3.504551649093628\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.229509162902832, Val_loss 3.549509048461914\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.2697044134140016, Val_loss 3.5594875812530518\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.197203493118286, Val_loss 3.578766107559204\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.1777453422546387, Val_loss 3.484954833984375\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1656511783599854, Val_loss 3.4769437313079834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.164152646064758, Val_loss 3.561288595199585\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1639692306518556, Val_loss 3.5422439575195312\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.192904329299927, Val_loss 3.6267335414886475\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.1925241947174072, Val_loss 3.567948579788208\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1764863967895507, Val_loss 3.5969009399414062\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1185874700546266, Val_loss 3.4860153198242188\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1758584499359133, Val_loss 3.5021095275878906\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.132531523704529, Val_loss 3.460206985473633\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.140430045127869, Val_loss 3.460599184036255\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1929684400558473, Val_loss 3.570683717727661\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1699774265289307, Val_loss 3.5989644527435303\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.199206066131592, Val_loss 3.557389974594116\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1772804737091063, Val_loss 3.510432243347168\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.127501964569092, Val_loss 3.530207633972168\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.19355993270874, Val_loss 3.5294787883758545\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1346474170684813, Val_loss 3.5412304401397705\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 47, Train_Loss 3.1990699768066406, Val_loss 3.629625082015991\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 48, Train_Loss 3.2036858797073364, Val_loss 3.439741373062134\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1562605619430544, Val_loss 3.421792984008789\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.168153738975525, Val_loss 3.4298760890960693\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1268771409988405, Val_loss 3.5124471187591553\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.132219386100769, Val_loss 3.5082976818084717\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.1135913610458372, Val_loss 3.4776265621185303\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 54, Train_Loss 3.2069055318832396, Val_loss 3.501704216003418\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.1400551557540894, Val_loss 3.4476654529571533\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1461047649383547, Val_loss 3.459920644760132\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.0724654674530028, Val_loss 3.48431658744812\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.134402942657471, Val_loss 3.4938671588897705\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.074795150756836, Val_loss 3.3878583908081055\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.080241012573242, Val_loss 3.442155122756958\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1851484060287474, Val_loss 3.4871675968170166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.1420220613479612, Val_loss 3.522662878036499\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1333268165588377, Val_loss 3.4716789722442627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.1008491039276125, Val_loss 3.5210342407226562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.126369071006775, Val_loss 3.4668872356414795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.1161669492721558, Val_loss 3.4739131927490234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.1064974546432493, Val_loss 3.478692054748535\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.085055136680603, Val_loss 3.464860200881958\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.102979826927185, Val_loss 3.46158766746521\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 70, Train_Loss 3.107509446144104, Val_loss 3.4675066471099854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0872071027755736, Val_loss 3.477574348449707\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0914617776870728, Val_loss 3.499042510986328\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.095245695114136, Val_loss 3.5023269653320312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0967539072036745, Val_loss 3.4826271533966064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.041392970085144, Val_loss 3.441204309463501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.065510082244873, Val_loss 3.474917411804199\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.1207009077072145, Val_loss 3.516176462173462\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.082934331893921, Val_loss 3.466724395751953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.1247177124023438, Val_loss 3.4765288829803467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.062319350242615, Val_loss 3.466110944747925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.100682020187378, Val_loss 3.417732000350952\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.0674392223358153, Val_loss 3.475926637649536\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.103680443763733, Val_loss 3.4622561931610107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.117866349220276, Val_loss 3.4629404544830322\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.1146425008773804, Val_loss 3.5026705265045166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.1167843103408814, Val_loss 3.4803383350372314\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.1094101667404175, Val_loss 3.4989230632781982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.0779438972473145, Val_loss 3.479267120361328\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.081926393508911, Val_loss 3.5001399517059326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.0794273376464845, Val_loss 3.468456506729126\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.0714168787002563, Val_loss 3.437847137451172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.15436589717865, Val_loss 3.4931411743164062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.08893723487854, Val_loss 3.4567415714263916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0744000673294067, Val_loss 3.473507881164551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0340277194976806, Val_loss 3.426595449447632\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0917815208435058, Val_loss 3.45329213142395\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.1384344816207888, Val_loss 3.513498306274414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.058658313751221, Val_loss 3.4360580444335938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.126374292373657, Val_loss 3.4893171787261963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.1095821619033814, Val_loss 3.50273060798645\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.926544690132141, Val_loss 4.302825450897217\n",
      "Train_acc_top_20 0.075\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.118243980407715, Val_loss 4.270422458648682\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.064657926559448, Val_loss 4.2820940017700195\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.9324318885803224, Val_loss 4.172183990478516\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8576446056365965, Val_loss 3.999701738357544\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7672608613967897, Val_loss 3.8199408054351807\n",
      "Train_acc_top_20 0.2313\tTrain_acc_top_30 0.375\tTrain_acc_top_40 0.4688\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.38\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.6803295612335205, Val_loss 3.746802568435669\n",
      "Train_acc_top_20 0.45\tTrain_acc_top_30 0.6438\tTrain_acc_top_40 0.725\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 8, Train_Loss 3.6315824508666994, Val_loss 3.731144666671753\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.562721586227417, Val_loss 3.7964060306549072\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.5309556484222413, Val_loss 3.7144711017608643\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.5141286611557008, Val_loss 3.6119072437286377\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4714192390441894, Val_loss 3.5929641723632812\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.4250123739242553, Val_loss 3.6947238445281982\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.3970707654953003, Val_loss 3.658252000808716\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3625487804412844, Val_loss 3.67498517036438\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3546525716781614, Val_loss 3.644364356994629\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.326490592956543, Val_loss 3.599825143814087\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.2914801120758055, Val_loss 3.5356838703155518\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.2742073774337768, Val_loss 3.6007816791534424\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.2612229108810427, Val_loss 3.6053571701049805\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.2615041494369508, Val_loss 3.4801700115203857\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.245798397064209, Val_loss 3.536888360977173\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.306170701980591, Val_loss 3.6350910663604736\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2953828811645507, Val_loss 3.7354698181152344\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 25, Train_Loss 3.2772133588790893, Val_loss 3.5508663654327393\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.239131450653076, Val_loss 3.534454345703125\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.2147084712982177, Val_loss 3.637444496154785\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.21922652721405, Val_loss 3.5715057849884033\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.18306941986084, Val_loss 3.5311572551727295\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.21336567401886, Val_loss 3.560297727584839\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.2133400201797486, Val_loss 3.5057153701782227\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.2466367721557616, Val_loss 3.4527931213378906\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 33, Train_Loss 3.213842177391052, Val_loss 3.4747159481048584\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.189273476600647, Val_loss 3.4572935104370117\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.2034337520599365, Val_loss 3.496995210647583\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.1951568841934206, Val_loss 3.503649950027466\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 37, Train_Loss 3.183766722679138, Val_loss 3.565640449523926\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.190142774581909, Val_loss 3.456143617630005\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1613916158676147, Val_loss 3.4348690509796143\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.1273840427398683, Val_loss 3.5321552753448486\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.267754602432251, Val_loss 3.668970823287964\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.1874687671661377, Val_loss 3.4922218322753906\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.1426076889038086, Val_loss 3.4441025257110596\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.2067354917526245, Val_loss 3.5054233074188232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1725324153900147, Val_loss 3.4853012561798096\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.100244641304016, Val_loss 3.5739452838897705\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1531320571899415, Val_loss 3.5422210693359375\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.1958364248275757, Val_loss 3.5519778728485107\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1327281951904298, Val_loss 3.5071465969085693\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1143995761871337, Val_loss 3.440178632736206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1946857929229737, Val_loss 3.4713973999023438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.151785635948181, Val_loss 3.4725170135498047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.170778441429138, Val_loss 3.5192034244537354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.131750774383545, Val_loss 3.4516026973724365\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.1218501567840575, Val_loss 3.513460397720337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1633437871932983, Val_loss 3.4581058025360107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.0997495651245117, Val_loss 3.501136541366577\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.1031593084335327, Val_loss 3.5112969875335693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.0980651140213014, Val_loss 3.4115869998931885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.073514723777771, Val_loss 3.4590559005737305\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.136333441734314, Val_loss 3.4666740894317627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.125122046470642, Val_loss 3.4732439517974854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.1246963262557985, Val_loss 3.483295440673828\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.0987749099731445, Val_loss 3.4634735584259033\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.169709587097168, Val_loss 3.5213730335235596\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.085545563697815, Val_loss 3.430389165878296\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.1091641902923586, Val_loss 3.429347276687622\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.0527034759521485, Val_loss 3.4328114986419678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.160299849510193, Val_loss 3.4493439197540283\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.1243656873703003, Val_loss 3.433295965194702\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.103251552581787, Val_loss 3.428966522216797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.12941734790802, Val_loss 3.440985679626465\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.131607484817505, Val_loss 3.5108120441436768\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.1064893007278442, Val_loss 3.487736940383911\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.05682373046875, Val_loss 3.4516050815582275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.1099908113479615, Val_loss 3.478382110595703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.135587191581726, Val_loss 3.5162413120269775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.091064524650574, Val_loss 3.457092523574829\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.188600182533264, Val_loss 3.5088987350463867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.083641195297241, Val_loss 3.4209043979644775\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.112430787086487, Val_loss 3.4685957431793213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.1569437742233277, Val_loss 3.43465518951416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.1417014837265014, Val_loss 3.4987337589263916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.1513041257858276, Val_loss 3.477278709411621\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.077529239654541, Val_loss 3.4495019912719727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.1083208084106446, Val_loss 3.442561149597168\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.0948317527770994, Val_loss 3.4473140239715576\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.118790626525879, Val_loss 3.488020896911621\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.1096774101257325, Val_loss 3.4672696590423584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.131637787818909, Val_loss 3.436617851257324\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.094142770767212, Val_loss 3.461942672729492\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.077914905548096, Val_loss 3.4641199111938477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.119552183151245, Val_loss 3.4535932540893555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.1264202117919924, Val_loss 3.4653327465057373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.114619731903076, Val_loss 3.4875752925872803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.1196886777877806, Val_loss 3.475156784057617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.117892789840698, Val_loss 3.4299862384796143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.095423698425293, Val_loss 3.487187147140503\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.141672205924988, Val_loss 3.486978530883789\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.0920585870742796, Val_loss 3.4459784030914307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.922972798347473, Val_loss 4.2853240966796875\n",
      "Train_acc_top_20 0.1625\tTrain_acc_top_30 0.1938\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.103590059280395, Val_loss 4.213107585906982\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.025672435760498, Val_loss 4.177341461181641\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.8644131660461425, Val_loss 4.145895481109619\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8005348205566407, Val_loss 4.007729530334473\n",
      "Train_acc_top_20 0.1625\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.12\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.710466194152832, Val_loss 3.8766071796417236\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.375\tTrain_acc_top_40 0.4688\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.608965802192688, Val_loss 3.822751045227051\n",
      "Train_acc_top_20 0.6312\tTrain_acc_top_30 0.7625\tTrain_acc_top_40 0.8438\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.42\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.582897257804871, Val_loss 3.7929422855377197\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.542664647102356, Val_loss 3.782693862915039\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.4641558170318603, Val_loss 3.859070062637329\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.431911826133728, Val_loss 3.635540723800659\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.386467170715332, Val_loss 3.760246992111206\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.3566741704940797, Val_loss 3.699509859085083\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 14, Train_Loss 3.3655028104782105, Val_loss 3.798802137374878\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 15, Train_Loss 3.301830506324768, Val_loss 3.768310546875\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 16, Train_Loss 3.302174115180969, Val_loss 3.6343460083007812\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.260186219215393, Val_loss 3.75869083404541\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 18, Train_Loss 3.251161742210388, Val_loss 3.5762064456939697\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.247439908981323, Val_loss 3.8102633953094482\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 20, Train_Loss 3.2242956876754763, Val_loss 3.7102878093719482\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.244289588928223, Val_loss 3.6696255207061768\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.199229431152344, Val_loss 3.5501458644866943\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.19461133480072, Val_loss 3.7251527309417725\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 24, Train_Loss 3.191296195983887, Val_loss 3.6624279022216797\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.237034797668457, Val_loss 3.7641751766204834\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.2193187713623046, Val_loss 3.6787641048431396\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.171043300628662, Val_loss 3.5826804637908936\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1708367347717283, Val_loss 3.588543653488159\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.1405154705047607, Val_loss 3.6078150272369385\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.1205142736434937, Val_loss 3.644958734512329\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.125200653076172, Val_loss 3.6426658630371094\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.141576313972473, Val_loss 3.80965518951416\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.62\t\n",
      "Epoch 33, Train_Loss 3.1209394693374635, Val_loss 3.746933698654175\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.1279609203338623, Val_loss 3.6976277828216553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.150171089172363, Val_loss 3.586479425430298\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1279542684555053, Val_loss 3.677515983581543\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.0987530946731567, Val_loss 3.6383020877838135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1116390228271484, Val_loss 3.561628580093384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1177990198135377, Val_loss 3.582592725753784\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1245157957077025, Val_loss 3.563717842102051\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.1236109018325804, Val_loss 3.601243734359741\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1366994380950928, Val_loss 3.616079330444336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1087021112442015, Val_loss 3.6695282459259033\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.120190739631653, Val_loss 3.73352313041687\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.080022168159485, Val_loss 3.625194549560547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.0839864730834963, Val_loss 3.618652582168579\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.096522903442383, Val_loss 3.576077461242676\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1383122205734253, Val_loss 3.7415931224823\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1220172166824343, Val_loss 3.7132914066314697\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.1436799287796022, Val_loss 3.5587146282196045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1117114782333375, Val_loss 3.509934425354004\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.116804838180542, Val_loss 3.5499818325042725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.1025392532348635, Val_loss 3.5477797985076904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.114444351196289, Val_loss 3.6317050457000732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.0739227294921876, Val_loss 3.547945022583008\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.0804902076721192, Val_loss 3.599620819091797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.0633817672729493, Val_loss 3.5736539363861084\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.103682518005371, Val_loss 3.6179189682006836\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.109504246711731, Val_loss 3.59057354927063\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.11379988193512, Val_loss 3.629682779312134\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 61, Train_Loss 3.125681972503662, Val_loss 3.5681800842285156\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0651811361312866, Val_loss 3.5839555263519287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.0807371854782106, Val_loss 3.629289388656616\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.075064015388489, Val_loss 3.627171516418457\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.0992391109466553, Val_loss 3.6470606327056885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.039577269554138, Val_loss 3.63166880607605\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.085537004470825, Val_loss 3.644110918045044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.119439458847046, Val_loss 3.6238696575164795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 69, Train_Loss 3.0824056386947634, Val_loss 3.6099326610565186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.0899353981018067, Val_loss 3.652480363845825\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.090279698371887, Val_loss 3.6329290866851807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.1063242673873903, Val_loss 3.6897172927856445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 73, Train_Loss 3.0671889543533326, Val_loss 3.6846110820770264\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 74, Train_Loss 3.122442030906677, Val_loss 3.691692352294922\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.081095051765442, Val_loss 3.679658889770508\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.097918915748596, Val_loss 3.6828269958496094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.1027669429779055, Val_loss 3.6669962406158447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.1086190700531007, Val_loss 3.667853355407715\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 79, Train_Loss 3.0930455923080444, Val_loss 3.6567583084106445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.0505751848220823, Val_loss 3.638341188430786\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.091012167930603, Val_loss 3.656609535217285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.096524167060852, Val_loss 3.649641990661621\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.088848280906677, Val_loss 3.637643814086914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.088476777076721, Val_loss 3.6388063430786133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.0993489742279055, Val_loss 3.6463613510131836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.051841688156128, Val_loss 3.6489484310150146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.07842276096344, Val_loss 3.661743402481079\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.095649576187134, Val_loss 3.6861114501953125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.039165997505188, Val_loss 3.645303726196289\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.0738911867141723, Val_loss 3.6510841846466064\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.071226620674133, Val_loss 3.645684003829956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.108133602142334, Val_loss 3.6551120281219482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.0738407373428345, Val_loss 3.65921950340271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 94, Train_Loss 3.102411460876465, Val_loss 3.686626434326172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.071145534515381, Val_loss 3.666362762451172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.0596216917037964, Val_loss 3.654752731323242\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.081360411643982, Val_loss 3.6648342609405518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.069152665138245, Val_loss 3.6662423610687256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.100876522064209, Val_loss 3.6680145263671875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.0866521120071413, Val_loss 3.663365602493286\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.9232189655303955, Val_loss 4.284103870391846\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.12045202255249, Val_loss 4.294010162353516\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.25\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.0534074068069454, Val_loss 4.2617878913879395\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.9241228103637695, Val_loss 4.243484973907471\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.8448875665664675, Val_loss 3.9996564388275146\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1562\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.7357587099075316, Val_loss 3.8693599700927734\n",
      "Train_acc_top_20 0.2437\tTrain_acc_top_30 0.3187\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.6792425870895387, Val_loss 3.7871816158294678\n",
      "Train_acc_top_20 0.5813\tTrain_acc_top_30 0.7875\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 8, Train_Loss 3.5931185722351073, Val_loss 3.745227575302124\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.537288999557495, Val_loss 3.805593729019165\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.5181057691574096, Val_loss 3.6739444732666016\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.4476156711578367, Val_loss 3.7228450775146484\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4278501510620116, Val_loss 3.738258123397827\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.406628942489624, Val_loss 3.744339942932129\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.373933124542236, Val_loss 3.7224626541137695\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 15, Train_Loss 3.3540432929992674, Val_loss 3.6969034671783447\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.302650284767151, Val_loss 3.6580069065093994\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.2691162824630737, Val_loss 3.636831045150757\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.250259590148926, Val_loss 3.647223711013794\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.222999596595764, Val_loss 3.697800397872925\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.224755573272705, Val_loss 3.6189324855804443\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2164985656738283, Val_loss 3.6755173206329346\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.2014208793640138, Val_loss 3.656081438064575\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 23, Train_Loss 3.2108825922012327, Val_loss 3.6656601428985596\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.21492223739624, Val_loss 3.655867338180542\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.18475923538208, Val_loss 3.645643472671509\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.161296582221985, Val_loss 3.67386531829834\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.245094633102417, Val_loss 3.7614240646362305\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 28, Train_Loss 3.1994158267974853, Val_loss 3.606945276260376\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.191370224952698, Val_loss 3.692174196243286\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1418869256973267, Val_loss 3.695721387863159\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1510666608810425, Val_loss 3.733835220336914\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 32, Train_Loss 3.1769695043563844, Val_loss 3.6023099422454834\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.177035188674927, Val_loss 3.72164249420166\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 34, Train_Loss 3.159269595146179, Val_loss 3.688951253890991\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.17485671043396, Val_loss 3.76031756401062\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.54\t\n",
      "Epoch 36, Train_Loss 3.1324645280838013, Val_loss 3.659541130065918\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.133125638961792, Val_loss 3.6158783435821533\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1434223890304565, Val_loss 3.6789557933807373\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.1770023107528687, Val_loss 3.737835645675659\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.147781777381897, Val_loss 3.618480682373047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.2072602987289427, Val_loss 3.7032129764556885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.14255428314209, Val_loss 3.7058534622192383\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1478554725646974, Val_loss 3.6552608013153076\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1260990142822265, Val_loss 3.7228925228118896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 45, Train_Loss 3.1068145751953127, Val_loss 3.599177598953247\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.148105788230896, Val_loss 3.638486623764038\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.0749058961868285, Val_loss 3.6367757320404053\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.125143313407898, Val_loss 3.683009147644043\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.136681890487671, Val_loss 3.6476564407348633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1277140617370605, Val_loss 3.638068914413452\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.087121510505676, Val_loss 3.625593423843384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.0811040878295897, Val_loss 3.6631031036376953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 53, Train_Loss 3.1177886009216307, Val_loss 3.670431137084961\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.0969589710235597, Val_loss 3.6390066146850586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.092567539215088, Val_loss 3.5978500843048096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1117900133132936, Val_loss 3.652621030807495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.168274974822998, Val_loss 3.6725027561187744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.1094174861907957, Val_loss 3.674546957015991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.132982110977173, Val_loss 3.5671370029449463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.0821630716323853, Val_loss 3.6168582439422607\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.0836695194244386, Val_loss 3.6603593826293945\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.1080618619918825, Val_loss 3.681278944015503\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.1189808368682863, Val_loss 3.69675612449646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.123424243927002, Val_loss 3.687835693359375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.0929587364196776, Val_loss 3.6547698974609375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.065134620666504, Val_loss 3.628981590270996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0663712501525877, Val_loss 3.7255780696868896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 68, Train_Loss 3.071787643432617, Val_loss 3.6601641178131104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.115218162536621, Val_loss 3.664661169052124\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.0943883895874023, Val_loss 3.694064140319824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 71, Train_Loss 3.1082574129104614, Val_loss 3.6899139881134033\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.0707387924194336, Val_loss 3.6733620166778564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 73, Train_Loss 3.066566324234009, Val_loss 3.6444203853607178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.1087210416793822, Val_loss 3.6515185832977295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.10328688621521, Val_loss 3.635378122329712\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.058216691017151, Val_loss 3.6807830333709717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.0644773721694945, Val_loss 3.653510332107544\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 78, Train_Loss 3.055385613441467, Val_loss 3.693072557449341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 79, Train_Loss 3.039131593704224, Val_loss 3.651829481124878\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.057016968727112, Val_loss 3.6423463821411133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 81, Train_Loss 3.0593213558197023, Val_loss 3.6472485065460205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 82, Train_Loss 3.0458009004592896, Val_loss 3.6843903064727783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.075760102272034, Val_loss 3.7125508785247803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.096914267539978, Val_loss 3.6441638469696045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.084066867828369, Val_loss 3.646089792251587\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.0633209943771362, Val_loss 3.677109479904175\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.0739670515060427, Val_loss 3.640150308609009\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 88, Train_Loss 3.0532126665115356, Val_loss 3.679326295852661\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 89, Train_Loss 3.081429648399353, Val_loss 3.6502466201782227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.1000784158706667, Val_loss 3.6746904850006104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.060387969017029, Val_loss 3.663742780685425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.0769768953323364, Val_loss 3.674785852432251\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.037771725654602, Val_loss 3.6617848873138428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.075559210777283, Val_loss 3.6877870559692383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.090015697479248, Val_loss 3.6552999019622803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 96, Train_Loss 3.072779083251953, Val_loss 3.6988277435302734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.1098973751068115, Val_loss 3.673306465148926\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.103970170021057, Val_loss 3.6734085083007812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.096603608131409, Val_loss 3.6458518505096436\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.0837950468063355, Val_loss 3.6426074504852295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9314571380615235, Val_loss 4.325234413146973\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.127281141281128, Val_loss 4.257734298706055\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.083116149902343, Val_loss 4.270731449127197\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9850189208984377, Val_loss 4.271432399749756\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.898316431045532, Val_loss 4.134011268615723\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.8085642099380492, Val_loss 3.7781851291656494\n",
      "Train_acc_top_20 0.3187\tTrain_acc_top_30 0.4125\tTrain_acc_top_40 0.5062\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 7, Train_Loss 3.729210138320923, Val_loss 3.853900909423828\n",
      "Train_acc_top_20 0.5875\tTrain_acc_top_30 0.725\tTrain_acc_top_40 0.8313\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 8, Train_Loss 3.6687925815582276, Val_loss 3.6206912994384766\n",
      "Train_acc_top_20 0.65\tTrain_acc_top_30 0.7688\tTrain_acc_top_40 0.8688\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.6282480478286745, Val_loss 3.5862467288970947\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.631453824043274, Val_loss 3.6506502628326416\n",
      "Train_acc_top_20 0.7188\tTrain_acc_top_30 0.8625\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.5397505283355715, Val_loss 3.58394455909729\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.494188737869263, Val_loss 3.591156244277954\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 13, Train_Loss 3.454303812980652, Val_loss 3.5130615234375\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 14, Train_Loss 3.4213844776153564, Val_loss 3.458915948867798\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.3819607496261597, Val_loss 3.486665964126587\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 16, Train_Loss 3.400966167449951, Val_loss 3.59250545501709\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.3453544855117796, Val_loss 3.5054399967193604\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.32665114402771, Val_loss 3.5010385513305664\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 19, Train_Loss 3.292982506752014, Val_loss 3.4585142135620117\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.270418906211853, Val_loss 3.4946796894073486\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 21, Train_Loss 3.261954593658447, Val_loss 3.5427331924438477\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 22, Train_Loss 3.2631990909576416, Val_loss 3.3970556259155273\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 23, Train_Loss 3.2554247856140135, Val_loss 3.608591318130493\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.2181273460388184, Val_loss 3.4538753032684326\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.199341583251953, Val_loss 3.466256856918335\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 26, Train_Loss 3.2219889879226686, Val_loss 3.5436418056488037\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.2725256443023683, Val_loss 3.6708803176879883\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 28, Train_Loss 3.3119427442550657, Val_loss 3.5642147064208984\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.8625\tTrain_acc_top_40 0.9125\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.301629066467285, Val_loss 3.518580436706543\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.241490697860718, Val_loss 3.4771745204925537\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.2182336330413817, Val_loss 3.450857162475586\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 32, Train_Loss 3.1950496435165405, Val_loss 3.4500551223754883\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.205867385864258, Val_loss 3.6042678356170654\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1791395425796507, Val_loss 3.4026143550872803\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.144625663757324, Val_loss 3.392580032348633\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 36, Train_Loss 3.1922014236450194, Val_loss 3.3924925327301025\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 37, Train_Loss 3.160651683807373, Val_loss 3.4074785709381104\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 38, Train_Loss 3.147969627380371, Val_loss 3.4198036193847656\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 39, Train_Loss 3.1867132425308227, Val_loss 3.3928310871124268\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.1788890838623045, Val_loss 3.4925010204315186\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 41, Train_Loss 3.179384136199951, Val_loss 3.481149435043335\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.134961795806885, Val_loss 3.3854684829711914\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.175116014480591, Val_loss 3.476360559463501\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.167015528678894, Val_loss 3.5415000915527344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.1452856063842773, Val_loss 3.4644415378570557\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.155202102661133, Val_loss 3.4641497135162354\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.1201873302459715, Val_loss 3.530395746231079\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1613474130630492, Val_loss 3.4564125537872314\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.1398102045059204, Val_loss 3.4536068439483643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.1621814489364626, Val_loss 3.4971277713775635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.150481700897217, Val_loss 3.4545841217041016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1287726879119875, Val_loss 3.4936885833740234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.186815643310547, Val_loss 3.507427215576172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.112338829040527, Val_loss 3.5414350032806396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.0839459180831907, Val_loss 3.4920406341552734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.176746702194214, Val_loss 3.473135232925415\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.0998833656311033, Val_loss 3.4457950592041016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.099245476722717, Val_loss 3.484447479248047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1106414556503297, Val_loss 3.504502296447754\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.0989142417907716, Val_loss 3.4651095867156982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.131924104690552, Val_loss 3.445307493209839\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.1488513708114625, Val_loss 3.4407989978790283\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.96\t\n",
      "Epoch 63, Train_Loss 3.151160216331482, Val_loss 3.4628183841705322\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.157251811027527, Val_loss 3.4995572566986084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.0868190050125124, Val_loss 3.5753934383392334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.093444299697876, Val_loss 3.505293130874634\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.1694032669067385, Val_loss 3.5058820247650146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.192792773246765, Val_loss 3.537935256958008\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.1061317205429075, Val_loss 3.583453416824341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 70, Train_Loss 3.19436936378479, Val_loss 3.4988701343536377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 71, Train_Loss 3.1108412742614746, Val_loss 3.5168421268463135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0882394075393678, Val_loss 3.501906156539917\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.1694496631622315, Val_loss 3.5120582580566406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.1300055980682373, Val_loss 3.5696146488189697\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.1271663427352907, Val_loss 3.481562852859497\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.047261357307434, Val_loss 3.503998041152954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.0814728498458863, Val_loss 3.5079309940338135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.1135645627975466, Val_loss 3.4951674938201904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.1551409006118774, Val_loss 3.5120689868927\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.0612317323684692, Val_loss 3.489454984664917\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 81, Train_Loss 3.1551000118255614, Val_loss 3.4967641830444336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 82, Train_Loss 3.103650951385498, Val_loss 3.4678165912628174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 83, Train_Loss 3.0623207569122313, Val_loss 3.4670305252075195\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.098342251777649, Val_loss 3.4777982234954834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 85, Train_Loss 3.055858874320984, Val_loss 3.478553533554077\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.0569517374038697, Val_loss 3.4744720458984375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.0726423978805544, Val_loss 3.468611478805542\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 88, Train_Loss 3.0749542236328127, Val_loss 3.468625783920288\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0385701656341553, Val_loss 3.49955677986145\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.084660458564758, Val_loss 3.517805337905884\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.1363792181015016, Val_loss 3.5091397762298584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.1047165632247924, Val_loss 3.453946828842163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.0490302801132203, Val_loss 3.4805803298950195\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.0709683418273928, Val_loss 3.4620020389556885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.03926305770874, Val_loss 3.461444616317749\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.1273532629013063, Val_loss 3.4933974742889404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.084218406677246, Val_loss 3.4940617084503174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.1120163440704345, Val_loss 3.4971001148223877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.1111655235290527, Val_loss 3.483973741531372\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 100, Train_Loss 3.0962337970733644, Val_loss 3.47748064994812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.9293046236038207, Val_loss 4.3014373779296875\n",
      "Train_acc_top_20 0.1562\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.128359317779541, Val_loss 4.232154846191406\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.081761121749878, Val_loss 4.2348856925964355\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.9723094940185546, Val_loss 4.160982131958008\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8601518154144285, Val_loss 3.9839296340942383\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.7838295459747315, Val_loss 3.891500234603882\n",
      "Train_acc_top_20 0.2437\tTrain_acc_top_30 0.3375\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.724724793434143, Val_loss 3.752568006515503\n",
      "Train_acc_top_20 0.525\tTrain_acc_top_30 0.725\tTrain_acc_top_40 0.7875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.6574187994003298, Val_loss 3.729262113571167\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.5859217405319215, Val_loss 3.7545177936553955\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.536315941810608, Val_loss 3.6578807830810547\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4770148754119874, Val_loss 3.6668128967285156\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.458077073097229, Val_loss 3.672342300415039\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 13, Train_Loss 3.409095287322998, Val_loss 3.70770525932312\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3869773149490356, Val_loss 3.628859281539917\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3384947776794434, Val_loss 3.6755330562591553\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.3303316116333006, Val_loss 3.6423985958099365\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.2862621307373048, Val_loss 3.647134780883789\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.3158414125442506, Val_loss 3.758258581161499\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 19, Train_Loss 3.304538679122925, Val_loss 3.68355393409729\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.3127570390701293, Val_loss 3.588512659072876\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.255016326904297, Val_loss 3.559586763381958\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2732481718063355, Val_loss 3.596842050552368\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 23, Train_Loss 3.271109461784363, Val_loss 3.709993362426758\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.206753158569336, Val_loss 3.597841262817383\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.193057990074158, Val_loss 3.6170904636383057\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.214931583404541, Val_loss 3.582324743270874\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.246476101875305, Val_loss 3.6230010986328125\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.179020047187805, Val_loss 3.5164949893951416\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.1861751794815065, Val_loss 3.701329231262207\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.5\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.206304502487183, Val_loss 3.5588865280151367\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 31, Train_Loss 3.1435739517211916, Val_loss 3.5396807193756104\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1577825784683227, Val_loss 3.565338134765625\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1685184478759765, Val_loss 3.586862325668335\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 34, Train_Loss 3.1670373916625976, Val_loss 3.6855525970458984\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1373470783233643, Val_loss 3.5164356231689453\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.135946440696716, Val_loss 3.6113908290863037\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1124186277389527, Val_loss 3.5284245014190674\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.128743529319763, Val_loss 3.622326612472534\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.1235300064086915, Val_loss 3.529850959777832\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1131625890731813, Val_loss 3.5644490718841553\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.055555534362793, Val_loss 3.574260711669922\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.058012104034424, Val_loss 3.556788206100464\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1203216314315796, Val_loss 3.4982900619506836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.0941333532333375, Val_loss 3.506669759750366\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1270200490951536, Val_loss 3.545755624771118\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.100606155395508, Val_loss 3.5673558712005615\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.1345160722732546, Val_loss 3.610957384109497\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1533212900161742, Val_loss 3.5774643421173096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1469202518463133, Val_loss 3.6122138500213623\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1317627668380736, Val_loss 3.55168080329895\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.093088245391846, Val_loss 3.494309663772583\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1441008329391478, Val_loss 3.571200132369995\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.051643633842468, Val_loss 3.5139524936676025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1487168073654175, Val_loss 3.583428382873535\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.0994063138961794, Val_loss 3.502347707748413\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.197227048873901, Val_loss 3.5303947925567627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.120265030860901, Val_loss 3.5828659534454346\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.140488886833191, Val_loss 3.522860288619995\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1239352464675902, Val_loss 3.5310490131378174\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.0734803438186646, Val_loss 3.5241363048553467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.122594141960144, Val_loss 3.559990882873535\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.098203706741333, Val_loss 3.5278313159942627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1312379598617555, Val_loss 3.556386709213257\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.1289968967437742, Val_loss 3.497729539871216\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.0649513244628905, Val_loss 3.5354435443878174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.038570189476013, Val_loss 3.5286624431610107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.118610143661499, Val_loss 3.534550428390503\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.0406821250915526, Val_loss 3.550102949142456\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.132131743431091, Val_loss 3.5006065368652344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.0920121669769287, Val_loss 3.526611566543579\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.0960330724716187, Val_loss 3.5130527019500732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.037641143798828, Val_loss 3.5025463104248047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0598629474639893, Val_loss 3.5331714153289795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.0463964462280275, Val_loss 3.507904291152954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0997233629226684, Val_loss 3.5078108310699463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.0089938640594482, Val_loss 3.5273630619049072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0377558708190917, Val_loss 3.5754566192626953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0507359981536863, Val_loss 3.5099847316741943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.055655860900879, Val_loss 3.5166218280792236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1396734952926635, Val_loss 3.5515849590301514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.090039014816284, Val_loss 3.5346763134002686\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.0878021717071533, Val_loss 3.5329742431640625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.0679033756256104, Val_loss 3.5260887145996094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0786377668380736, Val_loss 3.528244972229004\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0229056596755983, Val_loss 3.547377824783325\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0909419536590574, Val_loss 3.5264008045196533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.02491295337677, Val_loss 3.5220823287963867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.044978380203247, Val_loss 3.5286645889282227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.1219647884368897, Val_loss 3.5376577377319336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.055154275894165, Val_loss 3.521040678024292\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.062746691703796, Val_loss 3.5345420837402344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.060877561569214, Val_loss 3.503700017929077\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.1038767099380493, Val_loss 3.526026725769043\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0686181783676147, Val_loss 3.522322654724121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.0600375175476073, Val_loss 3.5056800842285156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0778869867324827, Val_loss 3.525102376937866\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.0917322397232057, Val_loss 3.5293729305267334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.1379729509353638, Val_loss 3.532803535461426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0292420387268066, Val_loss 3.518336057662964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.1355490922927856, Val_loss 3.5382728576660156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.925303554534912, Val_loss 4.320987224578857\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.38\t\n",
      "Epoch 2, Train_Loss 4.115470838546753, Val_loss 4.2310004234313965\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 3, Train_Loss 4.061852073669433, Val_loss 4.1695637702941895\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9277101278305055, Val_loss 4.073212146759033\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1688\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 5, Train_Loss 3.847927522659302, Val_loss 4.035901069641113\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.7546829700469972, Val_loss 3.7567644119262695\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.3563\tTrain_acc_top_40 0.4437\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 7, Train_Loss 3.694812774658203, Val_loss 3.537529230117798\n",
      "Train_acc_top_20 0.5188\tTrain_acc_top_30 0.7188\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 8, Train_Loss 3.6368000507354736, Val_loss 3.507997512817383\n",
      "Train_acc_top_20 0.7188\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5693775415420532, Val_loss 3.6790711879730225\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.52705295085907, Val_loss 3.4794137477874756\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.494931387901306, Val_loss 3.4241116046905518\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.438152003288269, Val_loss 3.575002908706665\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4271156787872314, Val_loss 3.438878297805786\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3868741273880003, Val_loss 3.501660108566284\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.354765796661377, Val_loss 3.4548208713531494\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.3361316680908204, Val_loss 3.4863293170928955\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.32984938621521, Val_loss 3.4757559299468994\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.295489048957825, Val_loss 3.50234317779541\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2963778972625732, Val_loss 3.6432077884674072\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.269357752799988, Val_loss 3.4461429119110107\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2224053859710695, Val_loss 3.4645936489105225\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.223337244987488, Val_loss 3.4201478958129883\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 23, Train_Loss 3.1964505910873413, Val_loss 3.418170690536499\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.1937402963638304, Val_loss 3.6085214614868164\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.205657482147217, Val_loss 3.462272882461548\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 26, Train_Loss 3.16293523311615, Val_loss 3.4732322692871094\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.209711694717407, Val_loss 3.50598406791687\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.162496781349182, Val_loss 3.5038506984710693\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.175368547439575, Val_loss 3.624621629714966\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.1573044776916506, Val_loss 3.615633964538574\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.126108717918396, Val_loss 3.472432851791382\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1916669368743897, Val_loss 3.696681022644043\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.1393030166625975, Val_loss 3.5526678562164307\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.167624807357788, Val_loss 3.440519332885742\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.2360262155532835, Val_loss 3.6385042667388916\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.2364140510559083, Val_loss 3.57144832611084\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.15888307094574, Val_loss 3.5318610668182373\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1158015012741087, Val_loss 3.5392682552337646\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1859862327575685, Val_loss 3.5631864070892334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.130963945388794, Val_loss 3.550062894821167\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.163484072685242, Val_loss 3.4903995990753174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.2147061347961428, Val_loss 3.5448577404022217\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1192646980285645, Val_loss 3.4758100509643555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.0884579181671143, Val_loss 3.503894567489624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.0779828786849976, Val_loss 3.4602229595184326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1468565225601197, Val_loss 3.4769773483276367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.0781967401504517, Val_loss 3.4484407901763916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.129790925979614, Val_loss 3.534458875656128\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1592392444610597, Val_loss 3.490149736404419\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1697097063064574, Val_loss 3.6695711612701416\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1239844083786013, Val_loss 3.5301456451416016\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 52, Train_Loss 3.1377997159957887, Val_loss 3.4617269039154053\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.0526315450668333, Val_loss 3.470181703567505\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.051856827735901, Val_loss 3.4313437938690186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.1078682422637938, Val_loss 3.4499318599700928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.0741235971450807, Val_loss 3.567730665206909\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.097005295753479, Val_loss 3.6769959926605225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 58, Train_Loss 3.087151598930359, Val_loss 3.5393028259277344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.131568741798401, Val_loss 3.410723924636841\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.10955126285553, Val_loss 3.4895713329315186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.1511637926101685, Val_loss 3.4685885906219482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.1419615030288695, Val_loss 3.5489284992218018\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.105143642425537, Val_loss 3.409851312637329\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0776927947998045, Val_loss 3.432058572769165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0884890079498293, Val_loss 3.48568058013916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.0485281229019163, Val_loss 3.5143356323242188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.0467214822769164, Val_loss 3.4669113159179688\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.0528985977172853, Val_loss 3.4036123752593994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.0322957038879395, Val_loss 3.4761555194854736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1165459871292116, Val_loss 3.443693161010742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.044713759422302, Val_loss 3.5501387119293213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.06983745098114, Val_loss 3.4832260608673096\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.1068469524383544, Val_loss 3.458817720413208\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.033246660232544, Val_loss 3.415372133255005\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.084915208816528, Val_loss 3.3998219966888428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.08394718170166, Val_loss 3.4093315601348877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.068137836456299, Val_loss 3.406125783920288\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.0484193086624147, Val_loss 3.463738441467285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.0708412647247316, Val_loss 3.4765493869781494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.109913206100464, Val_loss 3.446546792984009\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0265876770019533, Val_loss 3.470519781112671\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.076925849914551, Val_loss 3.487410545349121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.064797115325928, Val_loss 3.4592926502227783\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0693255186080934, Val_loss 3.464611053466797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.0085658550262453, Val_loss 3.4268314838409424\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0635330438613892, Val_loss 3.479739189147949\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0842665433883667, Val_loss 3.4303815364837646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.109675478935242, Val_loss 3.458500623703003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.037366437911987, Val_loss 3.421017646789551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.0685674428939818, Val_loss 3.416454315185547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.1156855821609497, Val_loss 3.3938732147216797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.079709053039551, Val_loss 3.4372756481170654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.1019848823547362, Val_loss 3.4518630504608154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.085888385772705, Val_loss 3.4548425674438477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.101596999168396, Val_loss 3.4530928134918213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.077339196205139, Val_loss 3.4581801891326904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.0646095752716063, Val_loss 3.4624252319335938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.087241840362549, Val_loss 3.4565210342407227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.0771801710128783, Val_loss 3.4835894107818604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.079836058616638, Val_loss 3.498067617416382\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9284964561462403, Val_loss 4.280447483062744\n",
      "Train_acc_top_20 0.0688\tTrain_acc_top_30 0.1062\tTrain_acc_top_40 0.15\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.1201406955719, Val_loss 4.302735805511475\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.043325686454773, Val_loss 4.379444599151611\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.948289895057678, Val_loss 4.326673984527588\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 5, Train_Loss 3.826230549812317, Val_loss 4.010871410369873\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.2188\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.724741530418396, Val_loss 3.8177196979522705\n",
      "Train_acc_top_20 0.25\tTrain_acc_top_30 0.4188\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.708171820640564, Val_loss 3.7603189945220947\n",
      "Train_acc_top_20 0.5062\tTrain_acc_top_30 0.6562\tTrain_acc_top_40 0.7063\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6289066791534426, Val_loss 3.6986656188964844\n",
      "Train_acc_top_20 0.6875\tTrain_acc_top_30 0.8187\tTrain_acc_top_40 0.8688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 9, Train_Loss 3.5798002004623415, Val_loss 3.6272404193878174\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.541500449180603, Val_loss 3.6128692626953125\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4914083003997805, Val_loss 3.604682683944702\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.4536100387573243, Val_loss 3.5700690746307373\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4133103609085085, Val_loss 3.5878448486328125\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3847755193710327, Val_loss 3.538088798522949\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.3571019649505613, Val_loss 3.503344774246216\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.3360804319381714, Val_loss 3.5432584285736084\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.320433807373047, Val_loss 3.5449209213256836\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.96\t\n",
      "Epoch 18, Train_Loss 3.304759311676025, Val_loss 3.54789662361145\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.246133732795715, Val_loss 3.489150047302246\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.260720229148865, Val_loss 3.616758108139038\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.2295198678970336, Val_loss 3.4868717193603516\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2200185537338255, Val_loss 3.4812119007110596\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2431951761245728, Val_loss 3.486677885055542\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 24, Train_Loss 3.2388602256774903, Val_loss 3.4575746059417725\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.206967997550964, Val_loss 3.506843328475952\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.1872201204299926, Val_loss 3.5061185359954834\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.2001679658889772, Val_loss 3.495405912399292\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.195868730545044, Val_loss 3.5464887619018555\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.204480791091919, Val_loss 3.4468777179718018\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.191005730628967, Val_loss 3.4979076385498047\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1561443567276, Val_loss 3.5145528316497803\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1797512054443358, Val_loss 3.6753368377685547\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.123074984550476, Val_loss 3.477670669555664\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.157368803024292, Val_loss 3.4565722942352295\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1206634283065795, Val_loss 3.4432296752929688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1599303245544434, Val_loss 3.492687225341797\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.1565095663070677, Val_loss 3.463912010192871\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.135864734649658, Val_loss 3.4874236583709717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1434341192245485, Val_loss 3.7180986404418945\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.1642033100128173, Val_loss 3.488116502761841\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.148197555541992, Val_loss 3.4263174533843994\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.1223270893096924, Val_loss 3.491244316101074\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.136123299598694, Val_loss 3.4514284133911133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.1461081743240356, Val_loss 3.48193621635437\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.187285614013672, Val_loss 3.4701201915740967\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.132252550125122, Val_loss 3.511261224746704\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1048246145248415, Val_loss 3.493878126144409\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1350197792053223, Val_loss 3.5350377559661865\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.089251923561096, Val_loss 3.4384024143218994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.124894213676453, Val_loss 3.432856559753418\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.108095574378967, Val_loss 3.4535036087036133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.0830338478088377, Val_loss 3.4607231616973877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.131006097793579, Val_loss 3.481370210647583\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.113313817977905, Val_loss 3.4637279510498047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.097179102897644, Val_loss 3.452824354171753\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1114933252334596, Val_loss 3.4869558811187744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1262032985687256, Val_loss 3.4186818599700928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.066450095176697, Val_loss 3.4573423862457275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.1151729583740235, Val_loss 3.4387245178222656\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1044750690460203, Val_loss 3.4713351726531982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1492547512054445, Val_loss 3.4663913249969482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.125932288169861, Val_loss 3.4346230030059814\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.1238765001296995, Val_loss 3.453137159347534\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.1245806217193604, Val_loss 3.451214551925659\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.125137948989868, Val_loss 3.472667694091797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.108956050872803, Val_loss 3.486943006515503\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.1013760328292848, Val_loss 3.3702218532562256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.052715039253235, Val_loss 3.4091007709503174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 69, Train_Loss 3.0681736946105955, Val_loss 3.4319350719451904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 70, Train_Loss 3.0698930740356447, Val_loss 3.4323463439941406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.119432497024536, Val_loss 3.4865987300872803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.0944844007492067, Val_loss 3.4371137619018555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.077775716781616, Val_loss 3.4708499908447266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.112002992630005, Val_loss 3.472107172012329\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.071624684333801, Val_loss 3.4603893756866455\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.0943499326705934, Val_loss 3.4764444828033447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.1111218690872193, Val_loss 3.4738504886627197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.054357814788818, Val_loss 3.4203941822052\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.1041126012802125, Val_loss 3.45703387260437\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.0666675329208375, Val_loss 3.4623258113861084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.069810485839844, Val_loss 3.462841749191284\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.1339282274246214, Val_loss 3.4749581813812256\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.0885130882263185, Val_loss 3.441415548324585\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.1167959690093996, Val_loss 3.460675001144409\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.0822829246520995, Val_loss 3.4367611408233643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.08008930683136, Val_loss 3.439680337905884\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.0529074668884277, Val_loss 3.413148880004883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.101073718070984, Val_loss 3.477341413497925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0717459201812742, Val_loss 3.425105094909668\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0494673013687135, Val_loss 3.4191322326660156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.108981227874756, Val_loss 3.4628992080688477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.078513669967651, Val_loss 3.444147825241089\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.075799489021301, Val_loss 3.408535957336426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.0913921356201173, Val_loss 3.4608242511749268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.0792999267578125, Val_loss 3.458282470703125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.0775835275650025, Val_loss 3.4502639770507812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.08617787361145, Val_loss 3.4440574645996094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.0714948177337646, Val_loss 3.403057336807251\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.0610619306564333, Val_loss 3.526867628097534\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.0577356815338135, Val_loss 3.416543960571289\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9296552419662474, Val_loss 4.319060325622559\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.123934698104859, Val_loss 4.261092662811279\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.065071558952331, Val_loss 4.2246880531311035\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.935473418235779, Val_loss 4.1704792976379395\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.85049307346344, Val_loss 4.011039733886719\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7538915157318113, Val_loss 3.827428102493286\n",
      "Train_acc_top_20 0.2125\tTrain_acc_top_30 0.3625\tTrain_acc_top_40 0.425\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.33\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.69616539478302, Val_loss 3.8255081176757812\n",
      "Train_acc_top_20 0.475\tTrain_acc_top_30 0.675\tTrain_acc_top_40 0.7438\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.42\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.619239616394043, Val_loss 3.679250478744507\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8625\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.578136706352234, Val_loss 3.7461376190185547\n",
      "Train_acc_top_20 0.6813\tTrain_acc_top_30 0.825\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 10, Train_Loss 3.5557854890823366, Val_loss 3.654276132583618\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.5083160638809203, Val_loss 3.748258590698242\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 12, Train_Loss 3.4404616355895996, Val_loss 3.65338397026062\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.4297200441360474, Val_loss 3.734069585800171\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.4012120723724366, Val_loss 3.6792335510253906\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 15, Train_Loss 3.361066222190857, Val_loss 3.7017810344696045\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3464537143707274, Val_loss 3.5842628479003906\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.357812237739563, Val_loss 3.548877716064453\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.342017102241516, Val_loss 3.6188735961914062\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.2953155040740967, Val_loss 3.6510918140411377\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2984046459198, Val_loss 3.6736650466918945\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.284099650382996, Val_loss 3.4998466968536377\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.2438459634780883, Val_loss 3.48819899559021\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2188419342041015, Val_loss 3.495985269546509\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.2002674341201782, Val_loss 3.485999345779419\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.200959873199463, Val_loss 3.4506731033325195\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.182425379753113, Val_loss 3.5862691402435303\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.1892632722854612, Val_loss 3.471170425415039\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1881214141845704, Val_loss 3.588189125061035\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1458315372467043, Val_loss 3.4959304332733154\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.1418394327163695, Val_loss 3.50046443939209\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.142089772224426, Val_loss 3.518460512161255\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.1485357522964477, Val_loss 3.4731056690216064\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 33, Train_Loss 3.174266886711121, Val_loss 3.5538203716278076\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.199122977256775, Val_loss 3.4885313510894775\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.1616532802581787, Val_loss 3.522097587585449\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1436776399612425, Val_loss 3.4524614810943604\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 37, Train_Loss 3.1713924407958984, Val_loss 3.52960467338562\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1285210847854614, Val_loss 3.483036756515503\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.2080156803131104, Val_loss 3.5757205486297607\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1915690183639525, Val_loss 3.4219372272491455\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.157516074180603, Val_loss 3.4344215393066406\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 42, Train_Loss 3.168414664268494, Val_loss 3.464276075363159\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.1229953527450562, Val_loss 3.492312431335449\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.093482565879822, Val_loss 3.449388265609741\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.133878469467163, Val_loss 3.4371449947357178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.0838767290115356, Val_loss 3.4332478046417236\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 47, Train_Loss 3.096176552772522, Val_loss 3.4630651473999023\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.109530448913574, Val_loss 3.5130434036254883\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.0661566972732546, Val_loss 3.425067901611328\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 50, Train_Loss 3.1009222269058228, Val_loss 3.4478657245635986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1083407640457152, Val_loss 3.6114275455474854\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.1737595081329344, Val_loss 3.496082067489624\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1838698863983153, Val_loss 3.44736385345459\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 54, Train_Loss 3.1109333753585817, Val_loss 3.569554090499878\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.0825069665908815, Val_loss 3.448746681213379\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.0580040216445923, Val_loss 3.4571712017059326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1074889659881593, Val_loss 3.4758403301239014\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 58, Train_Loss 3.1618977546691895, Val_loss 3.5828449726104736\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.180493927001953, Val_loss 3.506842851638794\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.1270362377166747, Val_loss 3.465862274169922\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.1198102712631224, Val_loss 3.463038206100464\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.154029440879822, Val_loss 3.4723784923553467\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.109298920631409, Val_loss 3.5089473724365234\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.1225028038024902, Val_loss 3.489914655685425\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0949593782424927, Val_loss 3.4577934741973877\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.116640496253967, Val_loss 3.4064481258392334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.069852352142334, Val_loss 3.5189802646636963\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.0700447797775268, Val_loss 3.4570515155792236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0663708686828612, Val_loss 3.5329630374908447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.0584776163101197, Val_loss 3.4828717708587646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.065284013748169, Val_loss 3.4667246341705322\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0574535608291624, Val_loss 3.468716621398926\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.0662620306015014, Val_loss 3.4359970092773438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.031220722198486, Val_loss 3.42254900932312\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.042432117462158, Val_loss 3.4033043384552\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.118681812286377, Val_loss 3.4182586669921875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.0776945829391478, Val_loss 3.443340539932251\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.1111129999160765, Val_loss 3.4591901302337646\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.106757974624634, Val_loss 3.4693682193756104\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.1205682277679445, Val_loss 3.415099859237671\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.0518100261688232, Val_loss 3.4137094020843506\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.120898222923279, Val_loss 3.491753578186035\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.1366039752960204, Val_loss 3.4987237453460693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.1247753381729124, Val_loss 3.463299036026001\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.0664980888366697, Val_loss 3.45251202583313\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.090338039398193, Val_loss 3.4931862354278564\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0868632078170775, Val_loss 3.487985372543335\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.1176612615585326, Val_loss 3.4532692432403564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.1161258935928347, Val_loss 3.477527618408203\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.132698392868042, Val_loss 3.4764835834503174\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.057280254364014, Val_loss 3.4290647506713867\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.0464398860931396, Val_loss 3.4037466049194336\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.028321385383606, Val_loss 3.4115991592407227\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.041375207901001, Val_loss 3.417374849319458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.1077972412109376, Val_loss 3.4564247131347656\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.0667377948760985, Val_loss 3.472015619277954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.0973145961761475, Val_loss 3.417633056640625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.0730494022369386, Val_loss 3.436058282852173\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.1202860116958617, Val_loss 3.419950246810913\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.0625100135803223, Val_loss 3.422254800796509\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.932442307472229, Val_loss 4.265352725982666\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.121071434020996, Val_loss 4.2064595222473145\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.085177040100097, Val_loss 4.211917400360107\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 4, Train_Loss 3.985403847694397, Val_loss 4.183695316314697\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8601927518844605, Val_loss 4.099245548248291\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.7687655687332153, Val_loss 3.918367385864258\n",
      "Train_acc_top_20 0.2125\tTrain_acc_top_30 0.2875\tTrain_acc_top_40 0.3625\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.38\tVal_acc_top_40 0.58\t\n",
      "Epoch 7, Train_Loss 3.6867281913757326, Val_loss 3.8718278408050537\n",
      "Train_acc_top_20 0.5\tTrain_acc_top_30 0.675\tTrain_acc_top_40 0.7625\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.601087951660156, Val_loss 3.8141777515411377\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 9, Train_Loss 3.545239782333374, Val_loss 3.7817142009735107\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.5\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.508018970489502, Val_loss 3.7582828998565674\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.4847435474395754, Val_loss 3.727597236633301\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.426818919181824, Val_loss 3.7873971462249756\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.4069979906082155, Val_loss 3.6944591999053955\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3683198928833007, Val_loss 3.802971124649048\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 15, Train_Loss 3.3347697973251345, Val_loss 3.6275634765625\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.322930431365967, Val_loss 3.7426607608795166\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 17, Train_Loss 3.3534929275512697, Val_loss 3.590627670288086\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.3138433694839478, Val_loss 3.590683937072754\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.272015690803528, Val_loss 3.5913619995117188\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2260049104690554, Val_loss 3.5867421627044678\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.2580333948135376, Val_loss 3.5450479984283447\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.215851593017578, Val_loss 3.533048391342163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.1942194223403932, Val_loss 3.6224935054779053\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.1849767923355103, Val_loss 3.5323193073272705\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.1946135997772216, Val_loss 3.6149911880493164\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.1598731517791747, Val_loss 3.5944712162017822\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.1411689281463624, Val_loss 3.5509564876556396\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1735683917999267, Val_loss 3.53761887550354\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.160581040382385, Val_loss 3.522998094558716\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.174439477920532, Val_loss 3.646371603012085\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.238792896270752, Val_loss 3.4770262241363525\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.187586188316345, Val_loss 3.533949136734009\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1710230112075806, Val_loss 3.5765035152435303\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.130940318107605, Val_loss 3.5472323894500732\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1567249298095703, Val_loss 3.5331220626831055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.15356650352478, Val_loss 3.4561288356781006\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 37, Train_Loss 3.1844217777252197, Val_loss 3.5073111057281494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1450335025787353, Val_loss 3.4710276126861572\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.113834500312805, Val_loss 3.5237998962402344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.12207977771759, Val_loss 3.4923388957977295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.1298145055770874, Val_loss 3.4922196865081787\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.14509437084198, Val_loss 3.4934113025665283\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1415596485137938, Val_loss 3.5099523067474365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.116428089141846, Val_loss 3.4784247875213623\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1388653755187987, Val_loss 3.4664275646209717\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.139208269119263, Val_loss 3.5010392665863037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.152508044242859, Val_loss 3.530705690383911\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.1177344799041746, Val_loss 3.4928390979766846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.080992579460144, Val_loss 3.5476627349853516\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1162402391433717, Val_loss 3.4984405040740967\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 51, Train_Loss 3.1100231647491454, Val_loss 3.5376150608062744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.1210377693176268, Val_loss 3.582690954208374\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.1709742546081543, Val_loss 3.5113656520843506\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.126846957206726, Val_loss 3.4459073543548584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1381722927093505, Val_loss 3.489847421646118\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.095913290977478, Val_loss 3.518744468688965\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1299147844314574, Val_loss 3.4908857345581055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 58, Train_Loss 3.0842753410339356, Val_loss 3.5200130939483643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.1093268632888793, Val_loss 3.4784276485443115\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.0970558166503905, Val_loss 3.476198434829712\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.092026686668396, Val_loss 3.4374873638153076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.1075679302215575, Val_loss 3.4700138568878174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.0991336584091185, Val_loss 3.5282142162323\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.1131901025772093, Val_loss 3.484990119934082\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0968761920928953, Val_loss 3.5161263942718506\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.142179012298584, Val_loss 3.5624172687530518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.122290563583374, Val_loss 3.5617332458496094\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.0903624057769776, Val_loss 3.4837148189544678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0802536249160766, Val_loss 3.472234010696411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.0666629314422607, Val_loss 3.4795782566070557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.077153944969177, Val_loss 3.51706600189209\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0895882129669188, Val_loss 3.4925925731658936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0883663654327393, Val_loss 3.503697156906128\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.1175130128860475, Val_loss 3.472264051437378\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.100652575492859, Val_loss 3.4866368770599365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.0615513801574705, Val_loss 3.477151870727539\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.084736371040344, Val_loss 3.493544340133667\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.076695775985718, Val_loss 3.4691314697265625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.0814706087112427, Val_loss 3.487025260925293\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.0590131998062136, Val_loss 3.4584763050079346\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.0631341695785523, Val_loss 3.456357717514038\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0919703006744386, Val_loss 3.4899816513061523\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0633360147476196, Val_loss 3.4855430126190186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.048226308822632, Val_loss 3.481086015701294\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0678441524505615, Val_loss 3.4747562408447266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0638055562973023, Val_loss 3.4699926376342773\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0512801885604857, Val_loss 3.4749953746795654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.1253666400909426, Val_loss 3.500089645385742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0867025375366213, Val_loss 3.5145931243896484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0950658082962037, Val_loss 3.4919145107269287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.0956361293792725, Val_loss 3.5046443939208984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0768173694610597, Val_loss 3.4984636306762695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.0507036209106446, Val_loss 3.4730350971221924\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.0726779222488405, Val_loss 3.4837636947631836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0777133464813233, Val_loss 3.461883544921875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.060132646560669, Val_loss 3.4572770595550537\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.048493504524231, Val_loss 3.475478410720825\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0616601943969726, Val_loss 3.491368293762207\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.0739220142364503, Val_loss 3.4882802963256836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0744077444076536, Val_loss 3.466080904006958\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.9317193031311035, Val_loss 4.31210470199585\n",
      "Train_acc_top_20 0.1625\tTrain_acc_top_30 0.225\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.08\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.131602334976196, Val_loss 4.2629170417785645\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.078279495239258, Val_loss 4.263838291168213\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.9778596639633177, Val_loss 4.2085700035095215\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.878455948829651, Val_loss 4.051043510437012\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.8060197114944456, Val_loss 3.890369415283203\n",
      "Train_acc_top_20 0.3\tTrain_acc_top_30 0.4188\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.46\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.7054779529571533, Val_loss 3.890042304992676\n",
      "Train_acc_top_20 0.6188\tTrain_acc_top_30 0.7688\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6471812248229982, Val_loss 3.7702667713165283\n",
      "Train_acc_top_20 0.7188\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5809362649917604, Val_loss 3.755875825881958\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.52224338054657, Val_loss 3.7909774780273438\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 11, Train_Loss 3.4672041177749633, Val_loss 3.696765184402466\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 12, Train_Loss 3.4407806158065797, Val_loss 3.69177508354187\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.417971301078796, Val_loss 3.7076005935668945\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.376354217529297, Val_loss 3.6641464233398438\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.345184016227722, Val_loss 3.721604108810425\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.33285448551178, Val_loss 3.6841812133789062\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.331917428970337, Val_loss 3.6564667224884033\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.277285170555115, Val_loss 3.6841204166412354\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.26323664188385, Val_loss 3.6878254413604736\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.255620837211609, Val_loss 3.649613618850708\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.231688451766968, Val_loss 3.625103712081909\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.2090497732162477, Val_loss 3.610252618789673\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 23, Train_Loss 3.208763337135315, Val_loss 3.6511669158935547\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 24, Train_Loss 3.2515610694885253, Val_loss 3.703181028366089\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2216723442077635, Val_loss 3.629028558731079\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.2059360265731813, Val_loss 3.6573712825775146\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.2051400661468508, Val_loss 3.6571457386016846\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1731612920761108, Val_loss 3.5885097980499268\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 29, Train_Loss 3.172315979003906, Val_loss 3.648583173751831\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.171076798439026, Val_loss 3.5578529834747314\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.1350661516189575, Val_loss 3.5747270584106445\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.1844289779663084, Val_loss 3.630286931991577\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.150334191322327, Val_loss 3.6435794830322266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.1252000093460084, Val_loss 3.572955369949341\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 35, Train_Loss 3.1224306344985964, Val_loss 3.627756357192993\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.136376738548279, Val_loss 3.6710879802703857\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.1393227100372316, Val_loss 3.647588014602661\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.1604244470596314, Val_loss 3.6602096557617188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.1147294521331785, Val_loss 3.683476686477661\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.1434083700180055, Val_loss 3.64316463470459\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1011928796768187, Val_loss 3.6353511810302734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 42, Train_Loss 3.1037493705749513, Val_loss 3.6140549182891846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1325818061828614, Val_loss 3.621762990951538\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.11235191822052, Val_loss 3.643813133239746\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.103283643722534, Val_loss 3.6958329677581787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 46, Train_Loss 3.152052617073059, Val_loss 3.71331524848938\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 47, Train_Loss 3.1068875312805178, Val_loss 3.644033670425415\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 48, Train_Loss 3.123781108856201, Val_loss 3.7110602855682373\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.0732993364334105, Val_loss 3.6419761180877686\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.064383363723755, Val_loss 3.655750036239624\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.068453145027161, Val_loss 3.6661417484283447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 52, Train_Loss 3.072809338569641, Val_loss 3.653150796890259\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 53, Train_Loss 3.060973596572876, Val_loss 3.5690901279449463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.0659114599227903, Val_loss 3.6215121746063232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 55, Train_Loss 3.085808038711548, Val_loss 3.5752532482147217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1049991607666017, Val_loss 3.7033958435058594\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 57, Train_Loss 3.0729000568389893, Val_loss 3.6814944744110107\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 58, Train_Loss 3.0744192600250244, Val_loss 3.66255784034729\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.065561890602112, Val_loss 3.6532328128814697\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 60, Train_Loss 3.0356973886489866, Val_loss 3.687455892562866\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 61, Train_Loss 3.041380000114441, Val_loss 3.6742849349975586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 62, Train_Loss 3.095137333869934, Val_loss 3.6454436779022217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.1249327182769777, Val_loss 3.638212203979492\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.059513473510742, Val_loss 3.6330385208129883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 65, Train_Loss 3.093600559234619, Val_loss 3.6377875804901123\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.0623427867889403, Val_loss 3.69549298286438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 67, Train_Loss 3.055116629600525, Val_loss 3.696950674057007\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 68, Train_Loss 3.1028146266937258, Val_loss 3.6460187435150146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 69, Train_Loss 3.0992432594299317, Val_loss 3.592209577560425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.0837352514266967, Val_loss 3.6206741333007812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 71, Train_Loss 3.097268056869507, Val_loss 3.66137957572937\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 72, Train_Loss 3.035813069343567, Val_loss 3.7141847610473633\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.089317035675049, Val_loss 3.7510197162628174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 74, Train_Loss 3.080112409591675, Val_loss 3.668977975845337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 75, Train_Loss 3.074717378616333, Val_loss 3.6326816082000732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 76, Train_Loss 3.06145761013031, Val_loss 3.6402034759521484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.0380115509033203, Val_loss 3.6407458782196045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 78, Train_Loss 3.0641807317733765, Val_loss 3.6744515895843506\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 79, Train_Loss 3.1117369890213014, Val_loss 3.667792320251465\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 80, Train_Loss 3.053566646575928, Val_loss 3.6367757320404053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 81, Train_Loss 3.084691548347473, Val_loss 3.6448776721954346\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 82, Train_Loss 3.0249688386917115, Val_loss 3.609518051147461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 83, Train_Loss 3.043810796737671, Val_loss 3.645867109298706\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 84, Train_Loss 3.059259557723999, Val_loss 3.636233329772949\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 85, Train_Loss 3.029216837882996, Val_loss 3.6206884384155273\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 86, Train_Loss 3.0538074254989622, Val_loss 3.6575934886932373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 87, Train_Loss 3.1009074211120606, Val_loss 3.6375083923339844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 88, Train_Loss 3.0471516609191895, Val_loss 3.6622984409332275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 89, Train_Loss 3.0557356119155883, Val_loss 3.6507718563079834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 90, Train_Loss 3.052036476135254, Val_loss 3.656886339187622\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 91, Train_Loss 3.077106785774231, Val_loss 3.6708428859710693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 92, Train_Loss 3.030813479423523, Val_loss 3.6536123752593994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 93, Train_Loss 3.0417631387710573, Val_loss 3.6491539478302\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 94, Train_Loss 3.031064176559448, Val_loss 3.660602569580078\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 95, Train_Loss 3.0076571226119997, Val_loss 3.6479570865631104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 96, Train_Loss 3.072108030319214, Val_loss 3.6416375637054443\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 97, Train_Loss 3.0952372312545777, Val_loss 3.644623041152954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 98, Train_Loss 3.086246943473816, Val_loss 3.653538703918457\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 99, Train_Loss 3.0690922260284426, Val_loss 3.624943494796753\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 100, Train_Loss 3.114866828918457, Val_loss 3.6720526218414307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 1, Train_Loss 3.9249430894851685, Val_loss 4.335537433624268\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.2125\tTrain_acc_top_40 0.25\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.114249897003174, Val_loss 4.3446879386901855\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.052387309074402, Val_loss 4.291629314422607\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.912539172172546, Val_loss 4.28141450881958\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.838250970840454, Val_loss 4.179240703582764\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 6, Train_Loss 3.7471854448318482, Val_loss 3.9032363891601562\n",
      "Train_acc_top_20 0.2188\tTrain_acc_top_30 0.3125\tTrain_acc_top_40 0.3812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.6632070302963258, Val_loss 3.6088016033172607\n",
      "Train_acc_top_20 0.5312\tTrain_acc_top_30 0.7438\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 8, Train_Loss 3.5853538274765016, Val_loss 3.6411378383636475\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.555047035217285, Val_loss 3.4811995029449463\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.4953023195266724, Val_loss 3.552334785461426\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 11, Train_Loss 3.460489106178284, Val_loss 3.4539995193481445\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 12, Train_Loss 3.450596022605896, Val_loss 3.4079182147979736\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.92\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 13, Train_Loss 3.4182714939117433, Val_loss 3.470926523208618\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 14, Train_Loss 3.403399395942688, Val_loss 3.4426262378692627\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 15, Train_Loss 3.3457102537155152, Val_loss 3.5795395374298096\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.2859050273895263, Val_loss 3.4363861083984375\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 17, Train_Loss 3.2806894302368166, Val_loss 3.4949772357940674\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 18, Train_Loss 3.247531270980835, Val_loss 3.472381591796875\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 19, Train_Loss 3.2296486139297484, Val_loss 3.513913154602051\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 20, Train_Loss 3.2894084453582764, Val_loss 3.596329689025879\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.3025155782699587, Val_loss 3.5850532054901123\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.2542688131332396, Val_loss 3.4933435916900635\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 23, Train_Loss 3.2309423685073853, Val_loss 3.4161417484283447\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 24, Train_Loss 3.200499439239502, Val_loss 3.466447114944458\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 25, Train_Loss 3.2274027824401856, Val_loss 3.6268131732940674\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.1875763893127442, Val_loss 3.4148292541503906\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 27, Train_Loss 3.1563272714614867, Val_loss 3.4174773693084717\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 28, Train_Loss 3.1642818689346313, Val_loss 3.466045379638672\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 29, Train_Loss 3.145027422904968, Val_loss 3.4543330669403076\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 30, Train_Loss 3.1226720809936523, Val_loss 3.461109161376953\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 31, Train_Loss 3.152109169960022, Val_loss 3.422250747680664\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 32, Train_Loss 3.145392370223999, Val_loss 3.363467216491699\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.96\tVal_acc_top_40 1.0\t\n",
      "Epoch 33, Train_Loss 3.162159967422485, Val_loss 3.3824615478515625\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.1251742839813232, Val_loss 3.419062376022339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.1416104316711424, Val_loss 3.4153025150299072\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.1269328355789185, Val_loss 3.452066659927368\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 37, Train_Loss 3.129176688194275, Val_loss 3.363023519515991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 38, Train_Loss 3.1685901880264282, Val_loss 3.3819258213043213\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 39, Train_Loss 3.130265974998474, Val_loss 3.4890358448028564\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 40, Train_Loss 3.202422285079956, Val_loss 3.4454457759857178\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1914870023727415, Val_loss 3.594104528427124\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.1413211107254027, Val_loss 3.524160146713257\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1066712379455566, Val_loss 3.530493974685669\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.13349072933197, Val_loss 3.4341824054718018\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.1098758220672607, Val_loss 3.438760757446289\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 46, Train_Loss 3.0929768562316893, Val_loss 3.49316143989563\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 47, Train_Loss 3.1208725690841677, Val_loss 3.4454309940338135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 48, Train_Loss 3.1587826728820803, Val_loss 3.4651012420654297\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.1067217350006104, Val_loss 3.457120656967163\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 50, Train_Loss 3.131152081489563, Val_loss 3.3994550704956055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 51, Train_Loss 3.1069430828094484, Val_loss 3.4834134578704834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.1253063678741455, Val_loss 3.3988466262817383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.107581067085266, Val_loss 3.357905149459839\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 54, Train_Loss 3.097706913948059, Val_loss 3.431774854660034\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.1119765281677245, Val_loss 3.506345748901367\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1044010400772093, Val_loss 3.4364864826202393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1534204721450805, Val_loss 3.4720447063446045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.0804030179977415, Val_loss 3.4662578105926514\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 59, Train_Loss 3.110298752784729, Val_loss 3.4425840377807617\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0905149936676026, Val_loss 3.495245933532715\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 61, Train_Loss 3.108634924888611, Val_loss 3.409322738647461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.1267184019088745, Val_loss 3.4264962673187256\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 63, Train_Loss 3.1120996952056883, Val_loss 3.405872106552124\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 64, Train_Loss 3.1036036014556885, Val_loss 3.3804969787597656\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.96\t\n",
      "Epoch 65, Train_Loss 3.0648552656173704, Val_loss 3.409999132156372\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.1129284381866453, Val_loss 3.436894416809082\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 67, Train_Loss 3.0993113279342652, Val_loss 3.405632972717285\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 68, Train_Loss 3.047337794303894, Val_loss 3.3830652236938477\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 69, Train_Loss 3.078490114212036, Val_loss 3.392650604248047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.0882605075836183, Val_loss 3.3571503162384033\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.0977575302124025, Val_loss 3.377718687057495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 72, Train_Loss 3.1113110065460203, Val_loss 3.3942983150482178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.0858206033706663, Val_loss 3.3851239681243896\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 74, Train_Loss 3.0714683055877687, Val_loss 3.373422622680664\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 75, Train_Loss 3.1269315481185913, Val_loss 3.387101173400879\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 76, Train_Loss 3.0615893602371216, Val_loss 3.438953161239624\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 77, Train_Loss 3.0866995096206664, Val_loss 3.4130489826202393\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.1114569664001466, Val_loss 3.4121294021606445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.077952837944031, Val_loss 3.4075441360473633\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 80, Train_Loss 3.1135256052017213, Val_loss 3.4189233779907227\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.0936839818954467, Val_loss 3.407944917678833\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.0567565679550173, Val_loss 3.403857946395874\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.0688105821609497, Val_loss 3.402397871017456\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.1332298040390016, Val_loss 3.418973207473755\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.106858801841736, Val_loss 3.401568651199341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.0966091394424438, Val_loss 3.407315969467163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 3.0891337156295777, Val_loss 3.3870255947113037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 88, Train_Loss 3.0835558652877806, Val_loss 3.4013006687164307\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 89, Train_Loss 3.073068046569824, Val_loss 3.3951923847198486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 90, Train_Loss 3.129976987838745, Val_loss 3.407050132751465\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 91, Train_Loss 3.0655669212341308, Val_loss 3.4115235805511475\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 92, Train_Loss 3.1046948432922363, Val_loss 3.413810968399048\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.0955291271209715, Val_loss 3.40356183052063\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.0817434787750244, Val_loss 3.402930974960327\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.134621500968933, Val_loss 3.395063638687134\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 96, Train_Loss 3.088543343544006, Val_loss 3.409435987472534\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.0749380111694338, Val_loss 3.3862807750701904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.081221842765808, Val_loss 3.412409543991089\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.04428653717041, Val_loss 3.3974876403808594\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.072234630584717, Val_loss 3.4263360500335693\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 1, Train_Loss 3.922757959365845, Val_loss 4.312020301818848\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.127742528915405, Val_loss 4.285228729248047\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.0672119140625, Val_loss 4.228325366973877\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.948713541030884, Val_loss 4.1265549659729\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8643195629119873, Val_loss 4.004695415496826\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.785066318511963, Val_loss 3.8466949462890625\n",
      "Train_acc_top_20 0.1875\tTrain_acc_top_30 0.325\tTrain_acc_top_40 0.3812\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 7, Train_Loss 3.72610285282135, Val_loss 3.7716662883758545\n",
      "Train_acc_top_20 0.4938\tTrain_acc_top_30 0.6813\tTrain_acc_top_40 0.7688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 8, Train_Loss 3.666791486740112, Val_loss 3.704625129699707\n",
      "Train_acc_top_20 0.7\tTrain_acc_top_30 0.8313\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.6288837432861327, Val_loss 3.7371957302093506\n",
      "Train_acc_top_20 0.6188\tTrain_acc_top_30 0.8187\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.542699193954468, Val_loss 3.782233953475952\n",
      "Train_acc_top_20 0.7625\tTrain_acc_top_30 0.8688\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.532688593864441, Val_loss 3.7142293453216553\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 12, Train_Loss 3.487791085243225, Val_loss 3.646946907043457\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.4228185415267944, Val_loss 3.6458187103271484\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.4051476955413817, Val_loss 3.6134490966796875\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3675729036331177, Val_loss 3.6214988231658936\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 16, Train_Loss 3.346778082847595, Val_loss 3.6029434204101562\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.334500956535339, Val_loss 3.708214044570923\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.3109196424484253, Val_loss 3.6564598083496094\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.3014598846435548, Val_loss 3.605804681777954\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.2787975072860718, Val_loss 3.598757028579712\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.260381484031677, Val_loss 3.639573812484741\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.220984411239624, Val_loss 3.6342051029205322\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.2581530094146727, Val_loss 3.573594093322754\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.211488652229309, Val_loss 3.599756956100464\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.196133518218994, Val_loss 3.5457189083099365\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.1695576667785645, Val_loss 3.5470287799835205\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.18699848651886, Val_loss 3.599505662918091\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.253378915786743, Val_loss 3.5785951614379883\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.202043557167053, Val_loss 3.5418739318847656\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.183234977722168, Val_loss 3.5172278881073\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.184146499633789, Val_loss 3.5735995769500732\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.176101899147034, Val_loss 3.5416128635406494\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 33, Train_Loss 3.1458186149597167, Val_loss 3.54378342628479\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.192084002494812, Val_loss 3.517645835876465\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.182820534706116, Val_loss 3.516313314437866\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.150796341896057, Val_loss 3.5349857807159424\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.191373682022095, Val_loss 3.5376806259155273\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.210399699211121, Val_loss 3.4774467945098877\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1387117862701417, Val_loss 3.5123403072357178\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.167901039123535, Val_loss 3.478402853012085\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1666457891464233, Val_loss 3.6525352001190186\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 42, Train_Loss 3.206188774108887, Val_loss 3.496386766433716\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.134377932548523, Val_loss 3.525965690612793\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.182837986946106, Val_loss 3.513942003250122\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.157617115974426, Val_loss 3.5313451290130615\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.1330050468444823, Val_loss 3.444814682006836\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.1414087057113647, Val_loss 3.5693235397338867\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.1335022926330565, Val_loss 3.484405279159546\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.1389171361923216, Val_loss 3.4792749881744385\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.0719181299209595, Val_loss 3.5303714275360107\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.117258358001709, Val_loss 3.4926793575286865\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.119918394088745, Val_loss 3.5103845596313477\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.129931902885437, Val_loss 3.519124746322632\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.0698315382003782, Val_loss 3.537036895751953\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.081621026992798, Val_loss 3.5306832790374756\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.115225625038147, Val_loss 3.543752431869507\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.1136303901672364, Val_loss 3.571516752243042\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.1149967670440675, Val_loss 3.4973678588867188\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.130853700637817, Val_loss 3.5220420360565186\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1098163604736326, Val_loss 3.478600263595581\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.0767305374145506, Val_loss 3.475809097290039\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0931160926818846, Val_loss 3.4701106548309326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.096607875823975, Val_loss 3.473062753677368\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.0930431365966795, Val_loss 3.4948806762695312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.0996168851852417, Val_loss 3.514101028442383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.084355688095093, Val_loss 3.521897315979004\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0743215084075928, Val_loss 3.5256154537200928\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 68, Train_Loss 3.1002240419387816, Val_loss 3.523496627807617\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.059232711791992, Val_loss 3.5219838619232178\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.094195079803467, Val_loss 3.508127450942993\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.046527290344238, Val_loss 3.4931223392486572\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.0840718030929564, Val_loss 3.536821126937866\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.100475525856018, Val_loss 3.512667417526245\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.109276628494263, Val_loss 3.5045297145843506\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 75, Train_Loss 3.1005653858184816, Val_loss 3.555203437805176\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.073596692085266, Val_loss 3.495013952255249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0454622507095337, Val_loss 3.496691942214966\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.0454248189926147, Val_loss 3.5231597423553467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.069357967376709, Val_loss 3.535146713256836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0643163204193113, Val_loss 3.49800181388855\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.020802855491638, Val_loss 3.4887282848358154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0657355785369873, Val_loss 3.492286443710327\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.068502426147461, Val_loss 3.4975764751434326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0793612718582155, Val_loss 3.5117452144622803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.059425163269043, Val_loss 3.5059690475463867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.108321928977966, Val_loss 3.5229129791259766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.063774037361145, Val_loss 3.5255281925201416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.064977192878723, Val_loss 3.5070431232452393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.0676507472991945, Val_loss 3.506101608276367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.06886830329895, Val_loss 3.5045366287231445\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.065359926223755, Val_loss 3.500697374343872\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.098393177986145, Val_loss 3.517390012741089\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.095296311378479, Val_loss 3.519592523574829\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0703880310058596, Val_loss 3.501084327697754\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.10778968334198, Val_loss 3.515411376953125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0969696760177614, Val_loss 3.526492118835449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.0680378675460815, Val_loss 3.5449163913726807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.0646127462387085, Val_loss 3.523813247680664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.0566749572753906, Val_loss 3.5215022563934326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.0637797117233276, Val_loss 3.483790636062622\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9256917238235474, Val_loss 4.249608516693115\n",
      "Train_acc_top_20 0.075\tTrain_acc_top_30 0.1125\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.118721580505371, Val_loss 4.20043420791626\n",
      "Train_acc_top_20 0.1375\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.42\t\n",
      "Epoch 3, Train_Loss 4.070424175262451, Val_loss 4.142766952514648\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9544930696487426, Val_loss 4.074403762817383\n",
      "Train_acc_top_20 0.075\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 5, Train_Loss 3.883996272087097, Val_loss 3.86560320854187\n",
      "Train_acc_top_20 0.1625\tTrain_acc_top_30 0.225\tTrain_acc_top_40 0.275\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.46\t\n",
      "Epoch 6, Train_Loss 3.804799485206604, Val_loss 3.7716925144195557\n",
      "Train_acc_top_20 0.3\tTrain_acc_top_30 0.4125\tTrain_acc_top_40 0.5125\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 7, Train_Loss 3.709180474281311, Val_loss 3.5987329483032227\n",
      "Train_acc_top_20 0.5875\tTrain_acc_top_30 0.7063\tTrain_acc_top_40 0.8\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 8, Train_Loss 3.6633238315582277, Val_loss 3.5253727436065674\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.5792293787002563, Val_loss 3.6407222747802734\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.562974047660828, Val_loss 3.576159715652466\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.5439227342605593, Val_loss 3.6337385177612305\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.4521722555160523, Val_loss 3.5578644275665283\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.452601599693298, Val_loss 3.6398468017578125\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.419945478439331, Val_loss 3.681328058242798\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.3669384241104128, Val_loss 3.459723472595215\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.3446686267852783, Val_loss 3.559363603591919\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.298207473754883, Val_loss 3.6886398792266846\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.2883389711380007, Val_loss 3.4947011470794678\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.2899417638778687, Val_loss 3.589689016342163\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.250528597831726, Val_loss 3.5383059978485107\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.303461766242981, Val_loss 3.437849998474121\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.2179426670074465, Val_loss 3.476839303970337\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2545398712158202, Val_loss 3.6318368911743164\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.1877278327941894, Val_loss 3.654822587966919\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.2314121961593627, Val_loss 3.462468147277832\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.229279804229736, Val_loss 3.52813720703125\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.2493837594985964, Val_loss 3.47259783744812\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 28, Train_Loss 3.2625659227371218, Val_loss 3.52260684967041\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1880515813827515, Val_loss 3.5117037296295166\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.1667330265045166, Val_loss 3.4735891819000244\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.207948160171509, Val_loss 3.5598020553588867\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1627506256103515, Val_loss 3.598262071609497\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1736064195632934, Val_loss 3.5800082683563232\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.1758788347244264, Val_loss 3.6293771266937256\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.1324318408966065, Val_loss 3.6344034671783447\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.2022698402404783, Val_loss 3.589916944503784\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.164069724082947, Val_loss 3.4817397594451904\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.2081828117370605, Val_loss 3.4394102096557617\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.1497687101364136, Val_loss 3.449857711791992\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.1887804746627806, Val_loss 3.521247625350952\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.163149929046631, Val_loss 3.6105663776397705\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.123810625076294, Val_loss 3.486088991165161\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 43, Train_Loss 3.145585298538208, Val_loss 3.4354970455169678\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.1307819843292237, Val_loss 3.531102418899536\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1421820163726806, Val_loss 3.701470136642456\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 46, Train_Loss 3.122799801826477, Val_loss 3.5083627700805664\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.1350694417953493, Val_loss 3.4628512859344482\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1877640962600706, Val_loss 3.6217823028564453\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.1886639833450316, Val_loss 3.5151100158691406\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1836687088012696, Val_loss 3.7589333057403564\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.132031297683716, Val_loss 3.6565544605255127\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 52, Train_Loss 3.1698054552078245, Val_loss 3.4594204425811768\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.2517698049545287, Val_loss 3.574320077896118\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 54, Train_Loss 3.1745636224746705, Val_loss 3.598564863204956\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.124255561828613, Val_loss 3.603959798812866\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.146344542503357, Val_loss 3.566913366317749\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.1224467754364014, Val_loss 3.528897285461426\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.143769907951355, Val_loss 3.592921257019043\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.0704925060272217, Val_loss 3.5992679595947266\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.086176133155823, Val_loss 3.5888888835906982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.123937201499939, Val_loss 3.6477108001708984\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 62, Train_Loss 3.0800793886184694, Val_loss 3.547067880630493\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.187829518318176, Val_loss 3.5309388637542725\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.103163003921509, Val_loss 3.4970414638519287\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 65, Train_Loss 3.1606655597686766, Val_loss 3.5262463092803955\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.172848868370056, Val_loss 3.579247236251831\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 67, Train_Loss 3.114997220039368, Val_loss 3.628948926925659\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.205997943878174, Val_loss 3.5941126346588135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 69, Train_Loss 3.1067747592926027, Val_loss 3.5457983016967773\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.1302395343780516, Val_loss 3.5184485912323\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.14045569896698, Val_loss 3.5070769786834717\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 72, Train_Loss 3.1309436321258546, Val_loss 3.5465171337127686\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.1452348947525026, Val_loss 3.57369065284729\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 74, Train_Loss 3.1972184419631957, Val_loss 3.5532093048095703\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.095897841453552, Val_loss 3.6193361282348633\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.0558521270751955, Val_loss 3.5821664333343506\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 77, Train_Loss 3.0832625150680544, Val_loss 3.5430567264556885\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.0651103019714356, Val_loss 3.563530206680298\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.105444240570068, Val_loss 3.5480031967163086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0944305896759032, Val_loss 3.651733636856079\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.1057381629943848, Val_loss 3.5749475955963135\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.042466068267822, Val_loss 3.5837106704711914\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.1155324220657348, Val_loss 3.588035821914673\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.135051894187927, Val_loss 3.5570802688598633\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.090079927444458, Val_loss 3.5430333614349365\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.1231441497802734, Val_loss 3.54352068901062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 87, Train_Loss 3.1015151500701905, Val_loss 3.5361649990081787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 88, Train_Loss 3.1307063817977907, Val_loss 3.558624029159546\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.0752504110336303, Val_loss 3.5385396480560303\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.0591058492660523, Val_loss 3.5617008209228516\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 91, Train_Loss 3.070058536529541, Val_loss 3.559502363204956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 92, Train_Loss 3.065186643600464, Val_loss 3.5290098190307617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.1302247047424316, Val_loss 3.5221359729766846\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.104456973075867, Val_loss 3.5292797088623047\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.121482825279236, Val_loss 3.5640790462493896\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.1105125188827514, Val_loss 3.559466600418091\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.134712028503418, Val_loss 3.5784835815429688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.140192723274231, Val_loss 3.5909271240234375\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.141399884223938, Val_loss 3.515618324279785\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.1001134872436524, Val_loss 3.5625598430633545\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 1, Train_Loss 3.9291579723358154, Val_loss 4.3421454429626465\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.124859380722046, Val_loss 4.304020404815674\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.070185708999634, Val_loss 4.2901482582092285\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.940544533729553, Val_loss 4.222346782684326\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.0\t\n",
      "Epoch 5, Train_Loss 3.8526467800140383, Val_loss 4.08569860458374\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.08\tVal_acc_top_40 0.17\t\n",
      "Epoch 6, Train_Loss 3.746427822113037, Val_loss 3.892392158508301\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.3688\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.42\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.708854579925537, Val_loss 3.820223093032837\n",
      "Train_acc_top_20 0.5437\tTrain_acc_top_30 0.6875\tTrain_acc_top_40 0.7375\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.643126058578491, Val_loss 3.6749322414398193\n",
      "Train_acc_top_20 0.6875\tTrain_acc_top_30 0.8063\tTrain_acc_top_40 0.875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5632982730865477, Val_loss 3.679570198059082\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5229814529418944, Val_loss 3.6112396717071533\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4897522926330566, Val_loss 3.6434056758880615\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 12, Train_Loss 3.4392054796218874, Val_loss 3.599493980407715\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4328604221343992, Val_loss 3.554126739501953\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.4075910091400146, Val_loss 3.532668352127075\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.367664337158203, Val_loss 3.5753486156463623\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.319460892677307, Val_loss 3.5513248443603516\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.31658821105957, Val_loss 3.6020586490631104\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.292324757575989, Val_loss 3.596035957336426\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.2610482454299925, Val_loss 3.4838597774505615\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 20, Train_Loss 3.2288604021072387, Val_loss 3.4806768894195557\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.210707926750183, Val_loss 3.5299713611602783\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 22, Train_Loss 3.195628023147583, Val_loss 3.4873697757720947\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.225916600227356, Val_loss 3.4782562255859375\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.2338945627212525, Val_loss 3.5448453426361084\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.2015893936157225, Val_loss 3.5129544734954834\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.1788809537887572, Val_loss 3.521456003189087\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.1930181980133057, Val_loss 3.4996445178985596\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.209634017944336, Val_loss 3.594947576522827\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 29, Train_Loss 3.282552886009216, Val_loss 3.561122179031372\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.274876284599304, Val_loss 3.667470932006836\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 31, Train_Loss 3.2360132455825807, Val_loss 3.5070762634277344\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.233003854751587, Val_loss 3.4984591007232666\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.2782586574554444, Val_loss 3.4843921661376953\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.2004740476608275, Val_loss 3.451392412185669\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.137429428100586, Val_loss 3.592827796936035\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1966229677200317, Val_loss 3.6568830013275146\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 37, Train_Loss 3.1951746702194215, Val_loss 3.4841558933258057\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.304163432121277, Val_loss 3.578232765197754\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.260998320579529, Val_loss 3.5951175689697266\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.2312384128570555, Val_loss 3.4712047576904297\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.1726479053497316, Val_loss 3.494769334793091\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.168137454986572, Val_loss 3.462538957595825\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1194762229919433, Val_loss 3.4138176441192627\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.134703516960144, Val_loss 3.4620361328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 45, Train_Loss 3.2036654472351076, Val_loss 3.4859488010406494\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.20276358127594, Val_loss 3.485414505004883\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1434236764907837, Val_loss 3.4455273151397705\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 48, Train_Loss 3.1486688613891602, Val_loss 3.4433717727661133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1618457555770876, Val_loss 3.4521186351776123\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1384538412094116, Val_loss 3.4165725708007812\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.133443069458008, Val_loss 3.5346434116363525\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.150842785835266, Val_loss 3.501938581466675\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.135420083999634, Val_loss 3.4570159912109375\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1234771490097044, Val_loss 3.4325859546661377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.0806333303451536, Val_loss 3.39858341217041\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1280898809432984, Val_loss 3.462601900100708\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1502682685852053, Val_loss 3.4442851543426514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.152402377128601, Val_loss 3.4640934467315674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.0986008167266847, Val_loss 3.429936170578003\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.09429292678833, Val_loss 3.473001480102539\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.1147467374801634, Val_loss 3.4766666889190674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.11234929561615, Val_loss 3.4689300060272217\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.123911905288696, Val_loss 3.484225273132324\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 64, Train_Loss 3.099774384498596, Val_loss 3.468431234359741\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.1238264799118043, Val_loss 3.4644525051116943\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.099075269699097, Val_loss 3.4680614471435547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.1171072006225584, Val_loss 3.5025253295898438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 68, Train_Loss 3.0932108402252196, Val_loss 3.43731689453125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.0685445785522463, Val_loss 3.413583755493164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.1152708292007447, Val_loss 3.480438232421875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 71, Train_Loss 3.0949620723724367, Val_loss 3.4328181743621826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.060719037055969, Val_loss 3.4240496158599854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 73, Train_Loss 3.110308313369751, Val_loss 3.4812967777252197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0841543674468994, Val_loss 3.412001371383667\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.0587197303771974, Val_loss 3.4192769527435303\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.081364941596985, Val_loss 3.4491193294525146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 77, Train_Loss 3.085674524307251, Val_loss 3.4857561588287354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 78, Train_Loss 3.0742897272109984, Val_loss 3.4651505947113037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.0651614904403686, Val_loss 3.427863359451294\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0885072708129884, Val_loss 3.4379026889801025\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.0850128650665285, Val_loss 3.4326322078704834\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 82, Train_Loss 3.091077756881714, Val_loss 3.4557018280029297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.0909846305847166, Val_loss 3.454726219177246\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.07631368637085, Val_loss 3.470496416091919\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.077743935585022, Val_loss 3.4705727100372314\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.089228796958923, Val_loss 3.4304466247558594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.0688334941864013, Val_loss 3.43192982673645\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.1031420707702635, Val_loss 3.47355055809021\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 89, Train_Loss 3.106005382537842, Val_loss 3.437885046005249\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.1114583730697634, Val_loss 3.4638407230377197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.0732982635498045, Val_loss 3.4178154468536377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0929228544235228, Val_loss 3.4592533111572266\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.072823333740234, Val_loss 3.4574766159057617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0696725606918336, Val_loss 3.433736562728882\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0983123064041136, Val_loss 3.4559381008148193\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.1109732151031495, Val_loss 3.462778329849243\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.1035905361175535, Val_loss 3.4841105937957764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.0843805074691772, Val_loss 3.4286696910858154\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0538422584533693, Val_loss 3.4494683742523193\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.0840867280960085, Val_loss 3.4662764072418213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.92824239730835, Val_loss 4.314105987548828\n",
      "Train_acc_top_20 0.0625\tTrain_acc_top_30 0.1\tTrain_acc_top_40 0.1562\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.127592945098877, Val_loss 4.277458190917969\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.071777820587158, Val_loss 4.25909948348999\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.974890041351318, Val_loss 4.154948711395264\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8372659921646117, Val_loss 3.991403341293335\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7484344482421874, Val_loss 3.816472053527832\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.3812\tTrain_acc_top_40 0.5062\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.708622360229492, Val_loss 3.8424596786499023\n",
      "Train_acc_top_20 0.5938\tTrain_acc_top_30 0.75\tTrain_acc_top_40 0.8562\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.6525092840194704, Val_loss 3.839031934738159\n",
      "Train_acc_top_20 0.625\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.59999840259552, Val_loss 3.72165846824646\n",
      "Train_acc_top_20 0.7188\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.5169730186462402, Val_loss 3.6869399547576904\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.4844134569168093, Val_loss 3.793651580810547\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.4796127557754515, Val_loss 3.767430067062378\n",
      "Train_acc_top_20 0.8\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.446587824821472, Val_loss 3.605637311935425\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.4083966493606566, Val_loss 3.7911508083343506\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.404319000244141, Val_loss 3.728337526321411\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.370949387550354, Val_loss 3.6407716274261475\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.326188826560974, Val_loss 3.6797962188720703\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 18, Train_Loss 3.3111857175827026, Val_loss 3.5828192234039307\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.299156832695007, Val_loss 3.734349250793457\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2873462438583374, Val_loss 3.595283269882202\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.27278892993927, Val_loss 3.61061692237854\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.269102358818054, Val_loss 3.5751521587371826\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.2134782314300536, Val_loss 3.5556280612945557\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 24, Train_Loss 3.25220103263855, Val_loss 3.6344964504241943\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.2493449687957763, Val_loss 3.8646323680877686\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.8688\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.46\t\n",
      "Epoch 26, Train_Loss 3.2968788623809813, Val_loss 3.5908241271972656\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.221972107887268, Val_loss 3.5961639881134033\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.2701043605804445, Val_loss 3.5931766033172607\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.2022786855697634, Val_loss 3.5636978149414062\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.2087192296981812, Val_loss 3.71905779838562\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.195271396636963, Val_loss 3.476611852645874\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.204376196861267, Val_loss 3.5247385501861572\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.18880832195282, Val_loss 3.696237802505493\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 34, Train_Loss 3.2200286388397217, Val_loss 3.5923335552215576\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.25510687828064, Val_loss 3.462125778198242\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1861834287643434, Val_loss 3.534924268722534\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.16424446105957, Val_loss 3.5349996089935303\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.1445400714874268, Val_loss 3.4825079441070557\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 39, Train_Loss 3.1579538583755493, Val_loss 3.4656951427459717\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.15615599155426, Val_loss 3.4382236003875732\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.116931748390198, Val_loss 3.467881917953491\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 42, Train_Loss 3.078467011451721, Val_loss 3.444544553756714\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.0765740394592287, Val_loss 3.4926984310150146\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.143013834953308, Val_loss 3.5499629974365234\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1285027265548706, Val_loss 3.4939661026000977\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.2070407390594484, Val_loss 3.4415645599365234\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 47, Train_Loss 3.129309868812561, Val_loss 3.50205397605896\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.241697335243225, Val_loss 3.4426562786102295\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.137520670890808, Val_loss 3.448241949081421\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1266273498535155, Val_loss 3.450004816055298\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1311334133148194, Val_loss 3.473956346511841\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.129145050048828, Val_loss 3.5384693145751953\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.152816367149353, Val_loss 3.46069598197937\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.1113949537277223, Val_loss 3.4143364429473877\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1291047096252442, Val_loss 3.438220262527466\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.068156623840332, Val_loss 3.4334871768951416\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.0859067916870115, Val_loss 3.3650410175323486\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.0740213632583617, Val_loss 3.417309045791626\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.091439414024353, Val_loss 3.3729372024536133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0793344497680666, Val_loss 3.3913447856903076\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.1546764612197875, Val_loss 3.38861346244812\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.105333924293518, Val_loss 3.379775285720825\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.13345410823822, Val_loss 3.3607170581817627\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.1481236934661867, Val_loss 3.4372901916503906\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.1537044286727904, Val_loss 3.431264877319336\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.1402965545654298, Val_loss 3.4993293285369873\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 67, Train_Loss 3.120421314239502, Val_loss 3.4183003902435303\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.0609386682510378, Val_loss 3.416057586669922\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0856744289398192, Val_loss 3.4075310230255127\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 70, Train_Loss 3.167654514312744, Val_loss 3.4729185104370117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.093546223640442, Val_loss 3.4052810668945312\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.10255081653595, Val_loss 3.4394044876098633\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.105192255973816, Val_loss 3.430644989013672\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.07097647190094, Val_loss 3.4259932041168213\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.1083338022232057, Val_loss 3.4626693725585938\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 76, Train_Loss 3.0784522771835325, Val_loss 3.4313127994537354\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0781351804733275, Val_loss 3.3776772022247314\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.059340572357178, Val_loss 3.3879196643829346\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.1430590391159057, Val_loss 3.442889451980591\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.082698655128479, Val_loss 3.4331653118133545\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0820966482162477, Val_loss 3.4329912662506104\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0823485612869264, Val_loss 3.4396092891693115\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.054072713851929, Val_loss 3.390380859375\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.1473674535751344, Val_loss 3.4205849170684814\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0734138250350953, Val_loss 3.399498224258423\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.092761778831482, Val_loss 3.3856594562530518\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.0689635992050173, Val_loss 3.405679702758789\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.1396395921707154, Val_loss 3.442946672439575\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0752206087112426, Val_loss 3.38720703125\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1073825359344482, Val_loss 3.421750783920288\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.104762816429138, Val_loss 3.405797243118286\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.1043872833251953, Val_loss 3.430997133255005\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.098434829711914, Val_loss 3.412538528442383\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 94, Train_Loss 3.096858501434326, Val_loss 3.4277517795562744\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.08697714805603, Val_loss 3.3874568939208984\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.0419050216674806, Val_loss 3.351058006286621\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.090305972099304, Val_loss 3.3980636596679688\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.0709983587265013, Val_loss 3.363461494445801\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.111898684501648, Val_loss 3.4068586826324463\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.0944706439971923, Val_loss 3.3890724182128906\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.9169748306274412, Val_loss 4.258762836456299\n",
      "Train_acc_top_20 0.1562\tTrain_acc_top_30 0.225\tTrain_acc_top_40 0.275\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.29\t\n",
      "Epoch 2, Train_Loss 4.123761463165283, Val_loss 4.17545747756958\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.06895809173584, Val_loss 4.167178630828857\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9357362270355223, Val_loss 4.091350078582764\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.869623231887817, Val_loss 4.005880832672119\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.753321981430054, Val_loss 3.9019644260406494\n",
      "Train_acc_top_20 0.3812\tTrain_acc_top_30 0.5\tTrain_acc_top_40 0.5625\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.5\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.6844124794006348, Val_loss 3.884862184524536\n",
      "Train_acc_top_20 0.7063\tTrain_acc_top_30 0.8313\tTrain_acc_top_40 0.875\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.587693476676941, Val_loss 3.828106641769409\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 9, Train_Loss 3.5170353651046753, Val_loss 3.8321094512939453\n",
      "Train_acc_top_20 0.8313\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 10, Train_Loss 3.4898298501968386, Val_loss 3.8728435039520264\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.446518969535828, Val_loss 3.8670542240142822\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.401429009437561, Val_loss 3.6968533992767334\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.423353838920593, Val_loss 3.722980260848999\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 14, Train_Loss 3.397419786453247, Val_loss 3.6671714782714844\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.363400411605835, Val_loss 3.689408540725708\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.3341984272003176, Val_loss 3.6514012813568115\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.2934375286102293, Val_loss 3.8022546768188477\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.2923706769943237, Val_loss 3.6704797744750977\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.359391188621521, Val_loss 3.6494569778442383\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2439510822296143, Val_loss 3.663820505142212\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 21, Train_Loss 3.2366251230239866, Val_loss 3.5669939517974854\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.2223987340927125, Val_loss 3.6366329193115234\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.1943997144699097, Val_loss 3.631704568862915\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2190765619277952, Val_loss 3.686366081237793\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.262166166305542, Val_loss 3.574448823928833\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.1688723802566527, Val_loss 3.6868162155151367\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.171883249282837, Val_loss 3.5693161487579346\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.1941957235336305, Val_loss 3.595548391342163\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.171473574638367, Val_loss 3.644939661026001\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 30, Train_Loss 3.2130875825881957, Val_loss 3.678938865661621\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 31, Train_Loss 3.1566614627838137, Val_loss 3.632014513015747\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.1898385763168333, Val_loss 3.6678874492645264\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.157511520385742, Val_loss 3.565005302429199\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.1210999488830566, Val_loss 3.6530096530914307\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.175107002258301, Val_loss 3.626143217086792\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1837705612182616, Val_loss 3.6342532634735107\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1704954147338866, Val_loss 3.7060794830322266\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.1312829732894896, Val_loss 3.5810489654541016\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.108048129081726, Val_loss 3.7029874324798584\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 40, Train_Loss 3.1145907402038575, Val_loss 3.674882650375366\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1735111236572267, Val_loss 3.6471967697143555\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.116775918006897, Val_loss 3.622711420059204\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1417068004608155, Val_loss 3.6718060970306396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.1281593561172487, Val_loss 3.6410579681396484\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.1598005294799805, Val_loss 3.646684408187866\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.109483790397644, Val_loss 3.6665241718292236\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.185854363441467, Val_loss 3.703259229660034\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.10450165271759, Val_loss 3.5491440296173096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1805417776107787, Val_loss 3.562856435775757\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1087590932846068, Val_loss 3.5565693378448486\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.123408627510071, Val_loss 3.7488601207733154\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 52, Train_Loss 3.1099870443344115, Val_loss 3.6372692584991455\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.233298349380493, Val_loss 3.6144113540649414\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 54, Train_Loss 3.150085926055908, Val_loss 3.513570547103882\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.1124396562576293, Val_loss 3.506214141845703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.0749793529510496, Val_loss 3.511139154434204\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 57, Train_Loss 3.1023773431777952, Val_loss 3.5646820068359375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.0844552755355834, Val_loss 3.514249563217163\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.1000920295715333, Val_loss 3.5284535884857178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.187136006355286, Val_loss 3.6072371006011963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1265159606933595, Val_loss 3.5428130626678467\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.097700095176697, Val_loss 3.5282671451568604\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.1374731779098513, Val_loss 3.5886497497558594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.142681860923767, Val_loss 3.5715630054473877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.0563289165496825, Val_loss 3.5272979736328125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.0861663103103636, Val_loss 3.521585702896118\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.1754106521606444, Val_loss 3.623453378677368\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 68, Train_Loss 3.1648016214370727, Val_loss 3.5910069942474365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.1051753997802733, Val_loss 3.5458695888519287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.092480754852295, Val_loss 3.531240463256836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0688329696655274, Val_loss 3.5317370891571045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.079082155227661, Val_loss 3.5579826831817627\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0842308044433593, Val_loss 3.530978202819824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.100722813606262, Val_loss 3.5375850200653076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.0947737455368043, Val_loss 3.5543336868286133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.105609154701233, Val_loss 3.5756359100341797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.0260552644729612, Val_loss 3.557063341140747\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.125954341888428, Val_loss 3.573550224304199\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.0868980169296263, Val_loss 3.5539710521698\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.137783169746399, Val_loss 3.574225425720215\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.122770571708679, Val_loss 3.576870918273926\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.0740685939788817, Val_loss 3.582869529724121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.1079357147216795, Val_loss 3.551542282104492\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.077818274497986, Val_loss 3.565990447998047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.072532534599304, Val_loss 3.554210901260376\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.084608960151672, Val_loss 3.5426080226898193\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0743515491485596, Val_loss 3.549156427383423\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.132935667037964, Val_loss 3.550924301147461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0648357629776, Val_loss 3.5333502292633057\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.07203152179718, Val_loss 3.5511457920074463\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.104239797592163, Val_loss 3.5603179931640625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0744133234024047, Val_loss 3.5756375789642334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.068251371383667, Val_loss 3.5742225646972656\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0835052967071532, Val_loss 3.516648054122925\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0667441844940186, Val_loss 3.510655403137207\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.061651515960693, Val_loss 3.558032274246216\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.082274079322815, Val_loss 3.5425570011138916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.109478402137756, Val_loss 3.5591132640838623\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0819823026657103, Val_loss 3.539072275161743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.0631298303604124, Val_loss 3.5512428283691406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9242077350616453, Val_loss 4.323997974395752\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.125033235549926, Val_loss 4.270174503326416\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.0708984375, Val_loss 4.236111164093018\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.959588146209717, Val_loss 4.199374675750732\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 5, Train_Loss 3.865120506286621, Val_loss 4.023823261260986\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.781847596168518, Val_loss 3.860811233520508\n",
      "Train_acc_top_20 0.3\tTrain_acc_top_30 0.45\tTrain_acc_top_40 0.5188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 7, Train_Loss 3.669229817390442, Val_loss 3.827960968017578\n",
      "Train_acc_top_20 0.6188\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.8125\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6083733320236204, Val_loss 3.7719829082489014\n",
      "Train_acc_top_20 0.7438\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.5398709774017334, Val_loss 3.753981351852417\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 10, Train_Loss 3.5275675296783446, Val_loss 3.775615692138672\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 11, Train_Loss 3.4811506509780883, Val_loss 3.7595138549804688\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.4306968688964843, Val_loss 3.7285993099212646\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.38673939704895, Val_loss 3.733443021774292\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.371748614311218, Val_loss 3.710062265396118\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.348111152648926, Val_loss 3.680724859237671\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3315085411071776, Val_loss 3.65750789642334\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.2824981451034545, Val_loss 3.6642167568206787\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.292248487472534, Val_loss 3.712998151779175\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 19, Train_Loss 3.2464716911315916, Val_loss 3.628558874130249\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.239423656463623, Val_loss 3.693810224533081\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.3017256259918213, Val_loss 3.619872808456421\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.225528597831726, Val_loss 3.5777428150177\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.244889426231384, Val_loss 3.6587069034576416\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.2049482107162475, Val_loss 3.6350367069244385\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.170280647277832, Val_loss 3.6768741607666016\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.1836312055587768, Val_loss 3.654528856277466\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.1876919746398924, Val_loss 3.615403890609741\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1597699165344237, Val_loss 3.619069814682007\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.1610187530517577, Val_loss 3.60052490234375\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 30, Train_Loss 3.1627622842788696, Val_loss 3.6475231647491455\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.174153137207031, Val_loss 3.655784845352173\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1528173208236696, Val_loss 3.565605878829956\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.16602463722229, Val_loss 3.7008135318756104\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 34, Train_Loss 3.1490794897079466, Val_loss 3.5250256061553955\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 35, Train_Loss 3.1457228660583496, Val_loss 3.597113609313965\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1538368701934814, Val_loss 3.6995296478271484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.127246046066284, Val_loss 3.573420286178589\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 38, Train_Loss 3.088564133644104, Val_loss 3.730281114578247\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1591814517974854, Val_loss 3.6946449279785156\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 40, Train_Loss 3.150814342498779, Val_loss 3.6771085262298584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.215883159637451, Val_loss 3.620744466781616\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.19284188747406, Val_loss 3.7049810886383057\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 43, Train_Loss 3.1651072978973387, Val_loss 3.808215379714966\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 44, Train_Loss 3.130267333984375, Val_loss 3.6944773197174072\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 45, Train_Loss 3.157406973838806, Val_loss 3.6914455890655518\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.144913744926453, Val_loss 3.7413012981414795\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.58\t\n",
      "Epoch 47, Train_Loss 3.1178503751754763, Val_loss 3.778299331665039\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 48, Train_Loss 3.1186307191848757, Val_loss 3.7149295806884766\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 49, Train_Loss 3.069159746170044, Val_loss 3.651474714279175\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 50, Train_Loss 3.1073649406433104, Val_loss 3.7450411319732666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.055662488937378, Val_loss 3.6683413982391357\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 52, Train_Loss 3.1083861112594606, Val_loss 3.7140824794769287\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 53, Train_Loss 3.107970666885376, Val_loss 3.6573336124420166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.1039846897125245, Val_loss 3.5811569690704346\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 55, Train_Loss 3.111341452598572, Val_loss 3.6648263931274414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 56, Train_Loss 3.140539598464966, Val_loss 3.7424228191375732\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 57, Train_Loss 3.044194769859314, Val_loss 3.6590993404388428\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 58, Train_Loss 3.1053040981292725, Val_loss 3.709139108657837\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 59, Train_Loss 3.128667950630188, Val_loss 3.6940348148345947\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 60, Train_Loss 3.0842201471328736, Val_loss 3.6848666667938232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 61, Train_Loss 3.0742498636245728, Val_loss 3.680204391479492\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 62, Train_Loss 3.0280239820480346, Val_loss 3.740994453430176\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 63, Train_Loss 3.0710845470428465, Val_loss 3.7774736881256104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 64, Train_Loss 3.062111520767212, Val_loss 3.707472562789917\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.078010392189026, Val_loss 3.705953598022461\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.0290115118026733, Val_loss 3.8126888275146484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 67, Train_Loss 3.0558454751968385, Val_loss 3.750910758972168\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.0890688419342043, Val_loss 3.683591842651367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.041643810272217, Val_loss 3.6885433197021484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.0485081911087035, Val_loss 3.7114078998565674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 71, Train_Loss 3.0722692728042604, Val_loss 3.74175763130188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 72, Train_Loss 2.9917187452316285, Val_loss 3.7487294673919678\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 73, Train_Loss 3.090575909614563, Val_loss 3.713067054748535\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 74, Train_Loss 3.020234227180481, Val_loss 3.6958281993865967\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.137750339508057, Val_loss 3.6951980590820312\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.1066428422927856, Val_loss 3.6822965145111084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.058682012557983, Val_loss 3.6379919052124023\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.0573585748672487, Val_loss 3.666924238204956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 79, Train_Loss 3.0790072441101075, Val_loss 3.6577603816986084\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.0301176071166993, Val_loss 3.6585073471069336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.0719671726226805, Val_loss 3.655902862548828\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 82, Train_Loss 3.0929299354553224, Val_loss 3.701697587966919\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.094797134399414, Val_loss 3.720715284347534\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.044088840484619, Val_loss 3.725918769836426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 85, Train_Loss 3.0471081495285035, Val_loss 3.7034060955047607\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.0591752767562865, Val_loss 3.6843416690826416\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.052658438682556, Val_loss 3.69356369972229\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 88, Train_Loss 3.0127106428146364, Val_loss 3.682725667953491\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 89, Train_Loss 3.041583299636841, Val_loss 3.68933367729187\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.0687930822372436, Val_loss 3.69258189201355\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.0671127080917358, Val_loss 3.6584079265594482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.067898750305176, Val_loss 3.678375244140625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.036903715133667, Val_loss 3.692307710647583\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.05639533996582, Val_loss 3.704641342163086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.0505122184753417, Val_loss 3.6732873916625977\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 96, Train_Loss 3.0223040103912355, Val_loss 3.695122480392456\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.028227925300598, Val_loss 3.6957390308380127\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.074590969085693, Val_loss 3.6720874309539795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 99, Train_Loss 3.104586458206177, Val_loss 3.694838523864746\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.0164035320281983, Val_loss 3.690114736557007\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9255268812179565, Val_loss 4.322318077087402\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 2, Train_Loss 4.128122234344483, Val_loss 4.283278942108154\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.095176744461059, Val_loss 4.245538234710693\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.993357014656067, Val_loss 4.19592809677124\n",
      "Train_acc_top_20 0.1187\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.9009570360183714, Val_loss 4.051607131958008\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.793533134460449, Val_loss 3.763047933578491\n",
      "Train_acc_top_20 0.3063\tTrain_acc_top_30 0.3812\tTrain_acc_top_40 0.4875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.726746845245361, Val_loss 3.6363322734832764\n",
      "Train_acc_top_20 0.5188\tTrain_acc_top_30 0.6875\tTrain_acc_top_40 0.775\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 8, Train_Loss 3.635101842880249, Val_loss 3.600996971130371\n",
      "Train_acc_top_20 0.6875\tTrain_acc_top_30 0.85\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 9, Train_Loss 3.59329206943512, Val_loss 3.577577590942383\n",
      "Train_acc_top_20 0.7125\tTrain_acc_top_30 0.8688\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 10, Train_Loss 3.5298710107803344, Val_loss 3.5465917587280273\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.4714043140411377, Val_loss 3.55216908454895\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.460399103164673, Val_loss 3.483152389526367\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 13, Train_Loss 3.434901738166809, Val_loss 3.4968559741973877\n",
      "Train_acc_top_20 0.8625\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 14, Train_Loss 3.375120162963867, Val_loss 3.553924322128296\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.361264371871948, Val_loss 3.42965030670166\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 16, Train_Loss 3.3264522790908813, Val_loss 3.4800541400909424\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.305227780342102, Val_loss 3.491361618041992\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.2999741554260256, Val_loss 3.413602590560913\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 19, Train_Loss 3.27859628200531, Val_loss 3.4278719425201416\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 20, Train_Loss 3.2781463623046876, Val_loss 3.4935576915740967\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.2733186721801757, Val_loss 3.442575454711914\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.2533257246017455, Val_loss 3.3980960845947266\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 23, Train_Loss 3.21579909324646, Val_loss 3.435762405395508\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 24, Train_Loss 3.190651512145996, Val_loss 3.436669111251831\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 25, Train_Loss 3.213747191429138, Val_loss 3.3981714248657227\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 26, Train_Loss 3.2049204826354982, Val_loss 3.415900468826294\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 27, Train_Loss 3.2042802810668944, Val_loss 3.365593671798706\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.88\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 28, Train_Loss 3.181069564819336, Val_loss 3.405794143676758\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 29, Train_Loss 3.209638571739197, Val_loss 3.5302810668945312\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.1715209007263185, Val_loss 3.470492362976074\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 31, Train_Loss 3.177879285812378, Val_loss 3.4490272998809814\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.1389546632766723, Val_loss 3.410921335220337\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.1776429414749146, Val_loss 3.424570322036743\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 34, Train_Loss 3.1420040845870973, Val_loss 3.5393426418304443\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 35, Train_Loss 3.174993968009949, Val_loss 3.4985809326171875\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 36, Train_Loss 3.2167779922485353, Val_loss 3.3930461406707764\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 37, Train_Loss 3.1813193798065185, Val_loss 3.436335563659668\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.15259165763855, Val_loss 3.467620611190796\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.1227509498596193, Val_loss 3.461127281188965\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.139215660095215, Val_loss 3.4361579418182373\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.1308736562728883, Val_loss 3.4149744510650635\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 42, Train_Loss 3.1043601274490356, Val_loss 3.461873769760132\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 43, Train_Loss 3.124269151687622, Val_loss 3.4450457096099854\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.1324474096298216, Val_loss 3.4308993816375732\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.070432686805725, Val_loss 3.39473032951355\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 46, Train_Loss 3.087307572364807, Val_loss 3.4465301036834717\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 47, Train_Loss 3.1371791124343873, Val_loss 3.439180612564087\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 48, Train_Loss 3.1775912284851073, Val_loss 3.59208607673645\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.0712817430496218, Val_loss 3.456238031387329\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 50, Train_Loss 3.1142260074615478, Val_loss 3.548792600631714\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.104717659950256, Val_loss 3.4550914764404297\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 52, Train_Loss 3.097925305366516, Val_loss 3.471480131149292\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 53, Train_Loss 3.1004547595977785, Val_loss 3.457056760787964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 54, Train_Loss 3.128254795074463, Val_loss 3.4995803833007812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 55, Train_Loss 3.122930335998535, Val_loss 3.4419755935668945\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 56, Train_Loss 3.059925413131714, Val_loss 3.413191795349121\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.150429391860962, Val_loss 3.4391982555389404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.133724546432495, Val_loss 3.654542922973633\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.124158763885498, Val_loss 3.4121227264404297\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0912171840667724, Val_loss 3.39532208442688\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 61, Train_Loss 3.07346773147583, Val_loss 3.433682441711426\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 62, Train_Loss 3.1190972089767457, Val_loss 3.4252312183380127\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 63, Train_Loss 3.1273342609405517, Val_loss 3.498215436935425\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.0992172956466675, Val_loss 3.4607551097869873\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.0746442317962646, Val_loss 3.446263313293457\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.0658161640167236, Val_loss 3.406369209289551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 67, Train_Loss 3.0998686075210573, Val_loss 3.539940595626831\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.0416552066802978, Val_loss 3.426175355911255\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 69, Train_Loss 3.0737162828445435, Val_loss 3.4378302097320557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 70, Train_Loss 3.1285277128219606, Val_loss 3.4584033489227295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 71, Train_Loss 3.097449016571045, Val_loss 3.4508848190307617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 72, Train_Loss 3.0739489555358888, Val_loss 3.4571831226348877\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 73, Train_Loss 3.0583093643188475, Val_loss 3.4761879444122314\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.1099921226501466, Val_loss 3.470391035079956\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 75, Train_Loss 3.0914565086364747, Val_loss 3.4956390857696533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.068370723724365, Val_loss 3.4689486026763916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 3.100506639480591, Val_loss 3.47748064994812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 78, Train_Loss 3.1066916227340697, Val_loss 3.487478494644165\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.0974514484405518, Val_loss 3.4731853008270264\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.0399582862854, Val_loss 3.465860605239868\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.0332233190536497, Val_loss 3.459871530532837\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.0504328489303587, Val_loss 3.438009023666382\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.1647149085998536, Val_loss 3.5166428089141846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.0575559616088865, Val_loss 3.4734795093536377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.1267844676971435, Val_loss 3.515035390853882\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.0839563846588134, Val_loss 3.4861042499542236\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.047565054893494, Val_loss 3.4873621463775635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 88, Train_Loss 3.0607341289520265, Val_loss 3.5055530071258545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 89, Train_Loss 3.030823278427124, Val_loss 3.41745924949646\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.102294373512268, Val_loss 3.466196298599243\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 91, Train_Loss 3.073346567153931, Val_loss 3.4666712284088135\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.081633973121643, Val_loss 3.4844815731048584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.096448516845703, Val_loss 3.5077102184295654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.0696001291275024, Val_loss 3.4807045459747314\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.0737220287322997, Val_loss 3.473684310913086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.076641321182251, Val_loss 3.5010383129119873\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.0748401880264282, Val_loss 3.475446939468384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.1613321542739867, Val_loss 3.4802112579345703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.0996085166931153, Val_loss 3.4917097091674805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.1576910257339477, Val_loss 3.4977195262908936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.9280331134796143, Val_loss 4.266332149505615\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.128243064880371, Val_loss 4.248959541320801\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 3, Train_Loss 4.069158411026001, Val_loss 4.223904609680176\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.29\t\n",
      "Epoch 4, Train_Loss 3.957962083816528, Val_loss 4.135559558868408\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.8354357957839964, Val_loss 3.9666178226470947\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7747400760650636, Val_loss 3.895116090774536\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.4313\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.42\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.707042670249939, Val_loss 3.7692410945892334\n",
      "Train_acc_top_20 0.475\tTrain_acc_top_30 0.6438\tTrain_acc_top_40 0.7375\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6430540800094606, Val_loss 3.774717330932617\n",
      "Train_acc_top_20 0.6312\tTrain_acc_top_30 0.8125\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 9, Train_Loss 3.5672953844070436, Val_loss 3.714775323867798\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.5387798309326173, Val_loss 3.719707489013672\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.4704397201538084, Val_loss 3.638861656188965\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.44964280128479, Val_loss 3.652857542037964\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.393150234222412, Val_loss 3.6040570735931396\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.3592449188232423, Val_loss 3.624187707901001\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3398608684539797, Val_loss 3.6131210327148438\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 16, Train_Loss 3.3320432186126707, Val_loss 3.6969645023345947\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 17, Train_Loss 3.2993547439575197, Val_loss 3.611085891723633\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.278896164894104, Val_loss 3.602672576904297\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.254176378250122, Val_loss 3.6166341304779053\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.235065984725952, Val_loss 3.5808136463165283\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 21, Train_Loss 3.227630591392517, Val_loss 3.665271043777466\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 22, Train_Loss 3.234348702430725, Val_loss 3.592264413833618\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.202728509902954, Val_loss 3.632606267929077\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 24, Train_Loss 3.217816376686096, Val_loss 3.7241694927215576\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 25, Train_Loss 3.230378007888794, Val_loss 3.6026451587677\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.208759093284607, Val_loss 3.5926475524902344\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.1692229747772216, Val_loss 3.5645358562469482\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.143721008300781, Val_loss 3.605807065963745\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.147930908203125, Val_loss 3.558119058609009\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.188847875595093, Val_loss 3.5495736598968506\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.1547747611999513, Val_loss 3.5465481281280518\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.1538374185562135, Val_loss 3.5698258876800537\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.1351699352264406, Val_loss 3.595482587814331\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.1594528436660765, Val_loss 3.547105073928833\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.127596855163574, Val_loss 3.503901243209839\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1580758571624754, Val_loss 3.518021583557129\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.1317354440689087, Val_loss 3.576422929763794\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 38, Train_Loss 3.104185700416565, Val_loss 3.5793263912200928\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1924078941345213, Val_loss 3.5575039386749268\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.1568657636642454, Val_loss 3.599048614501953\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.233744812011719, Val_loss 3.5864551067352295\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.140464735031128, Val_loss 3.5679244995117188\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.159399485588074, Val_loss 3.5323238372802734\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 44, Train_Loss 3.143186616897583, Val_loss 3.512848138809204\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1279528617858885, Val_loss 3.489870071411133\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 46, Train_Loss 3.101245307922363, Val_loss 3.5142323970794678\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 47, Train_Loss 3.13894636631012, Val_loss 3.488884925842285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.0909806966781614, Val_loss 3.5828750133514404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 49, Train_Loss 3.1029340028762817, Val_loss 3.4838106632232666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.104574728012085, Val_loss 3.5773134231567383\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.13177285194397, Val_loss 3.476949453353882\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 52, Train_Loss 3.1110625743865965, Val_loss 3.545417070388794\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.0993550539016725, Val_loss 3.5071613788604736\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.1280070781707763, Val_loss 3.523198366165161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.152423095703125, Val_loss 3.598284959793091\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 56, Train_Loss 3.1152170419692995, Val_loss 3.4482386112213135\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 57, Train_Loss 3.0635464429855346, Val_loss 3.4604127407073975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.098067831993103, Val_loss 3.47548770904541\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.088446760177612, Val_loss 3.4668290615081787\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.0956574201583864, Val_loss 3.5194485187530518\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.098091745376587, Val_loss 3.544795274734497\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.0911853075027467, Val_loss 3.4933664798736572\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 63, Train_Loss 3.0845124244689943, Val_loss 3.462017059326172\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.0687108039855957, Val_loss 3.4810526371002197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0846463441848755, Val_loss 3.4705989360809326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.113383388519287, Val_loss 3.515143632888794\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.0648581266403196, Val_loss 3.51397705078125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 68, Train_Loss 3.119869828224182, Val_loss 3.5283384323120117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.075859260559082, Val_loss 3.5027360916137695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.051869010925293, Val_loss 3.452385663986206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.0619958639144897, Val_loss 3.492906332015991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.0538291692733766, Val_loss 3.509509325027466\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0615712642669677, Val_loss 3.490001916885376\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0936374425888062, Val_loss 3.512244939804077\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 75, Train_Loss 3.0919707775115968, Val_loss 3.5311594009399414\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.055526685714722, Val_loss 3.4853193759918213\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.062972593307495, Val_loss 3.4825592041015625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.10235652923584, Val_loss 3.5006659030914307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 79, Train_Loss 3.098157835006714, Val_loss 3.509270429611206\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.0424774169921873, Val_loss 3.5063483715057373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0685741186141966, Val_loss 3.5125741958618164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.065397620201111, Val_loss 3.5079638957977295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.076507592201233, Val_loss 3.5241010189056396\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.0596808195114136, Val_loss 3.498586416244507\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.055037784576416, Val_loss 3.501352310180664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.0883207082748414, Val_loss 3.5087525844573975\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.0747565269470214, Val_loss 3.505131959915161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.0511191844940186, Val_loss 3.506304979324341\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.0216275215148927, Val_loss 3.49210524559021\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0630160093307497, Val_loss 3.4831321239471436\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.080398154258728, Val_loss 3.495351552963257\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.0834789991378786, Val_loss 3.4900128841400146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.0969961404800417, Val_loss 3.501516580581665\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.1067070960998535, Val_loss 3.514883041381836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.0797507047653196, Val_loss 3.4971582889556885\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.0653472185134887, Val_loss 3.5193862915039062\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.0831990003585816, Val_loss 3.515697479248047\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.093879723548889, Val_loss 3.5418918132781982\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.086291766166687, Val_loss 3.516916513442993\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.081009125709534, Val_loss 3.5321524143218994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9151397705078126, Val_loss 4.290826797485352\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.115191698074341, Val_loss 4.199070453643799\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 3, Train_Loss 4.05575213432312, Val_loss 4.127559185028076\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9334728002548216, Val_loss 4.074223041534424\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 5, Train_Loss 3.827191472053528, Val_loss 3.9593708515167236\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2562\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.769324541091919, Val_loss 3.7755401134490967\n",
      "Train_acc_top_20 0.2625\tTrain_acc_top_30 0.3688\tTrain_acc_top_40 0.4688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.6832980632781984, Val_loss 3.7052955627441406\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.7125\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.6180415868759157, Val_loss 3.6861541271209717\n",
      "Train_acc_top_20 0.6875\tTrain_acc_top_30 0.825\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5891672372817993, Val_loss 3.7797515392303467\n",
      "Train_acc_top_20 0.5938\tTrain_acc_top_30 0.7438\tTrain_acc_top_40 0.8\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.533886694908142, Val_loss 3.8026866912841797\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.493305778503418, Val_loss 3.4517414569854736\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.457303190231323, Val_loss 3.4951562881469727\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.3948612928390505, Val_loss 3.705686569213867\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3672061204910277, Val_loss 3.657123565673828\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.3173330307006834, Val_loss 3.4976043701171875\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.351325249671936, Val_loss 3.5600392818450928\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.332772731781006, Val_loss 3.449477195739746\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.3171310424804688, Val_loss 3.514655113220215\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.273105001449585, Val_loss 3.593191385269165\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2825591564178467, Val_loss 3.5051472187042236\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.29840407371521, Val_loss 3.5356738567352295\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.2099536180496218, Val_loss 3.5762054920196533\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 23, Train_Loss 3.2354945659637453, Val_loss 3.7701680660247803\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 24, Train_Loss 3.2278655767440796, Val_loss 3.526475667953491\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2689454317092896, Val_loss 3.5784361362457275\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.239621710777283, Val_loss 3.645209550857544\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.2416030406951903, Val_loss 3.4188148975372314\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.2154606580734253, Val_loss 3.5909595489501953\n",
      "Train_acc_top_20 0.6062\tTrain_acc_top_30 0.6875\tTrain_acc_top_40 0.7312\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.2316571950912474, Val_loss 3.9208409786224365\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.5\t\n",
      "Epoch 30, Train_Loss 3.213975739479065, Val_loss 3.543731927871704\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 31, Train_Loss 3.1499601364135743, Val_loss 3.4902212619781494\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.190556502342224, Val_loss 3.469454050064087\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.2740033626556397, Val_loss 3.6441729068756104\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.1517701148986816, Val_loss 3.5819473266601562\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 35, Train_Loss 3.169058632850647, Val_loss 3.4985551834106445\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 36, Train_Loss 3.2073676109313967, Val_loss 3.4304819107055664\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.127586555480957, Val_loss 3.3945958614349365\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.1454389095306396, Val_loss 3.524401903152466\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.22174186706543, Val_loss 3.484691858291626\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1528224468231203, Val_loss 3.441547393798828\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 41, Train_Loss 3.145741653442383, Val_loss 3.477705240249634\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1071225881576536, Val_loss 3.462399482727051\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1312726020812987, Val_loss 3.452838897705078\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 44, Train_Loss 3.0971258878707886, Val_loss 3.408612012863159\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.1873198747634888, Val_loss 3.4940929412841797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.098622751235962, Val_loss 3.5461089611053467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1322837591171266, Val_loss 3.442533254623413\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 48, Train_Loss 3.1626800060272218, Val_loss 3.4062840938568115\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.1125980854034423, Val_loss 3.5871078968048096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 50, Train_Loss 3.1229979753494264, Val_loss 3.4264824390411377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1234664916992188, Val_loss 3.5205166339874268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.131566548347473, Val_loss 3.4895200729370117\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.1169228553771973, Val_loss 3.4598944187164307\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.103386950492859, Val_loss 3.409388542175293\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.0787060976028444, Val_loss 3.4292850494384766\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1039583921432494, Val_loss 3.5311973094940186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.1698338270187376, Val_loss 3.459792137145996\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.147300100326538, Val_loss 3.4602720737457275\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 59, Train_Loss 3.0683417558670043, Val_loss 3.4852030277252197\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 60, Train_Loss 3.038521671295166, Val_loss 3.4726390838623047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 61, Train_Loss 3.087466239929199, Val_loss 3.477663040161133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 62, Train_Loss 3.075783133506775, Val_loss 3.4381625652313232\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.0389336824417112, Val_loss 3.437126874923706\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1356212854385377, Val_loss 3.397207260131836\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0542068243026734, Val_loss 3.4040908813476562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 66, Train_Loss 3.071703314781189, Val_loss 3.4175822734832764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.0374263763427733, Val_loss 3.405665397644043\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.103050637245178, Val_loss 3.584667921066284\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.0736711025238037, Val_loss 3.4869673252105713\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.0752121210098267, Val_loss 3.4433257579803467\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.0488280296325683, Val_loss 3.538924217224121\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 72, Train_Loss 3.1567497730255125, Val_loss 3.4468421936035156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.1153799533843993, Val_loss 3.4328062534332275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 74, Train_Loss 3.0938808917999268, Val_loss 3.425283193588257\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.1295547485351562, Val_loss 3.407386064529419\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.060429263114929, Val_loss 3.42679762840271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0933907270431518, Val_loss 3.4634227752685547\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.052871298789978, Val_loss 3.4503114223480225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 79, Train_Loss 3.0072008848190306, Val_loss 3.405012369155884\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.0684313058853148, Val_loss 3.4229202270507812\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 81, Train_Loss 3.1171077251434327, Val_loss 3.4325640201568604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 82, Train_Loss 3.0897810459136963, Val_loss 3.399780035018921\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 83, Train_Loss 3.1478042125701906, Val_loss 3.423121213912964\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.0869092464447023, Val_loss 3.454474449157715\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 85, Train_Loss 3.0959537029266357, Val_loss 3.413132905960083\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 86, Train_Loss 3.0443767309188843, Val_loss 3.485802412033081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 87, Train_Loss 3.0512098550796507, Val_loss 3.423654794692993\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.0720788478851317, Val_loss 3.4427757263183594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.1209425210952757, Val_loss 3.4498379230499268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.1187678575515747, Val_loss 3.4659512042999268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 91, Train_Loss 3.1127281665802, Val_loss 3.4937124252319336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0360357046127318, Val_loss 3.4449422359466553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 93, Train_Loss 3.0229527235031126, Val_loss 3.4923951625823975\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.045574498176575, Val_loss 3.4177563190460205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.0680052280426025, Val_loss 3.4643819332122803\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 96, Train_Loss 3.059353399276733, Val_loss 3.456610679626465\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 97, Train_Loss 3.0482672214508058, Val_loss 3.428826332092285\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 98, Train_Loss 3.0400043964385985, Val_loss 3.4461631774902344\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.1133124828338623, Val_loss 3.4531919956207275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 100, Train_Loss 3.1144450664520265, Val_loss 3.4548299312591553\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.9226216077804565, Val_loss 4.277793884277344\n",
      "Train_acc_top_20 0.0437\tTrain_acc_top_30 0.0875\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.08\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.133200645446777, Val_loss 4.300155162811279\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 3, Train_Loss 4.093538856506347, Val_loss 4.307919979095459\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 4, Train_Loss 3.9674482583999633, Val_loss 4.201074600219727\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1812\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.04\tVal_acc_top_40 0.04\t\n",
      "Epoch 5, Train_Loss 3.858991837501526, Val_loss 3.994830369949341\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2437\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.8196999788284303, Val_loss 3.8236019611358643\n",
      "Train_acc_top_20 0.2812\tTrain_acc_top_30 0.3875\tTrain_acc_top_40 0.4875\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 7, Train_Loss 3.705649733543396, Val_loss 3.7603111267089844\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.675\tTrain_acc_top_40 0.775\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 8, Train_Loss 3.6322428703308107, Val_loss 3.7345430850982666\n",
      "Train_acc_top_20 0.6687\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.6263018608093263, Val_loss 3.721395254135132\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.825\tTrain_acc_top_40 0.9\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.5593082427978517, Val_loss 3.6703968048095703\n",
      "Train_acc_top_20 0.8438\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.524411916732788, Val_loss 3.7595717906951904\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 12, Train_Loss 3.5066994190216065, Val_loss 3.615300178527832\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 13, Train_Loss 3.465287184715271, Val_loss 3.772217035293579\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.4215986728668213, Val_loss 3.604750871658325\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 15, Train_Loss 3.3949713945388793, Val_loss 3.6227846145629883\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.346865510940552, Val_loss 3.622666120529175\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 17, Train_Loss 3.3613163232803345, Val_loss 3.585330009460449\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.329268717765808, Val_loss 3.6476542949676514\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.3018041372299196, Val_loss 3.528778076171875\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2465903520584107, Val_loss 3.6106655597686768\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.2779404163360595, Val_loss 3.555905342102051\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.253229260444641, Val_loss 3.5919952392578125\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.2726104974746706, Val_loss 3.641709566116333\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 24, Train_Loss 3.262715554237366, Val_loss 3.565030813217163\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 25, Train_Loss 3.20292329788208, Val_loss 3.568898916244507\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 26, Train_Loss 3.216224431991577, Val_loss 3.6807448863983154\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 27, Train_Loss 3.2421371936798096, Val_loss 3.530097246170044\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.199207830429077, Val_loss 3.6015093326568604\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 29, Train_Loss 3.187859892845154, Val_loss 3.528613328933716\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 30, Train_Loss 3.1814762353897095, Val_loss 3.6939008235931396\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.1820010423660277, Val_loss 3.5544071197509766\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 32, Train_Loss 3.2029747009277343, Val_loss 3.586857795715332\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 33, Train_Loss 3.167825698852539, Val_loss 3.4806582927703857\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.146601414680481, Val_loss 3.4868462085723877\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 35, Train_Loss 3.132551670074463, Val_loss 3.5104119777679443\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 36, Train_Loss 3.206253695487976, Val_loss 3.5562808513641357\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.14534068107605, Val_loss 3.5343666076660156\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1240710258483886, Val_loss 3.627387046813965\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 39, Train_Loss 3.146590065956116, Val_loss 3.4590647220611572\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 40, Train_Loss 3.148956060409546, Val_loss 3.4551546573638916\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 41, Train_Loss 3.1120617628097533, Val_loss 3.472820997238159\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 42, Train_Loss 3.1429401874542235, Val_loss 3.5821304321289062\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 43, Train_Loss 3.094479727745056, Val_loss 3.479336977005005\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 44, Train_Loss 3.1166689872741697, Val_loss 3.4518516063690186\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1555375814437867, Val_loss 3.513002395629883\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.087906551361084, Val_loss 3.519190788269043\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 47, Train_Loss 3.0792128086090087, Val_loss 3.421149253845215\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.122513937950134, Val_loss 3.46701717376709\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.126239228248596, Val_loss 3.5603458881378174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 50, Train_Loss 3.1327985763549804, Val_loss 3.495471954345703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.1486337661743162, Val_loss 3.4985320568084717\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.0527905225753784, Val_loss 3.5237505435943604\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 53, Train_Loss 3.125359320640564, Val_loss 3.4925267696380615\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 54, Train_Loss 3.076495146751404, Val_loss 3.4222848415374756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.07229106426239, Val_loss 3.4584169387817383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.0868231534957884, Val_loss 3.507093667984009\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 57, Train_Loss 3.1177215576171875, Val_loss 3.4742658138275146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 58, Train_Loss 3.0983369827270506, Val_loss 3.5593106746673584\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.0997408866882323, Val_loss 3.497452974319458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 60, Train_Loss 3.056472110748291, Val_loss 3.4364442825317383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 61, Train_Loss 3.094731068611145, Val_loss 3.5142428874969482\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 62, Train_Loss 3.0884645223617553, Val_loss 3.4108707904815674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 63, Train_Loss 3.078601861000061, Val_loss 3.5242080688476562\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.099852991104126, Val_loss 3.4938862323760986\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 65, Train_Loss 3.126484203338623, Val_loss 3.5064237117767334\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.0637482166290284, Val_loss 3.482624053955078\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0889994621276857, Val_loss 3.4571754932403564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 68, Train_Loss 3.113056755065918, Val_loss 3.4732227325439453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 69, Train_Loss 3.079421806335449, Val_loss 3.566730260848999\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.0621087551116943, Val_loss 3.4970343112945557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 71, Train_Loss 3.086485409736633, Val_loss 3.4315195083618164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 72, Train_Loss 3.073021483421326, Val_loss 3.4476423263549805\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0522801637649537, Val_loss 3.5543746948242188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 74, Train_Loss 3.049621105194092, Val_loss 3.473237991333008\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.1042429208755493, Val_loss 3.4823544025421143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 76, Train_Loss 3.0768792390823365, Val_loss 3.4418294429779053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 77, Train_Loss 3.089680862426758, Val_loss 3.475792646408081\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 78, Train_Loss 3.100787401199341, Val_loss 3.509765386581421\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.0683960199356077, Val_loss 3.523094892501831\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 80, Train_Loss 3.0619027614593506, Val_loss 3.4525279998779297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 81, Train_Loss 3.0582471609115602, Val_loss 3.4440689086914062\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 82, Train_Loss 3.081507658958435, Val_loss 3.4899232387542725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 83, Train_Loss 3.059794521331787, Val_loss 3.467621088027954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 84, Train_Loss 3.0507978916168215, Val_loss 3.4715473651885986\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 85, Train_Loss 3.0523324489593504, Val_loss 3.4638168811798096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 86, Train_Loss 3.1074899196624757, Val_loss 3.4571285247802734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.099711227416992, Val_loss 3.4776172637939453\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.0890801429748533, Val_loss 3.492295265197754\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.061351013183594, Val_loss 3.4830589294433594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 90, Train_Loss 3.0905837059020995, Val_loss 3.485140085220337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.0904924154281614, Val_loss 3.4822628498077393\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.077495980262756, Val_loss 3.5183680057525635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 93, Train_Loss 3.087031388282776, Val_loss 3.493417501449585\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.031282067298889, Val_loss 3.4650888442993164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 95, Train_Loss 3.0834900617599486, Val_loss 3.506422996520996\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 96, Train_Loss 3.0561076641082763, Val_loss 3.4917852878570557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 97, Train_Loss 3.0883005380630495, Val_loss 3.4656717777252197\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 98, Train_Loss 3.0603863477706907, Val_loss 3.513706922531128\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 99, Train_Loss 3.0513309717178343, Val_loss 3.4550106525421143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 100, Train_Loss 3.0527049779891966, Val_loss 3.4641149044036865\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 1, Train_Loss 3.9326372385025024, Val_loss 4.271519184112549\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.129915857315064, Val_loss 4.216615200042725\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 3, Train_Loss 4.0823721408844, Val_loss 4.231185436248779\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 4, Train_Loss 3.974005198478699, Val_loss 4.218810558319092\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8496723651885985, Val_loss 4.086085796356201\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1313\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 6, Train_Loss 3.771843957901001, Val_loss 3.86025333404541\n",
      "Train_acc_top_20 0.2\tTrain_acc_top_30 0.3375\tTrain_acc_top_40 0.4125\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.38\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.7165754079818725, Val_loss 3.8711225986480713\n",
      "Train_acc_top_20 0.5062\tTrain_acc_top_30 0.6625\tTrain_acc_top_40 0.7\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.5\t\n",
      "Epoch 8, Train_Loss 3.6311543703079225, Val_loss 3.693495512008667\n",
      "Train_acc_top_20 0.65\tTrain_acc_top_30 0.7875\tTrain_acc_top_40 0.875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5990002870559694, Val_loss 3.625319480895996\n",
      "Train_acc_top_20 0.7562\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.528199291229248, Val_loss 3.7679574489593506\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 11, Train_Loss 3.4936046600341797, Val_loss 3.6441385746002197\n",
      "Train_acc_top_20 0.8125\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.9563\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.4362914085388185, Val_loss 3.7202682495117188\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 13, Train_Loss 3.4095542430877686, Val_loss 3.6903793811798096\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3959070444107056, Val_loss 3.585937261581421\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.377205491065979, Val_loss 3.6307525634765625\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 16, Train_Loss 3.3267143249511717, Val_loss 3.517390251159668\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 17, Train_Loss 3.3111524105072023, Val_loss 3.565479278564453\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 18, Train_Loss 3.288019800186157, Val_loss 3.57255482673645\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 19, Train_Loss 3.253190517425537, Val_loss 3.5452966690063477\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2573802947998045, Val_loss 3.462750196456909\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 21, Train_Loss 3.2371191024780273, Val_loss 3.65435528755188\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.291493463516235, Val_loss 3.590928077697754\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9187\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 23, Train_Loss 3.278111386299133, Val_loss 3.806640863418579\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 24, Train_Loss 3.2913708686828613, Val_loss 3.556854248046875\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 25, Train_Loss 3.2599978685379027, Val_loss 3.538198471069336\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.2727696657180787, Val_loss 3.5184438228607178\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 27, Train_Loss 3.251241397857666, Val_loss 3.6038272380828857\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1707782983779906, Val_loss 3.45927357673645\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 29, Train_Loss 3.210853028297424, Val_loss 3.487915277481079\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 30, Train_Loss 3.175176906585693, Val_loss 3.5178334712982178\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.261714744567871, Val_loss 3.496617078781128\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 32, Train_Loss 3.203468418121338, Val_loss 3.4442625045776367\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.184317183494568, Val_loss 3.5227432250976562\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 34, Train_Loss 3.2423815011978148, Val_loss 3.435750961303711\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.16710946559906, Val_loss 3.4411628246307373\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 36, Train_Loss 3.1607209920883177, Val_loss 3.5740230083465576\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1857353687286376, Val_loss 3.44921612739563\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.147365140914917, Val_loss 3.4798479080200195\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 39, Train_Loss 3.1880783081054687, Val_loss 3.447892427444458\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 40, Train_Loss 3.146157717704773, Val_loss 3.455159902572632\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 41, Train_Loss 3.1931633710861207, Val_loss 3.539876699447632\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1662874937057497, Val_loss 3.510370969772339\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 43, Train_Loss 3.1534758806228638, Val_loss 3.432724952697754\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 44, Train_Loss 3.1846121072769167, Val_loss 3.5052411556243896\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 45, Train_Loss 3.146762657165527, Val_loss 3.5851221084594727\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.1143469333648683, Val_loss 3.5071067810058594\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.113627552986145, Val_loss 3.437779188156128\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.2058117389678955, Val_loss 3.4817683696746826\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.2293370962142944, Val_loss 3.509370803833008\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 50, Train_Loss 3.1635955572128296, Val_loss 3.481132745742798\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1469478607177734, Val_loss 3.472334146499634\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.121664357185364, Val_loss 3.4829089641571045\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.1005507946014403, Val_loss 3.4805068969726562\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 54, Train_Loss 3.086735415458679, Val_loss 3.436579465866089\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 55, Train_Loss 3.159567379951477, Val_loss 3.419538736343384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 56, Train_Loss 3.1032741546630858, Val_loss 3.5002968311309814\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.0982519388198853, Val_loss 3.4055891036987305\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.113201713562012, Val_loss 3.447946786880493\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 59, Train_Loss 3.129748511314392, Val_loss 3.4568605422973633\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 60, Train_Loss 3.137484097480774, Val_loss 3.448902130126953\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 61, Train_Loss 3.088999128341675, Val_loss 3.5396616458892822\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 62, Train_Loss 3.1225303173065186, Val_loss 3.4951632022857666\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 63, Train_Loss 3.100478935241699, Val_loss 3.422266721725464\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 64, Train_Loss 3.0940357208251954, Val_loss 3.4028947353363037\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 65, Train_Loss 3.079147553443909, Val_loss 3.410442590713501\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 66, Train_Loss 3.047468113899231, Val_loss 3.415480852127075\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.1004444122314454, Val_loss 3.466069221496582\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.140466022491455, Val_loss 3.404081344604492\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 69, Train_Loss 3.09161376953125, Val_loss 3.4930524826049805\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 70, Train_Loss 3.1122029304504393, Val_loss 3.4130287170410156\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 71, Train_Loss 3.0987809896469116, Val_loss 3.4312584400177\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0581833839416506, Val_loss 3.4438064098358154\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.0421241760253905, Val_loss 3.403552293777466\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.0295357942581176, Val_loss 3.426630735397339\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.0650039196014403, Val_loss 3.4203109741210938\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 76, Train_Loss 3.0845784664154055, Val_loss 3.4423458576202393\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 77, Train_Loss 2.997956156730652, Val_loss 3.4268176555633545\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 78, Train_Loss 3.100662183761597, Val_loss 3.4305832386016846\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.109230899810791, Val_loss 3.430678129196167\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.1253329515457153, Val_loss 3.4340693950653076\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 81, Train_Loss 3.1084515333175657, Val_loss 3.461015462875366\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.138020896911621, Val_loss 3.465294599533081\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.1416388750076294, Val_loss 3.4541914463043213\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 84, Train_Loss 3.080068755149841, Val_loss 3.4270896911621094\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 85, Train_Loss 3.069233512878418, Val_loss 3.402808427810669\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 86, Train_Loss 3.091508984565735, Val_loss 3.41115665435791\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 87, Train_Loss 3.1728522539138795, Val_loss 3.467860221862793\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 88, Train_Loss 3.0844974279403687, Val_loss 3.422713279724121\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 89, Train_Loss 3.1140357732772825, Val_loss 3.4373815059661865\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 90, Train_Loss 3.135193967819214, Val_loss 3.464103937149048\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 91, Train_Loss 3.076682686805725, Val_loss 3.405705451965332\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 92, Train_Loss 3.0877667665481567, Val_loss 3.4131357669830322\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.083795356750488, Val_loss 3.4385335445404053\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 94, Train_Loss 3.0428552865982055, Val_loss 3.4065020084381104\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 95, Train_Loss 3.0896108627319334, Val_loss 3.440357208251953\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 96, Train_Loss 3.1388440847396852, Val_loss 3.4737370014190674\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 97, Train_Loss 3.0793493509292604, Val_loss 3.447550058364868\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 98, Train_Loss 3.098304009437561, Val_loss 3.466317892074585\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 99, Train_Loss 3.0416599035263063, Val_loss 3.4035444259643555\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.057556390762329, Val_loss 3.425903081893921\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.919178009033203, Val_loss 4.292656898498535\n",
      "Train_acc_top_20 0.1562\tTrain_acc_top_30 0.2\tTrain_acc_top_40 0.2687\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.0\tVal_acc_top_40 0.08\t\n",
      "Epoch 2, Train_Loss 4.10849084854126, Val_loss 4.208126068115234\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 3, Train_Loss 4.047329378128052, Val_loss 4.171548843383789\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.8922762632369996, Val_loss 4.086463451385498\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.7891286849975585, Val_loss 3.948195457458496\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.1875\t\n",
      "Val_acc_top_20 0.0\tVal_acc_top_30 0.25\tVal_acc_top_40 0.29\t\n",
      "Epoch 6, Train_Loss 3.7427106857299806, Val_loss 3.8212738037109375\n",
      "Train_acc_top_20 0.2875\tTrain_acc_top_30 0.3937\tTrain_acc_top_40 0.4375\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 7, Train_Loss 3.645453119277954, Val_loss 3.879979372024536\n",
      "Train_acc_top_20 0.5813\tTrain_acc_top_30 0.7188\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.33\tVal_acc_top_40 0.58\t\n",
      "Epoch 8, Train_Loss 3.557089638710022, Val_loss 3.8564529418945312\n",
      "Train_acc_top_20 0.7937\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 9, Train_Loss 3.554227089881897, Val_loss 3.855309247970581\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9125\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.62\t\n",
      "Epoch 10, Train_Loss 3.483846116065979, Val_loss 3.8227450847625732\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.8938\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.42\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.445194673538208, Val_loss 3.6589889526367188\n",
      "Train_acc_top_20 0.7875\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 12, Train_Loss 3.412506413459778, Val_loss 3.719115972518921\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.3683266162872316, Val_loss 3.6913297176361084\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 14, Train_Loss 3.3291539907455445, Val_loss 3.7376673221588135\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 15, Train_Loss 3.333768701553345, Val_loss 3.70041561126709\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 16, Train_Loss 3.327588963508606, Val_loss 3.637197494506836\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.2816874027252196, Val_loss 3.5749690532684326\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 18, Train_Loss 3.277401852607727, Val_loss 3.5757787227630615\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 19, Train_Loss 3.282368564605713, Val_loss 3.673330545425415\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 20, Train_Loss 3.2264636754989624, Val_loss 3.717989206314087\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.2440190076828004, Val_loss 3.5757572650909424\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 22, Train_Loss 3.2102410554885865, Val_loss 3.5960052013397217\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.1879503965377807, Val_loss 3.5809357166290283\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.1923309087753298, Val_loss 3.59665584564209\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.1748338460922243, Val_loss 3.6730825901031494\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.167996859550476, Val_loss 3.5825564861297607\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.2030481576919554, Val_loss 3.5780203342437744\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 28, Train_Loss 3.1751445293426515, Val_loss 3.658951759338379\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 29, Train_Loss 3.1555158615112306, Val_loss 3.7091548442840576\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 30, Train_Loss 3.160837435722351, Val_loss 3.580172538757324\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 31, Train_Loss 3.165754461288452, Val_loss 3.587735414505005\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.2331831455230713, Val_loss 3.626662492752075\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.2065736770629885, Val_loss 3.624227285385132\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 34, Train_Loss 3.161031794548035, Val_loss 3.600609540939331\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1862446308135985, Val_loss 3.5634634494781494\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.190703296661377, Val_loss 3.589487075805664\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 37, Train_Loss 3.147152066230774, Val_loss 3.644785165786743\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 38, Train_Loss 3.1471744537353517, Val_loss 3.529550790786743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.133099985122681, Val_loss 3.5390784740448\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.089446210861206, Val_loss 3.509174346923828\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 41, Train_Loss 3.102582859992981, Val_loss 3.652921676635742\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.099095869064331, Val_loss 3.579631805419922\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.118383026123047, Val_loss 3.6843698024749756\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.099098634719849, Val_loss 3.525718927383423\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 45, Train_Loss 3.1554974555969237, Val_loss 3.6038618087768555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1150290727615357, Val_loss 3.563831090927124\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 47, Train_Loss 3.2015485763549805, Val_loss 3.4407033920288086\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 48, Train_Loss 3.183513879776001, Val_loss 3.536288261413574\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 49, Train_Loss 3.1821727752685547, Val_loss 3.5862414836883545\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.0842517375946046, Val_loss 3.4885101318359375\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 51, Train_Loss 3.1305533409118653, Val_loss 3.6577064990997314\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.103237247467041, Val_loss 3.5531022548675537\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.110885667800903, Val_loss 3.527693748474121\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.0560354709625246, Val_loss 3.5301849842071533\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.136359930038452, Val_loss 3.562652349472046\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 56, Train_Loss 3.0981089591979982, Val_loss 3.5097782611846924\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 57, Train_Loss 3.0683680057525633, Val_loss 3.6066579818725586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.155910015106201, Val_loss 3.57672119140625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 59, Train_Loss 3.1077094793319704, Val_loss 3.5323894023895264\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 60, Train_Loss 3.077417731285095, Val_loss 3.5768020153045654\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.0808902740478517, Val_loss 3.542497396469116\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.1162232160568237, Val_loss 3.5028164386749268\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.071168613433838, Val_loss 3.495114326477051\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 64, Train_Loss 3.1582124710083006, Val_loss 3.592636823654175\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 65, Train_Loss 3.086155414581299, Val_loss 3.6020796298980713\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 66, Train_Loss 3.0734050273895264, Val_loss 3.5531978607177734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 67, Train_Loss 3.0746332168579102, Val_loss 3.597757339477539\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.120319390296936, Val_loss 3.5765466690063477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.11658661365509, Val_loss 3.621703863143921\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 70, Train_Loss 3.122570610046387, Val_loss 3.44360089302063\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.124410939216614, Val_loss 3.42453932762146\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.0771833181381227, Val_loss 3.501201868057251\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 73, Train_Loss 3.090723085403442, Val_loss 3.485605239868164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.0753366947174072, Val_loss 3.505042791366577\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.062500739097595, Val_loss 3.533116102218628\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.056702709197998, Val_loss 3.556518793106079\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.020389699935913, Val_loss 3.4973113536834717\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.076981616020203, Val_loss 3.4947497844696045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.1320369482040404, Val_loss 3.5261242389678955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 80, Train_Loss 3.062582540512085, Val_loss 3.5264170169830322\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.061905097961426, Val_loss 3.4943063259124756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0320876359939577, Val_loss 3.4939157962799072\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0433853387832643, Val_loss 3.4515316486358643\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 84, Train_Loss 3.0580281972885133, Val_loss 3.4770419597625732\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0630444526672362, Val_loss 3.5216712951660156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.1166284561157225, Val_loss 3.5211598873138428\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0480398416519163, Val_loss 3.4700167179107666\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.10291645526886, Val_loss 3.484379768371582\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 89, Train_Loss 3.0873127937316895, Val_loss 3.517787218093872\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 90, Train_Loss 3.0652462959289553, Val_loss 3.504897117614746\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.065553140640259, Val_loss 3.461470603942871\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 92, Train_Loss 3.043632698059082, Val_loss 3.4490087032318115\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.0371187210083006, Val_loss 3.4673893451690674\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.055168032646179, Val_loss 3.485178232192993\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 95, Train_Loss 3.0573372840881348, Val_loss 3.509653329849243\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.01998610496521, Val_loss 3.469446897506714\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.0472591400146483, Val_loss 3.488645553588867\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.0225032329559327, Val_loss 3.46506667137146\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 99, Train_Loss 3.0361016511917116, Val_loss 3.4915101528167725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0589783906936647, Val_loss 3.512631416320801\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 1, Train_Loss 3.919935202598572, Val_loss 4.318578243255615\n",
      "Train_acc_top_20 0.0563\tTrain_acc_top_30 0.1187\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.21\t\n",
      "Epoch 2, Train_Loss 4.122848176956177, Val_loss 4.275087833404541\n",
      "Train_acc_top_20 0.1313\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 3, Train_Loss 4.055313920974731, Val_loss 4.2648844718933105\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.12\t\n",
      "Epoch 4, Train_Loss 3.9121379613876344, Val_loss 4.105367183685303\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8320526361465452, Val_loss 3.920686960220337\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.21\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.7183794021606444, Val_loss 3.82599139213562\n",
      "Train_acc_top_20 0.3187\tTrain_acc_top_30 0.4188\tTrain_acc_top_40 0.525\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.33\tVal_acc_top_40 0.46\t\n",
      "Epoch 7, Train_Loss 3.6410121440887453, Val_loss 3.8225011825561523\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.8125\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.58\tVal_acc_top_40 0.83\t\n",
      "Epoch 8, Train_Loss 3.581054711341858, Val_loss 3.7706611156463623\n",
      "Train_acc_top_20 0.775\tTrain_acc_top_30 0.9187\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.5346184968948364, Val_loss 3.726396322250366\n",
      "Train_acc_top_20 0.825\tTrain_acc_top_30 0.9375\tTrain_acc_top_40 0.9625\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 10, Train_Loss 3.4517513036727907, Val_loss 3.6748621463775635\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 11, Train_Loss 3.4147196054458617, Val_loss 3.715374231338501\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 12, Train_Loss 3.3875568151474, Val_loss 3.685610055923462\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 13, Train_Loss 3.354779100418091, Val_loss 3.653139352798462\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3208747625350954, Val_loss 3.6936709880828857\n",
      "Train_acc_top_20 0.925\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 15, Train_Loss 3.344929575920105, Val_loss 3.6375253200531006\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.83\t\n",
      "Epoch 16, Train_Loss 3.2728285074234007, Val_loss 3.650456428527832\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 17, Train_Loss 3.248108148574829, Val_loss 3.6189544200897217\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 18, Train_Loss 3.231715750694275, Val_loss 3.6386377811431885\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.213624453544617, Val_loss 3.6919689178466797\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 20, Train_Loss 3.348333716392517, Val_loss 3.600536346435547\n",
      "Train_acc_top_20 0.8063\tTrain_acc_top_30 0.9062\tTrain_acc_top_40 0.95\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 21, Train_Loss 3.3135050535202026, Val_loss 3.6062285900115967\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 22, Train_Loss 3.269244885444641, Val_loss 3.69510817527771\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.46\tVal_acc_top_40 0.62\t\n",
      "Epoch 23, Train_Loss 3.197419786453247, Val_loss 3.6702802181243896\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 24, Train_Loss 3.1763038873672484, Val_loss 3.6176207065582275\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.1745258569717407, Val_loss 3.5673656463623047\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 26, Train_Loss 3.146048092842102, Val_loss 3.6049253940582275\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 27, Train_Loss 3.198181176185608, Val_loss 3.672541379928589\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 28, Train_Loss 3.171873617172241, Val_loss 3.6175830364227295\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 29, Train_Loss 3.1428928136825562, Val_loss 3.589609146118164\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.183086967468262, Val_loss 3.561746597290039\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 31, Train_Loss 3.155994939804077, Val_loss 3.6619513034820557\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 32, Train_Loss 3.1613667488098143, Val_loss 3.6657307147979736\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 33, Train_Loss 3.190191721916199, Val_loss 3.69221568107605\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.46\tVal_acc_top_40 0.54\t\n",
      "Epoch 34, Train_Loss 3.1509020566940307, Val_loss 3.5703999996185303\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 35, Train_Loss 3.1507578611373903, Val_loss 3.565497398376465\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1156237363815307, Val_loss 3.6546781063079834\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.58\t\n",
      "Epoch 37, Train_Loss 3.109732222557068, Val_loss 3.596302032470703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 38, Train_Loss 3.105231285095215, Val_loss 3.6788365840911865\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.58\t\n",
      "Epoch 39, Train_Loss 3.1230337381362916, Val_loss 3.6517813205718994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.1018217325210573, Val_loss 3.6431283950805664\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 41, Train_Loss 3.108271527290344, Val_loss 3.6081488132476807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 42, Train_Loss 3.084301209449768, Val_loss 3.5721235275268555\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 43, Train_Loss 3.1057331562042236, Val_loss 3.6821975708007812\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 44, Train_Loss 3.056839871406555, Val_loss 3.714688539505005\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.5\tVal_acc_top_40 0.54\t\n",
      "Epoch 45, Train_Loss 3.1105361461639403, Val_loss 3.670011281967163\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 46, Train_Loss 3.063335633277893, Val_loss 3.5848190784454346\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 47, Train_Loss 3.0855358839035034, Val_loss 3.6543452739715576\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 48, Train_Loss 3.070189642906189, Val_loss 3.5592634677886963\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.0527758598327637, Val_loss 3.66166090965271\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.0561673641204834, Val_loss 3.6492156982421875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.079750180244446, Val_loss 3.636730432510376\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 52, Train_Loss 3.032168483734131, Val_loss 3.63897705078125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 53, Train_Loss 3.08061306476593, Val_loss 3.6643495559692383\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.0799363374710085, Val_loss 3.704313278198242\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 55, Train_Loss 3.0221596479415895, Val_loss 3.6089465618133545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 56, Train_Loss 3.106430196762085, Val_loss 3.591372489929199\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 57, Train_Loss 3.0986526727676393, Val_loss 3.6160967350006104\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 58, Train_Loss 3.1155686140060426, Val_loss 3.591796875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 59, Train_Loss 3.085509181022644, Val_loss 3.602327585220337\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 60, Train_Loss 3.0742072582244875, Val_loss 3.6283271312713623\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 61, Train_Loss 3.026396465301514, Val_loss 3.595919609069824\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 62, Train_Loss 3.0238093614578245, Val_loss 3.6462907791137695\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 63, Train_Loss 3.1172303676605226, Val_loss 3.623152017593384\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 64, Train_Loss 3.0720993757247923, Val_loss 3.5965983867645264\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 65, Train_Loss 3.060567259788513, Val_loss 3.5756003856658936\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 66, Train_Loss 3.122210168838501, Val_loss 3.6164772510528564\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 67, Train_Loss 3.0611647844314573, Val_loss 3.600623369216919\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 68, Train_Loss 3.034343957901001, Val_loss 3.572122812271118\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 69, Train_Loss 3.0414731740951537, Val_loss 3.58640456199646\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 70, Train_Loss 3.084196186065674, Val_loss 3.6570494174957275\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 71, Train_Loss 3.046757626533508, Val_loss 3.597728729248047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 72, Train_Loss 3.089749240875244, Val_loss 3.643641710281372\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 73, Train_Loss 3.0389956712722777, Val_loss 3.6112844944000244\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 74, Train_Loss 3.0768362522125243, Val_loss 3.6117851734161377\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 75, Train_Loss 3.047437047958374, Val_loss 3.6128432750701904\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 76, Train_Loss 3.029346251487732, Val_loss 3.66096568107605\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 77, Train_Loss 3.0963205814361574, Val_loss 3.654510736465454\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 78, Train_Loss 3.0542944431304933, Val_loss 3.6650686264038086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 79, Train_Loss 3.048380494117737, Val_loss 3.6511995792388916\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 80, Train_Loss 3.0246949434280395, Val_loss 3.6372787952423096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 81, Train_Loss 3.065399098396301, Val_loss 3.632131338119507\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 82, Train_Loss 3.0701733589172364, Val_loss 3.6045522689819336\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 83, Train_Loss 3.081020879745483, Val_loss 3.6045291423797607\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 84, Train_Loss 3.062898874282837, Val_loss 3.5881919860839844\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 85, Train_Loss 3.0936487913131714, Val_loss 3.655352830886841\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 86, Train_Loss 3.0403016567230225, Val_loss 3.5908472537994385\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 87, Train_Loss 3.01348397731781, Val_loss 3.5858590602874756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 88, Train_Loss 3.061943292617798, Val_loss 3.614394187927246\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 89, Train_Loss 3.03559033870697, Val_loss 3.6061789989471436\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 90, Train_Loss 3.0385260343551637, Val_loss 3.61373233795166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 91, Train_Loss 3.0780503273010256, Val_loss 3.5963306427001953\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 92, Train_Loss 3.128919005393982, Val_loss 3.594036340713501\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 93, Train_Loss 3.0587358236312867, Val_loss 3.6096484661102295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 94, Train_Loss 3.052863526344299, Val_loss 3.592709541320801\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 95, Train_Loss 3.070457911491394, Val_loss 3.6190507411956787\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 96, Train_Loss 3.0113261938095093, Val_loss 3.6041924953460693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 97, Train_Loss 3.063941478729248, Val_loss 3.6080474853515625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 98, Train_Loss 3.0361769914627077, Val_loss 3.654909133911133\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 99, Train_Loss 3.0092600107192995, Val_loss 3.6030991077423096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 100, Train_Loss 3.062559795379639, Val_loss 3.640310049057007\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 1, Train_Loss 3.9317355394363402, Val_loss 4.31719446182251\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1375\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.12\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 2, Train_Loss 4.1174400806427, Val_loss 4.30145788192749\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.064819765090943, Val_loss 4.300401210784912\n",
      "Train_acc_top_20 0.0875\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2125\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9486332654953005, Val_loss 4.261807918548584\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 5, Train_Loss 3.8627145290374756, Val_loss 4.161423206329346\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.1812\t\n",
      "Val_acc_top_20 0.08\tVal_acc_top_30 0.12\tVal_acc_top_40 0.21\t\n",
      "Epoch 6, Train_Loss 3.770165133476257, Val_loss 3.7986743450164795\n",
      "Train_acc_top_20 0.35\tTrain_acc_top_30 0.4375\tTrain_acc_top_40 0.5375\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 7, Train_Loss 3.7353286504745484, Val_loss 3.68802809715271\n",
      "Train_acc_top_20 0.5687\tTrain_acc_top_30 0.6937\tTrain_acc_top_40 0.8187\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 8, Train_Loss 3.699986124038696, Val_loss 3.7247743606567383\n",
      "Train_acc_top_20 0.6687\tTrain_acc_top_30 0.7812\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.88\t\n",
      "Epoch 9, Train_Loss 3.606781315803528, Val_loss 3.5418508052825928\n",
      "Train_acc_top_20 0.7\tTrain_acc_top_30 0.7875\tTrain_acc_top_40 0.8812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 10, Train_Loss 3.566564178466797, Val_loss 3.547098159790039\n",
      "Train_acc_top_20 0.6875\tTrain_acc_top_30 0.825\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 11, Train_Loss 3.523120903968811, Val_loss 3.5829360485076904\n",
      "Train_acc_top_20 0.7312\tTrain_acc_top_30 0.875\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 12, Train_Loss 3.45845513343811, Val_loss 3.5786421298980713\n",
      "Train_acc_top_20 0.7812\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 13, Train_Loss 3.4341389656066896, Val_loss 3.5223236083984375\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 14, Train_Loss 3.431905436515808, Val_loss 3.5728302001953125\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 15, Train_Loss 3.4068757772445677, Val_loss 3.5867090225219727\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3475292921066284, Val_loss 3.507232666015625\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 17, Train_Loss 3.355711269378662, Val_loss 3.577094793319702\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 18, Train_Loss 3.306014633178711, Val_loss 3.4330685138702393\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 19, Train_Loss 3.278844213485718, Val_loss 3.519839286804199\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 20, Train_Loss 3.2800894260406492, Val_loss 3.41797137260437\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 21, Train_Loss 3.264672136306763, Val_loss 3.434767484664917\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.223013687133789, Val_loss 3.4940803050994873\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 23, Train_Loss 3.212954044342041, Val_loss 3.446697950363159\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 24, Train_Loss 3.189642238616943, Val_loss 3.4498374462127686\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 25, Train_Loss 3.2780248880386353, Val_loss 3.5485422611236572\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 26, Train_Loss 3.2115569829940798, Val_loss 3.3996222019195557\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 1.0\t\n",
      "Epoch 27, Train_Loss 3.252311134338379, Val_loss 3.5396993160247803\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 28, Train_Loss 3.196631646156311, Val_loss 3.464881658554077\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 29, Train_Loss 3.215291142463684, Val_loss 3.5238683223724365\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 30, Train_Loss 3.137559247016907, Val_loss 3.5650579929351807\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.174901819229126, Val_loss 3.4778363704681396\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 32, Train_Loss 3.1537829399108888, Val_loss 3.5461199283599854\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 33, Train_Loss 3.177174472808838, Val_loss 3.4590566158294678\n",
      "Train_acc_top_20 0.9437\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.141530752182007, Val_loss 3.4343202114105225\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.1762658596038817, Val_loss 3.588979482650757\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1523425817489623, Val_loss 3.462387800216675\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 37, Train_Loss 3.1602540969848634, Val_loss 3.536789655685425\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 38, Train_Loss 3.17112557888031, Val_loss 3.485119104385376\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 39, Train_Loss 3.13774995803833, Val_loss 3.4025356769561768\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 40, Train_Loss 3.18133430480957, Val_loss 3.37479567527771\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 41, Train_Loss 3.122043514251709, Val_loss 3.4618375301361084\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 42, Train_Loss 3.1451635122299195, Val_loss 3.446881055831909\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 43, Train_Loss 3.089097261428833, Val_loss 3.3995606899261475\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 44, Train_Loss 3.13410005569458, Val_loss 3.4426705837249756\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.121895933151245, Val_loss 3.3846609592437744\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 46, Train_Loss 3.1263938426971434, Val_loss 3.4596176147460938\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.96\tVal_acc_top_40 0.96\t\n",
      "Epoch 47, Train_Loss 3.171128749847412, Val_loss 3.4118213653564453\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.96\t\n",
      "Epoch 48, Train_Loss 3.166127014160156, Val_loss 3.4554672241210938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 49, Train_Loss 3.110749387741089, Val_loss 3.3584213256835938\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.92\tVal_acc_top_40 0.92\t\n",
      "Epoch 50, Train_Loss 3.122620701789856, Val_loss 3.454069137573242\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 51, Train_Loss 3.124087405204773, Val_loss 3.3807461261749268\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 52, Train_Loss 3.0979172468185423, Val_loss 3.4428508281707764\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 53, Train_Loss 3.138693380355835, Val_loss 3.4748380184173584\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 54, Train_Loss 3.0681170225143433, Val_loss 3.4052274227142334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 55, Train_Loss 3.1269002676010134, Val_loss 3.4480550289154053\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.92\t\n",
      "Epoch 56, Train_Loss 3.15623824596405, Val_loss 3.3989527225494385\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 57, Train_Loss 3.111910319328308, Val_loss 3.4001598358154297\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 58, Train_Loss 3.0995136737823485, Val_loss 3.436293363571167\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 59, Train_Loss 3.090094041824341, Val_loss 3.421314239501953\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 60, Train_Loss 3.0977592945098875, Val_loss 3.347869873046875\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 61, Train_Loss 3.105197286605835, Val_loss 3.3460590839385986\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 62, Train_Loss 3.0981228590011596, Val_loss 3.3843774795532227\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 63, Train_Loss 3.1028223991394044, Val_loss 3.3585824966430664\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 64, Train_Loss 3.0614636898040772, Val_loss 3.382554769515991\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.96\t\n",
      "Epoch 65, Train_Loss 3.0331251859664916, Val_loss 3.4035685062408447\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 66, Train_Loss 3.066419219970703, Val_loss 3.410674810409546\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 67, Train_Loss 3.1051101684570312, Val_loss 3.3948373794555664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 68, Train_Loss 3.1023826360702516, Val_loss 3.3962976932525635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 69, Train_Loss 3.040107583999634, Val_loss 3.3904898166656494\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 70, Train_Loss 3.086204504966736, Val_loss 3.44146728515625\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 71, Train_Loss 3.084400486946106, Val_loss 3.396023988723755\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 72, Train_Loss 3.0810988664627077, Val_loss 3.3839056491851807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 73, Train_Loss 3.0618024110794066, Val_loss 3.4079208374023438\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.92\t\n",
      "Epoch 74, Train_Loss 3.033154320716858, Val_loss 3.3919498920440674\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 75, Train_Loss 3.037796473503113, Val_loss 3.359055280685425\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 76, Train_Loss 3.0494140625, Val_loss 3.3980138301849365\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 77, Train_Loss 3.103762483596802, Val_loss 3.382568359375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 78, Train_Loss 3.06154887676239, Val_loss 3.353511095046997\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 79, Train_Loss 3.0749650239944457, Val_loss 3.3618392944335938\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.83\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 80, Train_Loss 3.066818380355835, Val_loss 3.376309633255005\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 81, Train_Loss 3.1095366716384887, Val_loss 3.378631591796875\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 82, Train_Loss 3.051365923881531, Val_loss 3.359463691711426\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 83, Train_Loss 3.021492838859558, Val_loss 3.352633237838745\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 84, Train_Loss 3.041955804824829, Val_loss 3.4195048809051514\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 85, Train_Loss 3.028073453903198, Val_loss 3.3539438247680664\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 86, Train_Loss 3.0133037090301515, Val_loss 3.376283884048462\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 87, Train_Loss 2.9953595638275146, Val_loss 3.351100206375122\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 88, Train_Loss 3.0579745054244993, Val_loss 3.3743209838867188\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 89, Train_Loss 3.111661195755005, Val_loss 3.402313470840454\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 90, Train_Loss 3.0133392095565794, Val_loss 3.3888723850250244\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 91, Train_Loss 3.0601230382919313, Val_loss 3.3619651794433594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.83\tVal_acc_top_40 0.92\t\n",
      "Epoch 92, Train_Loss 3.0620834827423096, Val_loss 3.373553514480591\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 93, Train_Loss 3.0609025239944456, Val_loss 3.369701623916626\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 94, Train_Loss 3.05027916431427, Val_loss 3.3538410663604736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 95, Train_Loss 3.048631453514099, Val_loss 3.3666064739227295\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 96, Train_Loss 3.024829959869385, Val_loss 3.3827102184295654\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 97, Train_Loss 3.0805966377258303, Val_loss 3.378577470779419\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 98, Train_Loss 3.0149333000183107, Val_loss 3.3376848697662354\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.79\tVal_acc_top_30 0.88\tVal_acc_top_40 0.92\t\n",
      "Epoch 99, Train_Loss 3.0673582315444947, Val_loss 3.401744842529297\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 100, Train_Loss 3.1043694972991944, Val_loss 3.3863399028778076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.75\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 1, Train_Loss 3.91714985370636, Val_loss 4.275233745574951\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.2062\tTrain_acc_top_40 0.25\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.12\tVal_acc_top_40 0.17\t\n",
      "Epoch 2, Train_Loss 4.1282069206237795, Val_loss 4.225182056427002\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.17\tVal_acc_top_40 0.25\t\n",
      "Epoch 3, Train_Loss 4.06820240020752, Val_loss 4.208273410797119\n",
      "Train_acc_top_20 0.125\tTrain_acc_top_30 0.1688\tTrain_acc_top_40 0.2188\t\n",
      "Val_acc_top_20 0.04\tVal_acc_top_30 0.21\tVal_acc_top_40 0.25\t\n",
      "Epoch 4, Train_Loss 3.9367151260375977, Val_loss 4.107717037200928\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1562\tTrain_acc_top_40 0.1938\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.17\tVal_acc_top_40 0.17\t\n",
      "Epoch 5, Train_Loss 3.8630505084991453, Val_loss 3.9554874897003174\n",
      "Train_acc_top_20 0.1125\tTrain_acc_top_30 0.1437\tTrain_acc_top_40 0.2062\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 6, Train_Loss 3.7786545276641847, Val_loss 3.8469467163085938\n",
      "Train_acc_top_20 0.2687\tTrain_acc_top_30 0.4062\tTrain_acc_top_40 0.4938\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.46\tVal_acc_top_40 0.5\t\n",
      "Epoch 7, Train_Loss 3.691682291030884, Val_loss 3.7753639221191406\n",
      "Train_acc_top_20 0.4938\tTrain_acc_top_30 0.6937\tTrain_acc_top_40 0.7937\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 8, Train_Loss 3.6199230670928957, Val_loss 3.736041784286499\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 9, Train_Loss 3.5465571165084837, Val_loss 3.649568557739258\n",
      "Train_acc_top_20 0.7\tTrain_acc_top_30 0.8812\tTrain_acc_top_40 0.9313\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 10, Train_Loss 3.5051859617233276, Val_loss 3.668476104736328\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.925\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 11, Train_Loss 3.5013925313949583, Val_loss 3.6238973140716553\n",
      "Train_acc_top_20 0.75\tTrain_acc_top_30 0.8438\tTrain_acc_top_40 0.9062\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 12, Train_Loss 3.426470232009888, Val_loss 3.7345094680786133\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 13, Train_Loss 3.392599415779114, Val_loss 3.6875953674316406\n",
      "Train_acc_top_20 0.9\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 14, Train_Loss 3.3627975940704347, Val_loss 3.6892459392547607\n",
      "Train_acc_top_20 0.8688\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.71\t\n",
      "Epoch 15, Train_Loss 3.345576858520508, Val_loss 3.7895421981811523\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 16, Train_Loss 3.3409497499465943, Val_loss 3.6529150009155273\n",
      "Train_acc_top_20 0.9375\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 17, Train_Loss 3.292151188850403, Val_loss 3.7158682346343994\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 18, Train_Loss 3.286896324157715, Val_loss 3.6301748752593994\n",
      "Train_acc_top_20 0.9125\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.58\tVal_acc_top_40 0.67\t\n",
      "Epoch 19, Train_Loss 3.2603205919265745, Val_loss 3.6562206745147705\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 20, Train_Loss 3.2457751274108886, Val_loss 3.6975390911102295\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.5\tVal_acc_top_40 0.67\t\n",
      "Epoch 21, Train_Loss 3.2402580976486206, Val_loss 3.585613250732422\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 22, Train_Loss 3.247101664543152, Val_loss 3.7479074001312256\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 23, Train_Loss 3.2008553743362427, Val_loss 3.6033785343170166\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2163979768753053, Val_loss 3.628451347351074\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 25, Train_Loss 3.241234302520752, Val_loss 3.701662063598633\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.975\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.240504288673401, Val_loss 3.679401397705078\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.975\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 27, Train_Loss 3.231459712982178, Val_loss 3.629328489303589\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.2284914016723634, Val_loss 3.66074275970459\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 29, Train_Loss 3.188973617553711, Val_loss 3.5412216186523438\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.208383655548096, Val_loss 3.6037704944610596\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 31, Train_Loss 3.1914040803909303, Val_loss 3.541663408279419\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 32, Train_Loss 3.151192879676819, Val_loss 3.5233781337738037\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 33, Train_Loss 3.151150417327881, Val_loss 3.5374326705932617\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 34, Train_Loss 3.182844400405884, Val_loss 3.5801422595977783\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.88\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.150935935974121, Val_loss 3.598457098007202\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 36, Train_Loss 3.1751654386520385, Val_loss 3.5474631786346436\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.137659454345703, Val_loss 3.515658140182495\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 38, Train_Loss 3.1440940856933595, Val_loss 3.5663747787475586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 39, Train_Loss 3.1202361822128295, Val_loss 3.580524206161499\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 40, Train_Loss 3.1457992792129517, Val_loss 3.5750133991241455\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 41, Train_Loss 3.1334296226501466, Val_loss 3.522305727005005\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 42, Train_Loss 3.1510403394699096, Val_loss 3.5742347240448\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 43, Train_Loss 3.1237753868103026, Val_loss 3.5024521350860596\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.127888798713684, Val_loss 3.536719560623169\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 45, Train_Loss 3.170372200012207, Val_loss 3.531846046447754\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 46, Train_Loss 3.1686025857925415, Val_loss 3.528787612915039\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 47, Train_Loss 3.1178240537643434, Val_loss 3.56130051612854\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 48, Train_Loss 3.1024009943008424, Val_loss 3.5831873416900635\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 49, Train_Loss 3.0967936754226684, Val_loss 3.5728256702423096\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 50, Train_Loss 3.1303739309310914, Val_loss 3.689223289489746\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 51, Train_Loss 3.145787978172302, Val_loss 3.5144598484039307\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 52, Train_Loss 3.1084410905838014, Val_loss 3.483670234680176\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 53, Train_Loss 3.110446882247925, Val_loss 3.5091753005981445\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 54, Train_Loss 3.1110485076904295, Val_loss 3.525623083114624\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.83\tVal_acc_top_40 0.83\t\n",
      "Epoch 55, Train_Loss 3.1301692962646483, Val_loss 3.509183645248413\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.1471033096313477, Val_loss 3.5122556686401367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 57, Train_Loss 3.0864980697631834, Val_loss 3.4783875942230225\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 58, Train_Loss 3.093892788887024, Val_loss 3.5215957164764404\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 59, Train_Loss 3.0724829912185667, Val_loss 3.5167715549468994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.0887676000595095, Val_loss 3.485661745071411\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 61, Train_Loss 3.1453296899795533, Val_loss 3.5305967330932617\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 62, Train_Loss 3.087498736381531, Val_loss 3.4873645305633545\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 63, Train_Loss 3.129728412628174, Val_loss 3.4766528606414795\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 64, Train_Loss 3.104707050323486, Val_loss 3.5120856761932373\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.0633841276168825, Val_loss 3.4824845790863037\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.115681529045105, Val_loss 3.5212669372558594\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 67, Train_Loss 3.111393690109253, Val_loss 3.481602907180786\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.1029489278793334, Val_loss 3.4908294677734375\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 69, Train_Loss 3.0418129920959474, Val_loss 3.4681129455566406\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 70, Train_Loss 3.0776623010635378, Val_loss 3.4838979244232178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 71, Train_Loss 3.062401866912842, Val_loss 3.5021419525146484\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 72, Train_Loss 3.047403836250305, Val_loss 3.4794390201568604\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 73, Train_Loss 3.0840368270874023, Val_loss 3.5138375759124756\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 74, Train_Loss 3.102548599243164, Val_loss 3.500082015991211\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 75, Train_Loss 3.074278545379639, Val_loss 3.485795021057129\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 76, Train_Loss 3.071205759048462, Val_loss 3.4898221492767334\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 77, Train_Loss 3.1299606800079345, Val_loss 3.502207040786743\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.1076557874679565, Val_loss 3.514040946960449\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 79, Train_Loss 3.069889998435974, Val_loss 3.5389747619628906\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 80, Train_Loss 3.0617754220962525, Val_loss 3.4778919219970703\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 81, Train_Loss 3.0704675912857056, Val_loss 3.5033960342407227\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 82, Train_Loss 3.0799398899078367, Val_loss 3.520703077316284\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 83, Train_Loss 3.0567397117614745, Val_loss 3.5077316761016846\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 84, Train_Loss 3.0544328689575195, Val_loss 3.493906021118164\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 85, Train_Loss 3.0530138969421388, Val_loss 3.530878782272339\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 86, Train_Loss 3.0647366762161257, Val_loss 3.505620241165161\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 87, Train_Loss 3.0708127498626707, Val_loss 3.5022945404052734\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 88, Train_Loss 3.1086478233337402, Val_loss 3.496253728866577\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 89, Train_Loss 3.0496737718582154, Val_loss 3.5046331882476807\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 90, Train_Loss 3.123742604255676, Val_loss 3.5155694484710693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 91, Train_Loss 3.0767542362213134, Val_loss 3.5032787322998047\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 92, Train_Loss 3.0887593984603883, Val_loss 3.490570306777954\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 93, Train_Loss 3.094362711906433, Val_loss 3.5062596797943115\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 94, Train_Loss 3.0464902400970457, Val_loss 3.5107107162475586\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 95, Train_Loss 3.0739978790283202, Val_loss 3.505693197250366\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 96, Train_Loss 3.0634752988815306, Val_loss 3.5005743503570557\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 97, Train_Loss 3.1060284852981566, Val_loss 3.503727674484253\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.79\t\n",
      "Epoch 98, Train_Loss 3.1168744802474975, Val_loss 3.523582696914673\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 99, Train_Loss 3.065320348739624, Val_loss 3.5130910873413086\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 100, Train_Loss 3.0630749225616456, Val_loss 3.519894599914551\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 1, Train_Loss 3.927970361709595, Val_loss 4.262121200561523\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.175\tTrain_acc_top_40 0.2313\t\n",
      "Val_acc_top_20 0.29\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 2, Train_Loss 4.120497846603394, Val_loss 4.19417142868042\n",
      "Train_acc_top_20 0.1\tTrain_acc_top_30 0.1625\tTrain_acc_top_40 0.2375\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 3, Train_Loss 4.088123798370361, Val_loss 4.148993015289307\n",
      "Train_acc_top_20 0.1062\tTrain_acc_top_30 0.15\tTrain_acc_top_40 0.2\t\n",
      "Val_acc_top_20 0.25\tVal_acc_top_30 0.29\tVal_acc_top_40 0.33\t\n",
      "Epoch 4, Train_Loss 3.9513731002807617, Val_loss 4.097288131713867\n",
      "Train_acc_top_20 0.0813\tTrain_acc_top_30 0.125\tTrain_acc_top_40 0.175\t\n",
      "Val_acc_top_20 0.21\tVal_acc_top_30 0.21\tVal_acc_top_40 0.21\t\n",
      "Epoch 5, Train_Loss 3.895831489562988, Val_loss 4.0858588218688965\n",
      "Train_acc_top_20 0.0938\tTrain_acc_top_30 0.1875\tTrain_acc_top_40 0.225\t\n",
      "Val_acc_top_20 0.17\tVal_acc_top_30 0.29\tVal_acc_top_40 0.42\t\n",
      "Epoch 6, Train_Loss 3.808300590515137, Val_loss 3.624316453933716\n",
      "Train_acc_top_20 0.2938\tTrain_acc_top_30 0.4125\tTrain_acc_top_40 0.5125\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 7, Train_Loss 3.7353789091110228, Val_loss 3.634469747543335\n",
      "Train_acc_top_20 0.5062\tTrain_acc_top_30 0.6875\tTrain_acc_top_40 0.8063\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.79\t\n",
      "Epoch 8, Train_Loss 3.653163695335388, Val_loss 3.7236242294311523\n",
      "Train_acc_top_20 0.6375\tTrain_acc_top_30 0.8187\tTrain_acc_top_40 0.8938\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 9, Train_Loss 3.61543493270874, Val_loss 3.5483920574188232\n",
      "Train_acc_top_20 0.7375\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 10, Train_Loss 3.551502799987793, Val_loss 3.7085702419281006\n",
      "Train_acc_top_20 0.875\tTrain_acc_top_30 0.95\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 11, Train_Loss 3.5281240463256838, Val_loss 3.5094757080078125\n",
      "Train_acc_top_20 0.8187\tTrain_acc_top_30 0.9313\tTrain_acc_top_40 0.9688\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 12, Train_Loss 3.5125115156173705, Val_loss 3.4920032024383545\n",
      "Train_acc_top_20 0.725\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9375\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 13, Train_Loss 3.4166002750396727, Val_loss 3.5704832077026367\n",
      "Train_acc_top_20 0.7688\tTrain_acc_top_30 0.8875\tTrain_acc_top_40 0.925\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 14, Train_Loss 3.411446285247803, Val_loss 3.615196943283081\n",
      "Train_acc_top_20 0.8562\tTrain_acc_top_30 0.9437\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 15, Train_Loss 3.3794103622436524, Val_loss 3.532094717025757\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 16, Train_Loss 3.3523159265518188, Val_loss 3.5942728519439697\n",
      "Train_acc_top_20 0.85\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 17, Train_Loss 3.3361181259155273, Val_loss 3.549666404724121\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9563\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.71\t\n",
      "Epoch 18, Train_Loss 3.3356194496154785, Val_loss 3.5469233989715576\n",
      "Train_acc_top_20 0.8812\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 19, Train_Loss 3.2965492963790894, Val_loss 3.6805636882781982\n",
      "Train_acc_top_20 0.9187\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9875\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 20, Train_Loss 3.2725584506988525, Val_loss 3.609058141708374\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 21, Train_Loss 3.235915994644165, Val_loss 3.4394190311431885\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9812\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.67\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 22, Train_Loss 3.2654197216033936, Val_loss 3.646969795227051\n",
      "Train_acc_top_20 0.9062\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 23, Train_Loss 3.325641703605652, Val_loss 3.541804313659668\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.62\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 24, Train_Loss 3.2992924451828003, Val_loss 3.4706106185913086\n",
      "Train_acc_top_20 0.8875\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.975\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 25, Train_Loss 3.2245863676071167, Val_loss 3.514681816101074\n",
      "Train_acc_top_20 0.9313\tTrain_acc_top_30 0.9688\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 26, Train_Loss 3.215693950653076, Val_loss 3.582195520401001\n",
      "Train_acc_top_20 0.95\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.67\t\n",
      "Epoch 27, Train_Loss 3.2410234212875366, Val_loss 3.5752251148223877\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 28, Train_Loss 3.1953466653823854, Val_loss 3.752984046936035\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 29, Train_Loss 3.293179416656494, Val_loss 3.4929912090301514\n",
      "Train_acc_top_20 0.6687\tTrain_acc_top_30 0.7438\tTrain_acc_top_40 0.7875\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 30, Train_Loss 3.26550133228302, Val_loss 3.5881574153900146\n",
      "Train_acc_top_20 0.8375\tTrain_acc_top_30 0.9\tTrain_acc_top_40 0.9437\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 31, Train_Loss 3.2176492691040037, Val_loss 3.556472063064575\n",
      "Train_acc_top_20 0.8938\tTrain_acc_top_30 0.9625\tTrain_acc_top_40 0.9812\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 32, Train_Loss 3.2409780740737917, Val_loss 3.442392110824585\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 33, Train_Loss 3.199851560592651, Val_loss 3.39115834236145\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.71\tVal_acc_top_30 0.83\tVal_acc_top_40 0.88\t\n",
      "Epoch 34, Train_Loss 3.1907036781311033, Val_loss 3.4693686962127686\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.79\tVal_acc_top_40 0.88\t\n",
      "Epoch 35, Train_Loss 3.2973799228668215, Val_loss 3.553375482559204\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 36, Train_Loss 3.1989617347717285, Val_loss 3.515103578567505\n",
      "Train_acc_top_20 0.9625\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 0.9938\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 37, Train_Loss 3.2171123027801514, Val_loss 3.641345262527466\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.62\t\n",
      "Epoch 38, Train_Loss 3.175707197189331, Val_loss 3.520017385482788\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 39, Train_Loss 3.16170916557312, Val_loss 3.6937382221221924\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9875\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.42\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 40, Train_Loss 3.1842077732086183, Val_loss 3.7217025756835938\n",
      "Train_acc_top_20 0.9688\tTrain_acc_top_30 0.9938\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.33\tVal_acc_top_30 0.5\tVal_acc_top_40 0.62\t\n",
      "Epoch 41, Train_Loss 3.215906596183777, Val_loss 3.5591847896575928\n",
      "Train_acc_top_20 0.9563\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 42, Train_Loss 3.1743101596832277, Val_loss 3.546893358230591\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 43, Train_Loss 3.1856677532196045, Val_loss 3.5665714740753174\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 44, Train_Loss 3.1356438636779784, Val_loss 3.5417048931121826\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.71\t\n",
      "Epoch 45, Train_Loss 3.136865472793579, Val_loss 3.5393011569976807\n",
      "Train_acc_top_20 0.975\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 46, Train_Loss 3.16954882144928, Val_loss 3.5986194610595703\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.62\t\n",
      "Epoch 47, Train_Loss 3.2004037857055665, Val_loss 3.53903865814209\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 48, Train_Loss 3.1044989109039305, Val_loss 3.550971031188965\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 49, Train_Loss 3.1369187355041506, Val_loss 3.5428946018218994\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 50, Train_Loss 3.133548951148987, Val_loss 3.590574264526367\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 51, Train_Loss 3.1133065700531004, Val_loss 3.650843620300293\n",
      "Train_acc_top_20 0.9812\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.38\tVal_acc_top_30 0.54\tVal_acc_top_40 0.62\t\n",
      "Epoch 52, Train_Loss 3.141385221481323, Val_loss 3.5154168605804443\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 53, Train_Loss 3.098699688911438, Val_loss 3.572190523147583\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.67\t\n",
      "Epoch 54, Train_Loss 3.1722294330596923, Val_loss 3.5503790378570557\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 55, Train_Loss 3.159315013885498, Val_loss 3.4927093982696533\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 56, Train_Loss 3.105645775794983, Val_loss 3.6155176162719727\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.67\t\n",
      "Epoch 57, Train_Loss 3.0722504377365114, Val_loss 3.6207940578460693\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 58, Train_Loss 3.099582624435425, Val_loss 3.5548744201660156\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 59, Train_Loss 3.138014054298401, Val_loss 3.507995843887329\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 60, Train_Loss 3.1692740440368654, Val_loss 3.515918731689453\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.79\tVal_acc_top_40 0.83\t\n",
      "Epoch 61, Train_Loss 3.129312610626221, Val_loss 3.517399549484253\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.83\t\n",
      "Epoch 62, Train_Loss 3.1771226644515993, Val_loss 3.579935073852539\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 63, Train_Loss 3.1213216304779055, Val_loss 3.5542209148406982\n",
      "Train_acc_top_20 0.9875\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.75\tVal_acc_top_40 0.75\t\n",
      "Epoch 64, Train_Loss 3.175386166572571, Val_loss 3.4659440517425537\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.83\t\n",
      "Epoch 65, Train_Loss 3.120910906791687, Val_loss 3.4467859268188477\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 66, Train_Loss 3.0701724529266357, Val_loss 3.504056692123413\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.75\tVal_acc_top_40 0.83\t\n",
      "Epoch 67, Train_Loss 3.123421478271484, Val_loss 3.5533297061920166\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.79\t\n",
      "Epoch 68, Train_Loss 3.1549530744552614, Val_loss 3.502229690551758\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 69, Train_Loss 3.105755829811096, Val_loss 3.5426390171051025\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.58\tVal_acc_top_30 0.71\tVal_acc_top_40 0.79\t\n",
      "Epoch 70, Train_Loss 3.1334736585617065, Val_loss 3.551189661026001\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 71, Train_Loss 3.096641492843628, Val_loss 3.5480098724365234\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 72, Train_Loss 3.14643874168396, Val_loss 3.5903308391571045\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.54\tVal_acc_top_40 0.75\t\n",
      "Epoch 73, Train_Loss 3.0865037202835084, Val_loss 3.5591602325439453\n",
      "Train_acc_top_20 0.9938\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 74, Train_Loss 3.146892952919006, Val_loss 3.6004750728607178\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.58\tVal_acc_top_40 0.75\t\n",
      "Epoch 75, Train_Loss 3.090663027763367, Val_loss 3.5976715087890625\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 76, Train_Loss 3.0918200731277468, Val_loss 3.637021064758301\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.54\tVal_acc_top_30 0.58\tVal_acc_top_40 0.79\t\n",
      "Epoch 77, Train_Loss 3.0891955375671385, Val_loss 3.5222179889678955\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.79\t\n",
      "Epoch 78, Train_Loss 3.118567395210266, Val_loss 3.589024782180786\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 79, Train_Loss 3.1402799606323244, Val_loss 3.5845205783843994\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 80, Train_Loss 3.1267889976501464, Val_loss 3.5821101665496826\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 81, Train_Loss 3.1372638463974, Val_loss 3.592296600341797\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 82, Train_Loss 3.0934292554855345, Val_loss 3.599677324295044\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 83, Train_Loss 3.107476282119751, Val_loss 3.5902645587921143\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 84, Train_Loss 3.1133682489395142, Val_loss 3.6044111251831055\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 85, Train_Loss 3.038707232475281, Val_loss 3.5783021450042725\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 86, Train_Loss 3.157765507698059, Val_loss 3.5799152851104736\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 87, Train_Loss 3.1541359663009643, Val_loss 3.5841243267059326\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 88, Train_Loss 3.1674651145935058, Val_loss 3.6112220287323\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 89, Train_Loss 3.118311548233032, Val_loss 3.63134503364563\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 90, Train_Loss 3.0717123985290526, Val_loss 3.584367036819458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 91, Train_Loss 3.1043357372283937, Val_loss 3.6072094440460205\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 92, Train_Loss 3.1191861152648928, Val_loss 3.6050899028778076\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 93, Train_Loss 3.11190402507782, Val_loss 3.617314100265503\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 94, Train_Loss 3.0856383800506593, Val_loss 3.621840476989746\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.71\tVal_acc_top_40 0.75\t\n",
      "Epoch 95, Train_Loss 3.072887396812439, Val_loss 3.649798631668091\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 96, Train_Loss 3.1019133806228636, Val_loss 3.5512936115264893\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.67\tVal_acc_top_40 0.75\t\n",
      "Epoch 97, Train_Loss 3.1482134103775024, Val_loss 3.555908203125\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 98, Train_Loss 3.062764120101929, Val_loss 3.6355466842651367\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.71\t\n",
      "Epoch 99, Train_Loss 3.086035060882568, Val_loss 3.5940372943878174\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.46\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n",
      "Epoch 100, Train_Loss 3.069002461433411, Val_loss 3.574601411819458\n",
      "Train_acc_top_20 1.0\tTrain_acc_top_30 1.0\tTrain_acc_top_40 1.0\t\n",
      "Val_acc_top_20 0.5\tVal_acc_top_30 0.62\tVal_acc_top_40 0.75\t\n"
     ]
    }
   ],
   "source": [
    "top_k_candidates = (20, 30, 40)\n",
    "k = 7\n",
    "temps = 0.7\n",
    "momentums = 0.99\n",
    "k_value = 64\n",
    "# parameters = {'epochs_pretrain_model': list(range(100, 1100, 100))}\n",
    "parameters = {'pretrain_model': ['self_pretrained', 'CEM', 'ImageNet', 'None']}\n",
    "# parameters = {'pretrain_model': ['CEM']}\n",
    "train_metrics = HistoryRecorder(['Train Loss', 'Train Acc', 'Val Loss', 'Val Acc'], list(parameters.keys()))\n",
    "parameters = list(itertools.product(*parameters.values()))\n",
    "\n",
    "for i, parameter in enumerate(parameters):\n",
    "\n",
    "    ### custom part to get parameters\n",
    "    pretrain_model = parameter[0]\n",
    "    ### END\n",
    "    \n",
    "    for j, images in enumerate(k_fold_train_validation_split(ORIGINAL_IMAGE, TARGET_IMAGE, k)):\n",
    "        train_dataset = SingleChannelNDIDatasetContrastiveLearningWithAug(images, False)\n",
    "        val_dataset = SingleChannelNDIDatasetContrastiveLearningWithAug(images, True)\n",
    "        train_iter = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "        val_iter = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "        model = get_self_pretrain_model(index=pretrain_model)\n",
    "        model = MoCo(model, dim=512, K=k_value, T=temps, m=momentums, mlp=True, customized_model=True)\n",
    "        device = torch.device('cuda:0')\n",
    "        criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.015, momentum=0.9, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100)\n",
    "        start_time = time.time()\n",
    "        print(f'Parameter Index: {i} / {len(parameters)}, Fold Index: {j} / {k}')\n",
    "        metrics = train_moco_return_metrics_top_k(model, train_iter, val_iter, criterion, optimizer, 100, device,\n",
    "                                                    tested_parameter=parameter, k_candidates=top_k_candidates, scheduler=scheduler)\n",
    "        end_time = time.time()\n",
    "        train_metrics.cal_add(metrics)\n",
    "train_metrics.cal_divide(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"880.079998pt\" height=\"1168.674375pt\" viewBox=\"0 0 880.079998 1168.674375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-02-02T16:43:24.973628</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 1168.674375 \nL 880.079998 1168.674375 \nL 880.079998 0 \nL 0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 213.490539 \nL 410.55767 213.490539 \nL 410.55767 22.318125 \nL 30.103125 22.318125 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 30.103125 213.490539 \nL 30.103125 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m0b69f7a329\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"30.103125\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(26.921875 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 105.440659 213.490539 \nL 105.440659 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"105.440659\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(99.078159 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 180.778193 213.490539 \nL 180.778193 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"180.778193\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(174.415693 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 256.115726 213.490539 \nL 256.115726 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"256.115726\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(249.753226 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 331.45326 213.490539 \nL 331.45326 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"331.45326\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(325.09076 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 406.790794 213.490539 \nL 406.790794 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"406.790794\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(397.247044 228.088976)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(202.414773 241.767101)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path d=\"M 30.103125 213.490539 \nL 410.55767 213.490539 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path id=\"mdda734422f\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #ffffff; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 217.289758)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path d=\"M 30.103125 189.593987 \nL 410.55767 189.593987 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"189.593987\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 193.393206)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path d=\"M 30.103125 165.697435 \nL 410.55767 165.697435 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"165.697435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 169.496654)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path d=\"M 30.103125 141.800884 \nL 410.55767 141.800884 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"141.800884\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 145.600102)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path d=\"M 30.103125 117.904332 \nL 410.55767 117.904332 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"117.904332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 121.703551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path d=\"M 30.103125 94.00778 \nL 410.55767 94.00778 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"94.00778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 97.806999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path d=\"M 30.103125 70.111228 \nL 410.55767 70.111228 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"70.111228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 73.910447)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path d=\"M 30.103125 46.214677 \nL 410.55767 46.214677 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"46.214677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 50.013895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_29\">\n      <path d=\"M 30.103125 22.318125 \nL 410.55767 22.318125 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"22.318125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 26.117344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_31\">\n    <path d=\"M 33.870002 25.796415 \nL 37.636878 16.912163 \nL 41.403755 20.04089 \nL 45.170632 25.645392 \nL 48.937508 29.998844 \nL 52.704385 34.05585 \nL 56.471262 37.699871 \nL 60.238139 40.583957 \nL 64.005015 43.255659 \nL 67.771892 45.637092 \nL 71.538769 48.439281 \nL 75.305645 49.360989 \nL 79.072522 50.875268 \nL 82.839399 52.618241 \nL 86.606275 53.714651 \nL 90.373152 54.354335 \nL 94.140029 55.523686 \nL 97.906905 56.577184 \nL 101.673782 57.129341 \nL 105.440659 57.161542 \nL 109.207535 58.319257 \nL 112.974412 58.435252 \nL 116.741289 59.629172 \nL 120.508166 59.984592 \nL 124.275042 60.037483 \nL 128.041919 60.209771 \nL 131.808796 60.824367 \nL 135.575672 60.976646 \nL 139.342549 60.938467 \nL 143.109426 61.342941 \nL 146.876302 61.918851 \nL 150.643179 61.753358 \nL 154.410056 61.857211 \nL 158.176932 62.305663 \nL 161.943809 62.729746 \nL 165.710686 62.505793 \nL 169.477562 62.273708 \nL 173.244439 62.360083 \nL 177.011316 63.098101 \nL 180.778193 63.04803 \nL 184.545069 63.019818 \nL 188.311946 63.612175 \nL 192.078823 63.630143 \nL 195.845699 63.580841 \nL 199.612576 63.506381 \nL 203.379453 63.317021 \nL 207.146329 63.935431 \nL 210.913206 64.066839 \nL 214.680083 64.051872 \nL 218.446959 64.007178 \nL 222.213836 63.763083 \nL 225.980713 64.278823 \nL 229.747589 64.471199 \nL 233.514466 64.432353 \nL 237.281343 64.47503 \nL 241.04822 64.768962 \nL 244.815096 64.454881 \nL 248.581973 64.889477 \nL 252.34885 64.423656 \nL 256.115726 64.646148 \nL 259.882603 64.603563 \nL 263.64948 65.097435 \nL 267.416356 65.171641 \nL 271.183233 64.964751 \nL 274.95011 64.878114 \nL 278.716986 64.846151 \nL 282.483863 64.759661 \nL 286.25074 65.280544 \nL 290.017616 65.637108 \nL 293.784493 65.40206 \nL 297.55137 65.586182 \nL 301.318247 65.647369 \nL 305.085123 65.520884 \nL 308.852 65.813225 \nL 312.618877 65.625402 \nL 316.385753 65.503908 \nL 320.15263 65.22074 \nL 323.919507 65.641782 \nL 327.686383 65.226904 \nL 331.45326 65.389973 \nL 335.220137 65.910657 \nL 338.987013 65.646582 \nL 342.75389 65.446068 \nL 346.520767 65.797506 \nL 350.287643 65.745591 \nL 354.05452 65.723503 \nL 357.821397 65.609955 \nL 361.588274 65.87243 \nL 365.35515 65.997937 \nL 369.122027 65.831791 \nL 372.888904 65.998469 \nL 376.65578 65.75093 \nL 380.422657 65.945203 \nL 384.189534 65.881278 \nL 387.95641 65.934268 \nL 391.723287 65.561577 \nL 395.490164 65.644822 \nL 399.25704 65.614522 \nL 403.023917 65.556099 \nL 406.790794 65.93875 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path d=\"M 33.870002 208.412522 \nL 37.636878 206.918987 \nL 41.403755 207.815108 \nL 45.170632 207.815108 \nL 48.937508 205.126746 \nL 52.704385 198.256487 \nL 56.471262 186.606918 \nL 60.238139 175.256056 \nL 64.005015 173.762522 \nL 67.771892 171.372866 \nL 71.538769 172.268987 \nL 75.305645 171.074159 \nL 79.072522 170.775453 \nL 82.839399 168.385797 \nL 86.606275 168.983211 \nL 90.373152 167.19097 \nL 94.140029 168.087091 \nL 97.906905 167.489677 \nL 101.673782 166.593556 \nL 105.440659 166.593556 \nL 109.207535 167.788384 \nL 112.974412 166.593556 \nL 116.741289 167.19097 \nL 120.508166 166.892263 \nL 124.275042 167.489677 \nL 128.041919 166.593556 \nL 131.808796 167.489677 \nL 135.575672 166.294849 \nL 139.342549 167.489677 \nL 143.109426 167.19097 \nL 146.876302 166.294849 \nL 150.643179 167.489677 \nL 154.410056 167.19097 \nL 158.176932 166.593556 \nL 161.943809 166.294849 \nL 165.710686 166.294849 \nL 169.477562 167.489677 \nL 173.244439 166.593556 \nL 177.011316 166.892263 \nL 180.778193 166.892263 \nL 184.545069 165.996142 \nL 188.311946 166.294849 \nL 192.078823 166.892263 \nL 195.845699 166.294849 \nL 199.612576 166.294849 \nL 203.379453 166.593556 \nL 207.146329 166.892263 \nL 210.913206 166.294849 \nL 214.680083 166.294849 \nL 218.446959 166.294849 \nL 222.213836 166.294849 \nL 225.980713 165.697435 \nL 229.747589 166.892263 \nL 233.514466 165.996142 \nL 237.281343 166.593556 \nL 241.04822 165.996142 \nL 244.815096 165.697435 \nL 248.581973 165.996142 \nL 252.34885 165.996142 \nL 256.115726 165.996142 \nL 259.882603 165.996142 \nL 263.64948 165.996142 \nL 267.416356 165.996142 \nL 271.183233 165.996142 \nL 274.95011 166.294849 \nL 278.716986 165.697435 \nL 282.483863 165.697435 \nL 286.25074 165.697435 \nL 290.017616 165.697435 \nL 293.784493 165.697435 \nL 297.55137 165.697435 \nL 301.318247 165.996142 \nL 305.085123 165.996142 \nL 308.852 166.294849 \nL 312.618877 165.697435 \nL 316.385753 165.697435 \nL 320.15263 165.697435 \nL 323.919507 165.996142 \nL 327.686383 165.697435 \nL 331.45326 165.697435 \nL 335.220137 165.996142 \nL 338.987013 165.697435 \nL 342.75389 165.697435 \nL 346.520767 165.697435 \nL 350.287643 165.697435 \nL 354.05452 165.996142 \nL 357.821397 165.697435 \nL 361.588274 165.996142 \nL 365.35515 165.996142 \nL 369.122027 165.697435 \nL 372.888904 165.996142 \nL 376.65578 165.996142 \nL 380.422657 165.996142 \nL 384.189534 165.697435 \nL 387.95641 165.697435 \nL 391.723287 166.294849 \nL 395.490164 165.996142 \nL 399.25704 165.996142 \nL 403.023917 165.996142 \nL 406.790794 165.697435 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path d=\"M 33.870002 205.724159 \nL 37.636878 205.425453 \nL 41.403755 205.126746 \nL 45.170632 206.321573 \nL 48.937508 201.84097 \nL 52.704385 191.684935 \nL 56.471262 178.840539 \nL 60.238139 170.476746 \nL 64.005015 170.476746 \nL 67.771892 169.580625 \nL 71.538769 170.178039 \nL 75.305645 168.684504 \nL 79.072522 168.087091 \nL 82.839399 167.19097 \nL 86.606275 168.087091 \nL 90.373152 166.593556 \nL 94.140029 166.593556 \nL 97.906905 166.294849 \nL 101.673782 166.294849 \nL 105.440659 166.593556 \nL 109.207535 166.593556 \nL 112.974412 165.996142 \nL 116.741289 166.294849 \nL 120.508166 166.294849 \nL 124.275042 165.996142 \nL 128.041919 165.996142 \nL 131.808796 165.996142 \nL 135.575672 165.996142 \nL 139.342549 166.892263 \nL 143.109426 165.996142 \nL 146.876302 165.996142 \nL 150.643179 165.697435 \nL 154.410056 165.996142 \nL 158.176932 165.996142 \nL 161.943809 165.697435 \nL 165.710686 165.697435 \nL 169.477562 165.697435 \nL 173.244439 165.697435 \nL 177.011316 165.697435 \nL 180.778193 165.697435 \nL 184.545069 165.697435 \nL 188.311946 165.697435 \nL 192.078823 165.996142 \nL 195.845699 165.697435 \nL 199.612576 165.697435 \nL 203.379453 165.697435 \nL 207.146329 165.996142 \nL 210.913206 165.697435 \nL 214.680083 165.697435 \nL 218.446959 165.697435 \nL 222.213836 165.697435 \nL 225.980713 165.697435 \nL 229.747589 165.697435 \nL 233.514466 165.697435 \nL 237.281343 165.697435 \nL 241.04822 165.697435 \nL 244.815096 165.697435 \nL 248.581973 165.697435 \nL 252.34885 165.697435 \nL 256.115726 165.697435 \nL 259.882603 165.697435 \nL 263.64948 165.697435 \nL 267.416356 165.697435 \nL 271.183233 165.697435 \nL 274.95011 165.697435 \nL 278.716986 165.697435 \nL 282.483863 165.697435 \nL 286.25074 165.697435 \nL 290.017616 165.697435 \nL 293.784493 165.697435 \nL 297.55137 165.697435 \nL 301.318247 165.697435 \nL 305.085123 165.697435 \nL 308.852 165.697435 \nL 312.618877 165.697435 \nL 316.385753 165.697435 \nL 320.15263 165.697435 \nL 323.919507 165.697435 \nL 327.686383 165.697435 \nL 331.45326 165.697435 \nL 335.220137 165.697435 \nL 338.987013 165.697435 \nL 342.75389 165.697435 \nL 346.520767 165.697435 \nL 350.287643 165.697435 \nL 354.05452 165.697435 \nL 357.821397 165.697435 \nL 361.588274 165.697435 \nL 365.35515 165.697435 \nL 369.122027 165.697435 \nL 372.888904 165.697435 \nL 376.65578 165.697435 \nL 380.422657 165.697435 \nL 384.189534 165.697435 \nL 387.95641 165.697435 \nL 391.723287 165.697435 \nL 395.490164 165.697435 \nL 399.25704 165.697435 \nL 403.023917 165.697435 \nL 406.790794 165.697435 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path d=\"M 33.870002 203.035797 \nL 37.636878 203.035797 \nL 41.403755 202.737091 \nL 45.170632 203.633211 \nL 48.937508 200.048728 \nL 52.704385 186.606918 \nL 56.471262 173.165108 \nL 60.238139 167.19097 \nL 64.005015 166.892263 \nL 67.771892 165.996142 \nL 71.538769 165.697435 \nL 75.305645 165.996142 \nL 79.072522 165.697435 \nL 82.839399 165.697435 \nL 86.606275 165.996142 \nL 90.373152 165.697435 \nL 94.140029 165.697435 \nL 97.906905 165.697435 \nL 101.673782 165.697435 \nL 105.440659 165.697435 \nL 109.207535 165.697435 \nL 112.974412 165.697435 \nL 116.741289 165.697435 \nL 120.508166 165.697435 \nL 124.275042 165.697435 \nL 128.041919 165.697435 \nL 131.808796 165.697435 \nL 135.575672 165.697435 \nL 139.342549 165.996142 \nL 143.109426 165.697435 \nL 146.876302 165.697435 \nL 150.643179 165.697435 \nL 154.410056 165.697435 \nL 158.176932 165.697435 \nL 161.943809 165.697435 \nL 165.710686 165.697435 \nL 169.477562 165.697435 \nL 173.244439 165.697435 \nL 177.011316 165.697435 \nL 180.778193 165.697435 \nL 184.545069 165.697435 \nL 188.311946 165.697435 \nL 192.078823 165.697435 \nL 195.845699 165.697435 \nL 199.612576 165.697435 \nL 203.379453 165.697435 \nL 207.146329 165.697435 \nL 210.913206 165.697435 \nL 214.680083 165.697435 \nL 218.446959 165.697435 \nL 222.213836 165.697435 \nL 225.980713 165.697435 \nL 229.747589 165.697435 \nL 233.514466 165.697435 \nL 237.281343 165.697435 \nL 241.04822 165.697435 \nL 244.815096 165.697435 \nL 248.581973 165.697435 \nL 252.34885 165.697435 \nL 256.115726 165.697435 \nL 259.882603 165.697435 \nL 263.64948 165.697435 \nL 267.416356 165.697435 \nL 271.183233 165.697435 \nL 274.95011 165.697435 \nL 278.716986 165.697435 \nL 282.483863 165.697435 \nL 286.25074 165.697435 \nL 290.017616 165.697435 \nL 293.784493 165.697435 \nL 297.55137 165.697435 \nL 301.318247 165.697435 \nL 305.085123 165.697435 \nL 308.852 165.697435 \nL 312.618877 165.697435 \nL 316.385753 165.697435 \nL 320.15263 165.697435 \nL 323.919507 165.697435 \nL 327.686383 165.697435 \nL 331.45326 165.697435 \nL 335.220137 165.697435 \nL 338.987013 165.697435 \nL 342.75389 165.697435 \nL 346.520767 165.697435 \nL 350.287643 165.697435 \nL 354.05452 165.697435 \nL 357.821397 165.697435 \nL 361.588274 165.697435 \nL 365.35515 165.697435 \nL 369.122027 165.697435 \nL 372.888904 165.697435 \nL 376.65578 165.697435 \nL 380.422657 165.697435 \nL 384.189534 165.697435 \nL 387.95641 165.697435 \nL 391.723287 165.697435 \nL 395.490164 165.697435 \nL 399.25704 165.697435 \nL 403.023917 165.697435 \nL 406.790794 165.697435 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path d=\"M 33.870002 13.974348 \nL 37.636878 15.810592 \nL 41.403755 18.239457 \nL 45.170632 21.546529 \nL 48.937508 24.301428 \nL 52.704385 29.26232 \nL 56.471262 33.230648 \nL 60.238139 34.678693 \nL 64.005015 36.515864 \nL 67.771892 37.212548 \nL 71.538769 37.26235 \nL 75.305645 37.478404 \nL 79.072522 37.944281 \nL 82.839399 38.367116 \nL 86.606275 39.491053 \nL 90.373152 38.521611 \nL 94.140029 39.674436 \nL 97.906905 39.697669 \nL 101.673782 39.560433 \nL 105.440659 38.954697 \nL 109.207535 40.597532 \nL 112.974412 40.917012 \nL 116.741289 39.880736 \nL 120.508166 40.394642 \nL 124.275042 40.092238 \nL 128.041919 39.459534 \nL 131.808796 40.716339 \nL 135.575672 40.687834 \nL 139.342549 38.50777 \nL 143.109426 40.262236 \nL 146.876302 40.497137 \nL 150.643179 39.948191 \nL 154.410056 40.421917 \nL 158.176932 40.90089 \nL 161.943809 41.615462 \nL 165.710686 40.909967 \nL 169.477562 40.614619 \nL 173.244439 39.652606 \nL 177.011316 39.356904 \nL 180.778193 39.934721 \nL 184.545069 41.066192 \nL 188.311946 40.466679 \nL 192.078823 39.235117 \nL 195.845699 40.755161 \nL 199.612576 39.599246 \nL 203.379453 40.326747 \nL 207.146329 40.215902 \nL 210.913206 40.599632 \nL 214.680083 40.501103 \nL 218.446959 41.600541 \nL 222.213836 40.336678 \nL 225.980713 40.14087 \nL 229.747589 40.312876 \nL 233.514466 41.316178 \nL 237.281343 41.234408 \nL 241.04822 40.553275 \nL 244.815096 40.30516 \nL 248.581973 40.260662 \nL 252.34885 40.158729 \nL 256.115726 41.121805 \nL 259.882603 39.788938 \nL 263.64948 40.231402 \nL 267.416356 40.464755 \nL 271.183233 39.770243 \nL 274.95011 40.010702 \nL 278.716986 39.287198 \nL 282.483863 39.835551 \nL 286.25074 40.59298 \nL 290.017616 39.994153 \nL 293.784493 39.07588 \nL 297.55137 39.930508 \nL 301.318247 39.038551 \nL 305.085123 39.287292 \nL 308.852 40.103605 \nL 312.618877 39.141607 \nL 316.385753 40.156387 \nL 320.15263 40.001071 \nL 323.919507 39.539367 \nL 327.686383 40.539879 \nL 331.45326 39.87946 \nL 335.220137 39.826924 \nL 338.987013 40.057492 \nL 342.75389 39.118269 \nL 346.520767 39.594465 \nL 350.287643 40.045659 \nL 354.05452 39.701602 \nL 357.821397 39.973522 \nL 361.588274 39.586577 \nL 365.35515 39.834879 \nL 369.122027 39.898647 \nL 372.888904 39.680821 \nL 376.65578 40.117925 \nL 380.422657 39.646186 \nL 384.189534 39.458751 \nL 387.95641 39.442384 \nL 391.723287 39.390836 \nL 395.490164 39.68746 \nL 399.25704 39.405099 \nL 403.023917 39.450216 \nL 406.790794 39.974775 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path d=\"M 33.870002 207.516401 \nL 37.636878 213.490539 \nL 41.403755 213.490539 \nL 45.170632 213.490539 \nL 48.937508 209.50778 \nL 52.704385 203.533642 \nL 56.471262 185.611228 \nL 60.238139 187.602608 \nL 64.005015 187.602608 \nL 67.771892 181.62847 \nL 71.538769 181.62847 \nL 75.305645 183.619849 \nL 79.072522 183.619849 \nL 82.839399 183.619849 \nL 86.606275 177.645711 \nL 90.373152 183.619849 \nL 94.140029 183.619849 \nL 97.906905 179.637091 \nL 101.673782 179.637091 \nL 105.440659 177.645711 \nL 109.207535 181.62847 \nL 112.974412 183.619849 \nL 116.741289 177.645711 \nL 120.508166 181.62847 \nL 124.275042 183.619849 \nL 128.041919 181.62847 \nL 131.808796 179.637091 \nL 135.575672 179.637091 \nL 139.342549 181.62847 \nL 143.109426 179.637091 \nL 146.876302 177.645711 \nL 150.643179 181.62847 \nL 154.410056 181.62847 \nL 158.176932 181.62847 \nL 161.943809 179.637091 \nL 165.710686 177.645711 \nL 169.477562 183.619849 \nL 173.244439 181.62847 \nL 177.011316 179.637091 \nL 180.778193 185.611228 \nL 184.545069 179.637091 \nL 188.311946 183.619849 \nL 192.078823 181.62847 \nL 195.845699 183.619849 \nL 199.612576 181.62847 \nL 203.379453 181.62847 \nL 207.146329 185.611228 \nL 210.913206 183.619849 \nL 214.680083 181.62847 \nL 218.446959 181.62847 \nL 222.213836 183.619849 \nL 225.980713 181.62847 \nL 229.747589 179.637091 \nL 233.514466 183.619849 \nL 237.281343 179.637091 \nL 241.04822 181.62847 \nL 244.815096 179.637091 \nL 248.581973 185.611228 \nL 252.34885 181.62847 \nL 256.115726 181.62847 \nL 259.882603 183.619849 \nL 263.64948 181.62847 \nL 267.416356 179.637091 \nL 271.183233 179.637091 \nL 274.95011 179.637091 \nL 278.716986 181.62847 \nL 282.483863 181.62847 \nL 286.25074 181.62847 \nL 290.017616 181.62847 \nL 293.784493 179.637091 \nL 297.55137 183.619849 \nL 301.318247 183.619849 \nL 305.085123 181.62847 \nL 308.852 181.62847 \nL 312.618877 181.62847 \nL 316.385753 181.62847 \nL 320.15263 181.62847 \nL 323.919507 179.637091 \nL 327.686383 181.62847 \nL 331.45326 183.619849 \nL 335.220137 181.62847 \nL 338.987013 183.619849 \nL 342.75389 183.619849 \nL 346.520767 179.637091 \nL 350.287643 181.62847 \nL 354.05452 183.619849 \nL 357.821397 179.637091 \nL 361.588274 179.637091 \nL 365.35515 179.637091 \nL 369.122027 179.637091 \nL 372.888904 181.62847 \nL 376.65578 183.619849 \nL 380.422657 179.637091 \nL 384.189534 181.62847 \nL 387.95641 181.62847 \nL 391.723287 179.637091 \nL 395.490164 179.637091 \nL 399.25704 181.62847 \nL 403.023917 179.637091 \nL 406.790794 179.637091 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path d=\"M 33.870002 205.525022 \nL 37.636878 209.50778 \nL 41.403755 211.499159 \nL 45.170632 213.490539 \nL 48.937508 205.525022 \nL 52.704385 193.576746 \nL 56.471262 181.62847 \nL 60.238139 181.62847 \nL 64.005015 181.62847 \nL 67.771892 177.645711 \nL 71.538769 175.654332 \nL 75.305645 175.654332 \nL 79.072522 177.645711 \nL 82.839399 173.662953 \nL 86.606275 173.662953 \nL 90.373152 177.645711 \nL 94.140029 173.662953 \nL 97.906905 175.654332 \nL 101.673782 175.654332 \nL 105.440659 175.654332 \nL 109.207535 173.662953 \nL 112.974412 177.645711 \nL 116.741289 175.654332 \nL 120.508166 177.645711 \nL 124.275042 181.62847 \nL 128.041919 175.654332 \nL 131.808796 175.654332 \nL 135.575672 177.645711 \nL 139.342549 179.637091 \nL 143.109426 175.654332 \nL 146.876302 175.654332 \nL 150.643179 179.637091 \nL 154.410056 175.654332 \nL 158.176932 177.645711 \nL 161.943809 175.654332 \nL 165.710686 175.654332 \nL 169.477562 181.62847 \nL 173.244439 177.645711 \nL 177.011316 175.654332 \nL 180.778193 177.645711 \nL 184.545069 175.654332 \nL 188.311946 181.62847 \nL 192.078823 179.637091 \nL 195.845699 177.645711 \nL 199.612576 177.645711 \nL 203.379453 177.645711 \nL 207.146329 183.619849 \nL 210.913206 179.637091 \nL 214.680083 177.645711 \nL 218.446959 179.637091 \nL 222.213836 179.637091 \nL 225.980713 177.645711 \nL 229.747589 177.645711 \nL 233.514466 181.62847 \nL 237.281343 177.645711 \nL 241.04822 177.645711 \nL 244.815096 177.645711 \nL 248.581973 175.654332 \nL 252.34885 177.645711 \nL 256.115726 177.645711 \nL 259.882603 179.637091 \nL 263.64948 177.645711 \nL 267.416356 177.645711 \nL 271.183233 175.654332 \nL 274.95011 177.645711 \nL 278.716986 177.645711 \nL 282.483863 177.645711 \nL 286.25074 177.645711 \nL 290.017616 177.645711 \nL 293.784493 177.645711 \nL 297.55137 179.637091 \nL 301.318247 177.645711 \nL 305.085123 177.645711 \nL 308.852 177.645711 \nL 312.618877 177.645711 \nL 316.385753 177.645711 \nL 320.15263 177.645711 \nL 323.919507 177.645711 \nL 327.686383 177.645711 \nL 331.45326 179.637091 \nL 335.220137 177.645711 \nL 338.987013 177.645711 \nL 342.75389 177.645711 \nL 346.520767 177.645711 \nL 350.287643 177.645711 \nL 354.05452 177.645711 \nL 357.821397 177.645711 \nL 361.588274 177.645711 \nL 365.35515 177.645711 \nL 369.122027 177.645711 \nL 372.888904 177.645711 \nL 376.65578 177.645711 \nL 380.422657 177.645711 \nL 384.189534 177.645711 \nL 387.95641 177.645711 \nL 391.723287 177.645711 \nL 395.490164 177.645711 \nL 399.25704 177.645711 \nL 403.023917 177.645711 \nL 406.790794 177.645711 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path d=\"M 33.870002 203.533642 \nL 37.636878 205.525022 \nL 41.403755 209.50778 \nL 45.170632 211.499159 \nL 48.937508 201.542263 \nL 52.704385 189.593987 \nL 56.471262 181.62847 \nL 60.238139 181.62847 \nL 64.005015 175.654332 \nL 67.771892 175.654332 \nL 71.538769 175.654332 \nL 75.305645 171.671573 \nL 79.072522 175.654332 \nL 82.839399 173.662953 \nL 86.606275 173.662953 \nL 90.373152 175.654332 \nL 94.140029 173.662953 \nL 97.906905 173.662953 \nL 101.673782 173.662953 \nL 105.440659 175.654332 \nL 109.207535 173.662953 \nL 112.974412 177.645711 \nL 116.741289 175.654332 \nL 120.508166 173.662953 \nL 124.275042 177.645711 \nL 128.041919 175.654332 \nL 131.808796 173.662953 \nL 135.575672 177.645711 \nL 139.342549 179.637091 \nL 143.109426 175.654332 \nL 146.876302 173.662953 \nL 150.643179 179.637091 \nL 154.410056 175.654332 \nL 158.176932 175.654332 \nL 161.943809 175.654332 \nL 165.710686 175.654332 \nL 169.477562 177.645711 \nL 173.244439 175.654332 \nL 177.011316 175.654332 \nL 180.778193 177.645711 \nL 184.545069 175.654332 \nL 188.311946 177.645711 \nL 192.078823 177.645711 \nL 195.845699 175.654332 \nL 199.612576 175.654332 \nL 203.379453 177.645711 \nL 207.146329 177.645711 \nL 210.913206 177.645711 \nL 214.680083 175.654332 \nL 218.446959 177.645711 \nL 222.213836 177.645711 \nL 225.980713 175.654332 \nL 229.747589 177.645711 \nL 233.514466 177.645711 \nL 237.281343 177.645711 \nL 241.04822 175.654332 \nL 244.815096 177.645711 \nL 248.581973 175.654332 \nL 252.34885 175.654332 \nL 256.115726 177.645711 \nL 259.882603 177.645711 \nL 263.64948 177.645711 \nL 267.416356 177.645711 \nL 271.183233 175.654332 \nL 274.95011 177.645711 \nL 278.716986 177.645711 \nL 282.483863 177.645711 \nL 286.25074 177.645711 \nL 290.017616 177.645711 \nL 293.784493 177.645711 \nL 297.55137 177.645711 \nL 301.318247 177.645711 \nL 305.085123 177.645711 \nL 308.852 177.645711 \nL 312.618877 177.645711 \nL 316.385753 177.645711 \nL 320.15263 177.645711 \nL 323.919507 177.645711 \nL 327.686383 177.645711 \nL 331.45326 177.645711 \nL 335.220137 177.645711 \nL 338.987013 177.645711 \nL 342.75389 177.645711 \nL 346.520767 177.645711 \nL 350.287643 177.645711 \nL 354.05452 177.645711 \nL 357.821397 177.645711 \nL 361.588274 177.645711 \nL 365.35515 177.645711 \nL 369.122027 177.645711 \nL 372.888904 177.645711 \nL 376.65578 177.645711 \nL 380.422657 177.645711 \nL 384.189534 177.645711 \nL 387.95641 177.645711 \nL 391.723287 177.645711 \nL 395.490164 177.645711 \nL 399.25704 177.645711 \nL 403.023917 177.645711 \nL 406.790794 177.645711 \n\" clip-path=\"url(#pb173291db9)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 213.490539 \nL 30.103125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 410.55767 213.490539 \nL 410.55767 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 213.490539 \nL 410.55767 213.490539 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 22.318125 \nL 410.55767 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- Training result when p = 100 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(133.661335 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 147.743125 \nL 149.8875 147.743125 \nQ 151.8875 147.743125 151.8875 145.743125 \nL 151.8875 29.318125 \nQ 151.8875 27.318125 149.8875 27.318125 \nL 37.103125 27.318125 \nQ 35.103125 27.318125 35.103125 29.318125 \nL 35.103125 145.743125 \nQ 35.103125 147.743125 37.103125 147.743125 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_39\">\n     <path d=\"M 39.103125 35.416563 \nL 49.103125 35.416563 \nL 59.103125 35.416563 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 38.916563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_40\">\n     <path d=\"M 39.103125 50.094687 \nL 49.103125 50.094687 \nL 59.103125 50.094687 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_41\">\n     <path d=\"M 39.103125 64.772813 \nL 49.103125 64.772813 \nL 59.103125 64.772813 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 68.272813)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_42\">\n     <path d=\"M 39.103125 79.450938 \nL 49.103125 79.450938 \nL 59.103125 79.450938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 82.950938)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_43\">\n     <path d=\"M 39.103125 94.129063 \nL 49.103125 94.129063 \nL 59.103125 94.129063 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_22\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 97.629063)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_44\">\n     <path d=\"M 39.103125 108.807188 \nL 49.103125 108.807188 \nL 59.103125 108.807188 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_23\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 112.307188)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_45\">\n     <path d=\"M 39.103125 123.485312 \nL 49.103125 123.485312 \nL 59.103125 123.485312 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_24\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 126.985312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_46\">\n     <path d=\"M 39.103125 138.163438 \nL 49.103125 138.163438 \nL 59.103125 138.163438 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_25\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 141.663438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 486.64858 213.490539 \nL 867.103125 213.490539 \nL 867.103125 22.318125 \nL 486.64858 22.318125 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_7\">\n     <g id=\"line2d_47\">\n      <path d=\"M 486.64858 213.490539 \nL 486.64858 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_48\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"486.64858\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(483.46733 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_49\">\n      <path d=\"M 561.986113 213.490539 \nL 561.986113 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_50\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"561.986113\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(555.623613 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_51\">\n      <path d=\"M 637.323647 213.490539 \nL 637.323647 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_52\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"637.323647\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_28\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(630.961147 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_53\">\n      <path d=\"M 712.661181 213.490539 \nL 712.661181 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_54\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"712.661181\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(706.298681 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_55\">\n      <path d=\"M 787.998715 213.490539 \nL 787.998715 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_56\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"787.998715\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(781.636215 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_57\">\n      <path d=\"M 863.336248 213.490539 \nL 863.336248 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_58\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"863.336248\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(853.792498 228.088976)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_32\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(658.960227 241.767101)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_10\">\n     <g id=\"line2d_59\">\n      <path d=\"M 486.64858 213.490539 \nL 867.103125 213.490539 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_60\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"213.490539\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_33\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 217.289758)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_61\">\n      <path d=\"M 486.64858 189.593987 \nL 867.103125 189.593987 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_62\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"189.593987\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_34\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 193.393206)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_63\">\n      <path d=\"M 486.64858 165.697435 \nL 867.103125 165.697435 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_64\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"165.697435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_35\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 169.496654)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_65\">\n      <path d=\"M 486.64858 141.800884 \nL 867.103125 141.800884 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_66\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"141.800884\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_36\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 145.600102)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_67\">\n      <path d=\"M 486.64858 117.904332 \nL 867.103125 117.904332 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_68\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"117.904332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_37\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 121.703551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_69\">\n      <path d=\"M 486.64858 94.00778 \nL 867.103125 94.00778 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_70\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"94.00778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_38\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 97.806999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_71\">\n      <path d=\"M 486.64858 70.111228 \nL 867.103125 70.111228 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_72\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"70.111228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_39\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 73.910447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_73\">\n      <path d=\"M 486.64858 46.214677 \nL 867.103125 46.214677 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_74\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"46.214677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_40\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 50.013895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_75\">\n      <path d=\"M 486.64858 22.318125 \nL 867.103125 22.318125 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_76\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"22.318125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_41\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 26.117344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_77\">\n    <path d=\"M 490.415456 25.535395 \nL 494.182333 17.23167 \nL 497.94921 20.900383 \nL 501.716086 26.974943 \nL 505.482963 31.340449 \nL 509.24984 35.157411 \nL 513.016716 38.636142 \nL 516.783593 41.231824 \nL 520.55047 43.844175 \nL 524.317346 45.667559 \nL 528.084223 47.918683 \nL 531.8511 49.362595 \nL 535.617976 51.13632 \nL 539.384853 52.801738 \nL 543.15173 54.282055 \nL 546.918607 54.674511 \nL 550.685483 55.981336 \nL 554.45236 56.208358 \nL 558.219237 57.238194 \nL 561.986113 58.102408 \nL 565.75299 58.571931 \nL 569.519867 59.468923 \nL 573.286743 60.085844 \nL 577.05362 60.239147 \nL 580.820497 60.517386 \nL 584.587373 59.990182 \nL 588.35425 60.918064 \nL 592.121127 61.109042 \nL 595.888003 61.690185 \nL 599.65488 61.718862 \nL 603.421757 61.472873 \nL 607.188634 62.606685 \nL 610.95551 62.364219 \nL 614.722387 62.088146 \nL 618.489264 62.734609 \nL 622.25614 62.995468 \nL 626.023017 62.792863 \nL 629.789894 63.039159 \nL 633.55677 62.960799 \nL 637.323647 63.300883 \nL 641.090524 63.102462 \nL 644.8574 63.692943 \nL 648.624277 63.937295 \nL 652.391154 63.389528 \nL 656.15803 63.852501 \nL 659.924907 63.830508 \nL 663.691784 63.384822 \nL 667.458661 63.820179 \nL 671.225537 64.010664 \nL 674.992414 64.549438 \nL 678.759291 63.915768 \nL 682.526167 64.150095 \nL 686.293044 64.800487 \nL 690.059921 64.222133 \nL 693.826797 64.327913 \nL 697.593674 64.161071 \nL 701.360551 64.436608 \nL 705.127427 65.011723 \nL 708.894304 64.342249 \nL 712.661181 64.911892 \nL 716.428057 64.369428 \nL 720.194934 65.197218 \nL 723.961811 64.549802 \nL 727.728688 65.095237 \nL 731.495564 65.435004 \nL 735.262441 64.621947 \nL 739.029318 65.774031 \nL 742.796194 65.380808 \nL 746.563071 65.226524 \nL 750.329948 64.41109 \nL 754.096824 65.024748 \nL 757.863701 65.303779 \nL 761.630578 64.754236 \nL 765.397454 65.073789 \nL 769.164331 65.345768 \nL 772.931208 65.25307 \nL 776.698084 65.583186 \nL 780.464961 65.523457 \nL 784.231838 64.184182 \nL 787.998715 64.923531 \nL 791.765591 65.539042 \nL 795.532468 64.700758 \nL 799.299345 65.274795 \nL 803.066221 65.430056 \nL 806.833098 65.555449 \nL 810.599975 64.904174 \nL 814.366851 65.589288 \nL 818.133728 65.27705 \nL 821.900605 65.871215 \nL 825.667481 65.177074 \nL 829.434358 65.175922 \nL 833.201235 65.145244 \nL 836.968111 65.064165 \nL 840.734988 65.871899 \nL 844.501865 66.028855 \nL 848.268742 65.555925 \nL 852.035618 64.918056 \nL 855.802495 65.034796 \nL 859.569372 65.305584 \nL 863.336248 65.567425 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_78\">\n    <path d=\"M 490.415456 208.711228 \nL 494.182333 206.918987 \nL 497.94921 207.217694 \nL 501.716086 207.516401 \nL 505.482963 207.217694 \nL 509.24984 202.438384 \nL 513.016716 186.606918 \nL 516.783593 178.243125 \nL 520.55047 175.256056 \nL 524.317346 175.85347 \nL 528.084223 172.268987 \nL 531.8511 171.372866 \nL 535.617976 172.567694 \nL 539.384853 171.372866 \nL 543.15173 170.775453 \nL 546.918607 171.372866 \nL 550.685483 171.671573 \nL 554.45236 169.281918 \nL 558.219237 169.879332 \nL 561.986113 169.580625 \nL 565.75299 168.684504 \nL 569.519867 168.684504 \nL 573.286743 168.087091 \nL 577.05362 168.385797 \nL 580.820497 168.087091 \nL 584.587373 168.684504 \nL 588.35425 168.087091 \nL 592.121127 168.087091 \nL 595.888003 168.385797 \nL 599.65488 168.684504 \nL 603.421757 168.385797 \nL 607.188634 167.489677 \nL 610.95551 167.19097 \nL 614.722387 167.489677 \nL 618.489264 168.087091 \nL 622.25614 166.593556 \nL 626.023017 166.892263 \nL 629.789894 168.385797 \nL 633.55677 168.087091 \nL 637.323647 166.892263 \nL 641.090524 166.294849 \nL 644.8574 167.19097 \nL 648.624277 166.294849 \nL 652.391154 165.697435 \nL 656.15803 165.697435 \nL 659.924907 165.697435 \nL 663.691784 165.697435 \nL 667.458661 165.996142 \nL 671.225537 165.697435 \nL 674.992414 166.294849 \nL 678.759291 166.294849 \nL 682.526167 165.996142 \nL 686.293044 166.294849 \nL 690.059921 166.294849 \nL 693.826797 165.697435 \nL 697.593674 166.294849 \nL 701.360551 165.996142 \nL 705.127427 165.996142 \nL 708.894304 165.996142 \nL 712.661181 165.697435 \nL 716.428057 165.697435 \nL 720.194934 165.697435 \nL 723.961811 165.697435 \nL 727.728688 165.697435 \nL 731.495564 165.697435 \nL 735.262441 165.697435 \nL 739.029318 165.697435 \nL 742.796194 165.697435 \nL 746.563071 165.697435 \nL 750.329948 165.697435 \nL 754.096824 165.697435 \nL 757.863701 165.697435 \nL 761.630578 165.697435 \nL 765.397454 165.697435 \nL 769.164331 165.697435 \nL 772.931208 165.697435 \nL 776.698084 165.697435 \nL 780.464961 165.697435 \nL 784.231838 165.697435 \nL 787.998715 165.697435 \nL 791.765591 165.697435 \nL 795.532468 165.697435 \nL 799.299345 165.697435 \nL 803.066221 165.697435 \nL 806.833098 165.697435 \nL 810.599975 165.697435 \nL 814.366851 165.697435 \nL 818.133728 165.697435 \nL 821.900605 165.697435 \nL 825.667481 165.697435 \nL 829.434358 165.697435 \nL 833.201235 165.697435 \nL 836.968111 165.697435 \nL 840.734988 165.697435 \nL 844.501865 165.697435 \nL 848.268742 165.697435 \nL 852.035618 165.697435 \nL 855.802495 165.697435 \nL 859.569372 165.697435 \nL 863.336248 165.697435 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_79\">\n    <path d=\"M 490.415456 206.321573 \nL 494.182333 205.126746 \nL 497.94921 204.529332 \nL 501.716086 204.828039 \nL 505.482963 205.126746 \nL 509.24984 194.970711 \nL 513.016716 179.736659 \nL 516.783593 171.372866 \nL 520.55047 170.178039 \nL 524.317346 170.178039 \nL 528.084223 168.684504 \nL 531.8511 167.489677 \nL 535.617976 169.580625 \nL 539.384853 167.19097 \nL 543.15173 167.489677 \nL 546.918607 167.19097 \nL 550.685483 167.788384 \nL 554.45236 166.294849 \nL 558.219237 166.294849 \nL 561.986113 166.294849 \nL 565.75299 166.294849 \nL 569.519867 165.697435 \nL 573.286743 165.996142 \nL 577.05362 165.996142 \nL 580.820497 165.697435 \nL 584.587373 165.996142 \nL 588.35425 165.697435 \nL 592.121127 165.996142 \nL 595.888003 166.294849 \nL 599.65488 165.996142 \nL 603.421757 166.294849 \nL 607.188634 165.697435 \nL 610.95551 165.697435 \nL 614.722387 165.996142 \nL 618.489264 165.697435 \nL 622.25614 165.697435 \nL 626.023017 165.996142 \nL 629.789894 166.294849 \nL 633.55677 165.697435 \nL 637.323647 165.697435 \nL 641.090524 165.697435 \nL 644.8574 165.697435 \nL 648.624277 165.697435 \nL 652.391154 165.697435 \nL 656.15803 165.697435 \nL 659.924907 165.697435 \nL 663.691784 165.697435 \nL 667.458661 165.697435 \nL 671.225537 165.697435 \nL 674.992414 165.697435 \nL 678.759291 165.697435 \nL 682.526167 165.697435 \nL 686.293044 165.697435 \nL 690.059921 165.697435 \nL 693.826797 165.697435 \nL 697.593674 165.697435 \nL 701.360551 165.697435 \nL 705.127427 165.697435 \nL 708.894304 165.697435 \nL 712.661181 165.697435 \nL 716.428057 165.697435 \nL 720.194934 165.697435 \nL 723.961811 165.697435 \nL 727.728688 165.697435 \nL 731.495564 165.697435 \nL 735.262441 165.697435 \nL 739.029318 165.697435 \nL 742.796194 165.697435 \nL 746.563071 165.697435 \nL 750.329948 165.697435 \nL 754.096824 165.697435 \nL 757.863701 165.697435 \nL 761.630578 165.697435 \nL 765.397454 165.697435 \nL 769.164331 165.697435 \nL 772.931208 165.697435 \nL 776.698084 165.697435 \nL 780.464961 165.697435 \nL 784.231838 165.697435 \nL 787.998715 165.697435 \nL 791.765591 165.697435 \nL 795.532468 165.697435 \nL 799.299345 165.697435 \nL 803.066221 165.697435 \nL 806.833098 165.697435 \nL 810.599975 165.697435 \nL 814.366851 165.697435 \nL 818.133728 165.697435 \nL 821.900605 165.697435 \nL 825.667481 165.697435 \nL 829.434358 165.697435 \nL 833.201235 165.697435 \nL 836.968111 165.697435 \nL 840.734988 165.697435 \nL 844.501865 165.697435 \nL 848.268742 165.697435 \nL 852.035618 165.697435 \nL 855.802495 165.697435 \nL 859.569372 165.697435 \nL 863.336248 165.697435 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_80\">\n    <path d=\"M 490.415456 204.529332 \nL 494.182333 201.243556 \nL 497.94921 202.139677 \nL 501.716086 203.035797 \nL 505.482963 203.035797 \nL 509.24984 192.581056 \nL 513.016716 174.957349 \nL 516.783593 168.385797 \nL 520.55047 167.788384 \nL 524.317346 168.087091 \nL 528.084223 166.294849 \nL 531.8511 166.593556 \nL 535.617976 166.593556 \nL 539.384853 165.996142 \nL 543.15173 165.996142 \nL 546.918607 165.996142 \nL 550.685483 165.996142 \nL 554.45236 165.697435 \nL 558.219237 165.996142 \nL 561.986113 165.996142 \nL 565.75299 165.697435 \nL 569.519867 165.697435 \nL 573.286743 165.697435 \nL 577.05362 165.697435 \nL 580.820497 165.697435 \nL 584.587373 165.697435 \nL 588.35425 165.697435 \nL 592.121127 165.697435 \nL 595.888003 165.697435 \nL 599.65488 165.697435 \nL 603.421757 165.697435 \nL 607.188634 165.697435 \nL 610.95551 165.697435 \nL 614.722387 165.697435 \nL 618.489264 165.697435 \nL 622.25614 165.697435 \nL 626.023017 165.697435 \nL 629.789894 165.697435 \nL 633.55677 165.697435 \nL 637.323647 165.697435 \nL 641.090524 165.697435 \nL 644.8574 165.697435 \nL 648.624277 165.697435 \nL 652.391154 165.697435 \nL 656.15803 165.697435 \nL 659.924907 165.697435 \nL 663.691784 165.697435 \nL 667.458661 165.697435 \nL 671.225537 165.697435 \nL 674.992414 165.697435 \nL 678.759291 165.697435 \nL 682.526167 165.697435 \nL 686.293044 165.697435 \nL 690.059921 165.697435 \nL 693.826797 165.697435 \nL 697.593674 165.697435 \nL 701.360551 165.697435 \nL 705.127427 165.697435 \nL 708.894304 165.697435 \nL 712.661181 165.697435 \nL 716.428057 165.697435 \nL 720.194934 165.697435 \nL 723.961811 165.697435 \nL 727.728688 165.697435 \nL 731.495564 165.697435 \nL 735.262441 165.697435 \nL 739.029318 165.697435 \nL 742.796194 165.697435 \nL 746.563071 165.697435 \nL 750.329948 165.697435 \nL 754.096824 165.697435 \nL 757.863701 165.697435 \nL 761.630578 165.697435 \nL 765.397454 165.697435 \nL 769.164331 165.697435 \nL 772.931208 165.697435 \nL 776.698084 165.697435 \nL 780.464961 165.697435 \nL 784.231838 165.697435 \nL 787.998715 165.697435 \nL 791.765591 165.697435 \nL 795.532468 165.697435 \nL 799.299345 165.697435 \nL 803.066221 165.697435 \nL 806.833098 165.697435 \nL 810.599975 165.697435 \nL 814.366851 165.697435 \nL 818.133728 165.697435 \nL 821.900605 165.697435 \nL 825.667481 165.697435 \nL 829.434358 165.697435 \nL 833.201235 165.697435 \nL 836.968111 165.697435 \nL 840.734988 165.697435 \nL 844.501865 165.697435 \nL 848.268742 165.697435 \nL 852.035618 165.697435 \nL 855.802495 165.697435 \nL 859.569372 165.697435 \nL 863.336248 165.697435 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_81\">\n    <path d=\"M 490.415456 10.527123 \nL 494.182333 12.086701 \nL 497.94921 12.756896 \nL 501.716086 16.524334 \nL 505.482963 20.252813 \nL 509.24984 30.667293 \nL 513.016716 33.705738 \nL 516.783593 36.348958 \nL 520.55047 37.453975 \nL 524.317346 39.018001 \nL 528.084223 38.611416 \nL 531.8511 39.617374 \nL 535.617976 39.869476 \nL 539.384853 41.454734 \nL 543.15173 41.316019 \nL 546.918607 41.510339 \nL 550.685483 39.740675 \nL 554.45236 41.475754 \nL 558.219237 38.233328 \nL 561.986113 41.962209 \nL 565.75299 43.132811 \nL 569.519867 42.250569 \nL 573.286743 42.646913 \nL 577.05362 42.830487 \nL 580.820497 41.679256 \nL 584.587373 39.598426 \nL 588.35425 42.543556 \nL 592.121127 42.975308 \nL 595.888003 43.530399 \nL 599.65488 42.976039 \nL 603.421757 43.012038 \nL 607.188634 43.012965 \nL 610.95551 42.160758 \nL 614.722387 43.893558 \nL 618.489264 43.154883 \nL 622.25614 43.156898 \nL 626.023017 42.193297 \nL 629.789894 42.32323 \nL 633.55677 42.363712 \nL 637.323647 42.036271 \nL 641.090524 42.563189 \nL 644.8574 41.854721 \nL 648.624277 42.771046 \nL 652.391154 43.037512 \nL 656.15803 43.084232 \nL 659.924907 40.985794 \nL 663.691784 42.982515 \nL 667.458661 41.975633 \nL 671.225537 43.01707 \nL 674.992414 42.789671 \nL 678.759291 42.397476 \nL 682.526167 42.96043 \nL 686.293044 42.659123 \nL 690.059921 41.551186 \nL 693.826797 42.040223 \nL 697.593674 42.357692 \nL 701.360551 43.291124 \nL 705.127427 42.190692 \nL 708.894304 43.058474 \nL 712.661181 43.2217 \nL 716.428057 42.566918 \nL 720.194934 43.985653 \nL 723.961811 43.420593 \nL 727.728688 41.541555 \nL 731.495564 42.535757 \nL 735.262441 41.729755 \nL 739.029318 42.720878 \nL 742.796194 42.892278 \nL 746.563071 41.962309 \nL 750.329948 41.700625 \nL 754.096824 43.05898 \nL 757.863701 42.159581 \nL 761.630578 42.785813 \nL 765.397454 41.878761 \nL 769.164331 42.539826 \nL 772.931208 42.738566 \nL 776.698084 42.899847 \nL 780.464961 42.99065 \nL 784.231838 43.116066 \nL 787.998715 42.365768 \nL 791.765591 42.929853 \nL 795.532468 42.46025 \nL 799.299345 42.178536 \nL 803.066221 43.263265 \nL 806.833098 43.051013 \nL 810.599975 42.830829 \nL 814.366851 42.490484 \nL 818.133728 43.019165 \nL 821.900605 43.044745 \nL 825.667481 42.654837 \nL 829.434358 43.109302 \nL 833.201235 42.494019 \nL 836.968111 41.998002 \nL 840.734988 42.689762 \nL 844.501865 43.368151 \nL 848.268742 42.855004 \nL 852.035618 42.983185 \nL 855.802495 43.322637 \nL 859.569372 42.872536 \nL 863.336248 42.713146 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_82\">\n    <path d=\"M 490.415456 213.490539 \nL 494.182333 213.490539 \nL 497.94921 213.490539 \nL 501.716086 213.490539 \nL 505.482963 213.490539 \nL 509.24984 207.516401 \nL 513.016716 191.585366 \nL 516.783593 191.585366 \nL 520.55047 187.602608 \nL 524.317346 187.602608 \nL 528.084223 185.611228 \nL 531.8511 183.619849 \nL 535.617976 185.611228 \nL 539.384853 183.619849 \nL 543.15173 189.593987 \nL 546.918607 185.611228 \nL 550.685483 185.611228 \nL 554.45236 193.576746 \nL 558.219237 189.593987 \nL 561.986113 183.619849 \nL 565.75299 183.619849 \nL 569.519867 189.593987 \nL 573.286743 183.619849 \nL 577.05362 187.602608 \nL 580.820497 195.568125 \nL 584.587373 185.611228 \nL 588.35425 187.602608 \nL 592.121127 185.611228 \nL 595.888003 185.611228 \nL 599.65488 189.593987 \nL 603.421757 189.593987 \nL 607.188634 185.611228 \nL 610.95551 189.593987 \nL 614.722387 185.611228 \nL 618.489264 183.619849 \nL 622.25614 191.585366 \nL 626.023017 189.593987 \nL 629.789894 189.593987 \nL 633.55677 185.611228 \nL 637.323647 191.585366 \nL 641.090524 185.611228 \nL 644.8574 187.602608 \nL 648.624277 187.602608 \nL 652.391154 183.619849 \nL 656.15803 181.62847 \nL 659.924907 181.62847 \nL 663.691784 187.602608 \nL 667.458661 183.619849 \nL 671.225537 187.602608 \nL 674.992414 185.611228 \nL 678.759291 183.619849 \nL 682.526167 187.602608 \nL 686.293044 181.62847 \nL 690.059921 181.62847 \nL 693.826797 183.619849 \nL 697.593674 183.619849 \nL 701.360551 181.62847 \nL 705.127427 179.637091 \nL 708.894304 181.62847 \nL 712.661181 183.619849 \nL 716.428057 185.611228 \nL 720.194934 181.62847 \nL 723.961811 179.637091 \nL 727.728688 183.619849 \nL 731.495564 183.619849 \nL 735.262441 183.619849 \nL 739.029318 183.619849 \nL 742.796194 183.619849 \nL 746.563071 181.62847 \nL 750.329948 185.611228 \nL 754.096824 183.619849 \nL 757.863701 183.619849 \nL 761.630578 185.611228 \nL 765.397454 185.611228 \nL 769.164331 183.619849 \nL 772.931208 183.619849 \nL 776.698084 185.611228 \nL 780.464961 183.619849 \nL 784.231838 181.62847 \nL 787.998715 183.619849 \nL 791.765591 181.62847 \nL 795.532468 181.62847 \nL 799.299345 181.62847 \nL 803.066221 181.62847 \nL 806.833098 179.637091 \nL 810.599975 179.637091 \nL 814.366851 181.62847 \nL 818.133728 181.62847 \nL 821.900605 181.62847 \nL 825.667481 181.62847 \nL 829.434358 181.62847 \nL 833.201235 181.62847 \nL 836.968111 181.62847 \nL 840.734988 183.619849 \nL 844.501865 181.62847 \nL 848.268742 183.619849 \nL 852.035618 183.619849 \nL 855.802495 181.62847 \nL 859.569372 183.619849 \nL 863.336248 183.619849 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_83\">\n    <path d=\"M 490.415456 211.499159 \nL 494.182333 213.490539 \nL 497.94921 211.499159 \nL 501.716086 213.490539 \nL 505.482963 213.490539 \nL 509.24984 197.559504 \nL 513.016716 177.645711 \nL 516.783593 183.619849 \nL 520.55047 175.654332 \nL 524.317346 179.637091 \nL 528.084223 179.637091 \nL 531.8511 175.654332 \nL 535.617976 177.645711 \nL 539.384853 175.654332 \nL 543.15173 173.662953 \nL 546.918607 173.662953 \nL 550.685483 177.645711 \nL 554.45236 177.645711 \nL 558.219237 177.645711 \nL 561.986113 175.654332 \nL 565.75299 173.662953 \nL 569.519867 175.654332 \nL 573.286743 175.654332 \nL 577.05362 173.662953 \nL 580.820497 183.619849 \nL 584.587373 175.654332 \nL 588.35425 181.62847 \nL 592.121127 177.645711 \nL 595.888003 183.619849 \nL 599.65488 175.654332 \nL 603.421757 181.62847 \nL 607.188634 181.62847 \nL 610.95551 181.62847 \nL 614.722387 177.645711 \nL 618.489264 175.654332 \nL 622.25614 181.62847 \nL 626.023017 181.62847 \nL 629.789894 179.637091 \nL 633.55677 177.645711 \nL 637.323647 179.637091 \nL 641.090524 175.654332 \nL 644.8574 177.645711 \nL 648.624277 179.637091 \nL 652.391154 175.654332 \nL 656.15803 175.654332 \nL 659.924907 179.637091 \nL 663.691784 179.637091 \nL 667.458661 175.654332 \nL 671.225537 179.637091 \nL 674.992414 179.637091 \nL 678.759291 179.637091 \nL 682.526167 177.645711 \nL 686.293044 177.645711 \nL 690.059921 181.62847 \nL 693.826797 179.637091 \nL 697.593674 177.645711 \nL 701.360551 179.637091 \nL 705.127427 175.654332 \nL 708.894304 177.645711 \nL 712.661181 177.645711 \nL 716.428057 177.645711 \nL 720.194934 177.645711 \nL 723.961811 177.645711 \nL 727.728688 177.645711 \nL 731.495564 177.645711 \nL 735.262441 179.637091 \nL 739.029318 177.645711 \nL 742.796194 177.645711 \nL 746.563071 179.637091 \nL 750.329948 179.637091 \nL 754.096824 179.637091 \nL 757.863701 179.637091 \nL 761.630578 177.645711 \nL 765.397454 179.637091 \nL 769.164331 179.637091 \nL 772.931208 179.637091 \nL 776.698084 177.645711 \nL 780.464961 177.645711 \nL 784.231838 177.645711 \nL 787.998715 177.645711 \nL 791.765591 177.645711 \nL 795.532468 179.637091 \nL 799.299345 179.637091 \nL 803.066221 177.645711 \nL 806.833098 179.637091 \nL 810.599975 177.645711 \nL 814.366851 177.645711 \nL 818.133728 177.645711 \nL 821.900605 177.645711 \nL 825.667481 177.645711 \nL 829.434358 177.645711 \nL 833.201235 179.637091 \nL 836.968111 177.645711 \nL 840.734988 177.645711 \nL 844.501865 177.645711 \nL 848.268742 177.645711 \nL 852.035618 177.645711 \nL 855.802495 177.645711 \nL 859.569372 177.645711 \nL 863.336248 177.645711 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_84\">\n    <path d=\"M 490.415456 207.516401 \nL 494.182333 209.50778 \nL 497.94921 209.50778 \nL 501.716086 213.490539 \nL 505.482963 213.490539 \nL 509.24984 191.585366 \nL 513.016716 175.654332 \nL 516.783593 179.637091 \nL 520.55047 175.654332 \nL 524.317346 175.654332 \nL 528.084223 173.662953 \nL 531.8511 173.662953 \nL 535.617976 173.662953 \nL 539.384853 173.662953 \nL 543.15173 173.662953 \nL 546.918607 173.662953 \nL 550.685483 173.662953 \nL 554.45236 173.662953 \nL 558.219237 177.645711 \nL 561.986113 173.662953 \nL 565.75299 171.671573 \nL 569.519867 175.654332 \nL 573.286743 175.654332 \nL 577.05362 171.671573 \nL 580.820497 179.637091 \nL 584.587373 173.662953 \nL 588.35425 175.654332 \nL 592.121127 175.654332 \nL 595.888003 175.654332 \nL 599.65488 173.662953 \nL 603.421757 175.654332 \nL 607.188634 175.654332 \nL 610.95551 173.662953 \nL 614.722387 175.654332 \nL 618.489264 175.654332 \nL 622.25614 179.637091 \nL 626.023017 177.645711 \nL 629.789894 179.637091 \nL 633.55677 171.671573 \nL 637.323647 179.637091 \nL 641.090524 175.654332 \nL 644.8574 173.662953 \nL 648.624277 177.645711 \nL 652.391154 173.662953 \nL 656.15803 175.654332 \nL 659.924907 175.654332 \nL 663.691784 177.645711 \nL 667.458661 175.654332 \nL 671.225537 175.654332 \nL 674.992414 177.645711 \nL 678.759291 177.645711 \nL 682.526167 175.654332 \nL 686.293044 175.654332 \nL 690.059921 175.654332 \nL 693.826797 177.645711 \nL 697.593674 175.654332 \nL 701.360551 177.645711 \nL 705.127427 175.654332 \nL 708.894304 177.645711 \nL 712.661181 177.645711 \nL 716.428057 177.645711 \nL 720.194934 177.645711 \nL 723.961811 177.645711 \nL 727.728688 177.645711 \nL 731.495564 175.654332 \nL 735.262441 177.645711 \nL 739.029318 177.645711 \nL 742.796194 177.645711 \nL 746.563071 175.654332 \nL 750.329948 179.637091 \nL 754.096824 177.645711 \nL 757.863701 177.645711 \nL 761.630578 177.645711 \nL 765.397454 177.645711 \nL 769.164331 177.645711 \nL 772.931208 177.645711 \nL 776.698084 175.654332 \nL 780.464961 177.645711 \nL 784.231838 177.645711 \nL 787.998715 177.645711 \nL 791.765591 177.645711 \nL 795.532468 177.645711 \nL 799.299345 177.645711 \nL 803.066221 177.645711 \nL 806.833098 177.645711 \nL 810.599975 177.645711 \nL 814.366851 177.645711 \nL 818.133728 177.645711 \nL 821.900605 177.645711 \nL 825.667481 177.645711 \nL 829.434358 175.654332 \nL 833.201235 177.645711 \nL 836.968111 177.645711 \nL 840.734988 177.645711 \nL 844.501865 175.654332 \nL 848.268742 177.645711 \nL 852.035618 177.645711 \nL 855.802495 177.645711 \nL 859.569372 177.645711 \nL 863.336248 175.654332 \n\" clip-path=\"url(#p1063115bc5)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 486.64858 213.490539 \nL 486.64858 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 867.103125 213.490539 \nL 867.103125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 486.64858 213.490539 \nL 867.103125 213.490539 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 486.64858 22.318125 \nL 867.103125 22.318125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_42\">\n    <!-- Training result when p = 200 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(590.20679 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 493.64858 147.743125 \nL 606.432955 147.743125 \nQ 608.432955 147.743125 608.432955 145.743125 \nL 608.432955 29.318125 \nQ 608.432955 27.318125 606.432955 27.318125 \nL 493.64858 27.318125 \nQ 491.64858 27.318125 491.64858 29.318125 \nL 491.64858 145.743125 \nQ 491.64858 147.743125 493.64858 147.743125 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_85\">\n     <path d=\"M 495.64858 35.416563 \nL 505.64858 35.416563 \nL 515.64858 35.416563 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_43\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 38.916563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_86\">\n     <path d=\"M 495.64858 50.094687 \nL 505.64858 50.094687 \nL 515.64858 50.094687 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_44\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_87\">\n     <path d=\"M 495.64858 64.772813 \nL 505.64858 64.772813 \nL 515.64858 64.772813 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_45\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 68.272813)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_88\">\n     <path d=\"M 495.64858 79.450938 \nL 505.64858 79.450938 \nL 515.64858 79.450938 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_46\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 82.950938)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_89\">\n     <path d=\"M 495.64858 94.129063 \nL 505.64858 94.129063 \nL 515.64858 94.129063 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_47\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 97.629063)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_90\">\n     <path d=\"M 495.64858 108.807188 \nL 505.64858 108.807188 \nL 515.64858 108.807188 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_48\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 112.307188)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_91\">\n     <path d=\"M 495.64858 123.485312 \nL 505.64858 123.485312 \nL 515.64858 123.485312 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_49\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 126.985312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_92\">\n     <path d=\"M 495.64858 138.163438 \nL 505.64858 138.163438 \nL 515.64858 138.163438 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_50\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 141.663438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_14\">\n    <path d=\"M 30.103125 442.897435 \nL 410.55767 442.897435 \nL 410.55767 251.725022 \nL 30.103125 251.725022 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_13\">\n     <g id=\"line2d_93\">\n      <path d=\"M 30.103125 442.897435 \nL 30.103125 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_94\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"30.103125\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_51\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(26.921875 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_95\">\n      <path d=\"M 105.440659 442.897435 \nL 105.440659 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_96\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"105.440659\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_52\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(99.078159 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_97\">\n      <path d=\"M 180.778193 442.897435 \nL 180.778193 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_98\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"180.778193\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_53\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(174.415693 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_99\">\n      <path d=\"M 256.115726 442.897435 \nL 256.115726 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_100\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"256.115726\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_54\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(249.753226 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_101\">\n      <path d=\"M 331.45326 442.897435 \nL 331.45326 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_102\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"331.45326\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_55\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(325.09076 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_103\">\n      <path d=\"M 406.790794 442.897435 \nL 406.790794 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_104\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"406.790794\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_56\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(397.247044 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_57\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(202.414773 471.173998)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_19\">\n     <g id=\"line2d_105\">\n      <path d=\"M 30.103125 442.897435 \nL 410.55767 442.897435 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_106\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_58\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 446.696654)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_107\">\n      <path d=\"M 30.103125 419.000884 \nL 410.55767 419.000884 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_108\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"419.000884\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_59\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 422.800102)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_21\">\n     <g id=\"line2d_109\">\n      <path d=\"M 30.103125 395.104332 \nL 410.55767 395.104332 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_110\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"395.104332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_60\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 398.903551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_111\">\n      <path d=\"M 30.103125 371.20778 \nL 410.55767 371.20778 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_112\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"371.20778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_61\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 375.006999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_113\">\n      <path d=\"M 30.103125 347.311228 \nL 410.55767 347.311228 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_114\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"347.311228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_62\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 351.110447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_24\">\n     <g id=\"line2d_115\">\n      <path d=\"M 30.103125 323.414677 \nL 410.55767 323.414677 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_116\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"323.414677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_63\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 327.213895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_25\">\n     <g id=\"line2d_117\">\n      <path d=\"M 30.103125 299.518125 \nL 410.55767 299.518125 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_118\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"299.518125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_64\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 303.317344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_26\">\n     <g id=\"line2d_119\">\n      <path d=\"M 30.103125 275.621573 \nL 410.55767 275.621573 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_120\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"275.621573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_65\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 279.420792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_27\">\n     <g id=\"line2d_121\">\n      <path d=\"M 30.103125 251.725022 \nL 410.55767 251.725022 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_122\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"251.725022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_66\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 255.52424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 33.870002 255.099987 \nL 37.636878 246.364497 \nL 41.403755 249.762695 \nL 45.170632 255.953674 \nL 48.937508 260.239295 \nL 52.704385 263.765901 \nL 56.471262 267.253472 \nL 60.238139 270.408123 \nL 64.005015 272.925559 \nL 67.771892 275.548701 \nL 71.538769 276.592539 \nL 75.305645 279.20199 \nL 79.072522 281.153434 \nL 82.839399 281.654361 \nL 86.606275 283.100577 \nL 90.373152 284.535853 \nL 94.140029 285.344912 \nL 97.906905 285.889516 \nL 101.673782 286.947001 \nL 105.440659 287.663825 \nL 109.207535 288.186195 \nL 112.974412 288.603399 \nL 116.741289 289.310774 \nL 120.508166 289.53672 \nL 124.275042 289.555031 \nL 128.041919 290.369115 \nL 131.808796 290.336041 \nL 135.575672 290.778785 \nL 139.342549 290.724662 \nL 143.109426 291.033097 \nL 146.876302 291.171342 \nL 150.643179 291.655143 \nL 154.410056 292.179563 \nL 158.176932 291.904483 \nL 161.943809 292.161295 \nL 165.710686 292.566267 \nL 169.477562 292.300753 \nL 173.244439 292.698235 \nL 177.011316 292.567034 \nL 180.778193 292.823668 \nL 184.545069 292.85015 \nL 188.311946 293.125403 \nL 192.078823 293.225024 \nL 195.845699 292.870159 \nL 199.612576 293.219782 \nL 203.379453 293.353987 \nL 207.146329 293.323963 \nL 210.913206 293.360169 \nL 214.680083 293.597848 \nL 218.446959 294.078499 \nL 222.213836 293.695486 \nL 225.980713 293.455187 \nL 229.747589 294.412397 \nL 233.514466 293.590259 \nL 237.281343 294.190566 \nL 241.04822 294.103936 \nL 244.815096 293.483997 \nL 248.581973 294.639154 \nL 252.34885 294.537351 \nL 256.115726 294.144377 \nL 259.882603 294.283353 \nL 263.64948 294.155075 \nL 267.416356 294.302344 \nL 271.183233 294.293331 \nL 274.95011 294.504989 \nL 278.716986 294.970858 \nL 282.483863 294.617946 \nL 286.25074 294.734174 \nL 290.017616 294.216048 \nL 293.784493 294.817896 \nL 297.55137 294.312486 \nL 301.318247 294.899077 \nL 305.085123 294.623579 \nL 308.852 294.260347 \nL 312.618877 294.834362 \nL 316.385753 294.581646 \nL 320.15263 294.692592 \nL 323.919507 294.529308 \nL 327.686383 294.165234 \nL 331.45326 294.267933 \nL 335.220137 294.612833 \nL 338.987013 294.494816 \nL 342.75389 294.548192 \nL 346.520767 295.28702 \nL 350.287643 295.012906 \nL 354.05452 294.952217 \nL 357.821397 294.542455 \nL 361.588274 294.626036 \nL 365.35515 295.132546 \nL 369.122027 294.466016 \nL 372.888904 295.007496 \nL 376.65578 294.811654 \nL 380.422657 294.521395 \nL 384.189534 295.045253 \nL 387.95641 294.763528 \nL 391.723287 294.624732 \nL 395.490164 295.10467 \nL 399.25704 294.711995 \nL 403.023917 295.215963 \nL 406.790794 294.300437 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 33.870002 438.715539 \nL 37.636878 436.923297 \nL 41.403755 436.923297 \nL 45.170632 436.624591 \nL 48.937508 436.923297 \nL 52.704385 430.351746 \nL 56.471262 414.221573 \nL 60.238139 409.143556 \nL 64.005015 406.455194 \nL 67.771892 403.468125 \nL 71.538769 401.974591 \nL 75.305645 402.870711 \nL 79.072522 401.377177 \nL 82.839399 401.675884 \nL 86.606275 402.273297 \nL 90.373152 398.688815 \nL 94.140029 397.792694 \nL 97.906905 398.688815 \nL 101.673782 397.19528 \nL 105.440659 396.896573 \nL 109.207535 397.19528 \nL 112.974412 396.299159 \nL 116.741289 396.299159 \nL 120.508166 396.896573 \nL 124.275042 396.597866 \nL 128.041919 395.403039 \nL 131.808796 395.403039 \nL 135.575672 395.403039 \nL 139.342549 396.896573 \nL 143.109426 395.701746 \nL 146.876302 395.403039 \nL 150.643179 395.403039 \nL 154.410056 395.403039 \nL 158.176932 395.403039 \nL 161.943809 396.000453 \nL 165.710686 395.403039 \nL 169.477562 395.403039 \nL 173.244439 395.403039 \nL 177.011316 395.104332 \nL 180.778193 395.403039 \nL 184.545069 395.403039 \nL 188.311946 395.104332 \nL 192.078823 395.104332 \nL 195.845699 395.403039 \nL 199.612576 395.403039 \nL 203.379453 395.403039 \nL 207.146329 395.104332 \nL 210.913206 395.104332 \nL 214.680083 395.104332 \nL 218.446959 395.403039 \nL 222.213836 395.104332 \nL 225.980713 395.104332 \nL 229.747589 395.104332 \nL 233.514466 395.403039 \nL 237.281343 395.104332 \nL 241.04822 395.104332 \nL 244.815096 395.104332 \nL 248.581973 395.104332 \nL 252.34885 395.104332 \nL 256.115726 395.403039 \nL 259.882603 395.104332 \nL 263.64948 395.104332 \nL 267.416356 395.104332 \nL 271.183233 395.104332 \nL 274.95011 395.104332 \nL 278.716986 395.104332 \nL 282.483863 395.104332 \nL 286.25074 395.104332 \nL 290.017616 395.104332 \nL 293.784493 395.104332 \nL 297.55137 395.104332 \nL 301.318247 395.104332 \nL 305.085123 395.104332 \nL 308.852 395.104332 \nL 312.618877 395.104332 \nL 316.385753 395.104332 \nL 320.15263 395.104332 \nL 323.919507 395.104332 \nL 327.686383 395.104332 \nL 331.45326 395.104332 \nL 335.220137 395.104332 \nL 338.987013 395.104332 \nL 342.75389 395.104332 \nL 346.520767 395.104332 \nL 350.287643 395.104332 \nL 354.05452 395.104332 \nL 357.821397 395.104332 \nL 361.588274 395.104332 \nL 365.35515 395.104332 \nL 369.122027 395.104332 \nL 372.888904 395.104332 \nL 376.65578 395.104332 \nL 380.422657 395.104332 \nL 384.189534 395.104332 \nL 387.95641 395.104332 \nL 391.723287 395.104332 \nL 395.490164 395.104332 \nL 399.25704 395.104332 \nL 403.023917 395.104332 \nL 406.790794 395.104332 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_125\">\n    <path d=\"M 33.870002 436.027177 \nL 37.636878 434.533642 \nL 41.403755 433.936228 \nL 45.170632 433.936228 \nL 48.937508 434.234935 \nL 52.704385 424.975022 \nL 56.471262 407.052608 \nL 60.238139 402.273297 \nL 64.005015 399.286228 \nL 67.771892 399.286228 \nL 71.538769 396.896573 \nL 75.305645 397.493987 \nL 79.072522 396.896573 \nL 82.839399 396.896573 \nL 86.606275 398.091401 \nL 90.373152 395.701746 \nL 94.140029 395.403039 \nL 97.906905 396.000453 \nL 101.673782 395.403039 \nL 105.440659 395.701746 \nL 109.207535 395.104332 \nL 112.974412 395.403039 \nL 116.741289 395.403039 \nL 120.508166 395.701746 \nL 124.275042 395.104332 \nL 128.041919 395.104332 \nL 131.808796 395.104332 \nL 135.575672 395.104332 \nL 139.342549 395.403039 \nL 143.109426 395.403039 \nL 146.876302 395.104332 \nL 150.643179 395.104332 \nL 154.410056 395.104332 \nL 158.176932 395.104332 \nL 161.943809 395.701746 \nL 165.710686 395.403039 \nL 169.477562 395.104332 \nL 173.244439 395.104332 \nL 177.011316 395.104332 \nL 180.778193 395.104332 \nL 184.545069 395.104332 \nL 188.311946 395.104332 \nL 192.078823 395.104332 \nL 195.845699 395.104332 \nL 199.612576 395.104332 \nL 203.379453 395.104332 \nL 207.146329 395.104332 \nL 210.913206 395.104332 \nL 214.680083 395.104332 \nL 218.446959 395.104332 \nL 222.213836 395.104332 \nL 225.980713 395.104332 \nL 229.747589 395.104332 \nL 233.514466 395.104332 \nL 237.281343 395.104332 \nL 241.04822 395.104332 \nL 244.815096 395.104332 \nL 248.581973 395.104332 \nL 252.34885 395.104332 \nL 256.115726 395.104332 \nL 259.882603 395.104332 \nL 263.64948 395.104332 \nL 267.416356 395.104332 \nL 271.183233 395.104332 \nL 274.95011 395.104332 \nL 278.716986 395.104332 \nL 282.483863 395.104332 \nL 286.25074 395.104332 \nL 290.017616 395.104332 \nL 293.784493 395.104332 \nL 297.55137 395.104332 \nL 301.318247 395.104332 \nL 305.085123 395.104332 \nL 308.852 395.104332 \nL 312.618877 395.104332 \nL 316.385753 395.104332 \nL 320.15263 395.104332 \nL 323.919507 395.104332 \nL 327.686383 395.104332 \nL 331.45326 395.104332 \nL 335.220137 395.104332 \nL 338.987013 395.104332 \nL 342.75389 395.104332 \nL 346.520767 395.104332 \nL 350.287643 395.104332 \nL 354.05452 395.104332 \nL 357.821397 395.104332 \nL 361.588274 395.104332 \nL 365.35515 395.104332 \nL 369.122027 395.104332 \nL 372.888904 395.104332 \nL 376.65578 395.104332 \nL 380.422657 395.104332 \nL 384.189534 395.104332 \nL 387.95641 395.104332 \nL 391.723287 395.104332 \nL 395.490164 395.104332 \nL 399.25704 395.104332 \nL 403.023917 395.104332 \nL 406.790794 395.104332 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_126\">\n    <path d=\"M 33.870002 433.637522 \nL 37.636878 431.84528 \nL 41.403755 431.247866 \nL 45.170632 431.546573 \nL 48.937508 433.338815 \nL 52.704385 421.987953 \nL 56.471262 404.364246 \nL 60.238139 400.182349 \nL 64.005015 396.896573 \nL 67.771892 397.792694 \nL 71.538769 396.597866 \nL 75.305645 396.299159 \nL 79.072522 395.701746 \nL 82.839399 396.299159 \nL 86.606275 396.896573 \nL 90.373152 395.403039 \nL 94.140029 395.403039 \nL 97.906905 395.403039 \nL 101.673782 395.403039 \nL 105.440659 395.403039 \nL 109.207535 395.104332 \nL 112.974412 395.104332 \nL 116.741289 395.104332 \nL 120.508166 395.104332 \nL 124.275042 395.104332 \nL 128.041919 395.104332 \nL 131.808796 395.104332 \nL 135.575672 395.104332 \nL 139.342549 395.403039 \nL 143.109426 395.403039 \nL 146.876302 395.104332 \nL 150.643179 395.104332 \nL 154.410056 395.104332 \nL 158.176932 395.104332 \nL 161.943809 395.403039 \nL 165.710686 395.104332 \nL 169.477562 395.104332 \nL 173.244439 395.104332 \nL 177.011316 395.104332 \nL 180.778193 395.104332 \nL 184.545069 395.104332 \nL 188.311946 395.104332 \nL 192.078823 395.104332 \nL 195.845699 395.104332 \nL 199.612576 395.104332 \nL 203.379453 395.104332 \nL 207.146329 395.104332 \nL 210.913206 395.104332 \nL 214.680083 395.104332 \nL 218.446959 395.104332 \nL 222.213836 395.104332 \nL 225.980713 395.104332 \nL 229.747589 395.104332 \nL 233.514466 395.104332 \nL 237.281343 395.104332 \nL 241.04822 395.104332 \nL 244.815096 395.104332 \nL 248.581973 395.104332 \nL 252.34885 395.104332 \nL 256.115726 395.104332 \nL 259.882603 395.104332 \nL 263.64948 395.104332 \nL 267.416356 395.104332 \nL 271.183233 395.104332 \nL 274.95011 395.104332 \nL 278.716986 395.104332 \nL 282.483863 395.104332 \nL 286.25074 395.104332 \nL 290.017616 395.104332 \nL 293.784493 395.104332 \nL 297.55137 395.104332 \nL 301.318247 395.104332 \nL 305.085123 395.104332 \nL 308.852 395.104332 \nL 312.618877 395.104332 \nL 316.385753 395.104332 \nL 320.15263 395.104332 \nL 323.919507 395.104332 \nL 327.686383 395.104332 \nL 331.45326 395.104332 \nL 335.220137 395.104332 \nL 338.987013 395.104332 \nL 342.75389 395.104332 \nL 346.520767 395.104332 \nL 350.287643 395.104332 \nL 354.05452 395.104332 \nL 357.821397 395.104332 \nL 361.588274 395.104332 \nL 365.35515 395.104332 \nL 369.122027 395.104332 \nL 372.888904 395.104332 \nL 376.65578 395.104332 \nL 380.422657 395.104332 \nL 384.189534 395.104332 \nL 387.95641 395.104332 \nL 391.723287 395.104332 \nL 395.490164 395.104332 \nL 399.25704 395.104332 \nL 403.023917 395.104332 \nL 406.790794 395.104332 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_127\">\n    <path d=\"M 33.870002 239.240098 \nL 37.636878 241.056094 \nL 41.403755 241.887176 \nL 45.170632 243.811257 \nL 48.937508 248.763824 \nL 52.704385 260.12056 \nL 56.471262 263.813481 \nL 60.238139 264.67462 \nL 64.005015 266.837124 \nL 67.771892 267.50892 \nL 71.538769 267.181477 \nL 75.305645 268.8631 \nL 79.072522 268.006484 \nL 82.839399 269.520799 \nL 86.606275 271.23623 \nL 90.373152 269.794167 \nL 94.140029 269.377259 \nL 97.906905 270.843127 \nL 101.673782 270.25483 \nL 105.440659 270.13407 \nL 109.207535 270.695229 \nL 112.974412 272.189724 \nL 116.741289 269.339692 \nL 120.508166 272.984244 \nL 124.275042 271.521221 \nL 128.041919 271.168371 \nL 131.808796 272.818193 \nL 135.575672 269.433064 \nL 139.342549 271.508964 \nL 143.109426 272.763161 \nL 146.876302 271.251457 \nL 150.643179 272.036826 \nL 154.410056 272.324915 \nL 158.176932 272.824141 \nL 161.943809 271.847138 \nL 165.710686 273.060213 \nL 169.477562 271.446047 \nL 173.244439 271.176142 \nL 177.011316 272.626074 \nL 180.778193 272.87648 \nL 184.545069 272.608129 \nL 188.311946 271.830071 \nL 192.078823 271.435386 \nL 195.845699 271.863167 \nL 199.612576 271.346849 \nL 203.379453 272.742732 \nL 207.146329 270.945581 \nL 210.913206 272.801864 \nL 214.680083 272.451615 \nL 218.446959 272.599955 \nL 222.213836 274.054977 \nL 225.980713 273.526005 \nL 229.747589 272.507419 \nL 233.514466 273.108393 \nL 237.281343 272.568879 \nL 241.04822 272.484036 \nL 244.815096 271.11644 \nL 248.581973 272.972136 \nL 252.34885 271.179909 \nL 256.115726 273.40515 \nL 259.882603 272.965239 \nL 263.64948 272.161963 \nL 267.416356 272.571499 \nL 271.183233 272.374092 \nL 274.95011 272.138873 \nL 278.716986 272.848474 \nL 282.483863 272.546271 \nL 286.25074 272.786974 \nL 290.017616 272.844262 \nL 293.784493 272.874509 \nL 297.55137 273.183068 \nL 301.318247 272.780261 \nL 305.085123 272.315088 \nL 308.852 272.578593 \nL 312.618877 271.932383 \nL 316.385753 272.702367 \nL 320.15263 272.628745 \nL 323.919507 272.572947 \nL 327.686383 272.016669 \nL 331.45326 272.335867 \nL 335.220137 272.405439 \nL 338.987013 272.951533 \nL 342.75389 272.47081 \nL 346.520767 272.304831 \nL 350.287643 272.188303 \nL 354.05452 272.455082 \nL 357.821397 272.312405 \nL 361.588274 272.441335 \nL 365.35515 272.195951 \nL 369.122027 273.034137 \nL 372.888904 272.02097 \nL 376.65578 272.361819 \nL 380.422657 272.797384 \nL 384.189534 272.763001 \nL 387.95641 272.477496 \nL 391.723287 272.208576 \nL 395.490164 272.65754 \nL 399.25704 272.325631 \nL 403.023917 272.936205 \nL 406.790794 271.994026 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_128\">\n    <path d=\"M 33.870002 438.914677 \nL 37.636878 442.897435 \nL 41.403755 442.897435 \nL 45.170632 442.897435 \nL 48.937508 440.906056 \nL 52.704385 432.940539 \nL 56.471262 419.000884 \nL 60.238139 419.000884 \nL 64.005015 419.000884 \nL 67.771892 419.000884 \nL 71.538769 417.009504 \nL 75.305645 420.992263 \nL 79.072522 420.992263 \nL 82.839399 415.018125 \nL 86.606275 409.043987 \nL 90.373152 413.026746 \nL 94.140029 415.018125 \nL 97.906905 411.035366 \nL 101.673782 415.018125 \nL 105.440659 413.026746 \nL 109.207535 413.026746 \nL 112.974412 409.043987 \nL 116.741289 413.026746 \nL 120.508166 409.043987 \nL 124.275042 415.018125 \nL 128.041919 409.043987 \nL 131.808796 409.043987 \nL 135.575672 419.000884 \nL 139.342549 411.035366 \nL 143.109426 409.043987 \nL 146.876302 407.052608 \nL 150.643179 411.035366 \nL 154.410056 413.026746 \nL 158.176932 409.043987 \nL 161.943809 415.018125 \nL 165.710686 409.043987 \nL 169.477562 409.043987 \nL 173.244439 409.043987 \nL 177.011316 411.035366 \nL 180.778193 411.035366 \nL 184.545069 409.043987 \nL 188.311946 411.035366 \nL 192.078823 413.026746 \nL 195.845699 409.043987 \nL 199.612576 409.043987 \nL 203.379453 415.018125 \nL 207.146329 411.035366 \nL 210.913206 409.043987 \nL 214.680083 407.052608 \nL 218.446959 411.035366 \nL 222.213836 409.043987 \nL 225.980713 405.061228 \nL 229.747589 411.035366 \nL 233.514466 407.052608 \nL 237.281343 409.043987 \nL 241.04822 407.052608 \nL 244.815096 409.043987 \nL 248.581973 413.026746 \nL 252.34885 411.035366 \nL 256.115726 411.035366 \nL 259.882603 411.035366 \nL 263.64948 409.043987 \nL 267.416356 417.009504 \nL 271.183233 407.052608 \nL 274.95011 411.035366 \nL 278.716986 413.026746 \nL 282.483863 409.043987 \nL 286.25074 411.035366 \nL 290.017616 411.035366 \nL 293.784493 409.043987 \nL 297.55137 409.043987 \nL 301.318247 411.035366 \nL 305.085123 409.043987 \nL 308.852 409.043987 \nL 312.618877 411.035366 \nL 316.385753 409.043987 \nL 320.15263 411.035366 \nL 323.919507 411.035366 \nL 327.686383 411.035366 \nL 331.45326 409.043987 \nL 335.220137 413.026746 \nL 338.987013 409.043987 \nL 342.75389 409.043987 \nL 346.520767 411.035366 \nL 350.287643 415.018125 \nL 354.05452 411.035366 \nL 357.821397 413.026746 \nL 361.588274 411.035366 \nL 365.35515 411.035366 \nL 369.122027 409.043987 \nL 372.888904 409.043987 \nL 376.65578 413.026746 \nL 380.422657 413.026746 \nL 384.189534 411.035366 \nL 387.95641 413.026746 \nL 391.723287 411.035366 \nL 395.490164 411.035366 \nL 399.25704 411.035366 \nL 403.023917 411.035366 \nL 406.790794 411.035366 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_129\">\n    <path d=\"M 33.870002 438.914677 \nL 37.636878 442.897435 \nL 41.403755 440.906056 \nL 45.170632 440.906056 \nL 48.937508 440.906056 \nL 52.704385 424.975022 \nL 56.471262 419.000884 \nL 60.238139 415.018125 \nL 64.005015 415.018125 \nL 67.771892 409.043987 \nL 71.538769 413.026746 \nL 75.305645 413.026746 \nL 79.072522 411.035366 \nL 82.839399 407.052608 \nL 86.606275 405.061228 \nL 90.373152 413.026746 \nL 94.140029 415.018125 \nL 97.906905 409.043987 \nL 101.673782 409.043987 \nL 105.440659 407.052608 \nL 109.207535 405.061228 \nL 112.974412 405.061228 \nL 116.741289 405.061228 \nL 120.508166 405.061228 \nL 124.275042 409.043987 \nL 128.041919 403.069849 \nL 131.808796 401.07847 \nL 135.575672 415.018125 \nL 139.342549 401.07847 \nL 143.109426 403.069849 \nL 146.876302 407.052608 \nL 150.643179 407.052608 \nL 154.410056 409.043987 \nL 158.176932 405.061228 \nL 161.943809 409.043987 \nL 165.710686 405.061228 \nL 169.477562 407.052608 \nL 173.244439 407.052608 \nL 177.011316 407.052608 \nL 180.778193 403.069849 \nL 184.545069 407.052608 \nL 188.311946 405.061228 \nL 192.078823 407.052608 \nL 195.845699 405.061228 \nL 199.612576 409.043987 \nL 203.379453 403.069849 \nL 207.146329 407.052608 \nL 210.913206 403.069849 \nL 214.680083 407.052608 \nL 218.446959 409.043987 \nL 222.213836 403.069849 \nL 225.980713 403.069849 \nL 229.747589 405.061228 \nL 233.514466 403.069849 \nL 237.281343 405.061228 \nL 241.04822 405.061228 \nL 244.815096 407.052608 \nL 248.581973 411.035366 \nL 252.34885 405.061228 \nL 256.115726 407.052608 \nL 259.882603 403.069849 \nL 263.64948 403.069849 \nL 267.416356 409.043987 \nL 271.183233 403.069849 \nL 274.95011 407.052608 \nL 278.716986 405.061228 \nL 282.483863 403.069849 \nL 286.25074 403.069849 \nL 290.017616 403.069849 \nL 293.784493 405.061228 \nL 297.55137 407.052608 \nL 301.318247 407.052608 \nL 305.085123 403.069849 \nL 308.852 407.052608 \nL 312.618877 407.052608 \nL 316.385753 405.061228 \nL 320.15263 405.061228 \nL 323.919507 405.061228 \nL 327.686383 403.069849 \nL 331.45326 405.061228 \nL 335.220137 407.052608 \nL 338.987013 405.061228 \nL 342.75389 405.061228 \nL 346.520767 407.052608 \nL 350.287643 407.052608 \nL 354.05452 405.061228 \nL 357.821397 405.061228 \nL 361.588274 405.061228 \nL 365.35515 405.061228 \nL 369.122027 405.061228 \nL 372.888904 405.061228 \nL 376.65578 407.052608 \nL 380.422657 407.052608 \nL 384.189534 405.061228 \nL 387.95641 405.061228 \nL 391.723287 407.052608 \nL 395.490164 405.061228 \nL 399.25704 405.061228 \nL 403.023917 407.052608 \nL 406.790794 407.052608 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_130\">\n    <path d=\"M 33.870002 438.914677 \nL 37.636878 438.914677 \nL 41.403755 438.914677 \nL 45.170632 438.914677 \nL 48.937508 438.914677 \nL 52.704385 415.018125 \nL 56.471262 415.018125 \nL 60.238139 411.035366 \nL 64.005015 409.043987 \nL 67.771892 405.061228 \nL 71.538769 411.035366 \nL 75.305645 409.043987 \nL 79.072522 405.061228 \nL 82.839399 405.061228 \nL 86.606275 403.069849 \nL 90.373152 411.035366 \nL 94.140029 411.035366 \nL 97.906905 403.069849 \nL 101.673782 405.061228 \nL 105.440659 405.061228 \nL 109.207535 403.069849 \nL 112.974412 405.061228 \nL 116.741289 401.07847 \nL 120.508166 405.061228 \nL 124.275042 403.069849 \nL 128.041919 403.069849 \nL 131.808796 399.087091 \nL 135.575672 411.035366 \nL 139.342549 401.07847 \nL 143.109426 403.069849 \nL 146.876302 401.07847 \nL 150.643179 405.061228 \nL 154.410056 403.069849 \nL 158.176932 403.069849 \nL 161.943809 405.061228 \nL 165.710686 401.07847 \nL 169.477562 401.07847 \nL 173.244439 403.069849 \nL 177.011316 403.069849 \nL 180.778193 403.069849 \nL 184.545069 403.069849 \nL 188.311946 401.07847 \nL 192.078823 401.07847 \nL 195.845699 399.087091 \nL 199.612576 405.061228 \nL 203.379453 401.07847 \nL 207.146329 401.07847 \nL 210.913206 401.07847 \nL 214.680083 401.07847 \nL 218.446959 401.07847 \nL 222.213836 401.07847 \nL 225.980713 401.07847 \nL 229.747589 401.07847 \nL 233.514466 401.07847 \nL 237.281343 401.07847 \nL 241.04822 405.061228 \nL 244.815096 401.07847 \nL 248.581973 403.069849 \nL 252.34885 401.07847 \nL 256.115726 403.069849 \nL 259.882603 403.069849 \nL 263.64948 401.07847 \nL 267.416356 403.069849 \nL 271.183233 401.07847 \nL 274.95011 401.07847 \nL 278.716986 403.069849 \nL 282.483863 401.07847 \nL 286.25074 401.07847 \nL 290.017616 401.07847 \nL 293.784493 401.07847 \nL 297.55137 401.07847 \nL 301.318247 401.07847 \nL 305.085123 401.07847 \nL 308.852 401.07847 \nL 312.618877 403.069849 \nL 316.385753 401.07847 \nL 320.15263 403.069849 \nL 323.919507 401.07847 \nL 327.686383 403.069849 \nL 331.45326 401.07847 \nL 335.220137 403.069849 \nL 338.987013 401.07847 \nL 342.75389 401.07847 \nL 346.520767 403.069849 \nL 350.287643 403.069849 \nL 354.05452 403.069849 \nL 357.821397 403.069849 \nL 361.588274 403.069849 \nL 365.35515 403.069849 \nL 369.122027 403.069849 \nL 372.888904 401.07847 \nL 376.65578 403.069849 \nL 380.422657 403.069849 \nL 384.189534 401.07847 \nL 387.95641 401.07847 \nL 391.723287 403.069849 \nL 395.490164 403.069849 \nL 399.25704 401.07847 \nL 403.023917 405.061228 \nL 406.790794 403.069849 \n\" clip-path=\"url(#p7487f6dc3e)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 30.103125 442.897435 \nL 30.103125 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 410.55767 442.897435 \nL 410.55767 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 30.103125 442.897435 \nL 410.55767 442.897435 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 30.103125 251.725022 \nL 410.55767 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_67\">\n    <!-- Training result when p = 300 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(133.661335 245.725022)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_3\">\n    <g id=\"patch_19\">\n     <path d=\"M 37.103125 377.150022 \nL 149.8875 377.150022 \nQ 151.8875 377.150022 151.8875 375.150022 \nL 151.8875 258.725022 \nQ 151.8875 256.725022 149.8875 256.725022 \nL 37.103125 256.725022 \nQ 35.103125 256.725022 35.103125 258.725022 \nL 35.103125 375.150022 \nQ 35.103125 377.150022 37.103125 377.150022 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_131\">\n     <path d=\"M 39.103125 264.823459 \nL 49.103125 264.823459 \nL 59.103125 264.823459 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_68\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 268.323459)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_132\">\n     <path d=\"M 39.103125 279.501584 \nL 49.103125 279.501584 \nL 59.103125 279.501584 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_69\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 283.001584)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_133\">\n     <path d=\"M 39.103125 294.179709 \nL 49.103125 294.179709 \nL 59.103125 294.179709 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_70\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 297.679709)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_134\">\n     <path d=\"M 39.103125 308.857834 \nL 49.103125 308.857834 \nL 59.103125 308.857834 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_71\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 312.357834)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_135\">\n     <path d=\"M 39.103125 323.535959 \nL 49.103125 323.535959 \nL 59.103125 323.535959 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_72\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 327.035959)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_136\">\n     <path d=\"M 39.103125 338.214084 \nL 49.103125 338.214084 \nL 59.103125 338.214084 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_73\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 341.714084)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_137\">\n     <path d=\"M 39.103125 352.892209 \nL 49.103125 352.892209 \nL 59.103125 352.892209 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_74\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 356.392209)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_138\">\n     <path d=\"M 39.103125 367.570334 \nL 49.103125 367.570334 \nL 59.103125 367.570334 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_75\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 371.070334)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_20\">\n    <path d=\"M 486.64858 442.897435 \nL 867.103125 442.897435 \nL 867.103125 251.725022 \nL 486.64858 251.725022 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_19\">\n     <g id=\"line2d_139\">\n      <path d=\"M 486.64858 442.897435 \nL 486.64858 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_140\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"486.64858\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_76\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(483.46733 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_141\">\n      <path d=\"M 561.986113 442.897435 \nL 561.986113 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_142\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"561.986113\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_77\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(555.623613 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_143\">\n      <path d=\"M 637.323647 442.897435 \nL 637.323647 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_144\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"637.323647\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_78\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(630.961147 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_145\">\n      <path d=\"M 712.661181 442.897435 \nL 712.661181 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_146\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"712.661181\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_79\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(706.298681 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_147\">\n      <path d=\"M 787.998715 442.897435 \nL 787.998715 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_148\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"787.998715\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_80\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(781.636215 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_149\">\n      <path d=\"M 863.336248 442.897435 \nL 863.336248 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_150\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"863.336248\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_81\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(853.792498 457.495873)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_82\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(658.960227 471.173998)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_28\">\n     <g id=\"line2d_151\">\n      <path d=\"M 486.64858 442.897435 \nL 867.103125 442.897435 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_152\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"442.897435\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_83\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 446.696654)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_29\">\n     <g id=\"line2d_153\">\n      <path d=\"M 486.64858 419.000884 \nL 867.103125 419.000884 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_154\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"419.000884\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_84\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 422.800102)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_30\">\n     <g id=\"line2d_155\">\n      <path d=\"M 486.64858 395.104332 \nL 867.103125 395.104332 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_156\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"395.104332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_85\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 398.903551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_31\">\n     <g id=\"line2d_157\">\n      <path d=\"M 486.64858 371.20778 \nL 867.103125 371.20778 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_158\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"371.20778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_86\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 375.006999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_32\">\n     <g id=\"line2d_159\">\n      <path d=\"M 486.64858 347.311228 \nL 867.103125 347.311228 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_160\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"347.311228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_87\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 351.110447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_33\">\n     <g id=\"line2d_161\">\n      <path d=\"M 486.64858 323.414677 \nL 867.103125 323.414677 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_162\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"323.414677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_88\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 327.213895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_34\">\n     <g id=\"line2d_163\">\n      <path d=\"M 486.64858 299.518125 \nL 867.103125 299.518125 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_164\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"299.518125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_89\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 303.317344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_35\">\n     <g id=\"line2d_165\">\n      <path d=\"M 486.64858 275.621573 \nL 867.103125 275.621573 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_166\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"275.621573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_90\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 279.420792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_36\">\n     <g id=\"line2d_167\">\n      <path d=\"M 486.64858 251.725022 \nL 867.103125 251.725022 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_168\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"251.725022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_91\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 255.52424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_169\">\n    <path d=\"M 490.415456 255.186514 \nL 494.182333 246.093453 \nL 497.94921 248.992127 \nL 501.716086 254.476991 \nL 505.482963 259.121308 \nL 509.24984 262.857147 \nL 513.016716 266.467575 \nL 516.783593 269.396795 \nL 520.55047 271.897749 \nL 524.317346 274.694058 \nL 528.084223 276.564212 \nL 531.8511 278.302728 \nL 535.617976 280.220428 \nL 539.384853 281.282358 \nL 543.15173 282.389494 \nL 546.918607 283.556773 \nL 550.685483 284.370883 \nL 554.45236 285.436134 \nL 558.219237 286.493332 \nL 561.986113 286.729586 \nL 565.75299 287.280088 \nL 569.519867 288.490895 \nL 573.286743 288.168332 \nL 577.05362 288.933074 \nL 580.820497 289.086108 \nL 584.587373 289.580815 \nL 588.35425 289.790216 \nL 592.121127 289.491331 \nL 595.888003 290.616457 \nL 599.65488 290.622064 \nL 603.421757 290.921152 \nL 607.188634 290.81709 \nL 610.95551 291.464663 \nL 614.722387 291.333509 \nL 618.489264 292.298641 \nL 622.25614 291.486201 \nL 626.023017 292.536827 \nL 629.789894 292.442317 \nL 633.55677 292.637805 \nL 637.323647 292.533816 \nL 641.090524 292.65169 \nL 644.8574 292.189797 \nL 648.624277 292.125222 \nL 652.391154 293.028242 \nL 656.15803 293.11741 \nL 659.924907 293.090228 \nL 663.691784 293.370975 \nL 667.458661 293.260234 \nL 671.225537 293.139842 \nL 674.992414 293.309789 \nL 678.759291 294.178006 \nL 682.526167 294.246676 \nL 686.293044 293.287134 \nL 690.059921 294.140147 \nL 693.826797 294.121145 \nL 697.593674 293.201313 \nL 701.360551 294.121631 \nL 705.127427 294.310866 \nL 708.894304 294.028479 \nL 712.661181 293.740468 \nL 716.428057 294.71903 \nL 720.194934 294.998599 \nL 723.961811 294.487247 \nL 727.728688 295.123398 \nL 731.495564 294.491628 \nL 735.262441 295.128598 \nL 739.029318 294.769753 \nL 742.796194 294.813635 \nL 746.563071 294.777574 \nL 750.329948 294.031914 \nL 754.096824 294.871221 \nL 757.863701 295.322016 \nL 761.630578 294.818877 \nL 765.397454 294.740544 \nL 769.164331 295.288248 \nL 772.931208 295.184207 \nL 776.698084 294.811604 \nL 780.464961 295.767377 \nL 784.231838 294.55717 \nL 787.998715 295.220538 \nL 791.765591 294.759106 \nL 795.532468 295.121867 \nL 799.299345 294.592438 \nL 803.066221 295.16176 \nL 806.833098 295.328412 \nL 810.599975 294.995107 \nL 814.366851 294.695738 \nL 818.133728 294.900851 \nL 821.900605 295.369004 \nL 825.667481 295.395778 \nL 829.434358 295.367591 \nL 833.201235 295.362734 \nL 836.968111 294.918506 \nL 840.734988 295.423708 \nL 844.501865 295.817906 \nL 848.268742 295.449778 \nL 852.035618 295.08355 \nL 855.802495 295.926736 \nL 859.569372 294.858993 \nL 863.336248 295.159293 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_170\">\n    <path d=\"M 490.415456 437.222004 \nL 494.182333 436.923297 \nL 497.94921 437.520711 \nL 501.716086 438.118125 \nL 505.482963 437.222004 \nL 509.24984 431.546573 \nL 513.016716 420.195711 \nL 516.783593 413.026746 \nL 520.55047 405.85778 \nL 524.317346 404.961659 \nL 528.084223 405.260366 \nL 531.8511 403.468125 \nL 535.617976 402.273297 \nL 539.384853 402.572004 \nL 543.15173 401.377177 \nL 546.918607 399.883642 \nL 550.685483 405.260366 \nL 554.45236 398.987522 \nL 558.219237 397.493987 \nL 561.986113 396.597866 \nL 565.75299 397.493987 \nL 569.519867 397.19528 \nL 573.286743 397.792694 \nL 577.05362 396.299159 \nL 580.820497 396.299159 \nL 584.587373 396.000453 \nL 588.35425 397.493987 \nL 592.121127 396.896573 \nL 595.888003 396.299159 \nL 599.65488 396.597866 \nL 603.421757 396.000453 \nL 607.188634 395.403039 \nL 610.95551 395.701746 \nL 614.722387 395.403039 \nL 618.489264 396.597866 \nL 622.25614 395.701746 \nL 626.023017 395.701746 \nL 629.789894 395.403039 \nL 633.55677 395.403039 \nL 637.323647 395.701746 \nL 641.090524 395.701746 \nL 644.8574 395.403039 \nL 648.624277 395.701746 \nL 652.391154 395.403039 \nL 656.15803 395.403039 \nL 659.924907 395.403039 \nL 663.691784 395.403039 \nL 667.458661 395.104332 \nL 671.225537 396.000453 \nL 674.992414 395.701746 \nL 678.759291 395.701746 \nL 682.526167 395.403039 \nL 686.293044 396.299159 \nL 690.059921 395.403039 \nL 693.826797 395.403039 \nL 697.593674 395.104332 \nL 701.360551 395.403039 \nL 705.127427 395.403039 \nL 708.894304 395.403039 \nL 712.661181 395.403039 \nL 716.428057 395.403039 \nL 720.194934 395.403039 \nL 723.961811 395.104332 \nL 727.728688 395.104332 \nL 731.495564 395.104332 \nL 735.262441 395.104332 \nL 739.029318 395.403039 \nL 742.796194 395.104332 \nL 746.563071 395.104332 \nL 750.329948 395.104332 \nL 754.096824 395.104332 \nL 757.863701 395.104332 \nL 761.630578 395.104332 \nL 765.397454 395.104332 \nL 769.164331 395.104332 \nL 772.931208 395.104332 \nL 776.698084 395.104332 \nL 780.464961 395.104332 \nL 784.231838 395.104332 \nL 787.998715 395.104332 \nL 791.765591 395.104332 \nL 795.532468 395.104332 \nL 799.299345 395.104332 \nL 803.066221 395.104332 \nL 806.833098 395.104332 \nL 810.599975 395.104332 \nL 814.366851 395.104332 \nL 818.133728 395.104332 \nL 821.900605 395.104332 \nL 825.667481 395.104332 \nL 829.434358 395.104332 \nL 833.201235 395.104332 \nL 836.968111 395.104332 \nL 840.734988 395.104332 \nL 844.501865 395.104332 \nL 848.268742 395.104332 \nL 852.035618 395.104332 \nL 855.802495 395.104332 \nL 859.569372 395.104332 \nL 863.336248 395.104332 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_171\">\n    <path d=\"M 490.415456 434.234935 \nL 494.182333 433.637522 \nL 497.94921 433.936228 \nL 501.716086 434.234935 \nL 505.482963 434.832349 \nL 509.24984 426.468556 \nL 513.016716 411.831918 \nL 516.783593 404.961659 \nL 520.55047 400.481056 \nL 524.317346 399.584935 \nL 528.084223 398.390108 \nL 531.8511 398.390108 \nL 535.617976 397.19528 \nL 539.384853 397.493987 \nL 543.15173 398.688815 \nL 546.918607 396.000453 \nL 550.685483 399.286228 \nL 554.45236 396.597866 \nL 558.219237 395.701746 \nL 561.986113 396.000453 \nL 565.75299 395.701746 \nL 569.519867 395.701746 \nL 573.286743 396.000453 \nL 577.05362 395.403039 \nL 580.820497 395.403039 \nL 584.587373 395.403039 \nL 588.35425 396.299159 \nL 592.121127 395.701746 \nL 595.888003 396.000453 \nL 599.65488 395.403039 \nL 603.421757 395.104332 \nL 607.188634 395.104332 \nL 610.95551 395.104332 \nL 614.722387 395.104332 \nL 618.489264 395.104332 \nL 622.25614 395.104332 \nL 626.023017 395.104332 \nL 629.789894 395.403039 \nL 633.55677 395.104332 \nL 637.323647 395.104332 \nL 641.090524 395.104332 \nL 644.8574 395.104332 \nL 648.624277 395.104332 \nL 652.391154 395.104332 \nL 656.15803 395.104332 \nL 659.924907 395.104332 \nL 663.691784 395.104332 \nL 667.458661 395.104332 \nL 671.225537 395.104332 \nL 674.992414 395.104332 \nL 678.759291 395.104332 \nL 682.526167 395.104332 \nL 686.293044 395.104332 \nL 690.059921 395.104332 \nL 693.826797 395.104332 \nL 697.593674 395.104332 \nL 701.360551 395.104332 \nL 705.127427 395.104332 \nL 708.894304 395.104332 \nL 712.661181 395.104332 \nL 716.428057 395.104332 \nL 720.194934 395.104332 \nL 723.961811 395.104332 \nL 727.728688 395.104332 \nL 731.495564 395.104332 \nL 735.262441 395.104332 \nL 739.029318 395.104332 \nL 742.796194 395.104332 \nL 746.563071 395.104332 \nL 750.329948 395.104332 \nL 754.096824 395.104332 \nL 757.863701 395.104332 \nL 761.630578 395.104332 \nL 765.397454 395.104332 \nL 769.164331 395.104332 \nL 772.931208 395.104332 \nL 776.698084 395.104332 \nL 780.464961 395.104332 \nL 784.231838 395.104332 \nL 787.998715 395.104332 \nL 791.765591 395.104332 \nL 795.532468 395.104332 \nL 799.299345 395.104332 \nL 803.066221 395.104332 \nL 806.833098 395.104332 \nL 810.599975 395.104332 \nL 814.366851 395.104332 \nL 818.133728 395.104332 \nL 821.900605 395.104332 \nL 825.667481 395.104332 \nL 829.434358 395.104332 \nL 833.201235 395.104332 \nL 836.968111 395.104332 \nL 840.734988 395.104332 \nL 844.501865 395.104332 \nL 848.268742 395.104332 \nL 852.035618 395.104332 \nL 855.802495 395.104332 \nL 859.569372 395.104332 \nL 863.336248 395.104332 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_172\">\n    <path d=\"M 490.415456 431.546573 \nL 494.182333 431.546573 \nL 497.94921 431.84528 \nL 501.716086 433.040108 \nL 505.482963 432.741401 \nL 509.24984 423.780194 \nL 513.016716 407.351315 \nL 516.783593 400.779763 \nL 520.55047 398.091401 \nL 524.317346 397.493987 \nL 528.084223 396.299159 \nL 531.8511 396.597866 \nL 535.617976 396.000453 \nL 539.384853 396.000453 \nL 543.15173 396.597866 \nL 546.918607 395.104332 \nL 550.685483 397.19528 \nL 554.45236 395.104332 \nL 558.219237 395.104332 \nL 561.986113 395.104332 \nL 565.75299 395.403039 \nL 569.519867 395.104332 \nL 573.286743 395.104332 \nL 577.05362 395.104332 \nL 580.820497 395.104332 \nL 584.587373 395.104332 \nL 588.35425 395.403039 \nL 592.121127 395.403039 \nL 595.888003 395.701746 \nL 599.65488 395.104332 \nL 603.421757 395.104332 \nL 607.188634 395.104332 \nL 610.95551 395.104332 \nL 614.722387 395.104332 \nL 618.489264 395.104332 \nL 622.25614 395.104332 \nL 626.023017 395.104332 \nL 629.789894 395.104332 \nL 633.55677 395.104332 \nL 637.323647 395.104332 \nL 641.090524 395.104332 \nL 644.8574 395.104332 \nL 648.624277 395.104332 \nL 652.391154 395.104332 \nL 656.15803 395.104332 \nL 659.924907 395.104332 \nL 663.691784 395.104332 \nL 667.458661 395.104332 \nL 671.225537 395.104332 \nL 674.992414 395.104332 \nL 678.759291 395.104332 \nL 682.526167 395.104332 \nL 686.293044 395.104332 \nL 690.059921 395.104332 \nL 693.826797 395.104332 \nL 697.593674 395.104332 \nL 701.360551 395.104332 \nL 705.127427 395.104332 \nL 708.894304 395.104332 \nL 712.661181 395.104332 \nL 716.428057 395.104332 \nL 720.194934 395.104332 \nL 723.961811 395.104332 \nL 727.728688 395.104332 \nL 731.495564 395.104332 \nL 735.262441 395.104332 \nL 739.029318 395.104332 \nL 742.796194 395.104332 \nL 746.563071 395.104332 \nL 750.329948 395.104332 \nL 754.096824 395.104332 \nL 757.863701 395.104332 \nL 761.630578 395.104332 \nL 765.397454 395.104332 \nL 769.164331 395.104332 \nL 772.931208 395.104332 \nL 776.698084 395.104332 \nL 780.464961 395.104332 \nL 784.231838 395.104332 \nL 787.998715 395.104332 \nL 791.765591 395.104332 \nL 795.532468 395.104332 \nL 799.299345 395.104332 \nL 803.066221 395.104332 \nL 806.833098 395.104332 \nL 810.599975 395.104332 \nL 814.366851 395.104332 \nL 818.133728 395.104332 \nL 821.900605 395.104332 \nL 825.667481 395.104332 \nL 829.434358 395.104332 \nL 833.201235 395.104332 \nL 836.968111 395.104332 \nL 840.734988 395.104332 \nL 844.501865 395.104332 \nL 848.268742 395.104332 \nL 852.035618 395.104332 \nL 855.802495 395.104332 \nL 859.569372 395.104332 \nL 863.336248 395.104332 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_173\">\n    <path d=\"M 490.415456 239.568033 \nL 494.182333 242.287175 \nL 497.94921 242.379889 \nL 501.716086 245.046892 \nL 505.482963 251.603786 \nL 509.24984 260.335257 \nL 513.016716 263.380081 \nL 516.783593 264.861867 \nL 520.55047 266.377475 \nL 524.317346 266.810414 \nL 528.084223 267.25078 \nL 531.8511 266.956843 \nL 535.617976 269.426619 \nL 539.384853 267.097551 \nL 543.15173 268.872481 \nL 546.918607 267.845412 \nL 550.685483 268.014035 \nL 554.45236 269.372826 \nL 558.219237 269.007763 \nL 561.986113 272.361421 \nL 565.75299 269.017829 \nL 569.519867 271.19312 \nL 573.286743 269.900412 \nL 577.05362 271.233936 \nL 580.820497 270.290058 \nL 584.587373 270.225677 \nL 588.35425 271.765735 \nL 592.121127 269.900445 \nL 595.888003 271.54626 \nL 599.65488 271.964502 \nL 603.421757 272.376323 \nL 607.188634 270.783065 \nL 610.95551 270.75814 \nL 614.722387 271.415956 \nL 618.489264 268.811187 \nL 622.25614 271.06651 \nL 626.023017 270.390359 \nL 629.789894 270.121444 \nL 633.55677 271.569773 \nL 637.323647 270.323521 \nL 641.090524 272.95193 \nL 644.8574 272.712238 \nL 648.624277 272.240361 \nL 652.391154 269.497926 \nL 656.15803 271.014174 \nL 659.924907 272.055937 \nL 663.691784 272.675849 \nL 667.458661 272.84068 \nL 671.225537 272.94033 \nL 674.992414 271.995304 \nL 678.759291 271.605969 \nL 682.526167 272.626844 \nL 686.293044 272.578138 \nL 690.059921 272.346915 \nL 693.826797 272.59858 \nL 697.593674 272.57204 \nL 701.360551 273.149587 \nL 705.127427 272.419418 \nL 708.894304 272.657541 \nL 712.661181 272.532725 \nL 716.428057 273.18781 \nL 720.194934 273.566404 \nL 723.961811 272.768687 \nL 727.728688 272.779963 \nL 731.495564 272.197688 \nL 735.262441 273.524549 \nL 739.029318 273.202585 \nL 742.796194 272.217583 \nL 746.563071 272.507542 \nL 750.329948 272.509118 \nL 754.096824 272.256118 \nL 757.863701 271.836607 \nL 761.630578 272.524043 \nL 765.397454 272.716311 \nL 769.164331 272.631641 \nL 772.931208 272.673439 \nL 776.698084 272.810236 \nL 780.464961 273.177452 \nL 784.231838 272.75051 \nL 787.998715 272.717089 \nL 791.765591 273.530849 \nL 795.532468 273.034762 \nL 799.299345 272.853525 \nL 803.066221 273.116483 \nL 806.833098 273.154622 \nL 810.599975 272.273128 \nL 814.366851 272.782625 \nL 818.133728 272.514732 \nL 821.900605 272.954769 \nL 825.667481 273.389038 \nL 829.434358 273.053812 \nL 833.201235 272.717398 \nL 836.968111 272.655231 \nL 840.734988 273.548946 \nL 844.501865 272.539076 \nL 848.268742 272.997099 \nL 852.035618 272.71551 \nL 855.802495 273.630579 \nL 859.569372 273.06381 \nL 863.336248 272.777286 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_174\">\n    <path d=\"M 490.415456 442.897435 \nL 494.182333 442.897435 \nL 497.94921 442.897435 \nL 501.716086 442.897435 \nL 505.482963 436.923297 \nL 509.24984 428.95778 \nL 513.016716 417.009504 \nL 516.783593 420.992263 \nL 520.55047 420.992263 \nL 524.317346 419.000884 \nL 528.084223 417.009504 \nL 531.8511 415.018125 \nL 535.617976 420.992263 \nL 539.384853 417.009504 \nL 543.15173 420.992263 \nL 546.918607 422.983642 \nL 550.685483 419.000884 \nL 554.45236 419.000884 \nL 558.219237 420.992263 \nL 561.986113 413.026746 \nL 565.75299 419.000884 \nL 569.519867 419.000884 \nL 573.286743 419.000884 \nL 577.05362 419.000884 \nL 580.820497 420.992263 \nL 584.587373 422.983642 \nL 588.35425 419.000884 \nL 592.121127 419.000884 \nL 595.888003 420.992263 \nL 599.65488 413.026746 \nL 603.421757 413.026746 \nL 607.188634 415.018125 \nL 610.95551 413.026746 \nL 614.722387 419.000884 \nL 618.489264 419.000884 \nL 622.25614 415.018125 \nL 626.023017 415.018125 \nL 629.789894 413.026746 \nL 633.55677 420.992263 \nL 637.323647 420.992263 \nL 641.090524 413.026746 \nL 644.8574 409.043987 \nL 648.624277 413.026746 \nL 652.391154 417.009504 \nL 656.15803 411.035366 \nL 659.924907 415.018125 \nL 663.691784 413.026746 \nL 667.458661 411.035366 \nL 671.225537 411.035366 \nL 674.992414 411.035366 \nL 678.759291 411.035366 \nL 682.526167 415.018125 \nL 686.293044 413.026746 \nL 690.059921 413.026746 \nL 693.826797 411.035366 \nL 697.593674 409.043987 \nL 701.360551 413.026746 \nL 705.127427 411.035366 \nL 708.894304 413.026746 \nL 712.661181 413.026746 \nL 716.428057 411.035366 \nL 720.194934 413.026746 \nL 723.961811 413.026746 \nL 727.728688 411.035366 \nL 731.495564 415.018125 \nL 735.262441 415.018125 \nL 739.029318 411.035366 \nL 742.796194 413.026746 \nL 746.563071 417.009504 \nL 750.329948 413.026746 \nL 754.096824 413.026746 \nL 757.863701 413.026746 \nL 761.630578 413.026746 \nL 765.397454 413.026746 \nL 769.164331 413.026746 \nL 772.931208 411.035366 \nL 776.698084 413.026746 \nL 780.464961 413.026746 \nL 784.231838 413.026746 \nL 787.998715 413.026746 \nL 791.765591 409.043987 \nL 795.532468 409.043987 \nL 799.299345 411.035366 \nL 803.066221 413.026746 \nL 806.833098 413.026746 \nL 810.599975 411.035366 \nL 814.366851 411.035366 \nL 818.133728 411.035366 \nL 821.900605 411.035366 \nL 825.667481 411.035366 \nL 829.434358 411.035366 \nL 833.201235 411.035366 \nL 836.968111 411.035366 \nL 840.734988 411.035366 \nL 844.501865 411.035366 \nL 848.268742 411.035366 \nL 852.035618 411.035366 \nL 855.802495 413.026746 \nL 859.569372 411.035366 \nL 863.336248 411.035366 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_175\">\n    <path d=\"M 490.415456 438.914677 \nL 494.182333 440.906056 \nL 497.94921 442.897435 \nL 501.716086 442.897435 \nL 505.482963 428.95778 \nL 509.24984 422.983642 \nL 513.016716 409.043987 \nL 516.783593 413.026746 \nL 520.55047 409.043987 \nL 524.317346 415.018125 \nL 528.084223 413.026746 \nL 531.8511 411.035366 \nL 535.617976 413.026746 \nL 539.384853 411.035366 \nL 543.15173 411.035366 \nL 546.918607 411.035366 \nL 550.685483 411.035366 \nL 554.45236 413.026746 \nL 558.219237 411.035366 \nL 561.986113 411.035366 \nL 565.75299 411.035366 \nL 569.519867 409.043987 \nL 573.286743 413.026746 \nL 577.05362 405.061228 \nL 580.820497 413.026746 \nL 584.587373 411.035366 \nL 588.35425 411.035366 \nL 592.121127 415.018125 \nL 595.888003 417.009504 \nL 599.65488 411.035366 \nL 603.421757 407.052608 \nL 607.188634 413.026746 \nL 610.95551 409.043987 \nL 614.722387 409.043987 \nL 618.489264 413.026746 \nL 622.25614 411.035366 \nL 626.023017 411.035366 \nL 629.789894 411.035366 \nL 633.55677 413.026746 \nL 637.323647 409.043987 \nL 641.090524 411.035366 \nL 644.8574 409.043987 \nL 648.624277 409.043987 \nL 652.391154 405.061228 \nL 656.15803 411.035366 \nL 659.924907 407.052608 \nL 663.691784 413.026746 \nL 667.458661 407.052608 \nL 671.225537 411.035366 \nL 674.992414 411.035366 \nL 678.759291 407.052608 \nL 682.526167 411.035366 \nL 686.293044 409.043987 \nL 690.059921 411.035366 \nL 693.826797 407.052608 \nL 697.593674 405.061228 \nL 701.360551 405.061228 \nL 705.127427 409.043987 \nL 708.894304 411.035366 \nL 712.661181 413.026746 \nL 716.428057 405.061228 \nL 720.194934 407.052608 \nL 723.961811 409.043987 \nL 727.728688 407.052608 \nL 731.495564 409.043987 \nL 735.262441 409.043987 \nL 739.029318 409.043987 \nL 742.796194 407.052608 \nL 746.563071 411.035366 \nL 750.329948 407.052608 \nL 754.096824 409.043987 \nL 757.863701 409.043987 \nL 761.630578 411.035366 \nL 765.397454 409.043987 \nL 769.164331 409.043987 \nL 772.931208 407.052608 \nL 776.698084 405.061228 \nL 780.464961 407.052608 \nL 784.231838 407.052608 \nL 787.998715 407.052608 \nL 791.765591 405.061228 \nL 795.532468 405.061228 \nL 799.299345 409.043987 \nL 803.066221 409.043987 \nL 806.833098 407.052608 \nL 810.599975 407.052608 \nL 814.366851 407.052608 \nL 818.133728 405.061228 \nL 821.900605 407.052608 \nL 825.667481 407.052608 \nL 829.434358 407.052608 \nL 833.201235 407.052608 \nL 836.968111 407.052608 \nL 840.734988 407.052608 \nL 844.501865 407.052608 \nL 848.268742 407.052608 \nL 852.035618 407.052608 \nL 855.802495 407.052608 \nL 859.569372 407.052608 \nL 863.336248 409.043987 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_176\">\n    <path d=\"M 490.415456 434.931918 \nL 494.182333 438.914677 \nL 497.94921 438.914677 \nL 501.716086 442.897435 \nL 505.482963 428.95778 \nL 509.24984 417.009504 \nL 513.016716 407.052608 \nL 516.783593 409.043987 \nL 520.55047 409.043987 \nL 524.317346 407.052608 \nL 528.084223 409.043987 \nL 531.8511 407.052608 \nL 535.617976 409.043987 \nL 539.384853 411.035366 \nL 543.15173 411.035366 \nL 546.918607 409.043987 \nL 550.685483 407.052608 \nL 554.45236 413.026746 \nL 558.219237 407.052608 \nL 561.986113 407.052608 \nL 565.75299 407.052608 \nL 569.519867 407.052608 \nL 573.286743 411.035366 \nL 577.05362 403.069849 \nL 580.820497 409.043987 \nL 584.587373 405.061228 \nL 588.35425 409.043987 \nL 592.121127 413.026746 \nL 595.888003 413.026746 \nL 599.65488 409.043987 \nL 603.421757 405.061228 \nL 607.188634 407.052608 \nL 610.95551 409.043987 \nL 614.722387 407.052608 \nL 618.489264 409.043987 \nL 622.25614 407.052608 \nL 626.023017 409.043987 \nL 629.789894 407.052608 \nL 633.55677 405.061228 \nL 637.323647 403.069849 \nL 641.090524 409.043987 \nL 644.8574 409.043987 \nL 648.624277 405.061228 \nL 652.391154 405.061228 \nL 656.15803 409.043987 \nL 659.924907 405.061228 \nL 663.691784 409.043987 \nL 667.458661 405.061228 \nL 671.225537 407.052608 \nL 674.992414 409.043987 \nL 678.759291 405.061228 \nL 682.526167 407.052608 \nL 686.293044 405.061228 \nL 690.059921 407.052608 \nL 693.826797 407.052608 \nL 697.593674 403.069849 \nL 701.360551 403.069849 \nL 705.127427 403.069849 \nL 708.894304 411.035366 \nL 712.661181 411.035366 \nL 716.428057 403.069849 \nL 720.194934 405.061228 \nL 723.961811 409.043987 \nL 727.728688 405.061228 \nL 731.495564 407.052608 \nL 735.262441 405.061228 \nL 739.029318 409.043987 \nL 742.796194 405.061228 \nL 746.563071 405.061228 \nL 750.329948 405.061228 \nL 754.096824 409.043987 \nL 757.863701 409.043987 \nL 761.630578 407.052608 \nL 765.397454 409.043987 \nL 769.164331 407.052608 \nL 772.931208 405.061228 \nL 776.698084 405.061228 \nL 780.464961 405.061228 \nL 784.231838 407.052608 \nL 787.998715 407.052608 \nL 791.765591 405.061228 \nL 795.532468 405.061228 \nL 799.299345 405.061228 \nL 803.066221 407.052608 \nL 806.833098 407.052608 \nL 810.599975 405.061228 \nL 814.366851 405.061228 \nL 818.133728 405.061228 \nL 821.900605 407.052608 \nL 825.667481 405.061228 \nL 829.434358 405.061228 \nL 833.201235 407.052608 \nL 836.968111 405.061228 \nL 840.734988 405.061228 \nL 844.501865 407.052608 \nL 848.268742 405.061228 \nL 852.035618 407.052608 \nL 855.802495 407.052608 \nL 859.569372 405.061228 \nL 863.336248 407.052608 \n\" clip-path=\"url(#p3573166e8c)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 486.64858 442.897435 \nL 486.64858 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 867.103125 442.897435 \nL 867.103125 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 486.64858 442.897435 \nL 867.103125 442.897435 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 486.64858 251.725022 \nL 867.103125 251.725022 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_92\">\n    <!-- Training result when p = 400 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(590.20679 245.725022)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_4\">\n    <g id=\"patch_25\">\n     <path d=\"M 493.64858 377.150022 \nL 606.432955 377.150022 \nQ 608.432955 377.150022 608.432955 375.150022 \nL 608.432955 258.725022 \nQ 608.432955 256.725022 606.432955 256.725022 \nL 493.64858 256.725022 \nQ 491.64858 256.725022 491.64858 258.725022 \nL 491.64858 375.150022 \nQ 491.64858 377.150022 493.64858 377.150022 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_177\">\n     <path d=\"M 495.64858 264.823459 \nL 505.64858 264.823459 \nL 515.64858 264.823459 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_93\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 268.323459)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_178\">\n     <path d=\"M 495.64858 279.501584 \nL 505.64858 279.501584 \nL 515.64858 279.501584 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_94\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 283.001584)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_179\">\n     <path d=\"M 495.64858 294.179709 \nL 505.64858 294.179709 \nL 515.64858 294.179709 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_95\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 297.679709)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_180\">\n     <path d=\"M 495.64858 308.857834 \nL 505.64858 308.857834 \nL 515.64858 308.857834 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_96\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 312.357834)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_181\">\n     <path d=\"M 495.64858 323.535959 \nL 505.64858 323.535959 \nL 515.64858 323.535959 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_97\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 327.035959)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_182\">\n     <path d=\"M 495.64858 338.214084 \nL 505.64858 338.214084 \nL 515.64858 338.214084 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_98\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 341.714084)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_183\">\n     <path d=\"M 495.64858 352.892209 \nL 505.64858 352.892209 \nL 515.64858 352.892209 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_99\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 356.392209)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_184\">\n     <path d=\"M 495.64858 367.570334 \nL 505.64858 367.570334 \nL 515.64858 367.570334 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_100\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 371.070334)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_26\">\n    <path d=\"M 30.103125 672.304332 \nL 410.55767 672.304332 \nL 410.55767 481.131918 \nL 30.103125 481.131918 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_9\">\n    <g id=\"xtick_25\">\n     <g id=\"line2d_185\">\n      <path d=\"M 30.103125 672.304332 \nL 30.103125 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_186\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"30.103125\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_101\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(26.921875 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_187\">\n      <path d=\"M 105.440659 672.304332 \nL 105.440659 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_188\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"105.440659\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_102\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(99.078159 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_189\">\n      <path d=\"M 180.778193 672.304332 \nL 180.778193 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_190\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"180.778193\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_103\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(174.415693 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_191\">\n      <path d=\"M 256.115726 672.304332 \nL 256.115726 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_192\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"256.115726\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_104\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(249.753226 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_29\">\n     <g id=\"line2d_193\">\n      <path d=\"M 331.45326 672.304332 \nL 331.45326 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_194\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"331.45326\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_105\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(325.09076 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_195\">\n      <path d=\"M 406.790794 672.304332 \nL 406.790794 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_196\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"406.790794\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_106\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(397.247044 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_107\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(202.414773 700.580894)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_37\">\n     <g id=\"line2d_197\">\n      <path d=\"M 30.103125 672.304332 \nL 410.55767 672.304332 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_198\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_108\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 676.103551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_38\">\n     <g id=\"line2d_199\">\n      <path d=\"M 30.103125 648.40778 \nL 410.55767 648.40778 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_200\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"648.40778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_109\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 652.206999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_39\">\n     <g id=\"line2d_201\">\n      <path d=\"M 30.103125 624.511228 \nL 410.55767 624.511228 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_202\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"624.511228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_110\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 628.310447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_40\">\n     <g id=\"line2d_203\">\n      <path d=\"M 30.103125 600.614677 \nL 410.55767 600.614677 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_204\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"600.614677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_111\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 604.413895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_41\">\n     <g id=\"line2d_205\">\n      <path d=\"M 30.103125 576.718125 \nL 410.55767 576.718125 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_206\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"576.718125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_112\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 580.517344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_42\">\n     <g id=\"line2d_207\">\n      <path d=\"M 30.103125 552.821573 \nL 410.55767 552.821573 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_208\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"552.821573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_113\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 556.620792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_43\">\n     <g id=\"line2d_209\">\n      <path d=\"M 30.103125 528.925022 \nL 410.55767 528.925022 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_210\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"528.925022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_114\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 532.72424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_44\">\n     <g id=\"line2d_211\">\n      <path d=\"M 30.103125 505.02847 \nL 410.55767 505.02847 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_212\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"505.02847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_115\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 508.827689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_45\">\n     <g id=\"line2d_213\">\n      <path d=\"M 30.103125 481.131918 \nL 410.55767 481.131918 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_214\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"481.131918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_116\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 484.931137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_215\">\n    <path d=\"M 33.870002 484.509998 \nL 37.636878 475.298953 \nL 41.403755 477.857406 \nL 45.170632 483.404398 \nL 48.937508 488.333374 \nL 52.704385 492.584541 \nL 56.471262 495.68909 \nL 60.238139 498.709157 \nL 64.005015 501.087424 \nL 67.771892 503.539415 \nL 71.538769 505.737953 \nL 75.305645 507.66351 \nL 79.072522 509.018767 \nL 82.839399 510.719971 \nL 86.606275 511.515916 \nL 90.373152 513.350922 \nL 94.140029 514.420945 \nL 97.906905 514.707957 \nL 101.673782 515.570178 \nL 105.440659 516.417821 \nL 109.207535 516.810555 \nL 112.974412 517.955445 \nL 116.741289 518.147491 \nL 120.508166 518.695043 \nL 124.275042 519.463444 \nL 128.041919 518.460654 \nL 131.808796 519.097981 \nL 135.575672 519.433901 \nL 139.342549 519.967653 \nL 143.109426 519.733322 \nL 146.876302 520.365453 \nL 150.643179 521.321801 \nL 154.410056 520.843236 \nL 158.176932 521.099775 \nL 161.943809 521.928818 \nL 165.710686 521.52118 \nL 169.477562 521.952254 \nL 173.244439 521.826297 \nL 177.011316 522.162383 \nL 180.778193 521.098789 \nL 184.545069 521.134439 \nL 188.311946 521.270931 \nL 192.078823 522.384894 \nL 195.845699 521.553387 \nL 199.612576 521.753509 \nL 203.379453 523.006537 \nL 207.146329 521.804111 \nL 210.913206 522.48727 \nL 214.680083 523.729261 \nL 218.446959 523.512537 \nL 222.213836 522.71281 \nL 225.980713 521.700336 \nL 229.747589 523.393572 \nL 233.514466 522.942653 \nL 237.281343 524.160937 \nL 241.04822 523.028067 \nL 244.815096 523.360347 \nL 248.581973 524.003895 \nL 252.34885 523.46357 \nL 256.115726 522.398059 \nL 259.882603 523.941239 \nL 263.64948 523.19668 \nL 267.416356 523.729641 \nL 271.183233 522.816859 \nL 274.95011 523.816701 \nL 278.716986 524.473483 \nL 282.483863 523.839345 \nL 286.25074 522.996485 \nL 290.017616 524.014435 \nL 293.784493 524.827433 \nL 297.55137 524.413749 \nL 301.318247 524.373426 \nL 305.085123 524.589515 \nL 308.852 523.860596 \nL 312.618877 524.211971 \nL 316.385753 524.70218 \nL 320.15263 524.748919 \nL 323.919507 525.294867 \nL 327.686383 525.075296 \nL 331.45326 524.981093 \nL 335.220137 524.815362 \nL 338.987013 524.032944 \nL 342.75389 525.005337 \nL 346.520767 524.222301 \nL 350.287643 524.746855 \nL 354.05452 524.993201 \nL 357.821397 525.381182 \nL 361.588274 524.123381 \nL 365.35515 524.017863 \nL 369.122027 523.631779 \nL 372.888904 524.725818 \nL 376.65578 524.878468 \nL 380.422657 524.753247 \nL 384.189534 524.571509 \nL 387.95641 524.310624 \nL 391.723287 525.430806 \nL 395.490164 524.897086 \nL 399.25704 525.404033 \nL 403.023917 525.047122 \nL 406.790794 524.46715 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_216\">\n    <path d=\"M 33.870002 666.628901 \nL 37.636878 667.226315 \nL 41.403755 666.628901 \nL 45.170632 666.031487 \nL 48.937508 666.330194 \nL 52.704385 660.057349 \nL 56.471262 646.316832 \nL 60.238139 638.251746 \nL 64.005015 634.368556 \nL 67.771892 633.472435 \nL 71.538769 630.485366 \nL 75.305645 629.589246 \nL 79.072522 630.485366 \nL 82.839399 628.095711 \nL 86.606275 626.900884 \nL 90.373152 627.199591 \nL 94.140029 626.602177 \nL 97.906905 626.004763 \nL 101.673782 627.199591 \nL 105.440659 627.199591 \nL 109.207535 627.199591 \nL 112.974412 626.602177 \nL 116.741289 626.30347 \nL 120.508166 625.108642 \nL 124.275042 625.407349 \nL 128.041919 625.706056 \nL 131.808796 625.108642 \nL 135.575672 625.407349 \nL 139.342549 625.407349 \nL 143.109426 625.108642 \nL 146.876302 625.407349 \nL 150.643179 625.706056 \nL 154.410056 626.30347 \nL 158.176932 625.706056 \nL 161.943809 625.407349 \nL 165.710686 625.108642 \nL 169.477562 624.511228 \nL 173.244439 625.108642 \nL 177.011316 625.108642 \nL 180.778193 624.809935 \nL 184.545069 624.511228 \nL 188.311946 624.511228 \nL 192.078823 624.809935 \nL 195.845699 624.809935 \nL 199.612576 624.809935 \nL 203.379453 624.809935 \nL 207.146329 624.511228 \nL 210.913206 624.511228 \nL 214.680083 624.511228 \nL 218.446959 624.511228 \nL 222.213836 624.511228 \nL 225.980713 624.511228 \nL 229.747589 624.511228 \nL 233.514466 624.511228 \nL 237.281343 624.511228 \nL 241.04822 624.511228 \nL 244.815096 624.511228 \nL 248.581973 624.511228 \nL 252.34885 626.30347 \nL 256.115726 625.108642 \nL 259.882603 624.511228 \nL 263.64948 624.511228 \nL 267.416356 624.511228 \nL 271.183233 624.511228 \nL 274.95011 624.511228 \nL 278.716986 624.511228 \nL 282.483863 624.511228 \nL 286.25074 624.511228 \nL 290.017616 624.511228 \nL 293.784493 624.809935 \nL 297.55137 624.511228 \nL 301.318247 624.511228 \nL 305.085123 624.511228 \nL 308.852 624.511228 \nL 312.618877 624.511228 \nL 316.385753 624.511228 \nL 320.15263 624.511228 \nL 323.919507 624.511228 \nL 327.686383 624.511228 \nL 331.45326 624.511228 \nL 335.220137 624.511228 \nL 338.987013 624.511228 \nL 342.75389 624.511228 \nL 346.520767 624.511228 \nL 350.287643 624.511228 \nL 354.05452 624.511228 \nL 357.821397 624.511228 \nL 361.588274 624.511228 \nL 365.35515 624.511228 \nL 369.122027 624.511228 \nL 372.888904 624.511228 \nL 376.65578 624.511228 \nL 380.422657 624.511228 \nL 384.189534 624.511228 \nL 387.95641 624.511228 \nL 391.723287 624.511228 \nL 395.490164 624.511228 \nL 399.25704 624.511228 \nL 403.023917 624.511228 \nL 406.790794 624.511228 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_217\">\n    <path d=\"M 33.870002 664.836659 \nL 37.636878 662.745711 \nL 41.403755 663.940539 \nL 45.170632 663.940539 \nL 48.937508 663.343125 \nL 52.704385 655.278039 \nL 56.471262 637.654332 \nL 60.238139 631.680194 \nL 64.005015 627.797004 \nL 67.771892 627.498297 \nL 71.538769 626.900884 \nL 75.305645 626.900884 \nL 79.072522 627.199591 \nL 82.839399 626.30347 \nL 86.606275 625.108642 \nL 90.373152 625.407349 \nL 94.140029 626.004763 \nL 97.906905 625.108642 \nL 101.673782 625.407349 \nL 105.440659 625.706056 \nL 109.207535 626.004763 \nL 112.974412 625.706056 \nL 116.741289 624.809935 \nL 120.508166 624.511228 \nL 124.275042 624.511228 \nL 128.041919 624.511228 \nL 131.808796 624.511228 \nL 135.575672 624.809935 \nL 139.342549 624.809935 \nL 143.109426 624.809935 \nL 146.876302 624.511228 \nL 150.643179 624.511228 \nL 154.410056 625.108642 \nL 158.176932 625.108642 \nL 161.943809 624.511228 \nL 165.710686 624.511228 \nL 169.477562 624.511228 \nL 173.244439 624.511228 \nL 177.011316 624.511228 \nL 180.778193 624.511228 \nL 184.545069 624.511228 \nL 188.311946 624.511228 \nL 192.078823 624.809935 \nL 195.845699 624.809935 \nL 199.612576 624.809935 \nL 203.379453 624.511228 \nL 207.146329 624.511228 \nL 210.913206 624.511228 \nL 214.680083 624.511228 \nL 218.446959 624.511228 \nL 222.213836 624.511228 \nL 225.980713 624.511228 \nL 229.747589 624.511228 \nL 233.514466 624.511228 \nL 237.281343 624.511228 \nL 241.04822 624.511228 \nL 244.815096 624.511228 \nL 248.581973 624.511228 \nL 252.34885 626.004763 \nL 256.115726 624.809935 \nL 259.882603 624.511228 \nL 263.64948 624.511228 \nL 267.416356 624.511228 \nL 271.183233 624.511228 \nL 274.95011 624.511228 \nL 278.716986 624.511228 \nL 282.483863 624.511228 \nL 286.25074 624.511228 \nL 290.017616 624.511228 \nL 293.784493 624.511228 \nL 297.55137 624.511228 \nL 301.318247 624.511228 \nL 305.085123 624.511228 \nL 308.852 624.511228 \nL 312.618877 624.511228 \nL 316.385753 624.511228 \nL 320.15263 624.511228 \nL 323.919507 624.511228 \nL 327.686383 624.511228 \nL 331.45326 624.511228 \nL 335.220137 624.511228 \nL 338.987013 624.511228 \nL 342.75389 624.511228 \nL 346.520767 624.511228 \nL 350.287643 624.511228 \nL 354.05452 624.511228 \nL 357.821397 624.511228 \nL 361.588274 624.511228 \nL 365.35515 624.511228 \nL 369.122027 624.511228 \nL 372.888904 624.511228 \nL 376.65578 624.511228 \nL 380.422657 624.511228 \nL 384.189534 624.511228 \nL 387.95641 624.511228 \nL 391.723287 624.511228 \nL 395.490164 624.511228 \nL 399.25704 624.511228 \nL 403.023917 624.511228 \nL 406.790794 624.511228 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_218\">\n    <path d=\"M 33.870002 663.044418 \nL 37.636878 660.654763 \nL 41.403755 660.95347 \nL 45.170632 662.447004 \nL 48.937508 661.252177 \nL 52.704385 650.200022 \nL 56.471262 634.368556 \nL 60.238139 628.991832 \nL 64.005015 626.30347 \nL 67.771892 625.108642 \nL 71.538769 625.407349 \nL 75.305645 625.706056 \nL 79.072522 626.004763 \nL 82.839399 625.407349 \nL 86.606275 625.108642 \nL 90.373152 624.809935 \nL 94.140029 625.108642 \nL 97.906905 624.809935 \nL 101.673782 624.809935 \nL 105.440659 625.706056 \nL 109.207535 625.108642 \nL 112.974412 625.108642 \nL 116.741289 624.511228 \nL 120.508166 624.511228 \nL 124.275042 624.511228 \nL 128.041919 624.511228 \nL 131.808796 624.511228 \nL 135.575672 624.809935 \nL 139.342549 624.511228 \nL 143.109426 624.511228 \nL 146.876302 624.511228 \nL 150.643179 624.511228 \nL 154.410056 625.108642 \nL 158.176932 624.809935 \nL 161.943809 624.511228 \nL 165.710686 624.511228 \nL 169.477562 624.511228 \nL 173.244439 624.511228 \nL 177.011316 624.511228 \nL 180.778193 624.511228 \nL 184.545069 624.511228 \nL 188.311946 624.511228 \nL 192.078823 624.809935 \nL 195.845699 624.511228 \nL 199.612576 624.511228 \nL 203.379453 624.511228 \nL 207.146329 624.511228 \nL 210.913206 624.511228 \nL 214.680083 624.511228 \nL 218.446959 624.511228 \nL 222.213836 624.511228 \nL 225.980713 624.511228 \nL 229.747589 624.511228 \nL 233.514466 624.511228 \nL 237.281343 624.511228 \nL 241.04822 624.511228 \nL 244.815096 624.511228 \nL 248.581973 624.511228 \nL 252.34885 625.108642 \nL 256.115726 624.511228 \nL 259.882603 624.511228 \nL 263.64948 624.511228 \nL 267.416356 624.511228 \nL 271.183233 624.511228 \nL 274.95011 624.511228 \nL 278.716986 624.511228 \nL 282.483863 624.511228 \nL 286.25074 624.511228 \nL 290.017616 624.511228 \nL 293.784493 624.511228 \nL 297.55137 624.511228 \nL 301.318247 624.511228 \nL 305.085123 624.511228 \nL 308.852 624.511228 \nL 312.618877 624.511228 \nL 316.385753 624.511228 \nL 320.15263 624.511228 \nL 323.919507 624.511228 \nL 327.686383 624.511228 \nL 331.45326 624.511228 \nL 335.220137 624.511228 \nL 338.987013 624.511228 \nL 342.75389 624.511228 \nL 346.520767 624.511228 \nL 350.287643 624.511228 \nL 354.05452 624.511228 \nL 357.821397 624.511228 \nL 361.588274 624.511228 \nL 365.35515 624.511228 \nL 369.122027 624.511228 \nL 372.888904 624.511228 \nL 376.65578 624.511228 \nL 380.422657 624.511228 \nL 384.189534 624.511228 \nL 387.95641 624.511228 \nL 391.723287 624.511228 \nL 395.490164 624.511228 \nL 399.25704 624.511228 \nL 403.023917 624.511228 \nL 406.790794 624.511228 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_219\">\n    <path d=\"M 33.870002 467.813083 \nL 37.636878 470.498933 \nL 41.403755 471.207235 \nL 45.170632 474.705323 \nL 48.937508 479.983751 \nL 52.704385 488.753238 \nL 56.471262 492.006661 \nL 60.238139 494.627562 \nL 64.005015 497.311187 \nL 67.771892 497.521238 \nL 71.538769 496.942452 \nL 75.305645 498.364503 \nL 79.072522 499.76137 \nL 82.839399 499.084557 \nL 86.606275 497.843122 \nL 90.373152 499.190696 \nL 94.140029 501.48554 \nL 97.906905 501.219457 \nL 101.673782 501.024089 \nL 105.440659 500.799376 \nL 109.207535 501.37803 \nL 112.974412 500.474889 \nL 116.741289 502.375801 \nL 120.508166 499.642756 \nL 124.275042 501.635653 \nL 128.041919 501.542465 \nL 131.808796 501.736923 \nL 135.575672 504.545415 \nL 139.342549 502.56736 \nL 143.109426 502.246975 \nL 146.876302 502.219063 \nL 150.643179 501.265986 \nL 154.410056 502.111244 \nL 158.176932 503.011955 \nL 161.943809 500.301536 \nL 165.710686 503.265059 \nL 169.477562 503.30252 \nL 173.244439 501.130665 \nL 177.011316 502.932688 \nL 180.778193 505.185939 \nL 184.545069 502.931062 \nL 188.311946 500.117258 \nL 192.078823 503.404631 \nL 195.845699 501.561357 \nL 199.612576 502.361595 \nL 203.379453 502.725513 \nL 207.146329 503.108898 \nL 210.913206 503.289904 \nL 214.680083 502.783104 \nL 218.446959 504.330007 \nL 222.213836 503.199003 \nL 225.980713 503.850512 \nL 229.747589 503.091103 \nL 233.514466 503.846048 \nL 237.281343 503.106885 \nL 241.04822 502.327629 \nL 244.815096 503.504861 \nL 248.581973 504.141604 \nL 252.34885 502.218988 \nL 256.115726 503.456494 \nL 259.882603 504.222228 \nL 263.64948 503.127074 \nL 267.416356 503.606283 \nL 271.183233 504.142644 \nL 274.95011 503.57015 \nL 278.716986 504.282567 \nL 282.483863 503.952028 \nL 286.25074 504.512324 \nL 290.017616 504.610293 \nL 293.784493 504.416208 \nL 297.55137 503.768141 \nL 301.318247 503.905496 \nL 305.085123 504.09685 \nL 308.852 504.324833 \nL 312.618877 504.002523 \nL 316.385753 504.09315 \nL 320.15263 504.03212 \nL 323.919507 504.276077 \nL 327.686383 504.258537 \nL 331.45326 503.647582 \nL 335.220137 503.940289 \nL 338.987013 504.065308 \nL 342.75389 503.738573 \nL 346.520767 503.457575 \nL 350.287643 504.083723 \nL 354.05452 503.82993 \nL 357.821397 504.536289 \nL 361.588274 503.421667 \nL 365.35515 504.012706 \nL 369.122027 504.238308 \nL 372.888904 504.079796 \nL 376.65578 504.626765 \nL 380.422657 503.218299 \nL 384.189534 504.126351 \nL 387.95641 504.197849 \nL 391.723287 504.528079 \nL 395.490164 503.657719 \nL 399.25704 504.217651 \nL 403.023917 503.979792 \nL 406.790794 503.90954 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_220\">\n    <path d=\"M 33.870002 668.321573 \nL 37.636878 672.304332 \nL 41.403755 672.304332 \nL 45.170632 672.304332 \nL 48.937508 670.312953 \nL 52.704385 658.364677 \nL 56.471262 646.416401 \nL 60.238139 648.40778 \nL 64.005015 642.433642 \nL 67.771892 640.442263 \nL 71.538769 642.433642 \nL 75.305645 642.433642 \nL 79.072522 642.433642 \nL 82.839399 644.425022 \nL 86.606275 642.433642 \nL 90.373152 644.425022 \nL 94.140029 640.442263 \nL 97.906905 640.442263 \nL 101.673782 646.416401 \nL 105.440659 646.416401 \nL 109.207535 640.442263 \nL 112.974412 638.450884 \nL 116.741289 644.425022 \nL 120.508166 646.416401 \nL 124.275042 642.433642 \nL 128.041919 644.425022 \nL 131.808796 642.433642 \nL 135.575672 638.450884 \nL 139.342549 640.442263 \nL 143.109426 640.442263 \nL 146.876302 644.425022 \nL 150.643179 648.40778 \nL 154.410056 642.433642 \nL 158.176932 640.442263 \nL 161.943809 638.450884 \nL 165.710686 642.433642 \nL 169.477562 642.433642 \nL 173.244439 644.425022 \nL 177.011316 642.433642 \nL 180.778193 640.442263 \nL 184.545069 640.442263 \nL 188.311946 646.416401 \nL 192.078823 640.442263 \nL 195.845699 642.433642 \nL 199.612576 640.442263 \nL 203.379453 642.433642 \nL 207.146329 638.450884 \nL 210.913206 638.450884 \nL 214.680083 638.450884 \nL 218.446959 642.433642 \nL 222.213836 638.450884 \nL 225.980713 644.425022 \nL 229.747589 642.433642 \nL 233.514466 640.442263 \nL 237.281343 642.433642 \nL 241.04822 642.433642 \nL 244.815096 642.433642 \nL 248.581973 640.442263 \nL 252.34885 650.399159 \nL 256.115726 640.442263 \nL 259.882603 638.450884 \nL 263.64948 640.442263 \nL 267.416356 638.450884 \nL 271.183233 640.442263 \nL 274.95011 644.425022 \nL 278.716986 640.442263 \nL 282.483863 642.433642 \nL 286.25074 640.442263 \nL 290.017616 642.433642 \nL 293.784493 642.433642 \nL 297.55137 640.442263 \nL 301.318247 640.442263 \nL 305.085123 642.433642 \nL 308.852 640.442263 \nL 312.618877 638.450884 \nL 316.385753 640.442263 \nL 320.15263 640.442263 \nL 323.919507 640.442263 \nL 327.686383 640.442263 \nL 331.45326 642.433642 \nL 335.220137 642.433642 \nL 338.987013 642.433642 \nL 342.75389 642.433642 \nL 346.520767 642.433642 \nL 350.287643 642.433642 \nL 354.05452 640.442263 \nL 357.821397 642.433642 \nL 361.588274 642.433642 \nL 365.35515 640.442263 \nL 369.122027 640.442263 \nL 372.888904 640.442263 \nL 376.65578 640.442263 \nL 380.422657 638.450884 \nL 384.189534 640.442263 \nL 387.95641 640.442263 \nL 391.723287 640.442263 \nL 395.490164 638.450884 \nL 399.25704 638.450884 \nL 403.023917 638.450884 \nL 406.790794 640.442263 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_221\">\n    <path d=\"M 33.870002 668.321573 \nL 37.636878 672.304332 \nL 41.403755 672.304332 \nL 45.170632 672.304332 \nL 48.937508 668.321573 \nL 52.704385 652.390539 \nL 56.471262 642.433642 \nL 60.238139 642.433642 \nL 64.005015 640.442263 \nL 67.771892 640.442263 \nL 71.538769 636.459504 \nL 75.305645 636.459504 \nL 79.072522 638.450884 \nL 82.839399 638.450884 \nL 86.606275 640.442263 \nL 90.373152 642.433642 \nL 94.140029 638.450884 \nL 97.906905 636.459504 \nL 101.673782 644.425022 \nL 105.440659 640.442263 \nL 109.207535 638.450884 \nL 112.974412 638.450884 \nL 116.741289 634.468125 \nL 120.508166 638.450884 \nL 124.275042 634.468125 \nL 128.041919 640.442263 \nL 131.808796 638.450884 \nL 135.575672 634.468125 \nL 139.342549 634.468125 \nL 143.109426 640.442263 \nL 146.876302 638.450884 \nL 150.643179 642.433642 \nL 154.410056 636.459504 \nL 158.176932 638.450884 \nL 161.943809 634.468125 \nL 165.710686 636.459504 \nL 169.477562 638.450884 \nL 173.244439 638.450884 \nL 177.011316 638.450884 \nL 180.778193 636.459504 \nL 184.545069 636.459504 \nL 188.311946 642.433642 \nL 192.078823 638.450884 \nL 195.845699 640.442263 \nL 199.612576 640.442263 \nL 203.379453 640.442263 \nL 207.146329 638.450884 \nL 210.913206 638.450884 \nL 214.680083 636.459504 \nL 218.446959 638.450884 \nL 222.213836 638.450884 \nL 225.980713 636.459504 \nL 229.747589 636.459504 \nL 233.514466 638.450884 \nL 237.281343 636.459504 \nL 241.04822 636.459504 \nL 244.815096 640.442263 \nL 248.581973 636.459504 \nL 252.34885 644.425022 \nL 256.115726 634.468125 \nL 259.882603 636.459504 \nL 263.64948 634.468125 \nL 267.416356 636.459504 \nL 271.183233 636.459504 \nL 274.95011 638.450884 \nL 278.716986 636.459504 \nL 282.483863 638.450884 \nL 286.25074 636.459504 \nL 290.017616 638.450884 \nL 293.784493 636.459504 \nL 297.55137 638.450884 \nL 301.318247 636.459504 \nL 305.085123 636.459504 \nL 308.852 636.459504 \nL 312.618877 632.476746 \nL 316.385753 632.476746 \nL 320.15263 636.459504 \nL 323.919507 634.468125 \nL 327.686383 636.459504 \nL 331.45326 638.450884 \nL 335.220137 636.459504 \nL 338.987013 638.450884 \nL 342.75389 636.459504 \nL 346.520767 634.468125 \nL 350.287643 636.459504 \nL 354.05452 636.459504 \nL 357.821397 638.450884 \nL 361.588274 638.450884 \nL 365.35515 634.468125 \nL 369.122027 634.468125 \nL 372.888904 636.459504 \nL 376.65578 636.459504 \nL 380.422657 636.459504 \nL 384.189534 636.459504 \nL 387.95641 634.468125 \nL 391.723287 636.459504 \nL 395.490164 636.459504 \nL 399.25704 636.459504 \nL 403.023917 636.459504 \nL 406.790794 634.468125 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_222\">\n    <path d=\"M 33.870002 666.330194 \nL 37.636878 670.312953 \nL 41.403755 670.312953 \nL 45.170632 672.304332 \nL 48.937508 664.338815 \nL 52.704385 650.399159 \nL 56.471262 638.450884 \nL 60.238139 640.442263 \nL 64.005015 636.459504 \nL 67.771892 636.459504 \nL 71.538769 636.459504 \nL 75.305645 634.468125 \nL 79.072522 636.459504 \nL 82.839399 632.476746 \nL 86.606275 634.468125 \nL 90.373152 638.450884 \nL 94.140029 636.459504 \nL 97.906905 636.459504 \nL 101.673782 642.433642 \nL 105.440659 640.442263 \nL 109.207535 638.450884 \nL 112.974412 636.459504 \nL 116.741289 630.485366 \nL 120.508166 630.485366 \nL 124.275042 632.476746 \nL 128.041919 636.459504 \nL 131.808796 632.476746 \nL 135.575672 632.476746 \nL 139.342549 628.493987 \nL 143.109426 636.459504 \nL 146.876302 636.459504 \nL 150.643179 642.433642 \nL 154.410056 634.468125 \nL 158.176932 632.476746 \nL 161.943809 632.476746 \nL 165.710686 634.468125 \nL 169.477562 638.450884 \nL 173.244439 634.468125 \nL 177.011316 636.459504 \nL 180.778193 634.468125 \nL 184.545069 634.468125 \nL 188.311946 640.442263 \nL 192.078823 634.468125 \nL 195.845699 638.450884 \nL 199.612576 638.450884 \nL 203.379453 638.450884 \nL 207.146329 638.450884 \nL 210.913206 634.468125 \nL 214.680083 636.459504 \nL 218.446959 636.459504 \nL 222.213836 636.459504 \nL 225.980713 634.468125 \nL 229.747589 634.468125 \nL 233.514466 634.468125 \nL 237.281343 636.459504 \nL 241.04822 632.476746 \nL 244.815096 632.476746 \nL 248.581973 632.476746 \nL 252.34885 638.450884 \nL 256.115726 634.468125 \nL 259.882603 634.468125 \nL 263.64948 634.468125 \nL 267.416356 634.468125 \nL 271.183233 634.468125 \nL 274.95011 636.459504 \nL 278.716986 634.468125 \nL 282.483863 636.459504 \nL 286.25074 636.459504 \nL 290.017616 636.459504 \nL 293.784493 634.468125 \nL 297.55137 634.468125 \nL 301.318247 634.468125 \nL 305.085123 634.468125 \nL 308.852 634.468125 \nL 312.618877 632.476746 \nL 316.385753 632.476746 \nL 320.15263 634.468125 \nL 323.919507 634.468125 \nL 327.686383 636.459504 \nL 331.45326 634.468125 \nL 335.220137 634.468125 \nL 338.987013 638.450884 \nL 342.75389 634.468125 \nL 346.520767 634.468125 \nL 350.287643 634.468125 \nL 354.05452 634.468125 \nL 357.821397 634.468125 \nL 361.588274 634.468125 \nL 365.35515 634.468125 \nL 369.122027 634.468125 \nL 372.888904 634.468125 \nL 376.65578 634.468125 \nL 380.422657 636.459504 \nL 384.189534 634.468125 \nL 387.95641 634.468125 \nL 391.723287 634.468125 \nL 395.490164 634.468125 \nL 399.25704 636.459504 \nL 403.023917 636.459504 \nL 406.790794 634.468125 \n\" clip-path=\"url(#pf30be4b301)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 30.103125 672.304332 \nL 30.103125 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 410.55767 672.304332 \nL 410.55767 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 30.103125 672.304332 \nL 410.55767 672.304332 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 30.103125 481.131918 \nL 410.55767 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_117\">\n    <!-- Training result when p = 500 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(133.661335 475.131918)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_5\">\n    <g id=\"patch_31\">\n     <path d=\"M 37.103125 606.556918 \nL 149.8875 606.556918 \nQ 151.8875 606.556918 151.8875 604.556918 \nL 151.8875 488.131918 \nQ 151.8875 486.131918 149.8875 486.131918 \nL 37.103125 486.131918 \nQ 35.103125 486.131918 35.103125 488.131918 \nL 35.103125 604.556918 \nQ 35.103125 606.556918 37.103125 606.556918 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_223\">\n     <path d=\"M 39.103125 494.230356 \nL 49.103125 494.230356 \nL 59.103125 494.230356 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_118\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 497.730356)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_224\">\n     <path d=\"M 39.103125 508.908481 \nL 49.103125 508.908481 \nL 59.103125 508.908481 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_119\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 512.408481)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_225\">\n     <path d=\"M 39.103125 523.586606 \nL 49.103125 523.586606 \nL 59.103125 523.586606 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_120\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 527.086606)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_226\">\n     <path d=\"M 39.103125 538.264731 \nL 49.103125 538.264731 \nL 59.103125 538.264731 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_121\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 541.764731)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_227\">\n     <path d=\"M 39.103125 552.942856 \nL 49.103125 552.942856 \nL 59.103125 552.942856 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_122\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 556.442856)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_228\">\n     <path d=\"M 39.103125 567.620981 \nL 49.103125 567.620981 \nL 59.103125 567.620981 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_123\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 571.120981)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_229\">\n     <path d=\"M 39.103125 582.299106 \nL 49.103125 582.299106 \nL 59.103125 582.299106 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_124\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 585.799106)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_230\">\n     <path d=\"M 39.103125 596.977231 \nL 49.103125 596.977231 \nL 59.103125 596.977231 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_125\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 600.477231)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_6\">\n   <g id=\"patch_32\">\n    <path d=\"M 486.64858 672.304332 \nL 867.103125 672.304332 \nL 867.103125 481.131918 \nL 486.64858 481.131918 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_11\">\n    <g id=\"xtick_31\">\n     <g id=\"line2d_231\">\n      <path d=\"M 486.64858 672.304332 \nL 486.64858 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_232\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"486.64858\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_126\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(483.46733 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_233\">\n      <path d=\"M 561.986113 672.304332 \nL 561.986113 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_234\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"561.986113\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_127\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(555.623613 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_235\">\n      <path d=\"M 637.323647 672.304332 \nL 637.323647 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_236\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"637.323647\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_128\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(630.961147 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_237\">\n      <path d=\"M 712.661181 672.304332 \nL 712.661181 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_238\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"712.661181\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_129\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(706.298681 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_239\">\n      <path d=\"M 787.998715 672.304332 \nL 787.998715 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_240\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"787.998715\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_130\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(781.636215 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_241\">\n      <path d=\"M 863.336248 672.304332 \nL 863.336248 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_242\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"863.336248\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_131\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(853.792498 686.902769)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_132\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(658.960227 700.580894)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_12\">\n    <g id=\"ytick_46\">\n     <g id=\"line2d_243\">\n      <path d=\"M 486.64858 672.304332 \nL 867.103125 672.304332 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_244\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"672.304332\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_133\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 676.103551)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_47\">\n     <g id=\"line2d_245\">\n      <path d=\"M 486.64858 648.40778 \nL 867.103125 648.40778 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_246\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"648.40778\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_134\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 652.206999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_48\">\n     <g id=\"line2d_247\">\n      <path d=\"M 486.64858 624.511228 \nL 867.103125 624.511228 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_248\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"624.511228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_135\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 628.310447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_49\">\n     <g id=\"line2d_249\">\n      <path d=\"M 486.64858 600.614677 \nL 867.103125 600.614677 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_250\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"600.614677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_136\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 604.413895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_50\">\n     <g id=\"line2d_251\">\n      <path d=\"M 486.64858 576.718125 \nL 867.103125 576.718125 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_252\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"576.718125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_137\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 580.517344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_51\">\n     <g id=\"line2d_253\">\n      <path d=\"M 486.64858 552.821573 \nL 867.103125 552.821573 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_254\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"552.821573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_138\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 556.620792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_52\">\n     <g id=\"line2d_255\">\n      <path d=\"M 486.64858 528.925022 \nL 867.103125 528.925022 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_256\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"528.925022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_139\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 532.72424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_53\">\n     <g id=\"line2d_257\">\n      <path d=\"M 486.64858 505.02847 \nL 867.103125 505.02847 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_258\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"505.02847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_140\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 508.827689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_54\">\n     <g id=\"line2d_259\">\n      <path d=\"M 486.64858 481.131918 \nL 867.103125 481.131918 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_260\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"481.131918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_141\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 484.931137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_261\">\n    <path d=\"M 490.415456 484.655988 \nL 494.182333 475.388459 \nL 497.94921 478.049432 \nL 501.716086 483.947126 \nL 505.482963 488.430292 \nL 509.24984 492.83543 \nL 513.016716 496.024046 \nL 516.783593 498.691675 \nL 520.55047 501.435047 \nL 524.317346 504.343795 \nL 528.084223 506.311287 \nL 531.8511 508.098255 \nL 535.617976 509.329188 \nL 539.384853 510.598736 \nL 543.15173 512.711267 \nL 546.918607 513.166847 \nL 550.685483 514.479143 \nL 554.45236 514.946574 \nL 558.219237 515.873938 \nL 561.986113 517.23695 \nL 565.75299 516.835192 \nL 569.519867 517.241698 \nL 573.286743 517.872917 \nL 577.05362 518.133993 \nL 580.820497 517.538333 \nL 584.587373 518.670108 \nL 588.35425 517.759017 \nL 592.121127 518.46864 \nL 595.888003 519.262784 \nL 599.65488 520.232008 \nL 603.421757 520.104663 \nL 607.188634 520.721006 \nL 610.95551 520.500669 \nL 614.722387 519.926854 \nL 618.489264 520.875175 \nL 622.25614 520.538254 \nL 626.023017 521.169211 \nL 629.789894 521.556015 \nL 633.55677 521.044908 \nL 637.323647 521.360687 \nL 641.090524 522.118794 \nL 644.8574 522.430711 \nL 648.624277 522.194269 \nL 652.391154 521.487979 \nL 656.15803 522.206507 \nL 659.924907 521.113068 \nL 663.691784 522.407343 \nL 667.458661 522.62046 \nL 671.225537 521.851997 \nL 674.992414 522.501603 \nL 678.759291 523.825301 \nL 682.526167 522.598769 \nL 686.293044 523.809167 \nL 690.059921 523.109483 \nL 693.826797 523.661555 \nL 697.593674 523.010299 \nL 701.360551 522.945336 \nL 705.127427 523.596373 \nL 708.894304 523.843701 \nL 712.661181 523.395642 \nL 716.428057 524.017761 \nL 720.194934 524.429238 \nL 723.961811 523.678479 \nL 727.728688 523.958869 \nL 731.495564 523.790747 \nL 735.262441 524.551404 \nL 739.029318 523.914344 \nL 742.796194 524.420321 \nL 746.563071 524.277751 \nL 750.329948 524.791528 \nL 754.096824 523.474236 \nL 757.863701 524.799816 \nL 761.630578 524.931842 \nL 765.397454 524.792969 \nL 769.164331 524.394984 \nL 772.931208 524.214629 \nL 776.698084 525.230923 \nL 780.464961 524.803268 \nL 784.231838 524.358254 \nL 787.998715 525.780614 \nL 791.765591 525.611596 \nL 795.532468 524.683406 \nL 799.299345 524.720625 \nL 803.066221 525.199602 \nL 806.833098 524.189391 \nL 810.599975 524.780771 \nL 814.366851 524.236786 \nL 818.133728 524.772176 \nL 821.900605 525.462683 \nL 825.667481 525.085347 \nL 829.434358 524.613364 \nL 833.201235 524.970803 \nL 836.968111 525.207361 \nL 840.734988 524.575838 \nL 844.501865 524.906313 \nL 848.268742 524.886623 \nL 852.035618 525.346998 \nL 855.802495 525.253473 \nL 859.569372 524.418206 \nL 863.336248 524.998423 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_262\">\n    <path d=\"M 490.415456 666.330194 \nL 494.182333 666.330194 \nL 497.94921 666.927608 \nL 501.716086 666.031487 \nL 505.482963 666.330194 \nL 509.24984 660.057349 \nL 513.016716 646.615539 \nL 516.783593 639.147866 \nL 520.55047 633.472435 \nL 524.317346 631.680194 \nL 528.084223 631.680194 \nL 531.8511 628.095711 \nL 535.617976 628.095711 \nL 539.384853 627.199591 \nL 543.15173 627.199591 \nL 546.918607 626.602177 \nL 550.685483 626.900884 \nL 554.45236 626.30347 \nL 558.219237 627.797004 \nL 561.986113 624.809935 \nL 565.75299 625.706056 \nL 569.519867 625.706056 \nL 573.286743 625.407349 \nL 577.05362 628.394418 \nL 580.820497 625.407349 \nL 584.587373 624.809935 \nL 588.35425 625.407349 \nL 592.121127 626.30347 \nL 595.888003 624.511228 \nL 599.65488 624.511228 \nL 603.421757 624.809935 \nL 607.188634 625.108642 \nL 610.95551 624.511228 \nL 614.722387 625.108642 \nL 618.489264 624.511228 \nL 622.25614 624.511228 \nL 626.023017 625.108642 \nL 629.789894 625.407349 \nL 633.55677 624.511228 \nL 637.323647 624.809935 \nL 641.090524 624.809935 \nL 644.8574 624.511228 \nL 648.624277 624.809935 \nL 652.391154 625.108642 \nL 656.15803 624.511228 \nL 659.924907 624.511228 \nL 663.691784 624.511228 \nL 667.458661 624.511228 \nL 671.225537 624.511228 \nL 674.992414 624.511228 \nL 678.759291 624.511228 \nL 682.526167 624.511228 \nL 686.293044 624.511228 \nL 690.059921 624.809935 \nL 693.826797 624.809935 \nL 697.593674 624.511228 \nL 701.360551 624.511228 \nL 705.127427 624.511228 \nL 708.894304 624.809935 \nL 712.661181 624.809935 \nL 716.428057 624.809935 \nL 720.194934 624.511228 \nL 723.961811 624.511228 \nL 727.728688 624.511228 \nL 731.495564 624.511228 \nL 735.262441 624.511228 \nL 739.029318 624.511228 \nL 742.796194 624.511228 \nL 746.563071 624.511228 \nL 750.329948 624.511228 \nL 754.096824 624.511228 \nL 757.863701 624.511228 \nL 761.630578 624.511228 \nL 765.397454 624.511228 \nL 769.164331 624.511228 \nL 772.931208 624.511228 \nL 776.698084 624.511228 \nL 780.464961 624.511228 \nL 784.231838 624.511228 \nL 787.998715 624.511228 \nL 791.765591 624.511228 \nL 795.532468 624.511228 \nL 799.299345 624.511228 \nL 803.066221 624.511228 \nL 806.833098 624.511228 \nL 810.599975 624.511228 \nL 814.366851 624.511228 \nL 818.133728 624.511228 \nL 821.900605 624.511228 \nL 825.667481 624.511228 \nL 829.434358 624.511228 \nL 833.201235 624.511228 \nL 836.968111 624.511228 \nL 840.734988 624.511228 \nL 844.501865 624.511228 \nL 848.268742 624.511228 \nL 852.035618 624.511228 \nL 855.802495 624.511228 \nL 859.569372 624.511228 \nL 863.336248 624.511228 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_263\">\n    <path d=\"M 490.415456 663.641832 \nL 494.182333 663.940539 \nL 497.94921 663.343125 \nL 501.716086 663.641832 \nL 505.482963 664.239246 \nL 509.24984 655.875453 \nL 513.016716 640.940108 \nL 516.783593 630.485366 \nL 520.55047 627.498297 \nL 524.317346 627.498297 \nL 528.084223 627.797004 \nL 531.8511 626.602177 \nL 535.617976 625.407349 \nL 539.384853 625.706056 \nL 543.15173 625.407349 \nL 546.918607 625.108642 \nL 550.685483 625.706056 \nL 554.45236 624.809935 \nL 558.219237 625.407349 \nL 561.986113 624.511228 \nL 565.75299 624.809935 \nL 569.519867 624.511228 \nL 573.286743 624.511228 \nL 577.05362 625.407349 \nL 580.820497 624.809935 \nL 584.587373 624.511228 \nL 588.35425 624.511228 \nL 592.121127 624.809935 \nL 595.888003 624.511228 \nL 599.65488 624.511228 \nL 603.421757 624.511228 \nL 607.188634 624.511228 \nL 610.95551 624.511228 \nL 614.722387 624.809935 \nL 618.489264 624.511228 \nL 622.25614 624.511228 \nL 626.023017 624.511228 \nL 629.789894 624.511228 \nL 633.55677 624.511228 \nL 637.323647 624.511228 \nL 641.090524 624.511228 \nL 644.8574 624.511228 \nL 648.624277 624.511228 \nL 652.391154 624.511228 \nL 656.15803 624.511228 \nL 659.924907 624.511228 \nL 663.691784 624.511228 \nL 667.458661 624.511228 \nL 671.225537 624.511228 \nL 674.992414 624.511228 \nL 678.759291 624.511228 \nL 682.526167 624.511228 \nL 686.293044 624.511228 \nL 690.059921 624.809935 \nL 693.826797 624.809935 \nL 697.593674 624.511228 \nL 701.360551 624.511228 \nL 705.127427 624.511228 \nL 708.894304 624.511228 \nL 712.661181 624.511228 \nL 716.428057 624.511228 \nL 720.194934 624.511228 \nL 723.961811 624.511228 \nL 727.728688 624.511228 \nL 731.495564 624.511228 \nL 735.262441 624.511228 \nL 739.029318 624.511228 \nL 742.796194 624.511228 \nL 746.563071 624.511228 \nL 750.329948 624.511228 \nL 754.096824 624.511228 \nL 757.863701 624.511228 \nL 761.630578 624.511228 \nL 765.397454 624.511228 \nL 769.164331 624.511228 \nL 772.931208 624.511228 \nL 776.698084 624.511228 \nL 780.464961 624.511228 \nL 784.231838 624.511228 \nL 787.998715 624.511228 \nL 791.765591 624.511228 \nL 795.532468 624.511228 \nL 799.299345 624.511228 \nL 803.066221 624.511228 \nL 806.833098 624.511228 \nL 810.599975 624.511228 \nL 814.366851 624.511228 \nL 818.133728 624.511228 \nL 821.900605 624.511228 \nL 825.667481 624.511228 \nL 829.434358 624.511228 \nL 833.201235 624.511228 \nL 836.968111 624.511228 \nL 840.734988 624.511228 \nL 844.501865 624.511228 \nL 848.268742 624.511228 \nL 852.035618 624.511228 \nL 855.802495 624.511228 \nL 859.569372 624.511228 \nL 863.336248 624.511228 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_264\">\n    <path d=\"M 490.415456 662.447004 \nL 494.182333 660.057349 \nL 497.94921 660.95347 \nL 501.716086 661.550884 \nL 505.482963 662.148297 \nL 509.24984 652.29097 \nL 513.016716 635.264677 \nL 516.783593 626.30347 \nL 520.55047 626.004763 \nL 524.317346 625.407349 \nL 528.084223 625.407349 \nL 531.8511 625.108642 \nL 535.617976 625.108642 \nL 539.384853 624.809935 \nL 543.15173 625.108642 \nL 546.918607 625.108642 \nL 550.685483 624.511228 \nL 554.45236 624.511228 \nL 558.219237 624.809935 \nL 561.986113 624.511228 \nL 565.75299 624.511228 \nL 569.519867 624.511228 \nL 573.286743 624.511228 \nL 577.05362 624.809935 \nL 580.820497 624.809935 \nL 584.587373 624.511228 \nL 588.35425 624.511228 \nL 592.121127 624.511228 \nL 595.888003 624.511228 \nL 599.65488 624.511228 \nL 603.421757 624.511228 \nL 607.188634 624.511228 \nL 610.95551 624.511228 \nL 614.722387 624.511228 \nL 618.489264 624.511228 \nL 622.25614 624.511228 \nL 626.023017 624.511228 \nL 629.789894 624.511228 \nL 633.55677 624.511228 \nL 637.323647 624.511228 \nL 641.090524 624.511228 \nL 644.8574 624.511228 \nL 648.624277 624.511228 \nL 652.391154 624.511228 \nL 656.15803 624.511228 \nL 659.924907 624.511228 \nL 663.691784 624.511228 \nL 667.458661 624.511228 \nL 671.225537 624.511228 \nL 674.992414 624.511228 \nL 678.759291 624.511228 \nL 682.526167 624.511228 \nL 686.293044 624.511228 \nL 690.059921 624.809935 \nL 693.826797 624.809935 \nL 697.593674 624.511228 \nL 701.360551 624.511228 \nL 705.127427 624.511228 \nL 708.894304 624.511228 \nL 712.661181 624.511228 \nL 716.428057 624.511228 \nL 720.194934 624.511228 \nL 723.961811 624.511228 \nL 727.728688 624.511228 \nL 731.495564 624.511228 \nL 735.262441 624.511228 \nL 739.029318 624.511228 \nL 742.796194 624.511228 \nL 746.563071 624.511228 \nL 750.329948 624.511228 \nL 754.096824 624.511228 \nL 757.863701 624.511228 \nL 761.630578 624.511228 \nL 765.397454 624.511228 \nL 769.164331 624.511228 \nL 772.931208 624.511228 \nL 776.698084 624.511228 \nL 780.464961 624.511228 \nL 784.231838 624.511228 \nL 787.998715 624.511228 \nL 791.765591 624.511228 \nL 795.532468 624.511228 \nL 799.299345 624.511228 \nL 803.066221 624.511228 \nL 806.833098 624.511228 \nL 810.599975 624.511228 \nL 814.366851 624.511228 \nL 818.133728 624.511228 \nL 821.900605 624.511228 \nL 825.667481 624.511228 \nL 829.434358 624.511228 \nL 833.201235 624.511228 \nL 836.968111 624.511228 \nL 840.734988 624.511228 \nL 844.501865 624.511228 \nL 848.268742 624.511228 \nL 852.035618 624.511228 \nL 855.802495 624.511228 \nL 859.569372 624.511228 \nL 863.336248 624.511228 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_265\">\n    <path d=\"M 490.415456 468.80713 \nL 494.182333 470.40773 \nL 497.94921 470.569122 \nL 501.716086 473.264885 \nL 505.482963 478.906366 \nL 509.24984 487.744716 \nL 513.016716 493.280429 \nL 516.783593 494.674637 \nL 520.55047 495.566395 \nL 524.317346 496.249584 \nL 528.084223 496.396257 \nL 531.8511 497.324945 \nL 535.617976 498.79785 \nL 539.384853 499.312384 \nL 543.15173 499.787307 \nL 546.918607 499.809292 \nL 550.685483 501.409927 \nL 554.45236 500.479552 \nL 558.219237 498.842962 \nL 561.986113 500.309146 \nL 565.75299 500.304854 \nL 569.519867 501.48562 \nL 573.286743 500.462223 \nL 577.05362 499.952817 \nL 580.820497 499.050119 \nL 584.587373 500.827183 \nL 588.35425 499.637369 \nL 592.121127 501.149489 \nL 595.888003 502.657309 \nL 599.65488 502.452386 \nL 603.421757 502.454253 \nL 607.188634 503.585416 \nL 610.95551 500.975969 \nL 614.722387 500.584255 \nL 618.489264 500.303301 \nL 622.25614 501.022939 \nL 626.023017 502.348744 \nL 629.789894 502.467396 \nL 633.55677 503.077398 \nL 637.323647 501.152932 \nL 641.090524 499.88005 \nL 644.8574 502.243388 \nL 648.624277 501.675372 \nL 652.391154 501.876377 \nL 656.15803 503.400821 \nL 659.924907 502.991386 \nL 663.691784 502.719702 \nL 667.458661 501.694137 \nL 671.225537 501.306914 \nL 674.992414 502.608523 \nL 678.759291 502.08811 \nL 682.526167 503.267123 \nL 686.293044 501.316136 \nL 690.059921 502.197211 \nL 693.826797 501.478184 \nL 697.593674 503.133765 \nL 701.360551 502.851479 \nL 705.127427 502.337674 \nL 708.894304 503.228988 \nL 712.661181 502.50339 \nL 716.428057 504.125759 \nL 720.194934 503.311455 \nL 723.961811 503.210692 \nL 727.728688 502.887911 \nL 731.495564 503.266514 \nL 735.262441 504.281751 \nL 739.029318 503.967567 \nL 742.796194 503.3616 \nL 746.563071 502.99072 \nL 750.329948 503.275174 \nL 754.096824 503.127675 \nL 757.863701 503.317527 \nL 761.630578 503.403725 \nL 765.397454 503.708059 \nL 769.164331 503.757519 \nL 772.931208 504.480178 \nL 776.698084 504.067229 \nL 780.464961 503.864304 \nL 784.231838 504.050198 \nL 787.998715 503.152895 \nL 791.765591 504.307998 \nL 795.532468 504.741444 \nL 799.299345 504.478137 \nL 803.066221 503.865382 \nL 806.833098 504.45544 \nL 810.599975 503.842592 \nL 814.366851 504.135755 \nL 818.133728 504.228264 \nL 821.900605 503.719871 \nL 825.667481 504.15932 \nL 829.434358 504.138667 \nL 833.201235 504.627638 \nL 836.968111 504.251518 \nL 840.734988 504.652659 \nL 844.501865 503.584656 \nL 848.268742 503.970005 \nL 852.035618 503.875147 \nL 855.802495 503.430729 \nL 859.569372 504.502066 \nL 863.336248 504.020912 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_266\">\n    <path d=\"M 490.415456 670.312953 \nL 494.182333 672.304332 \nL 497.94921 672.304332 \nL 501.716086 672.304332 \nL 505.482963 672.304332 \nL 509.24984 664.338815 \nL 513.016716 646.416401 \nL 516.783593 644.425022 \nL 520.55047 650.399159 \nL 524.317346 648.40778 \nL 528.084223 646.416401 \nL 531.8511 644.425022 \nL 535.617976 644.425022 \nL 539.384853 640.442263 \nL 543.15173 648.40778 \nL 546.918607 636.459504 \nL 550.685483 646.416401 \nL 554.45236 640.442263 \nL 558.219237 640.442263 \nL 561.986113 644.425022 \nL 565.75299 642.433642 \nL 569.519867 644.425022 \nL 573.286743 638.450884 \nL 577.05362 652.390539 \nL 580.820497 644.425022 \nL 584.587373 640.442263 \nL 588.35425 644.425022 \nL 592.121127 640.442263 \nL 595.888003 640.442263 \nL 599.65488 650.399159 \nL 603.421757 646.416401 \nL 607.188634 642.433642 \nL 610.95551 644.425022 \nL 614.722387 644.425022 \nL 618.489264 640.442263 \nL 622.25614 644.425022 \nL 626.023017 642.433642 \nL 629.789894 646.416401 \nL 633.55677 642.433642 \nL 637.323647 636.459504 \nL 641.090524 640.442263 \nL 644.8574 640.442263 \nL 648.624277 640.442263 \nL 652.391154 638.450884 \nL 656.15803 640.442263 \nL 659.924907 640.442263 \nL 663.691784 638.450884 \nL 667.458661 640.442263 \nL 671.225537 640.442263 \nL 674.992414 640.442263 \nL 678.759291 636.459504 \nL 682.526167 644.425022 \nL 686.293044 640.442263 \nL 690.059921 644.425022 \nL 693.826797 642.433642 \nL 697.593674 638.450884 \nL 701.360551 638.450884 \nL 705.127427 642.433642 \nL 708.894304 642.433642 \nL 712.661181 638.450884 \nL 716.428057 638.450884 \nL 720.194934 642.433642 \nL 723.961811 640.442263 \nL 727.728688 638.450884 \nL 731.495564 638.450884 \nL 735.262441 642.433642 \nL 739.029318 638.450884 \nL 742.796194 638.450884 \nL 746.563071 642.433642 \nL 750.329948 640.442263 \nL 754.096824 638.450884 \nL 757.863701 642.433642 \nL 761.630578 636.459504 \nL 765.397454 636.459504 \nL 769.164331 638.450884 \nL 772.931208 636.459504 \nL 776.698084 636.459504 \nL 780.464961 640.442263 \nL 784.231838 642.433642 \nL 787.998715 642.433642 \nL 791.765591 640.442263 \nL 795.532468 640.442263 \nL 799.299345 642.433642 \nL 803.066221 642.433642 \nL 806.833098 640.442263 \nL 810.599975 636.459504 \nL 814.366851 636.459504 \nL 818.133728 640.442263 \nL 821.900605 640.442263 \nL 825.667481 640.442263 \nL 829.434358 638.450884 \nL 833.201235 638.450884 \nL 836.968111 638.450884 \nL 840.734988 640.442263 \nL 844.501865 640.442263 \nL 848.268742 640.442263 \nL 852.035618 640.442263 \nL 855.802495 638.450884 \nL 859.569372 640.442263 \nL 863.336248 638.450884 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_267\">\n    <path d=\"M 490.415456 670.312953 \nL 494.182333 672.304332 \nL 497.94921 670.312953 \nL 501.716086 672.304332 \nL 505.482963 670.312953 \nL 509.24984 658.364677 \nL 513.016716 640.442263 \nL 516.783593 644.425022 \nL 520.55047 644.425022 \nL 524.317346 640.442263 \nL 528.084223 638.450884 \nL 531.8511 640.442263 \nL 535.617976 636.459504 \nL 539.384853 632.476746 \nL 543.15173 640.442263 \nL 546.918607 630.485366 \nL 550.685483 640.442263 \nL 554.45236 634.468125 \nL 558.219237 634.468125 \nL 561.986113 638.450884 \nL 565.75299 638.450884 \nL 569.519867 634.468125 \nL 573.286743 636.459504 \nL 577.05362 640.442263 \nL 580.820497 636.459504 \nL 584.587373 634.468125 \nL 588.35425 642.433642 \nL 592.121127 636.459504 \nL 595.888003 634.468125 \nL 599.65488 640.442263 \nL 603.421757 638.450884 \nL 607.188634 638.450884 \nL 610.95551 636.459504 \nL 614.722387 634.468125 \nL 618.489264 638.450884 \nL 622.25614 638.450884 \nL 626.023017 640.442263 \nL 629.789894 636.459504 \nL 633.55677 636.459504 \nL 637.323647 634.468125 \nL 641.090524 634.468125 \nL 644.8574 634.468125 \nL 648.624277 634.468125 \nL 652.391154 636.459504 \nL 656.15803 634.468125 \nL 659.924907 632.476746 \nL 663.691784 634.468125 \nL 667.458661 636.459504 \nL 671.225537 632.476746 \nL 674.992414 636.459504 \nL 678.759291 634.468125 \nL 682.526167 638.450884 \nL 686.293044 636.459504 \nL 690.059921 636.459504 \nL 693.826797 640.442263 \nL 697.593674 632.476746 \nL 701.360551 634.468125 \nL 705.127427 634.468125 \nL 708.894304 632.476746 \nL 712.661181 634.468125 \nL 716.428057 634.468125 \nL 720.194934 634.468125 \nL 723.961811 634.468125 \nL 727.728688 632.476746 \nL 731.495564 634.468125 \nL 735.262441 632.476746 \nL 739.029318 632.476746 \nL 742.796194 632.476746 \nL 746.563071 636.459504 \nL 750.329948 632.476746 \nL 754.096824 636.459504 \nL 757.863701 634.468125 \nL 761.630578 632.476746 \nL 765.397454 634.468125 \nL 769.164331 634.468125 \nL 772.931208 632.476746 \nL 776.698084 632.476746 \nL 780.464961 632.476746 \nL 784.231838 632.476746 \nL 787.998715 634.468125 \nL 791.765591 632.476746 \nL 795.532468 634.468125 \nL 799.299345 634.468125 \nL 803.066221 632.476746 \nL 806.833098 632.476746 \nL 810.599975 632.476746 \nL 814.366851 632.476746 \nL 818.133728 632.476746 \nL 821.900605 632.476746 \nL 825.667481 632.476746 \nL 829.434358 632.476746 \nL 833.201235 632.476746 \nL 836.968111 632.476746 \nL 840.734988 634.468125 \nL 844.501865 634.468125 \nL 848.268742 632.476746 \nL 852.035618 634.468125 \nL 855.802495 632.476746 \nL 859.569372 632.476746 \nL 863.336248 632.476746 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_268\">\n    <path d=\"M 490.415456 670.312953 \nL 494.182333 668.321573 \nL 497.94921 668.321573 \nL 501.716086 672.304332 \nL 505.482963 666.330194 \nL 509.24984 656.373297 \nL 513.016716 638.450884 \nL 516.783593 644.425022 \nL 520.55047 638.450884 \nL 524.317346 636.459504 \nL 528.084223 634.468125 \nL 531.8511 636.459504 \nL 535.617976 630.485366 \nL 539.384853 630.485366 \nL 543.15173 636.459504 \nL 546.918607 630.485366 \nL 550.685483 632.476746 \nL 554.45236 634.468125 \nL 558.219237 632.476746 \nL 561.986113 634.468125 \nL 565.75299 636.459504 \nL 569.519867 632.476746 \nL 573.286743 634.468125 \nL 577.05362 636.459504 \nL 580.820497 632.476746 \nL 584.587373 632.476746 \nL 588.35425 636.459504 \nL 592.121127 632.476746 \nL 595.888003 632.476746 \nL 599.65488 636.459504 \nL 603.421757 634.468125 \nL 607.188634 636.459504 \nL 610.95551 634.468125 \nL 614.722387 634.468125 \nL 618.489264 632.476746 \nL 622.25614 636.459504 \nL 626.023017 636.459504 \nL 629.789894 632.476746 \nL 633.55677 636.459504 \nL 637.323647 632.476746 \nL 641.090524 630.485366 \nL 644.8574 630.485366 \nL 648.624277 632.476746 \nL 652.391154 634.468125 \nL 656.15803 632.476746 \nL 659.924907 630.485366 \nL 663.691784 632.476746 \nL 667.458661 634.468125 \nL 671.225537 632.476746 \nL 674.992414 630.485366 \nL 678.759291 632.476746 \nL 682.526167 638.450884 \nL 686.293044 634.468125 \nL 690.059921 632.476746 \nL 693.826797 634.468125 \nL 697.593674 632.476746 \nL 701.360551 632.476746 \nL 705.127427 634.468125 \nL 708.894304 632.476746 \nL 712.661181 632.476746 \nL 716.428057 634.468125 \nL 720.194934 634.468125 \nL 723.961811 634.468125 \nL 727.728688 632.476746 \nL 731.495564 632.476746 \nL 735.262441 632.476746 \nL 739.029318 632.476746 \nL 742.796194 630.485366 \nL 746.563071 632.476746 \nL 750.329948 632.476746 \nL 754.096824 632.476746 \nL 757.863701 630.485366 \nL 761.630578 632.476746 \nL 765.397454 632.476746 \nL 769.164331 632.476746 \nL 772.931208 630.485366 \nL 776.698084 632.476746 \nL 780.464961 630.485366 \nL 784.231838 632.476746 \nL 787.998715 632.476746 \nL 791.765591 632.476746 \nL 795.532468 632.476746 \nL 799.299345 632.476746 \nL 803.066221 632.476746 \nL 806.833098 632.476746 \nL 810.599975 632.476746 \nL 814.366851 632.476746 \nL 818.133728 632.476746 \nL 821.900605 632.476746 \nL 825.667481 632.476746 \nL 829.434358 632.476746 \nL 833.201235 632.476746 \nL 836.968111 632.476746 \nL 840.734988 632.476746 \nL 844.501865 632.476746 \nL 848.268742 632.476746 \nL 852.035618 632.476746 \nL 855.802495 632.476746 \nL 859.569372 632.476746 \nL 863.336248 632.476746 \n\" clip-path=\"url(#p7ab555a4aa)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 486.64858 672.304332 \nL 486.64858 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 867.103125 672.304332 \nL 867.103125 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 486.64858 672.304332 \nL 867.103125 672.304332 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 486.64858 481.131918 \nL 867.103125 481.131918 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_142\">\n    <!-- Training result when p = 600 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(590.20679 475.131918)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_6\">\n    <g id=\"patch_37\">\n     <path d=\"M 493.64858 606.556918 \nL 606.432955 606.556918 \nQ 608.432955 606.556918 608.432955 604.556918 \nL 608.432955 488.131918 \nQ 608.432955 486.131918 606.432955 486.131918 \nL 493.64858 486.131918 \nQ 491.64858 486.131918 491.64858 488.131918 \nL 491.64858 604.556918 \nQ 491.64858 606.556918 493.64858 606.556918 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_269\">\n     <path d=\"M 495.64858 494.230356 \nL 505.64858 494.230356 \nL 515.64858 494.230356 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_143\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 497.730356)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_270\">\n     <path d=\"M 495.64858 508.908481 \nL 505.64858 508.908481 \nL 515.64858 508.908481 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_144\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 512.408481)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_271\">\n     <path d=\"M 495.64858 523.586606 \nL 505.64858 523.586606 \nL 515.64858 523.586606 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_145\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 527.086606)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_272\">\n     <path d=\"M 495.64858 538.264731 \nL 505.64858 538.264731 \nL 515.64858 538.264731 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_146\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 541.764731)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_273\">\n     <path d=\"M 495.64858 552.942856 \nL 505.64858 552.942856 \nL 515.64858 552.942856 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_147\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 556.442856)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_274\">\n     <path d=\"M 495.64858 567.620981 \nL 505.64858 567.620981 \nL 515.64858 567.620981 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_148\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 571.120981)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_275\">\n     <path d=\"M 495.64858 582.299106 \nL 505.64858 582.299106 \nL 515.64858 582.299106 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_149\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 585.799106)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_276\">\n     <path d=\"M 495.64858 596.977231 \nL 505.64858 596.977231 \nL 515.64858 596.977231 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_150\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 600.477231)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_7\">\n   <g id=\"patch_38\">\n    <path d=\"M 30.103125 901.711228 \nL 410.55767 901.711228 \nL 410.55767 710.538815 \nL 30.103125 710.538815 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_13\">\n    <g id=\"xtick_37\">\n     <g id=\"line2d_277\">\n      <path d=\"M 30.103125 901.711228 \nL 30.103125 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_278\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"30.103125\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_151\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(26.921875 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_279\">\n      <path d=\"M 105.440659 901.711228 \nL 105.440659 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_280\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"105.440659\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_152\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(99.078159 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_281\">\n      <path d=\"M 180.778193 901.711228 \nL 180.778193 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_282\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"180.778193\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_153\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(174.415693 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_283\">\n      <path d=\"M 256.115726 901.711228 \nL 256.115726 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_284\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"256.115726\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_154\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(249.753226 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_285\">\n      <path d=\"M 331.45326 901.711228 \nL 331.45326 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_286\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"331.45326\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_155\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(325.09076 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_287\">\n      <path d=\"M 406.790794 901.711228 \nL 406.790794 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_288\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"406.790794\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_156\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(397.247044 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_157\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(202.414773 929.987791)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_14\">\n    <g id=\"ytick_55\">\n     <g id=\"line2d_289\">\n      <path d=\"M 30.103125 901.711228 \nL 410.55767 901.711228 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_290\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_158\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 905.510447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_56\">\n     <g id=\"line2d_291\">\n      <path d=\"M 30.103125 877.814677 \nL 410.55767 877.814677 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_292\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"877.814677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_159\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 881.613895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_57\">\n     <g id=\"line2d_293\">\n      <path d=\"M 30.103125 853.918125 \nL 410.55767 853.918125 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_294\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"853.918125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_160\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 857.717344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_58\">\n     <g id=\"line2d_295\">\n      <path d=\"M 30.103125 830.021573 \nL 410.55767 830.021573 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_296\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"830.021573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_161\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 833.820792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_59\">\n     <g id=\"line2d_297\">\n      <path d=\"M 30.103125 806.125022 \nL 410.55767 806.125022 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_298\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"806.125022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_162\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 809.92424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_60\">\n     <g id=\"line2d_299\">\n      <path d=\"M 30.103125 782.22847 \nL 410.55767 782.22847 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_300\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"782.22847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_163\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 786.027689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_61\">\n     <g id=\"line2d_301\">\n      <path d=\"M 30.103125 758.331918 \nL 410.55767 758.331918 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_302\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"758.331918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_164\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 762.131137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_62\">\n     <g id=\"line2d_303\">\n      <path d=\"M 30.103125 734.435366 \nL 410.55767 734.435366 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_304\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"734.435366\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_165\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 738.234585)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_63\">\n     <g id=\"line2d_305\">\n      <path d=\"M 30.103125 710.538815 \nL 410.55767 710.538815 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_306\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"710.538815\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_166\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 714.338033)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_307\">\n    <path d=\"M 33.870002 714.064331 \nL 37.636878 704.909301 \nL 41.403755 707.732904 \nL 45.170632 713.935419 \nL 48.937508 717.798158 \nL 52.704385 722.240966 \nL 56.471262 725.606879 \nL 60.238139 728.423844 \nL 64.005015 730.952293 \nL 67.771892 732.845589 \nL 71.538769 735.115551 \nL 75.305645 737.080708 \nL 79.072522 738.499829 \nL 82.839399 739.797531 \nL 86.606275 741.629406 \nL 90.373152 742.091771 \nL 94.140029 743.602083 \nL 97.906905 744.374499 \nL 101.673782 745.189184 \nL 105.440659 745.756712 \nL 109.207535 746.685784 \nL 112.974412 746.956742 \nL 116.741289 746.732858 \nL 120.508166 747.389577 \nL 124.275042 748.009632 \nL 128.041919 748.437983 \nL 131.808796 747.207976 \nL 135.575672 748.499223 \nL 139.342549 749.074577 \nL 143.109426 749.821211 \nL 146.876302 750.537025 \nL 150.643179 749.635956 \nL 154.410056 750.013119 \nL 158.176932 750.256045 \nL 161.943809 749.982143 \nL 165.710686 750.557175 \nL 169.477562 751.344175 \nL 173.244439 751.70745 \nL 177.011316 750.870374 \nL 180.778193 751.397373 \nL 184.545069 750.363941 \nL 188.311946 751.001763 \nL 192.078823 751.564769 \nL 195.845699 751.981348 \nL 199.612576 752.165122 \nL 203.379453 752.394314 \nL 207.146329 752.483879 \nL 210.913206 750.770793 \nL 214.680083 751.547635 \nL 218.446959 751.384158 \nL 222.213836 752.269361 \nL 225.980713 752.237702 \nL 229.747589 752.898604 \nL 233.514466 752.439902 \nL 237.281343 753.418677 \nL 241.04822 751.846898 \nL 244.815096 753.409055 \nL 248.581973 753.023141 \nL 252.34885 752.996214 \nL 256.115726 754.019174 \nL 259.882603 751.937779 \nL 263.64948 752.669093 \nL 267.416356 752.560676 \nL 271.183233 753.12893 \nL 274.95011 753.357777 \nL 278.716986 755.007109 \nL 282.483863 753.536872 \nL 286.25074 754.1305 \nL 290.017616 753.337794 \nL 293.784493 752.739262 \nL 297.55137 753.958276 \nL 301.318247 754.278652 \nL 305.085123 753.574674 \nL 308.852 753.934577 \nL 312.618877 754.273577 \nL 316.385753 755.110397 \nL 320.15263 754.160953 \nL 323.919507 754.571807 \nL 327.686383 753.367354 \nL 331.45326 754.478626 \nL 335.220137 753.995219 \nL 338.987013 753.995807 \nL 342.75389 754.20115 \nL 346.520767 753.546688 \nL 350.287643 755.171306 \nL 354.05452 754.565176 \nL 357.821397 754.65558 \nL 361.588274 754.404657 \nL 365.35515 754.849161 \nL 369.122027 754.280313 \nL 372.888904 754.153533 \nL 376.65578 753.807314 \nL 380.422657 754.406099 \nL 384.189534 754.206241 \nL 387.95641 754.845027 \nL 391.723287 754.054774 \nL 395.490164 753.633547 \nL 399.25704 753.795424 \nL 403.023917 753.667896 \nL 406.790794 753.663851 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_308\">\n    <path d=\"M 33.870002 895.737091 \nL 37.636878 896.035797 \nL 41.403755 895.438384 \nL 45.170632 895.737091 \nL 48.937508 895.737091 \nL 52.704385 886.17847 \nL 56.471262 874.528901 \nL 60.238139 868.554763 \nL 64.005015 864.97028 \nL 67.771892 862.580625 \nL 71.538769 861.385797 \nL 75.305645 859.892263 \nL 79.072522 858.996142 \nL 82.839399 857.203901 \nL 86.606275 857.801315 \nL 90.373152 856.905194 \nL 94.140029 855.112953 \nL 97.906905 857.203901 \nL 101.673782 856.905194 \nL 105.440659 855.710366 \nL 109.207535 856.009073 \nL 112.974412 855.112953 \nL 116.741289 855.112953 \nL 120.508166 857.502608 \nL 124.275042 857.502608 \nL 128.041919 854.216832 \nL 131.808796 854.814246 \nL 135.575672 854.814246 \nL 139.342549 854.814246 \nL 143.109426 853.918125 \nL 146.876302 856.009073 \nL 150.643179 856.606487 \nL 154.410056 855.411659 \nL 158.176932 855.112953 \nL 161.943809 855.710366 \nL 165.710686 854.216832 \nL 169.477562 854.814246 \nL 173.244439 854.515539 \nL 177.011316 854.515539 \nL 180.778193 854.515539 \nL 184.545069 854.216832 \nL 188.311946 855.411659 \nL 192.078823 854.515539 \nL 195.845699 854.515539 \nL 199.612576 854.515539 \nL 203.379453 854.814246 \nL 207.146329 855.112953 \nL 210.913206 855.112953 \nL 214.680083 854.814246 \nL 218.446959 854.216832 \nL 222.213836 854.216832 \nL 225.980713 854.515539 \nL 229.747589 855.112953 \nL 233.514466 854.515539 \nL 237.281343 854.515539 \nL 241.04822 853.918125 \nL 244.815096 854.216832 \nL 248.581973 853.918125 \nL 252.34885 854.216832 \nL 256.115726 853.918125 \nL 259.882603 853.918125 \nL 263.64948 853.918125 \nL 267.416356 854.216832 \nL 271.183233 853.918125 \nL 274.95011 853.918125 \nL 278.716986 853.918125 \nL 282.483863 853.918125 \nL 286.25074 853.918125 \nL 290.017616 853.918125 \nL 293.784493 853.918125 \nL 297.55137 853.918125 \nL 301.318247 853.918125 \nL 305.085123 853.918125 \nL 308.852 853.918125 \nL 312.618877 853.918125 \nL 316.385753 853.918125 \nL 320.15263 853.918125 \nL 323.919507 853.918125 \nL 327.686383 853.918125 \nL 331.45326 853.918125 \nL 335.220137 853.918125 \nL 338.987013 853.918125 \nL 342.75389 853.918125 \nL 346.520767 853.918125 \nL 350.287643 853.918125 \nL 354.05452 853.918125 \nL 357.821397 853.918125 \nL 361.588274 853.918125 \nL 365.35515 853.918125 \nL 369.122027 853.918125 \nL 372.888904 853.918125 \nL 376.65578 853.918125 \nL 380.422657 853.918125 \nL 384.189534 853.918125 \nL 387.95641 853.918125 \nL 391.723287 853.918125 \nL 395.490164 853.918125 \nL 399.25704 853.918125 \nL 403.023917 853.918125 \nL 406.790794 853.918125 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_309\">\n    <path d=\"M 33.870002 893.347435 \nL 37.636878 892.152608 \nL 41.403755 892.750022 \nL 45.170632 892.451315 \nL 48.937508 892.451315 \nL 52.704385 878.412091 \nL 56.471262 866.463815 \nL 60.238139 861.385797 \nL 64.005015 858.697435 \nL 67.771892 856.606487 \nL 71.538769 856.606487 \nL 75.305645 856.30778 \nL 79.072522 855.411659 \nL 82.839399 855.112953 \nL 86.606275 854.515539 \nL 90.373152 854.814246 \nL 94.140029 854.515539 \nL 97.906905 854.515539 \nL 101.673782 854.216832 \nL 105.440659 854.216832 \nL 109.207535 854.216832 \nL 112.974412 853.918125 \nL 116.741289 853.918125 \nL 120.508166 854.814246 \nL 124.275042 853.918125 \nL 128.041919 853.918125 \nL 131.808796 853.918125 \nL 135.575672 853.918125 \nL 139.342549 853.918125 \nL 143.109426 853.918125 \nL 146.876302 854.216832 \nL 150.643179 853.918125 \nL 154.410056 854.216832 \nL 158.176932 854.216832 \nL 161.943809 854.216832 \nL 165.710686 854.216832 \nL 169.477562 854.216832 \nL 173.244439 853.918125 \nL 177.011316 853.918125 \nL 180.778193 853.918125 \nL 184.545069 853.918125 \nL 188.311946 853.918125 \nL 192.078823 853.918125 \nL 195.845699 853.918125 \nL 199.612576 853.918125 \nL 203.379453 853.918125 \nL 207.146329 853.918125 \nL 210.913206 854.814246 \nL 214.680083 854.216832 \nL 218.446959 854.216832 \nL 222.213836 853.918125 \nL 225.980713 853.918125 \nL 229.747589 853.918125 \nL 233.514466 853.918125 \nL 237.281343 853.918125 \nL 241.04822 853.918125 \nL 244.815096 853.918125 \nL 248.581973 853.918125 \nL 252.34885 853.918125 \nL 256.115726 853.918125 \nL 259.882603 853.918125 \nL 263.64948 853.918125 \nL 267.416356 853.918125 \nL 271.183233 853.918125 \nL 274.95011 853.918125 \nL 278.716986 853.918125 \nL 282.483863 853.918125 \nL 286.25074 853.918125 \nL 290.017616 853.918125 \nL 293.784493 853.918125 \nL 297.55137 853.918125 \nL 301.318247 853.918125 \nL 305.085123 853.918125 \nL 308.852 853.918125 \nL 312.618877 853.918125 \nL 316.385753 853.918125 \nL 320.15263 853.918125 \nL 323.919507 853.918125 \nL 327.686383 853.918125 \nL 331.45326 853.918125 \nL 335.220137 853.918125 \nL 338.987013 853.918125 \nL 342.75389 853.918125 \nL 346.520767 853.918125 \nL 350.287643 853.918125 \nL 354.05452 853.918125 \nL 357.821397 853.918125 \nL 361.588274 853.918125 \nL 365.35515 853.918125 \nL 369.122027 853.918125 \nL 372.888904 853.918125 \nL 376.65578 853.918125 \nL 380.422657 853.918125 \nL 384.189534 853.918125 \nL 387.95641 853.918125 \nL 391.723287 853.918125 \nL 395.490164 853.918125 \nL 399.25704 853.918125 \nL 403.023917 853.918125 \nL 406.790794 853.918125 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_310\">\n    <path d=\"M 33.870002 890.360366 \nL 37.636878 890.061659 \nL 41.403755 890.659073 \nL 45.170632 891.256487 \nL 48.937508 890.360366 \nL 52.704385 876.918556 \nL 56.471262 862.580625 \nL 60.238139 858.100022 \nL 64.005015 856.30778 \nL 67.771892 855.411659 \nL 71.538769 855.112953 \nL 75.305645 854.814246 \nL 79.072522 854.814246 \nL 82.839399 854.814246 \nL 86.606275 854.216832 \nL 90.373152 854.515539 \nL 94.140029 854.515539 \nL 97.906905 854.216832 \nL 101.673782 853.918125 \nL 105.440659 854.216832 \nL 109.207535 854.216832 \nL 112.974412 853.918125 \nL 116.741289 853.918125 \nL 120.508166 854.515539 \nL 124.275042 853.918125 \nL 128.041919 853.918125 \nL 131.808796 853.918125 \nL 135.575672 853.918125 \nL 139.342549 853.918125 \nL 143.109426 853.918125 \nL 146.876302 853.918125 \nL 150.643179 853.918125 \nL 154.410056 853.918125 \nL 158.176932 853.918125 \nL 161.943809 854.216832 \nL 165.710686 853.918125 \nL 169.477562 853.918125 \nL 173.244439 853.918125 \nL 177.011316 853.918125 \nL 180.778193 853.918125 \nL 184.545069 853.918125 \nL 188.311946 853.918125 \nL 192.078823 853.918125 \nL 195.845699 853.918125 \nL 199.612576 853.918125 \nL 203.379453 853.918125 \nL 207.146329 853.918125 \nL 210.913206 853.918125 \nL 214.680083 853.918125 \nL 218.446959 853.918125 \nL 222.213836 853.918125 \nL 225.980713 853.918125 \nL 229.747589 853.918125 \nL 233.514466 853.918125 \nL 237.281343 853.918125 \nL 241.04822 853.918125 \nL 244.815096 853.918125 \nL 248.581973 853.918125 \nL 252.34885 853.918125 \nL 256.115726 853.918125 \nL 259.882603 853.918125 \nL 263.64948 853.918125 \nL 267.416356 853.918125 \nL 271.183233 853.918125 \nL 274.95011 853.918125 \nL 278.716986 853.918125 \nL 282.483863 853.918125 \nL 286.25074 853.918125 \nL 290.017616 853.918125 \nL 293.784493 853.918125 \nL 297.55137 853.918125 \nL 301.318247 853.918125 \nL 305.085123 853.918125 \nL 308.852 853.918125 \nL 312.618877 853.918125 \nL 316.385753 853.918125 \nL 320.15263 853.918125 \nL 323.919507 853.918125 \nL 327.686383 853.918125 \nL 331.45326 853.918125 \nL 335.220137 853.918125 \nL 338.987013 853.918125 \nL 342.75389 853.918125 \nL 346.520767 853.918125 \nL 350.287643 853.918125 \nL 354.05452 853.918125 \nL 357.821397 853.918125 \nL 361.588274 853.918125 \nL 365.35515 853.918125 \nL 369.122027 853.918125 \nL 372.888904 853.918125 \nL 376.65578 853.918125 \nL 380.422657 853.918125 \nL 384.189534 853.918125 \nL 387.95641 853.918125 \nL 391.723287 853.918125 \nL 395.490164 853.918125 \nL 399.25704 853.918125 \nL 403.023917 853.918125 \nL 406.790794 853.918125 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_311\">\n    <path d=\"M 33.870002 695.849053 \nL 37.636878 698.069674 \nL 41.403755 698.076807 \nL 45.170632 700.809021 \nL 48.937508 709.216605 \nL 52.704385 718.745784 \nL 56.471262 722.461584 \nL 60.238139 725.584464 \nL 64.005015 723.131201 \nL 67.771892 726.491801 \nL 71.538769 728.599256 \nL 75.305645 727.473079 \nL 79.072522 728.097753 \nL 82.839399 728.739712 \nL 86.606275 728.179649 \nL 90.373152 729.074272 \nL 94.140029 729.63201 \nL 97.906905 730.308611 \nL 101.673782 727.358839 \nL 105.440659 730.882886 \nL 109.207535 731.37445 \nL 112.974412 732.994946 \nL 116.741289 728.09908 \nL 120.508166 729.841227 \nL 124.275042 730.947447 \nL 128.041919 730.777203 \nL 131.808796 728.694035 \nL 135.575672 731.497311 \nL 139.342549 729.92484 \nL 143.109426 730.819363 \nL 146.876302 731.660118 \nL 150.643179 730.208568 \nL 154.410056 728.878915 \nL 158.176932 731.427764 \nL 161.943809 731.10205 \nL 165.710686 731.690308 \nL 169.477562 732.457452 \nL 173.244439 732.808124 \nL 177.011316 733.057798 \nL 180.778193 731.758608 \nL 184.545069 730.214541 \nL 188.311946 731.986591 \nL 192.078823 732.866493 \nL 195.845699 730.720402 \nL 199.612576 733.004493 \nL 203.379453 731.835436 \nL 207.146329 731.195723 \nL 210.913206 731.126327 \nL 214.680083 732.073992 \nL 218.446959 732.488016 \nL 222.213836 733.763451 \nL 225.980713 732.929779 \nL 229.747589 733.024771 \nL 233.514466 732.522101 \nL 237.281343 734.085513 \nL 241.04822 732.786306 \nL 244.815096 731.449889 \nL 248.581973 732.085034 \nL 252.34885 735.094698 \nL 256.115726 733.571204 \nL 259.882603 733.368432 \nL 263.64948 732.532517 \nL 267.416356 733.001052 \nL 271.183233 732.872802 \nL 274.95011 731.795764 \nL 278.716986 732.979425 \nL 282.483863 732.489012 \nL 286.25074 733.251763 \nL 290.017616 732.757549 \nL 293.784493 732.957044 \nL 297.55137 732.322792 \nL 301.318247 732.45 \nL 305.085123 732.071534 \nL 308.852 732.342943 \nL 312.618877 733.772803 \nL 316.385753 732.676565 \nL 320.15263 732.097343 \nL 323.919507 732.703662 \nL 327.686383 732.392173 \nL 331.45326 733.375113 \nL 335.220137 733.123473 \nL 338.987013 732.845798 \nL 342.75389 732.635638 \nL 346.520767 733.111882 \nL 350.287643 733.087693 \nL 354.05452 732.867961 \nL 357.821397 733.280097 \nL 361.588274 732.465493 \nL 365.35515 732.925158 \nL 369.122027 733.164416 \nL 372.888904 733.43327 \nL 376.65578 733.19219 \nL 380.422657 733.139427 \nL 384.189534 732.711938 \nL 387.95641 733.369915 \nL 391.723287 732.669005 \nL 395.490164 732.609089 \nL 399.25704 732.733107 \nL 403.023917 732.550534 \nL 406.790794 732.602138 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_312\">\n    <path d=\"M 33.870002 901.711228 \nL 37.636878 901.711228 \nL 41.403755 901.711228 \nL 45.170632 901.711228 \nL 48.937508 895.737091 \nL 52.704385 883.788815 \nL 56.471262 877.814677 \nL 60.238139 875.823297 \nL 64.005015 875.823297 \nL 67.771892 871.840539 \nL 71.538769 883.788815 \nL 75.305645 869.849159 \nL 79.072522 877.814677 \nL 82.839399 867.85778 \nL 86.606275 875.823297 \nL 90.373152 877.814677 \nL 94.140029 869.849159 \nL 97.906905 877.814677 \nL 101.673782 871.840539 \nL 105.440659 873.831918 \nL 109.207535 881.797435 \nL 112.974412 877.814677 \nL 116.741289 875.823297 \nL 120.508166 869.849159 \nL 124.275042 871.840539 \nL 128.041919 871.840539 \nL 131.808796 877.814677 \nL 135.575672 875.823297 \nL 139.342549 869.849159 \nL 143.109426 873.831918 \nL 146.876302 879.806056 \nL 150.643179 875.823297 \nL 154.410056 881.797435 \nL 158.176932 873.831918 \nL 161.943809 879.806056 \nL 165.710686 875.823297 \nL 169.477562 873.831918 \nL 173.244439 871.840539 \nL 177.011316 871.840539 \nL 180.778193 873.831918 \nL 184.545069 877.814677 \nL 188.311946 875.823297 \nL 192.078823 875.823297 \nL 195.845699 873.831918 \nL 199.612576 873.831918 \nL 203.379453 879.806056 \nL 207.146329 873.831918 \nL 210.913206 873.831918 \nL 214.680083 875.823297 \nL 218.446959 867.85778 \nL 222.213836 871.840539 \nL 225.980713 873.831918 \nL 229.747589 873.831918 \nL 233.514466 873.831918 \nL 237.281343 873.831918 \nL 241.04822 873.831918 \nL 244.815096 875.823297 \nL 248.581973 875.823297 \nL 252.34885 869.849159 \nL 256.115726 871.840539 \nL 259.882603 873.831918 \nL 263.64948 873.831918 \nL 267.416356 875.823297 \nL 271.183233 873.831918 \nL 274.95011 873.831918 \nL 278.716986 871.840539 \nL 282.483863 873.831918 \nL 286.25074 875.823297 \nL 290.017616 873.831918 \nL 293.784493 873.831918 \nL 297.55137 873.831918 \nL 301.318247 871.840539 \nL 305.085123 873.831918 \nL 308.852 873.831918 \nL 312.618877 871.840539 \nL 316.385753 873.831918 \nL 320.15263 877.814677 \nL 323.919507 875.823297 \nL 327.686383 873.831918 \nL 331.45326 871.840539 \nL 335.220137 875.823297 \nL 338.987013 873.831918 \nL 342.75389 869.849159 \nL 346.520767 871.840539 \nL 350.287643 871.840539 \nL 354.05452 871.840539 \nL 357.821397 873.831918 \nL 361.588274 871.840539 \nL 365.35515 871.840539 \nL 369.122027 873.831918 \nL 372.888904 873.831918 \nL 376.65578 873.831918 \nL 380.422657 873.831918 \nL 384.189534 873.831918 \nL 387.95641 873.831918 \nL 391.723287 875.823297 \nL 395.490164 875.823297 \nL 399.25704 873.831918 \nL 403.023917 873.831918 \nL 406.790794 873.831918 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_313\">\n    <path d=\"M 33.870002 901.711228 \nL 37.636878 901.711228 \nL 41.403755 901.711228 \nL 45.170632 901.711228 \nL 48.937508 893.745711 \nL 52.704385 877.814677 \nL 56.471262 873.831918 \nL 60.238139 863.875022 \nL 64.005015 871.840539 \nL 67.771892 865.866401 \nL 71.538769 877.814677 \nL 75.305645 869.849159 \nL 79.072522 867.85778 \nL 82.839399 865.866401 \nL 86.606275 869.849159 \nL 90.373152 875.823297 \nL 94.140029 869.849159 \nL 97.906905 873.831918 \nL 101.673782 867.85778 \nL 105.440659 865.866401 \nL 109.207535 871.840539 \nL 112.974412 865.866401 \nL 116.741289 873.831918 \nL 120.508166 867.85778 \nL 124.275042 863.875022 \nL 128.041919 867.85778 \nL 131.808796 869.849159 \nL 135.575672 869.849159 \nL 139.342549 865.866401 \nL 143.109426 867.85778 \nL 146.876302 871.840539 \nL 150.643179 865.866401 \nL 154.410056 875.823297 \nL 158.176932 867.85778 \nL 161.943809 871.840539 \nL 165.710686 871.840539 \nL 169.477562 869.849159 \nL 173.244439 865.866401 \nL 177.011316 865.866401 \nL 180.778193 869.849159 \nL 184.545069 873.831918 \nL 188.311946 869.849159 \nL 192.078823 869.849159 \nL 195.845699 867.85778 \nL 199.612576 871.840539 \nL 203.379453 875.823297 \nL 207.146329 869.849159 \nL 210.913206 869.849159 \nL 214.680083 861.883642 \nL 218.446959 863.875022 \nL 222.213836 867.85778 \nL 225.980713 869.849159 \nL 229.747589 869.849159 \nL 233.514466 869.849159 \nL 237.281343 863.875022 \nL 241.04822 865.866401 \nL 244.815096 871.840539 \nL 248.581973 871.840539 \nL 252.34885 865.866401 \nL 256.115726 867.85778 \nL 259.882603 865.866401 \nL 263.64948 867.85778 \nL 267.416356 867.85778 \nL 271.183233 867.85778 \nL 274.95011 867.85778 \nL 278.716986 869.849159 \nL 282.483863 869.849159 \nL 286.25074 867.85778 \nL 290.017616 863.875022 \nL 293.784493 867.85778 \nL 297.55137 863.875022 \nL 301.318247 867.85778 \nL 305.085123 867.85778 \nL 308.852 865.866401 \nL 312.618877 865.866401 \nL 316.385753 867.85778 \nL 320.15263 871.840539 \nL 323.919507 869.849159 \nL 327.686383 871.840539 \nL 331.45326 871.840539 \nL 335.220137 869.849159 \nL 338.987013 867.85778 \nL 342.75389 867.85778 \nL 346.520767 869.849159 \nL 350.287643 869.849159 \nL 354.05452 867.85778 \nL 357.821397 865.866401 \nL 361.588274 865.866401 \nL 365.35515 865.866401 \nL 369.122027 865.866401 \nL 372.888904 865.866401 \nL 376.65578 865.866401 \nL 380.422657 869.849159 \nL 384.189534 865.866401 \nL 387.95641 865.866401 \nL 391.723287 869.849159 \nL 395.490164 865.866401 \nL 399.25704 869.849159 \nL 403.023917 867.85778 \nL 406.790794 865.866401 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_314\">\n    <path d=\"M 33.870002 899.719849 \nL 37.636878 895.737091 \nL 41.403755 897.72847 \nL 45.170632 899.719849 \nL 48.937508 889.762953 \nL 52.704385 873.831918 \nL 56.471262 865.866401 \nL 60.238139 859.892263 \nL 64.005015 863.875022 \nL 67.771892 861.883642 \nL 71.538769 867.85778 \nL 75.305645 867.85778 \nL 79.072522 865.866401 \nL 82.839399 861.883642 \nL 86.606275 865.866401 \nL 90.373152 871.840539 \nL 94.140029 867.85778 \nL 97.906905 867.85778 \nL 101.673782 865.866401 \nL 105.440659 865.866401 \nL 109.207535 865.866401 \nL 112.974412 863.875022 \nL 116.741289 871.840539 \nL 120.508166 863.875022 \nL 124.275042 861.883642 \nL 128.041919 865.866401 \nL 131.808796 865.866401 \nL 135.575672 867.85778 \nL 139.342549 863.875022 \nL 143.109426 865.866401 \nL 146.876302 867.85778 \nL 150.643179 863.875022 \nL 154.410056 869.849159 \nL 158.176932 863.875022 \nL 161.943809 865.866401 \nL 165.710686 865.866401 \nL 169.477562 861.883642 \nL 173.244439 865.866401 \nL 177.011316 865.866401 \nL 180.778193 865.866401 \nL 184.545069 867.85778 \nL 188.311946 863.875022 \nL 192.078823 865.866401 \nL 195.845699 863.875022 \nL 199.612576 865.866401 \nL 203.379453 871.840539 \nL 207.146329 869.849159 \nL 210.913206 865.866401 \nL 214.680083 859.892263 \nL 218.446959 861.883642 \nL 222.213836 865.866401 \nL 225.980713 867.85778 \nL 229.747589 867.85778 \nL 233.514466 865.866401 \nL 237.281343 861.883642 \nL 241.04822 863.875022 \nL 244.815096 869.849159 \nL 248.581973 865.866401 \nL 252.34885 863.875022 \nL 256.115726 865.866401 \nL 259.882603 861.883642 \nL 263.64948 863.875022 \nL 267.416356 865.866401 \nL 271.183233 865.866401 \nL 274.95011 863.875022 \nL 278.716986 865.866401 \nL 282.483863 865.866401 \nL 286.25074 861.883642 \nL 290.017616 861.883642 \nL 293.784493 863.875022 \nL 297.55137 861.883642 \nL 301.318247 863.875022 \nL 305.085123 865.866401 \nL 308.852 863.875022 \nL 312.618877 865.866401 \nL 316.385753 863.875022 \nL 320.15263 863.875022 \nL 323.919507 865.866401 \nL 327.686383 863.875022 \nL 331.45326 865.866401 \nL 335.220137 867.85778 \nL 338.987013 863.875022 \nL 342.75389 863.875022 \nL 346.520767 861.883642 \nL 350.287643 863.875022 \nL 354.05452 863.875022 \nL 357.821397 861.883642 \nL 361.588274 861.883642 \nL 365.35515 861.883642 \nL 369.122027 861.883642 \nL 372.888904 861.883642 \nL 376.65578 861.883642 \nL 380.422657 863.875022 \nL 384.189534 863.875022 \nL 387.95641 863.875022 \nL 391.723287 865.866401 \nL 395.490164 861.883642 \nL 399.25704 863.875022 \nL 403.023917 861.883642 \nL 406.790794 861.883642 \n\" clip-path=\"url(#pe6c35d5558)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 30.103125 901.711228 \nL 30.103125 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 410.55767 901.711228 \nL 410.55767 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_41\">\n    <path d=\"M 30.103125 901.711228 \nL 410.55767 901.711228 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_42\">\n    <path d=\"M 30.103125 710.538815 \nL 410.55767 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_167\">\n    <!-- Training result when p = 700 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(133.661335 704.538815)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_7\">\n    <g id=\"patch_43\">\n     <path d=\"M 37.103125 835.963815 \nL 149.8875 835.963815 \nQ 151.8875 835.963815 151.8875 833.963815 \nL 151.8875 717.538815 \nQ 151.8875 715.538815 149.8875 715.538815 \nL 37.103125 715.538815 \nQ 35.103125 715.538815 35.103125 717.538815 \nL 35.103125 833.963815 \nQ 35.103125 835.963815 37.103125 835.963815 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_315\">\n     <path d=\"M 39.103125 723.637252 \nL 49.103125 723.637252 \nL 59.103125 723.637252 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_168\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 727.137252)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_316\">\n     <path d=\"M 39.103125 738.315377 \nL 49.103125 738.315377 \nL 59.103125 738.315377 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_169\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 741.815377)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_317\">\n     <path d=\"M 39.103125 752.993502 \nL 49.103125 752.993502 \nL 59.103125 752.993502 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_170\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 756.493502)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_318\">\n     <path d=\"M 39.103125 767.671627 \nL 49.103125 767.671627 \nL 59.103125 767.671627 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_171\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 771.171627)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_319\">\n     <path d=\"M 39.103125 782.349752 \nL 49.103125 782.349752 \nL 59.103125 782.349752 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_172\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 785.849752)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_320\">\n     <path d=\"M 39.103125 797.027877 \nL 49.103125 797.027877 \nL 59.103125 797.027877 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_173\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 800.527877)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_321\">\n     <path d=\"M 39.103125 811.706002 \nL 49.103125 811.706002 \nL 59.103125 811.706002 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_174\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 815.206002)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_322\">\n     <path d=\"M 39.103125 826.384127 \nL 49.103125 826.384127 \nL 59.103125 826.384127 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_175\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 829.884127)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_8\">\n   <g id=\"patch_44\">\n    <path d=\"M 486.64858 901.711228 \nL 867.103125 901.711228 \nL 867.103125 710.538815 \nL 486.64858 710.538815 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_15\">\n    <g id=\"xtick_43\">\n     <g id=\"line2d_323\">\n      <path d=\"M 486.64858 901.711228 \nL 486.64858 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_324\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"486.64858\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_176\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(483.46733 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_325\">\n      <path d=\"M 561.986113 901.711228 \nL 561.986113 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_326\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"561.986113\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_177\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(555.623613 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_327\">\n      <path d=\"M 637.323647 901.711228 \nL 637.323647 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_328\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"637.323647\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_178\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(630.961147 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_329\">\n      <path d=\"M 712.661181 901.711228 \nL 712.661181 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_330\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"712.661181\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_179\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(706.298681 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_331\">\n      <path d=\"M 787.998715 901.711228 \nL 787.998715 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_332\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"787.998715\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_180\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(781.636215 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_333\">\n      <path d=\"M 863.336248 901.711228 \nL 863.336248 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_334\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"863.336248\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_181\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(853.792498 916.309666)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_182\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(658.960227 929.987791)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_16\">\n    <g id=\"ytick_64\">\n     <g id=\"line2d_335\">\n      <path d=\"M 486.64858 901.711228 \nL 867.103125 901.711228 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_336\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"901.711228\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_183\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 905.510447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_65\">\n     <g id=\"line2d_337\">\n      <path d=\"M 486.64858 877.814677 \nL 867.103125 877.814677 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_338\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"877.814677\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_184\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 881.613895)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_66\">\n     <g id=\"line2d_339\">\n      <path d=\"M 486.64858 853.918125 \nL 867.103125 853.918125 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_340\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"853.918125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_185\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 857.717344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_67\">\n     <g id=\"line2d_341\">\n      <path d=\"M 486.64858 830.021573 \nL 867.103125 830.021573 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_342\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"830.021573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_186\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 833.820792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_68\">\n     <g id=\"line2d_343\">\n      <path d=\"M 486.64858 806.125022 \nL 867.103125 806.125022 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_344\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"806.125022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_187\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 809.92424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_69\">\n     <g id=\"line2d_345\">\n      <path d=\"M 486.64858 782.22847 \nL 867.103125 782.22847 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_346\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"782.22847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_188\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 786.027689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_70\">\n     <g id=\"line2d_347\">\n      <path d=\"M 486.64858 758.331918 \nL 867.103125 758.331918 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_348\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"758.331918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_189\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 762.131137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_71\">\n     <g id=\"line2d_349\">\n      <path d=\"M 486.64858 734.435366 \nL 867.103125 734.435366 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_350\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"734.435366\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_190\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 738.234585)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_72\">\n     <g id=\"line2d_351\">\n      <path d=\"M 486.64858 710.538815 \nL 867.103125 710.538815 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_352\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"710.538815\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_191\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 714.338033)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_353\">\n    <path d=\"M 490.415456 713.981925 \nL 494.182333 704.684411 \nL 497.94921 707.385308 \nL 501.716086 712.841264 \nL 505.482963 717.353161 \nL 509.24984 721.528022 \nL 513.016716 724.910653 \nL 516.783593 728.209396 \nL 520.55047 730.698812 \nL 524.317346 732.8751 \nL 528.084223 734.512023 \nL 531.8511 736.809792 \nL 535.617976 738.110715 \nL 539.384853 739.493554 \nL 543.15173 741.410814 \nL 546.918607 742.521476 \nL 550.685483 742.785134 \nL 554.45236 744.098484 \nL 558.219237 745.374854 \nL 561.986113 745.636123 \nL 565.75299 745.566379 \nL 569.519867 747.530938 \nL 573.286743 747.348687 \nL 577.05362 748.258624 \nL 580.820497 748.23281 \nL 584.587373 749.306747 \nL 588.35425 749.261813 \nL 592.121127 748.698559 \nL 595.888003 750.013652 \nL 599.65488 750.473356 \nL 603.421757 750.027545 \nL 607.188634 750.244321 \nL 610.95551 750.819634 \nL 614.722387 750.782183 \nL 618.489264 751.379148 \nL 622.25614 751.002161 \nL 626.023017 750.57396 \nL 629.789894 750.432288 \nL 633.55677 751.512797 \nL 637.323647 750.272879 \nL 641.090524 751.108306 \nL 644.8574 751.42987 \nL 648.624277 752.051259 \nL 652.391154 752.08139 \nL 656.15803 751.688758 \nL 659.924907 752.486331 \nL 663.691784 752.475573 \nL 667.458661 751.735685 \nL 671.225537 753.252171 \nL 674.992414 752.91642 \nL 678.759291 753.203408 \nL 682.526167 752.421477 \nL 686.293044 751.257811 \nL 690.059921 753.149045 \nL 693.826797 753.405681 \nL 697.593674 753.304213 \nL 701.360551 752.6923 \nL 705.127427 753.373642 \nL 708.894304 752.991376 \nL 712.661181 753.888716 \nL 716.428057 753.472217 \nL 720.194934 752.98878 \nL 723.961811 752.502669 \nL 727.728688 753.418809 \nL 731.495564 753.308782 \nL 735.262441 752.868133 \nL 739.029318 753.980932 \nL 742.796194 753.760872 \nL 746.563071 754.518445 \nL 750.329948 754.293647 \nL 754.096824 753.935779 \nL 757.863701 754.210339 \nL 761.630578 753.871783 \nL 765.397454 753.424164 \nL 769.164331 754.147826 \nL 772.931208 754.733241 \nL 776.698084 754.733858 \nL 780.464961 754.724635 \nL 784.231838 753.847333 \nL 787.998715 754.425937 \nL 791.765591 754.988646 \nL 795.532468 754.66739 \nL 799.299345 754.337034 \nL 803.066221 753.575138 \nL 806.833098 754.903064 \nL 810.599975 754.125336 \nL 814.366851 754.601453 \nL 818.133728 753.754071 \nL 821.900605 754.60215 \nL 825.667481 754.322629 \nL 829.434358 754.645091 \nL 833.201235 754.91226 \nL 836.968111 754.797702 \nL 840.734988 754.96525 \nL 844.501865 753.987104 \nL 848.268742 754.422527 \nL 852.035618 754.201835 \nL 855.802495 754.382305 \nL 859.569372 754.462564 \nL 863.336248 754.606459 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_354\">\n    <path d=\"M 490.415456 898.425453 \nL 494.182333 896.035797 \nL 497.94921 895.737091 \nL 501.716086 896.035797 \nL 505.482963 895.438384 \nL 509.24984 889.762953 \nL 513.016716 877.51597 \nL 516.783593 868.85347 \nL 520.55047 866.463815 \nL 524.317346 863.476746 \nL 528.084223 860.788384 \nL 531.8511 861.983211 \nL 535.617976 858.697435 \nL 539.384853 858.697435 \nL 543.15173 859.892263 \nL 546.918607 858.996142 \nL 550.685483 856.30778 \nL 554.45236 856.009073 \nL 558.219237 855.710366 \nL 561.986113 856.606487 \nL 565.75299 855.411659 \nL 569.519867 855.411659 \nL 573.286743 854.216832 \nL 577.05362 854.515539 \nL 580.820497 856.30778 \nL 584.587373 854.814246 \nL 588.35425 855.112953 \nL 592.121127 854.515539 \nL 595.888003 853.918125 \nL 599.65488 854.515539 \nL 603.421757 854.216832 \nL 607.188634 854.814246 \nL 610.95551 857.801315 \nL 614.722387 855.112953 \nL 618.489264 854.515539 \nL 622.25614 854.216832 \nL 626.023017 854.515539 \nL 629.789894 853.918125 \nL 633.55677 855.411659 \nL 637.323647 855.112953 \nL 641.090524 854.216832 \nL 644.8574 855.112953 \nL 648.624277 854.216832 \nL 652.391154 853.918125 \nL 656.15803 854.216832 \nL 659.924907 853.918125 \nL 663.691784 853.918125 \nL 667.458661 854.216832 \nL 671.225537 853.918125 \nL 674.992414 853.918125 \nL 678.759291 854.216832 \nL 682.526167 853.918125 \nL 686.293044 853.918125 \nL 690.059921 853.918125 \nL 693.826797 853.918125 \nL 697.593674 853.918125 \nL 701.360551 853.918125 \nL 705.127427 853.918125 \nL 708.894304 853.918125 \nL 712.661181 853.918125 \nL 716.428057 853.918125 \nL 720.194934 853.918125 \nL 723.961811 853.918125 \nL 727.728688 853.918125 \nL 731.495564 853.918125 \nL 735.262441 853.918125 \nL 739.029318 853.918125 \nL 742.796194 853.918125 \nL 746.563071 853.918125 \nL 750.329948 853.918125 \nL 754.096824 853.918125 \nL 757.863701 853.918125 \nL 761.630578 853.918125 \nL 765.397454 853.918125 \nL 769.164331 853.918125 \nL 772.931208 853.918125 \nL 776.698084 853.918125 \nL 780.464961 853.918125 \nL 784.231838 853.918125 \nL 787.998715 853.918125 \nL 791.765591 853.918125 \nL 795.532468 853.918125 \nL 799.299345 853.918125 \nL 803.066221 853.918125 \nL 806.833098 853.918125 \nL 810.599975 853.918125 \nL 814.366851 853.918125 \nL 818.133728 853.918125 \nL 821.900605 853.918125 \nL 825.667481 853.918125 \nL 829.434358 853.918125 \nL 833.201235 853.918125 \nL 836.968111 853.918125 \nL 840.734988 853.918125 \nL 844.501865 853.918125 \nL 848.268742 853.918125 \nL 852.035618 853.918125 \nL 855.802495 853.918125 \nL 859.569372 853.918125 \nL 863.336248 853.918125 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_355\">\n    <path d=\"M 490.415456 896.633211 \nL 494.182333 892.152608 \nL 497.94921 892.750022 \nL 501.716086 892.750022 \nL 505.482963 891.256487 \nL 509.24984 881.697866 \nL 513.016716 870.347004 \nL 516.783593 862.580625 \nL 520.55047 859.294849 \nL 524.317346 857.203901 \nL 528.084223 856.905194 \nL 531.8511 858.697435 \nL 535.617976 855.710366 \nL 539.384853 855.112953 \nL 543.15173 856.009073 \nL 546.918607 856.30778 \nL 550.685483 854.216832 \nL 554.45236 854.515539 \nL 558.219237 854.216832 \nL 561.986113 854.216832 \nL 565.75299 853.918125 \nL 569.519867 853.918125 \nL 573.286743 853.918125 \nL 577.05362 853.918125 \nL 580.820497 853.918125 \nL 584.587373 853.918125 \nL 588.35425 854.216832 \nL 592.121127 853.918125 \nL 595.888003 853.918125 \nL 599.65488 853.918125 \nL 603.421757 853.918125 \nL 607.188634 854.216832 \nL 610.95551 854.814246 \nL 614.722387 854.216832 \nL 618.489264 853.918125 \nL 622.25614 853.918125 \nL 626.023017 853.918125 \nL 629.789894 853.918125 \nL 633.55677 854.216832 \nL 637.323647 854.216832 \nL 641.090524 853.918125 \nL 644.8574 854.515539 \nL 648.624277 853.918125 \nL 652.391154 853.918125 \nL 656.15803 853.918125 \nL 659.924907 853.918125 \nL 663.691784 853.918125 \nL 667.458661 853.918125 \nL 671.225537 853.918125 \nL 674.992414 853.918125 \nL 678.759291 853.918125 \nL 682.526167 853.918125 \nL 686.293044 853.918125 \nL 690.059921 853.918125 \nL 693.826797 853.918125 \nL 697.593674 853.918125 \nL 701.360551 853.918125 \nL 705.127427 853.918125 \nL 708.894304 853.918125 \nL 712.661181 853.918125 \nL 716.428057 853.918125 \nL 720.194934 853.918125 \nL 723.961811 853.918125 \nL 727.728688 853.918125 \nL 731.495564 853.918125 \nL 735.262441 853.918125 \nL 739.029318 853.918125 \nL 742.796194 853.918125 \nL 746.563071 853.918125 \nL 750.329948 853.918125 \nL 754.096824 853.918125 \nL 757.863701 853.918125 \nL 761.630578 853.918125 \nL 765.397454 853.918125 \nL 769.164331 853.918125 \nL 772.931208 853.918125 \nL 776.698084 853.918125 \nL 780.464961 853.918125 \nL 784.231838 853.918125 \nL 787.998715 853.918125 \nL 791.765591 853.918125 \nL 795.532468 853.918125 \nL 799.299345 853.918125 \nL 803.066221 853.918125 \nL 806.833098 853.918125 \nL 810.599975 853.918125 \nL 814.366851 853.918125 \nL 818.133728 853.918125 \nL 821.900605 853.918125 \nL 825.667481 853.918125 \nL 829.434358 853.918125 \nL 833.201235 853.918125 \nL 836.968111 853.918125 \nL 840.734988 853.918125 \nL 844.501865 853.918125 \nL 848.268742 853.918125 \nL 852.035618 853.918125 \nL 855.802495 853.918125 \nL 859.569372 853.918125 \nL 863.336248 853.918125 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_356\">\n    <path d=\"M 490.415456 894.542263 \nL 494.182333 890.95778 \nL 497.94921 890.659073 \nL 501.716086 890.360366 \nL 505.482963 890.061659 \nL 509.24984 878.113384 \nL 513.016716 867.957349 \nL 516.783593 860.19097 \nL 520.55047 857.203901 \nL 524.317346 856.009073 \nL 528.084223 855.112953 \nL 531.8511 857.502608 \nL 535.617976 854.814246 \nL 539.384853 854.814246 \nL 543.15173 855.112953 \nL 546.918607 854.814246 \nL 550.685483 854.216832 \nL 554.45236 853.918125 \nL 558.219237 853.918125 \nL 561.986113 854.216832 \nL 565.75299 853.918125 \nL 569.519867 853.918125 \nL 573.286743 853.918125 \nL 577.05362 853.918125 \nL 580.820497 853.918125 \nL 584.587373 853.918125 \nL 588.35425 853.918125 \nL 592.121127 853.918125 \nL 595.888003 853.918125 \nL 599.65488 853.918125 \nL 603.421757 853.918125 \nL 607.188634 853.918125 \nL 610.95551 854.515539 \nL 614.722387 853.918125 \nL 618.489264 853.918125 \nL 622.25614 853.918125 \nL 626.023017 853.918125 \nL 629.789894 853.918125 \nL 633.55677 853.918125 \nL 637.323647 853.918125 \nL 641.090524 853.918125 \nL 644.8574 854.515539 \nL 648.624277 853.918125 \nL 652.391154 853.918125 \nL 656.15803 853.918125 \nL 659.924907 853.918125 \nL 663.691784 853.918125 \nL 667.458661 853.918125 \nL 671.225537 853.918125 \nL 674.992414 853.918125 \nL 678.759291 853.918125 \nL 682.526167 853.918125 \nL 686.293044 853.918125 \nL 690.059921 853.918125 \nL 693.826797 853.918125 \nL 697.593674 853.918125 \nL 701.360551 853.918125 \nL 705.127427 853.918125 \nL 708.894304 853.918125 \nL 712.661181 853.918125 \nL 716.428057 853.918125 \nL 720.194934 853.918125 \nL 723.961811 853.918125 \nL 727.728688 853.918125 \nL 731.495564 853.918125 \nL 735.262441 853.918125 \nL 739.029318 853.918125 \nL 742.796194 853.918125 \nL 746.563071 853.918125 \nL 750.329948 853.918125 \nL 754.096824 853.918125 \nL 757.863701 853.918125 \nL 761.630578 853.918125 \nL 765.397454 853.918125 \nL 769.164331 853.918125 \nL 772.931208 853.918125 \nL 776.698084 853.918125 \nL 780.464961 853.918125 \nL 784.231838 853.918125 \nL 787.998715 853.918125 \nL 791.765591 853.918125 \nL 795.532468 853.918125 \nL 799.299345 853.918125 \nL 803.066221 853.918125 \nL 806.833098 853.918125 \nL 810.599975 853.918125 \nL 814.366851 853.918125 \nL 818.133728 853.918125 \nL 821.900605 853.918125 \nL 825.667481 853.918125 \nL 829.434358 853.918125 \nL 833.201235 853.918125 \nL 836.968111 853.918125 \nL 840.734988 853.918125 \nL 844.501865 853.918125 \nL 848.268742 853.918125 \nL 852.035618 853.918125 \nL 855.802495 853.918125 \nL 859.569372 853.918125 \nL 863.336248 853.918125 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_357\">\n    <path d=\"M 490.415456 696.377503 \nL 494.182333 697.815226 \nL 497.94921 698.640995 \nL 501.716086 701.172788 \nL 505.482963 709.024869 \nL 509.24984 717.533619 \nL 513.016716 721.962062 \nL 516.783593 725.330805 \nL 520.55047 725.763748 \nL 524.317346 726.057002 \nL 528.084223 727.06655 \nL 531.8511 728.868461 \nL 535.617976 727.740466 \nL 539.384853 728.141402 \nL 543.15173 729.553265 \nL 546.918607 729.976568 \nL 550.685483 729.432629 \nL 554.45236 730.576981 \nL 558.219237 730.141933 \nL 561.986113 729.245229 \nL 565.75299 732.254996 \nL 569.519867 732.953098 \nL 573.286743 731.855247 \nL 577.05362 731.703643 \nL 580.820497 732.137635 \nL 584.587373 732.153414 \nL 588.35425 733.313871 \nL 592.121127 732.19555 \nL 595.888003 733.600352 \nL 599.65488 733.380348 \nL 603.421757 733.476644 \nL 607.188634 732.277708 \nL 610.95551 732.675028 \nL 614.722387 733.53838 \nL 618.489264 733.122934 \nL 622.25614 733.415769 \nL 626.023017 734.224669 \nL 629.789894 735.114844 \nL 633.55677 731.347047 \nL 637.323647 734.49918 \nL 641.090524 732.076326 \nL 644.8574 733.960013 \nL 648.624277 733.975099 \nL 652.391154 734.211495 \nL 656.15803 732.789223 \nL 659.924907 733.717088 \nL 663.691784 733.68919 \nL 667.458661 732.228217 \nL 671.225537 734.403858 \nL 674.992414 732.908222 \nL 678.759291 731.695215 \nL 682.526167 734.016845 \nL 686.293044 734.704784 \nL 690.059921 733.287798 \nL 693.826797 733.700305 \nL 697.593674 732.978225 \nL 701.360551 733.483866 \nL 705.127427 732.528386 \nL 708.894304 733.471845 \nL 712.661181 733.318463 \nL 716.428057 733.929821 \nL 720.194934 734.666591 \nL 723.961811 734.173292 \nL 727.728688 734.902531 \nL 731.495564 734.198302 \nL 735.262441 733.142629 \nL 739.029318 733.014659 \nL 742.796194 734.458851 \nL 746.563071 734.505182 \nL 750.329948 735.123608 \nL 754.096824 734.369228 \nL 757.863701 733.819216 \nL 761.630578 733.526984 \nL 765.397454 734.660268 \nL 769.164331 734.130495 \nL 772.931208 734.242883 \nL 776.698084 734.406152 \nL 780.464961 734.28525 \nL 784.231838 733.944369 \nL 787.998715 734.153138 \nL 791.765591 734.780792 \nL 795.532468 734.120843 \nL 799.299345 734.028718 \nL 803.066221 734.236738 \nL 806.833098 734.877187 \nL 810.599975 734.201847 \nL 814.366851 734.692379 \nL 818.133728 734.025939 \nL 821.900605 734.381897 \nL 825.667481 734.314489 \nL 829.434358 734.167899 \nL 833.201235 734.707232 \nL 836.968111 735.202688 \nL 840.734988 734.736733 \nL 844.501865 734.441498 \nL 848.268742 734.322104 \nL 852.035618 734.493587 \nL 855.802495 734.359085 \nL 859.569372 734.471895 \nL 863.336248 734.779348 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_358\">\n    <path d=\"M 490.415456 901.711228 \nL 494.182333 901.711228 \nL 497.94921 901.711228 \nL 501.716086 901.711228 \nL 505.482963 897.72847 \nL 509.24984 885.780194 \nL 513.016716 879.806056 \nL 516.783593 877.814677 \nL 520.55047 869.849159 \nL 524.317346 873.831918 \nL 528.084223 873.831918 \nL 531.8511 869.849159 \nL 535.617976 873.831918 \nL 539.384853 871.840539 \nL 543.15173 871.840539 \nL 546.918607 869.849159 \nL 550.685483 873.831918 \nL 554.45236 869.849159 \nL 558.219237 869.849159 \nL 561.986113 871.840539 \nL 565.75299 867.85778 \nL 569.519867 871.840539 \nL 573.286743 873.831918 \nL 577.05362 867.85778 \nL 580.820497 871.840539 \nL 584.587373 873.831918 \nL 588.35425 875.823297 \nL 592.121127 871.840539 \nL 595.888003 871.840539 \nL 599.65488 871.840539 \nL 603.421757 873.831918 \nL 607.188634 875.823297 \nL 610.95551 871.840539 \nL 614.722387 869.849159 \nL 618.489264 869.849159 \nL 622.25614 871.840539 \nL 626.023017 869.849159 \nL 629.789894 871.840539 \nL 633.55677 881.797435 \nL 637.323647 869.849159 \nL 641.090524 867.85778 \nL 644.8574 871.840539 \nL 648.624277 871.840539 \nL 652.391154 871.840539 \nL 656.15803 869.849159 \nL 659.924907 871.840539 \nL 663.691784 871.840539 \nL 667.458661 873.831918 \nL 671.225537 873.831918 \nL 674.992414 869.849159 \nL 678.759291 869.849159 \nL 682.526167 871.840539 \nL 686.293044 869.849159 \nL 690.059921 867.85778 \nL 693.826797 869.849159 \nL 697.593674 871.840539 \nL 701.360551 871.840539 \nL 705.127427 871.840539 \nL 708.894304 871.840539 \nL 712.661181 869.849159 \nL 716.428057 871.840539 \nL 720.194934 871.840539 \nL 723.961811 867.85778 \nL 727.728688 869.849159 \nL 731.495564 869.849159 \nL 735.262441 869.849159 \nL 739.029318 869.849159 \nL 742.796194 871.840539 \nL 746.563071 871.840539 \nL 750.329948 867.85778 \nL 754.096824 869.849159 \nL 757.863701 869.849159 \nL 761.630578 869.849159 \nL 765.397454 869.849159 \nL 769.164331 867.85778 \nL 772.931208 867.85778 \nL 776.698084 871.840539 \nL 780.464961 867.85778 \nL 784.231838 869.849159 \nL 787.998715 869.849159 \nL 791.765591 869.849159 \nL 795.532468 871.840539 \nL 799.299345 867.85778 \nL 803.066221 871.840539 \nL 806.833098 873.831918 \nL 810.599975 867.85778 \nL 814.366851 869.849159 \nL 818.133728 871.840539 \nL 821.900605 869.849159 \nL 825.667481 869.849159 \nL 829.434358 867.85778 \nL 833.201235 867.85778 \nL 836.968111 867.85778 \nL 840.734988 867.85778 \nL 844.501865 867.85778 \nL 848.268742 867.85778 \nL 852.035618 867.85778 \nL 855.802495 869.849159 \nL 859.569372 867.85778 \nL 863.336248 869.849159 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_359\">\n    <path d=\"M 490.415456 901.711228 \nL 494.182333 901.711228 \nL 497.94921 901.711228 \nL 501.716086 901.711228 \nL 505.482963 893.745711 \nL 509.24984 879.806056 \nL 513.016716 875.823297 \nL 516.783593 871.840539 \nL 520.55047 863.875022 \nL 524.317346 869.849159 \nL 528.084223 869.849159 \nL 531.8511 867.85778 \nL 535.617976 869.849159 \nL 539.384853 867.85778 \nL 543.15173 863.875022 \nL 546.918607 863.875022 \nL 550.685483 867.85778 \nL 554.45236 867.85778 \nL 558.219237 863.875022 \nL 561.986113 865.866401 \nL 565.75299 865.866401 \nL 569.519867 865.866401 \nL 573.286743 859.892263 \nL 577.05362 863.875022 \nL 580.820497 865.866401 \nL 584.587373 871.840539 \nL 588.35425 865.866401 \nL 592.121127 867.85778 \nL 595.888003 867.85778 \nL 599.65488 865.866401 \nL 603.421757 867.85778 \nL 607.188634 873.831918 \nL 610.95551 867.85778 \nL 614.722387 867.85778 \nL 618.489264 865.866401 \nL 622.25614 869.849159 \nL 626.023017 865.866401 \nL 629.789894 865.866401 \nL 633.55677 873.831918 \nL 637.323647 863.875022 \nL 641.090524 863.875022 \nL 644.8574 865.866401 \nL 648.624277 867.85778 \nL 652.391154 867.85778 \nL 656.15803 865.866401 \nL 659.924907 867.85778 \nL 663.691784 869.849159 \nL 667.458661 867.85778 \nL 671.225537 867.85778 \nL 674.992414 865.866401 \nL 678.759291 867.85778 \nL 682.526167 867.85778 \nL 686.293044 863.875022 \nL 690.059921 865.866401 \nL 693.826797 865.866401 \nL 697.593674 865.866401 \nL 701.360551 867.85778 \nL 705.127427 869.849159 \nL 708.894304 869.849159 \nL 712.661181 865.866401 \nL 716.428057 867.85778 \nL 720.194934 863.875022 \nL 723.961811 867.85778 \nL 727.728688 865.866401 \nL 731.495564 867.85778 \nL 735.262441 865.866401 \nL 739.029318 863.875022 \nL 742.796194 867.85778 \nL 746.563071 865.866401 \nL 750.329948 865.866401 \nL 754.096824 867.85778 \nL 757.863701 865.866401 \nL 761.630578 867.85778 \nL 765.397454 865.866401 \nL 769.164331 865.866401 \nL 772.931208 865.866401 \nL 776.698084 867.85778 \nL 780.464961 867.85778 \nL 784.231838 867.85778 \nL 787.998715 867.85778 \nL 791.765591 865.866401 \nL 795.532468 865.866401 \nL 799.299345 865.866401 \nL 803.066221 865.866401 \nL 806.833098 865.866401 \nL 810.599975 867.85778 \nL 814.366851 865.866401 \nL 818.133728 867.85778 \nL 821.900605 865.866401 \nL 825.667481 865.866401 \nL 829.434358 865.866401 \nL 833.201235 865.866401 \nL 836.968111 865.866401 \nL 840.734988 865.866401 \nL 844.501865 865.866401 \nL 848.268742 865.866401 \nL 852.035618 865.866401 \nL 855.802495 865.866401 \nL 859.569372 865.866401 \nL 863.336248 865.866401 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_360\">\n    <path d=\"M 490.415456 897.72847 \nL 494.182333 897.72847 \nL 497.94921 897.72847 \nL 501.716086 897.72847 \nL 505.482963 889.762953 \nL 509.24984 875.823297 \nL 513.016716 871.840539 \nL 516.783593 869.849159 \nL 520.55047 861.883642 \nL 524.317346 865.866401 \nL 528.084223 861.883642 \nL 531.8511 865.866401 \nL 535.617976 863.875022 \nL 539.384853 861.883642 \nL 543.15173 863.875022 \nL 546.918607 857.900884 \nL 550.685483 855.909504 \nL 554.45236 863.875022 \nL 558.219237 863.875022 \nL 561.986113 863.875022 \nL 565.75299 865.866401 \nL 569.519867 861.883642 \nL 573.286743 857.900884 \nL 577.05362 861.883642 \nL 580.820497 863.875022 \nL 584.587373 867.85778 \nL 588.35425 863.875022 \nL 592.121127 863.875022 \nL 595.888003 863.875022 \nL 599.65488 863.875022 \nL 603.421757 863.875022 \nL 607.188634 869.849159 \nL 610.95551 863.875022 \nL 614.722387 863.875022 \nL 618.489264 863.875022 \nL 622.25614 867.85778 \nL 626.023017 865.866401 \nL 629.789894 861.883642 \nL 633.55677 871.840539 \nL 637.323647 863.875022 \nL 641.090524 861.883642 \nL 644.8574 863.875022 \nL 648.624277 863.875022 \nL 652.391154 865.866401 \nL 656.15803 863.875022 \nL 659.924907 863.875022 \nL 663.691784 865.866401 \nL 667.458661 867.85778 \nL 671.225537 863.875022 \nL 674.992414 863.875022 \nL 678.759291 867.85778 \nL 682.526167 863.875022 \nL 686.293044 861.883642 \nL 690.059921 863.875022 \nL 693.826797 861.883642 \nL 697.593674 861.883642 \nL 701.360551 863.875022 \nL 705.127427 865.866401 \nL 708.894304 863.875022 \nL 712.661181 865.866401 \nL 716.428057 861.883642 \nL 720.194934 859.892263 \nL 723.961811 861.883642 \nL 727.728688 863.875022 \nL 731.495564 863.875022 \nL 735.262441 863.875022 \nL 739.029318 861.883642 \nL 742.796194 861.883642 \nL 746.563071 861.883642 \nL 750.329948 863.875022 \nL 754.096824 859.892263 \nL 757.863701 861.883642 \nL 761.630578 863.875022 \nL 765.397454 861.883642 \nL 769.164331 863.875022 \nL 772.931208 861.883642 \nL 776.698084 861.883642 \nL 780.464961 861.883642 \nL 784.231838 861.883642 \nL 787.998715 861.883642 \nL 791.765591 861.883642 \nL 795.532468 861.883642 \nL 799.299345 861.883642 \nL 803.066221 861.883642 \nL 806.833098 861.883642 \nL 810.599975 861.883642 \nL 814.366851 861.883642 \nL 818.133728 861.883642 \nL 821.900605 863.875022 \nL 825.667481 861.883642 \nL 829.434358 861.883642 \nL 833.201235 861.883642 \nL 836.968111 861.883642 \nL 840.734988 861.883642 \nL 844.501865 861.883642 \nL 848.268742 861.883642 \nL 852.035618 861.883642 \nL 855.802495 861.883642 \nL 859.569372 865.866401 \nL 863.336248 861.883642 \n\" clip-path=\"url(#p2894dc4dff)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 486.64858 901.711228 \nL 486.64858 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 867.103125 901.711228 \nL 867.103125 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_47\">\n    <path d=\"M 486.64858 901.711228 \nL 867.103125 901.711228 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_48\">\n    <path d=\"M 486.64858 710.538815 \nL 867.103125 710.538815 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_192\">\n    <!-- Training result when p = 800 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(590.20679 704.538815)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_8\">\n    <g id=\"patch_49\">\n     <path d=\"M 493.64858 835.963815 \nL 606.432955 835.963815 \nQ 608.432955 835.963815 608.432955 833.963815 \nL 608.432955 717.538815 \nQ 608.432955 715.538815 606.432955 715.538815 \nL 493.64858 715.538815 \nQ 491.64858 715.538815 491.64858 717.538815 \nL 491.64858 833.963815 \nQ 491.64858 835.963815 493.64858 835.963815 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_361\">\n     <path d=\"M 495.64858 723.637252 \nL 505.64858 723.637252 \nL 515.64858 723.637252 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_193\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 727.137252)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_362\">\n     <path d=\"M 495.64858 738.315377 \nL 505.64858 738.315377 \nL 515.64858 738.315377 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_194\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 741.815377)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_363\">\n     <path d=\"M 495.64858 752.993502 \nL 505.64858 752.993502 \nL 515.64858 752.993502 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_195\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 756.493502)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_364\">\n     <path d=\"M 495.64858 767.671627 \nL 505.64858 767.671627 \nL 515.64858 767.671627 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_196\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 771.171627)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_365\">\n     <path d=\"M 495.64858 782.349752 \nL 505.64858 782.349752 \nL 515.64858 782.349752 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_197\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 785.849752)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_366\">\n     <path d=\"M 495.64858 797.027877 \nL 505.64858 797.027877 \nL 515.64858 797.027877 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_198\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 800.527877)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_367\">\n     <path d=\"M 495.64858 811.706002 \nL 505.64858 811.706002 \nL 515.64858 811.706002 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_199\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 815.206002)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_368\">\n     <path d=\"M 495.64858 826.384127 \nL 505.64858 826.384127 \nL 515.64858 826.384127 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_200\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 829.884127)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_9\">\n   <g id=\"patch_50\">\n    <path d=\"M 30.103125 1131.118125 \nL 410.55767 1131.118125 \nL 410.55767 939.945711 \nL 30.103125 939.945711 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_17\">\n    <g id=\"xtick_49\">\n     <g id=\"line2d_369\">\n      <path d=\"M 30.103125 1131.118125 \nL 30.103125 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_370\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"30.103125\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_201\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(26.921875 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_371\">\n      <path d=\"M 105.440659 1131.118125 \nL 105.440659 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_372\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"105.440659\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_202\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(99.078159 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_51\">\n     <g id=\"line2d_373\">\n      <path d=\"M 180.778193 1131.118125 \nL 180.778193 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_374\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"180.778193\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_203\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(174.415693 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_52\">\n     <g id=\"line2d_375\">\n      <path d=\"M 256.115726 1131.118125 \nL 256.115726 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_376\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"256.115726\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_204\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(249.753226 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_53\">\n     <g id=\"line2d_377\">\n      <path d=\"M 331.45326 1131.118125 \nL 331.45326 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_378\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"331.45326\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_205\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(325.09076 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_54\">\n     <g id=\"line2d_379\">\n      <path d=\"M 406.790794 1131.118125 \nL 406.790794 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_380\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"406.790794\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_206\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(397.247044 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_207\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(202.414773 1159.394688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_18\">\n    <g id=\"ytick_73\">\n     <g id=\"line2d_381\">\n      <path d=\"M 30.103125 1131.118125 \nL 410.55767 1131.118125 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_382\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_208\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1134.917344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_74\">\n     <g id=\"line2d_383\">\n      <path d=\"M 30.103125 1107.221573 \nL 410.55767 1107.221573 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_384\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1107.221573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_209\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1111.020792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_75\">\n     <g id=\"line2d_385\">\n      <path d=\"M 30.103125 1083.325022 \nL 410.55767 1083.325022 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_386\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1083.325022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_210\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1087.12424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_76\">\n     <g id=\"line2d_387\">\n      <path d=\"M 30.103125 1059.42847 \nL 410.55767 1059.42847 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_388\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1059.42847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_211\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1063.227689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_77\">\n     <g id=\"line2d_389\">\n      <path d=\"M 30.103125 1035.531918 \nL 410.55767 1035.531918 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_390\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1035.531918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_212\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1039.331137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_78\">\n     <g id=\"line2d_391\">\n      <path d=\"M 30.103125 1011.635366 \nL 410.55767 1011.635366 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_392\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"1011.635366\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_213\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 1015.434585)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_79\">\n     <g id=\"line2d_393\">\n      <path d=\"M 30.103125 987.738815 \nL 410.55767 987.738815 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_394\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"987.738815\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_214\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 991.538033)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_80\">\n     <g id=\"line2d_395\">\n      <path d=\"M 30.103125 963.842263 \nL 410.55767 963.842263 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_396\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"963.842263\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_215\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 967.641482)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_81\">\n     <g id=\"line2d_397\">\n      <path d=\"M 30.103125 939.945711 \nL 410.55767 939.945711 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_398\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"30.103125\" y=\"939.945711\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_216\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(7.2 943.74493)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_399\">\n    <path d=\"M 33.870002 943.582884 \nL 37.636878 933.986567 \nL 41.403755 936.518896 \nL 45.170632 942.024364 \nL 48.937508 946.853584 \nL 52.704385 951.090861 \nL 56.471262 954.364161 \nL 60.238139 957.780051 \nL 64.005015 960.633586 \nL 67.771892 962.750604 \nL 71.538769 964.955261 \nL 75.305645 966.448426 \nL 79.072522 967.853779 \nL 82.839399 969.394953 \nL 86.606275 970.656514 \nL 90.373152 971.585169 \nL 94.140029 973.018075 \nL 97.906905 973.509231 \nL 101.673782 974.275186 \nL 105.440659 975.480888 \nL 109.207535 975.304408 \nL 112.974412 976.74445 \nL 116.741289 977.274131 \nL 120.508166 977.180268 \nL 124.275042 976.838902 \nL 128.041919 977.623304 \nL 131.808796 978.25071 \nL 135.575672 978.358017 \nL 139.342549 978.135469 \nL 143.109426 977.949491 \nL 146.876302 979.240426 \nL 150.643179 979.112948 \nL 154.410056 978.334365 \nL 158.176932 979.928676 \nL 161.943809 979.648018 \nL 165.710686 978.84496 \nL 169.477562 980.243477 \nL 173.244439 980.428061 \nL 177.011316 979.388114 \nL 180.778193 980.21684 \nL 184.545069 979.618534 \nL 188.311946 981.538208 \nL 192.078823 981.472418 \nL 195.845699 981.533195 \nL 199.612576 980.671709 \nL 203.379453 981.243203 \nL 207.146329 981.014683 \nL 210.913206 980.605691 \nL 214.680083 982.03176 \nL 218.446959 982.119684 \nL 222.213836 982.252135 \nL 225.980713 982.011047 \nL 229.747589 981.278292 \nL 233.514466 981.944983 \nL 237.281343 982.361553 \nL 241.04822 983.021865 \nL 244.815096 982.505082 \nL 248.581973 982.309002 \nL 252.34885 982.961228 \nL 256.115726 983.161739 \nL 259.882603 982.760038 \nL 263.64948 983.441034 \nL 267.416356 982.845456 \nL 271.183233 982.575515 \nL 274.95011 983.469063 \nL 278.716986 983.605035 \nL 282.483863 983.157929 \nL 286.25074 983.14661 \nL 290.017616 984.159215 \nL 293.784493 983.099312 \nL 297.55137 984.066369 \nL 301.318247 984.198038 \nL 305.085123 983.467696 \nL 308.852 983.822523 \nL 312.618877 982.873752 \nL 316.385753 983.939974 \nL 320.15263 984.288037 \nL 323.919507 983.78658 \nL 327.686383 983.799735 \nL 331.45326 984.393477 \nL 335.220137 983.773677 \nL 338.987013 984.010704 \nL 342.75389 982.708134 \nL 346.520767 983.985456 \nL 350.287643 983.993376 \nL 354.05452 984.035336 \nL 357.821397 984.746021 \nL 361.588274 983.830976 \nL 365.35515 984.591035 \nL 369.122027 983.343599 \nL 372.888904 983.533797 \nL 376.65578 984.046655 \nL 380.422657 984.374108 \nL 384.189534 984.131709 \nL 387.95641 984.160997 \nL 391.723287 984.747132 \nL 395.490164 984.251933 \nL 399.25704 983.405588 \nL 403.023917 983.290489 \nL 406.790794 983.565548 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_400\">\n    <path d=\"M 33.870002 1124.84528 \nL 37.636878 1125.442694 \nL 41.403755 1125.741401 \nL 45.170632 1125.442694 \nL 48.937508 1125.442694 \nL 52.704385 1118.572435 \nL 56.471262 1105.130625 \nL 60.238139 1098.260366 \nL 64.005015 1094.07847 \nL 67.771892 1091.688815 \nL 71.538769 1091.688815 \nL 75.305645 1088.403039 \nL 79.072522 1087.805625 \nL 82.839399 1086.610797 \nL 86.606275 1087.805625 \nL 90.373152 1086.610797 \nL 94.140029 1085.41597 \nL 97.906905 1085.117263 \nL 101.673782 1086.013384 \nL 105.440659 1084.519849 \nL 109.207535 1083.623728 \nL 112.974412 1084.221142 \nL 116.741289 1085.41597 \nL 120.508166 1086.909504 \nL 124.275042 1085.41597 \nL 128.041919 1084.818556 \nL 131.808796 1085.117263 \nL 135.575672 1086.312091 \nL 139.342549 1085.41597 \nL 143.109426 1089.299159 \nL 146.876302 1086.610797 \nL 150.643179 1086.312091 \nL 154.410056 1087.208211 \nL 158.176932 1085.117263 \nL 161.943809 1084.519849 \nL 165.710686 1084.818556 \nL 169.477562 1083.623728 \nL 173.244439 1083.922435 \nL 177.011316 1085.714677 \nL 180.778193 1085.117263 \nL 184.545069 1083.623728 \nL 188.311946 1083.325022 \nL 192.078823 1083.623728 \nL 195.845699 1083.325022 \nL 199.612576 1083.623728 \nL 203.379453 1083.623728 \nL 207.146329 1083.623728 \nL 210.913206 1083.623728 \nL 214.680083 1084.221142 \nL 218.446959 1083.922435 \nL 222.213836 1083.623728 \nL 225.980713 1083.623728 \nL 229.747589 1083.623728 \nL 233.514466 1083.325022 \nL 237.281343 1083.325022 \nL 241.04822 1083.325022 \nL 244.815096 1083.325022 \nL 248.581973 1083.325022 \nL 252.34885 1083.325022 \nL 256.115726 1083.325022 \nL 259.882603 1083.325022 \nL 263.64948 1083.325022 \nL 267.416356 1083.325022 \nL 271.183233 1083.325022 \nL 274.95011 1083.325022 \nL 278.716986 1083.325022 \nL 282.483863 1083.325022 \nL 286.25074 1083.325022 \nL 290.017616 1083.325022 \nL 293.784493 1083.325022 \nL 297.55137 1083.325022 \nL 301.318247 1083.325022 \nL 305.085123 1083.325022 \nL 308.852 1083.325022 \nL 312.618877 1083.325022 \nL 316.385753 1083.325022 \nL 320.15263 1083.325022 \nL 323.919507 1083.325022 \nL 327.686383 1083.325022 \nL 331.45326 1083.325022 \nL 335.220137 1083.325022 \nL 338.987013 1083.325022 \nL 342.75389 1083.325022 \nL 346.520767 1083.325022 \nL 350.287643 1083.325022 \nL 354.05452 1083.325022 \nL 357.821397 1083.325022 \nL 361.588274 1083.325022 \nL 365.35515 1083.325022 \nL 369.122027 1083.325022 \nL 372.888904 1083.325022 \nL 376.65578 1083.325022 \nL 380.422657 1083.325022 \nL 384.189534 1083.325022 \nL 387.95641 1083.325022 \nL 391.723287 1083.325022 \nL 395.490164 1083.325022 \nL 399.25704 1083.325022 \nL 403.023917 1083.325022 \nL 406.790794 1083.325022 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_401\">\n    <path d=\"M 33.870002 1122.455625 \nL 37.636878 1121.559504 \nL 41.403755 1122.156918 \nL 45.170632 1122.754332 \nL 48.937508 1122.455625 \nL 52.704385 1113.494418 \nL 56.471262 1098.260366 \nL 60.238139 1092.584935 \nL 64.005015 1087.506918 \nL 67.771892 1086.610797 \nL 71.538769 1086.013384 \nL 75.305645 1085.117263 \nL 79.072522 1083.922435 \nL 82.839399 1084.221142 \nL 86.606275 1084.221142 \nL 90.373152 1083.922435 \nL 94.140029 1083.623728 \nL 97.906905 1083.922435 \nL 101.673782 1083.325022 \nL 105.440659 1083.325022 \nL 109.207535 1083.325022 \nL 112.974412 1083.325022 \nL 116.741289 1083.325022 \nL 120.508166 1083.922435 \nL 124.275042 1083.325022 \nL 128.041919 1083.325022 \nL 131.808796 1083.325022 \nL 135.575672 1083.623728 \nL 139.342549 1084.519849 \nL 143.109426 1085.41597 \nL 146.876302 1083.623728 \nL 150.643179 1084.818556 \nL 154.410056 1085.714677 \nL 158.176932 1084.221142 \nL 161.943809 1083.325022 \nL 165.710686 1083.623728 \nL 169.477562 1083.325022 \nL 173.244439 1083.325022 \nL 177.011316 1084.221142 \nL 180.778193 1083.922435 \nL 184.545069 1083.325022 \nL 188.311946 1083.325022 \nL 192.078823 1083.325022 \nL 195.845699 1083.325022 \nL 199.612576 1083.325022 \nL 203.379453 1083.325022 \nL 207.146329 1083.325022 \nL 210.913206 1083.325022 \nL 214.680083 1083.325022 \nL 218.446959 1083.325022 \nL 222.213836 1083.325022 \nL 225.980713 1083.325022 \nL 229.747589 1083.325022 \nL 233.514466 1083.325022 \nL 237.281343 1083.325022 \nL 241.04822 1083.325022 \nL 244.815096 1083.325022 \nL 248.581973 1083.325022 \nL 252.34885 1083.325022 \nL 256.115726 1083.325022 \nL 259.882603 1083.325022 \nL 263.64948 1083.325022 \nL 267.416356 1083.325022 \nL 271.183233 1083.325022 \nL 274.95011 1083.325022 \nL 278.716986 1083.325022 \nL 282.483863 1083.325022 \nL 286.25074 1083.325022 \nL 290.017616 1083.325022 \nL 293.784493 1083.325022 \nL 297.55137 1083.325022 \nL 301.318247 1083.325022 \nL 305.085123 1083.325022 \nL 308.852 1083.325022 \nL 312.618877 1083.325022 \nL 316.385753 1083.325022 \nL 320.15263 1083.325022 \nL 323.919507 1083.325022 \nL 327.686383 1083.325022 \nL 331.45326 1083.325022 \nL 335.220137 1083.325022 \nL 338.987013 1083.325022 \nL 342.75389 1083.325022 \nL 346.520767 1083.325022 \nL 350.287643 1083.325022 \nL 354.05452 1083.325022 \nL 357.821397 1083.325022 \nL 361.588274 1083.325022 \nL 365.35515 1083.325022 \nL 369.122027 1083.325022 \nL 372.888904 1083.325022 \nL 376.65578 1083.325022 \nL 380.422657 1083.325022 \nL 384.189534 1083.325022 \nL 387.95641 1083.325022 \nL 391.723287 1083.325022 \nL 395.490164 1083.325022 \nL 399.25704 1083.325022 \nL 403.023917 1083.325022 \nL 406.790794 1083.325022 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_402\">\n    <path d=\"M 33.870002 1119.767263 \nL 37.636878 1119.767263 \nL 41.403755 1120.06597 \nL 45.170632 1120.364677 \nL 48.937508 1121.260797 \nL 52.704385 1110.208642 \nL 56.471262 1095.870711 \nL 60.238139 1089.299159 \nL 64.005015 1084.818556 \nL 67.771892 1084.519849 \nL 71.538769 1085.41597 \nL 75.305645 1084.818556 \nL 79.072522 1083.623728 \nL 82.839399 1083.922435 \nL 86.606275 1084.221142 \nL 90.373152 1083.623728 \nL 94.140029 1083.623728 \nL 97.906905 1083.623728 \nL 101.673782 1083.325022 \nL 105.440659 1083.325022 \nL 109.207535 1083.325022 \nL 112.974412 1083.325022 \nL 116.741289 1083.325022 \nL 120.508166 1083.325022 \nL 124.275042 1083.325022 \nL 128.041919 1083.325022 \nL 131.808796 1083.325022 \nL 135.575672 1083.325022 \nL 139.342549 1083.922435 \nL 143.109426 1085.117263 \nL 146.876302 1083.325022 \nL 150.643179 1083.623728 \nL 154.410056 1084.519849 \nL 158.176932 1083.623728 \nL 161.943809 1083.325022 \nL 165.710686 1083.623728 \nL 169.477562 1083.325022 \nL 173.244439 1083.325022 \nL 177.011316 1083.922435 \nL 180.778193 1083.623728 \nL 184.545069 1083.325022 \nL 188.311946 1083.325022 \nL 192.078823 1083.325022 \nL 195.845699 1083.325022 \nL 199.612576 1083.325022 \nL 203.379453 1083.325022 \nL 207.146329 1083.325022 \nL 210.913206 1083.325022 \nL 214.680083 1083.325022 \nL 218.446959 1083.325022 \nL 222.213836 1083.325022 \nL 225.980713 1083.325022 \nL 229.747589 1083.325022 \nL 233.514466 1083.325022 \nL 237.281343 1083.325022 \nL 241.04822 1083.325022 \nL 244.815096 1083.325022 \nL 248.581973 1083.325022 \nL 252.34885 1083.325022 \nL 256.115726 1083.325022 \nL 259.882603 1083.325022 \nL 263.64948 1083.325022 \nL 267.416356 1083.325022 \nL 271.183233 1083.325022 \nL 274.95011 1083.325022 \nL 278.716986 1083.325022 \nL 282.483863 1083.325022 \nL 286.25074 1083.325022 \nL 290.017616 1083.325022 \nL 293.784493 1083.325022 \nL 297.55137 1083.325022 \nL 301.318247 1083.325022 \nL 305.085123 1083.325022 \nL 308.852 1083.325022 \nL 312.618877 1083.325022 \nL 316.385753 1083.325022 \nL 320.15263 1083.325022 \nL 323.919507 1083.325022 \nL 327.686383 1083.325022 \nL 331.45326 1083.325022 \nL 335.220137 1083.325022 \nL 338.987013 1083.325022 \nL 342.75389 1083.325022 \nL 346.520767 1083.325022 \nL 350.287643 1083.325022 \nL 354.05452 1083.325022 \nL 357.821397 1083.325022 \nL 361.588274 1083.325022 \nL 365.35515 1083.325022 \nL 369.122027 1083.325022 \nL 372.888904 1083.325022 \nL 376.65578 1083.325022 \nL 380.422657 1083.325022 \nL 384.189534 1083.325022 \nL 387.95641 1083.325022 \nL 391.723287 1083.325022 \nL 395.490164 1083.325022 \nL 399.25704 1083.325022 \nL 403.023917 1083.325022 \nL 406.790794 1083.325022 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_403\">\n    <path d=\"M 33.870002 925.481543 \nL 37.636878 927.93995 \nL 41.403755 929.366096 \nL 45.170632 932.614721 \nL 48.937508 939.36945 \nL 52.704385 947.419569 \nL 56.471262 950.280117 \nL 60.238139 952.39976 \nL 64.005015 953.195162 \nL 67.771892 953.494204 \nL 71.538769 955.60548 \nL 75.305645 957.536694 \nL 79.072522 957.541855 \nL 82.839399 956.766914 \nL 86.606275 958.966033 \nL 90.373152 958.80307 \nL 94.140029 958.37848 \nL 97.906905 959.791706 \nL 101.673782 959.514104 \nL 105.440659 960.338964 \nL 109.207535 960.626638 \nL 112.974412 961.497235 \nL 116.741289 959.316717 \nL 120.508166 959.144482 \nL 124.275042 959.007222 \nL 128.041919 959.695305 \nL 131.808796 962.958275 \nL 135.575672 960.392262 \nL 139.342549 957.837226 \nL 143.109426 958.538671 \nL 146.876302 962.085633 \nL 150.643179 962.429688 \nL 154.410056 959.672829 \nL 158.176932 961.178437 \nL 161.943809 961.935675 \nL 165.710686 961.335584 \nL 169.477562 962.435714 \nL 173.244439 960.814777 \nL 177.011316 960.689501 \nL 180.778193 962.216113 \nL 184.545069 962.410332 \nL 188.311946 962.29258 \nL 192.078823 961.679652 \nL 195.845699 962.47747 \nL 199.612576 962.499016 \nL 203.379453 961.509441 \nL 207.146329 961.795771 \nL 210.913206 962.262722 \nL 214.680083 962.873781 \nL 218.446959 962.334894 \nL 222.213836 961.258985 \nL 225.980713 961.123676 \nL 229.747589 963.066857 \nL 233.514466 964.703787 \nL 237.281343 963.996636 \nL 241.04822 963.553601 \nL 244.815096 964.576156 \nL 248.581973 962.510243 \nL 252.34885 964.596598 \nL 256.115726 963.542807 \nL 259.882603 963.538856 \nL 263.64948 964.014815 \nL 267.416356 963.101981 \nL 271.183233 963.679958 \nL 274.95011 964.184174 \nL 278.716986 962.881209 \nL 282.483863 962.102779 \nL 286.25074 962.700998 \nL 290.017616 963.957913 \nL 293.784493 963.500065 \nL 297.55137 963.198358 \nL 301.318247 963.270788 \nL 305.085123 963.466861 \nL 308.852 963.98341 \nL 312.618877 963.393946 \nL 316.385753 963.709602 \nL 320.15263 963.965492 \nL 323.919507 963.623776 \nL 327.686383 964.047416 \nL 331.45326 963.849569 \nL 335.220137 963.819001 \nL 338.987013 963.667264 \nL 342.75389 963.28766 \nL 346.520767 963.094431 \nL 350.287643 963.451667 \nL 354.05452 963.680347 \nL 357.821397 963.866306 \nL 361.588274 963.126862 \nL 365.35515 964.47601 \nL 369.122027 963.537761 \nL 372.888904 963.855414 \nL 376.65578 963.407346 \nL 380.422657 962.898913 \nL 384.189534 963.868743 \nL 387.95641 964.097872 \nL 391.723287 963.541669 \nL 395.490164 963.566148 \nL 399.25704 963.899627 \nL 403.023917 963.486846 \nL 406.790794 963.286441 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_404\">\n    <path d=\"M 33.870002 1131.118125 \nL 37.636878 1131.118125 \nL 41.403755 1131.118125 \nL 45.170632 1131.118125 \nL 48.937508 1129.126746 \nL 52.704385 1113.195711 \nL 56.471262 1111.204332 \nL 60.238139 1107.221573 \nL 64.005015 1099.256056 \nL 67.771892 1097.264677 \nL 71.538769 1105.230194 \nL 75.305645 1105.230194 \nL 79.072522 1099.256056 \nL 82.839399 1099.256056 \nL 86.606275 1103.238815 \nL 90.373152 1099.256056 \nL 94.140029 1099.256056 \nL 97.906905 1103.238815 \nL 101.673782 1095.273297 \nL 105.440659 1099.256056 \nL 109.207535 1097.264677 \nL 112.974412 1099.256056 \nL 116.741289 1101.247435 \nL 120.508166 1103.238815 \nL 124.275042 1097.264677 \nL 128.041919 1099.256056 \nL 131.808796 1097.264677 \nL 135.575672 1109.212953 \nL 139.342549 1099.256056 \nL 143.109426 1107.221573 \nL 146.876302 1101.247435 \nL 150.643179 1107.221573 \nL 154.410056 1101.247435 \nL 158.176932 1097.264677 \nL 161.943809 1101.247435 \nL 165.710686 1105.230194 \nL 169.477562 1101.247435 \nL 173.244439 1105.230194 \nL 177.011316 1105.230194 \nL 180.778193 1099.256056 \nL 184.545069 1103.238815 \nL 188.311946 1103.238815 \nL 192.078823 1099.256056 \nL 195.845699 1099.256056 \nL 199.612576 1103.238815 \nL 203.379453 1099.256056 \nL 207.146329 1099.256056 \nL 210.913206 1099.256056 \nL 214.680083 1101.247435 \nL 218.446959 1099.256056 \nL 222.213836 1099.256056 \nL 225.980713 1101.247435 \nL 229.747589 1099.256056 \nL 233.514466 1099.256056 \nL 237.281343 1099.256056 \nL 241.04822 1099.256056 \nL 244.815096 1101.247435 \nL 248.581973 1099.256056 \nL 252.34885 1101.247435 \nL 256.115726 1099.256056 \nL 259.882603 1101.247435 \nL 263.64948 1101.247435 \nL 267.416356 1101.247435 \nL 271.183233 1101.247435 \nL 274.95011 1101.247435 \nL 278.716986 1101.247435 \nL 282.483863 1101.247435 \nL 286.25074 1101.247435 \nL 290.017616 1101.247435 \nL 293.784493 1101.247435 \nL 297.55137 1101.247435 \nL 301.318247 1099.256056 \nL 305.085123 1101.247435 \nL 308.852 1101.247435 \nL 312.618877 1101.247435 \nL 316.385753 1101.247435 \nL 320.15263 1101.247435 \nL 323.919507 1101.247435 \nL 327.686383 1101.247435 \nL 331.45326 1101.247435 \nL 335.220137 1101.247435 \nL 338.987013 1101.247435 \nL 342.75389 1101.247435 \nL 346.520767 1103.238815 \nL 350.287643 1101.247435 \nL 354.05452 1101.247435 \nL 357.821397 1101.247435 \nL 361.588274 1101.247435 \nL 365.35515 1101.247435 \nL 369.122027 1101.247435 \nL 372.888904 1101.247435 \nL 376.65578 1101.247435 \nL 380.422657 1101.247435 \nL 384.189534 1101.247435 \nL 387.95641 1101.247435 \nL 391.723287 1101.247435 \nL 395.490164 1101.247435 \nL 399.25704 1101.247435 \nL 403.023917 1101.247435 \nL 406.790794 1101.247435 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_405\">\n    <path d=\"M 33.870002 1131.118125 \nL 37.636878 1131.118125 \nL 41.403755 1131.118125 \nL 45.170632 1131.118125 \nL 48.937508 1127.135366 \nL 52.704385 1111.204332 \nL 56.471262 1107.221573 \nL 60.238139 1097.264677 \nL 64.005015 1095.273297 \nL 67.771892 1097.264677 \nL 71.538769 1101.247435 \nL 75.305645 1099.256056 \nL 79.072522 1095.273297 \nL 82.839399 1095.273297 \nL 86.606275 1097.264677 \nL 90.373152 1095.273297 \nL 94.140029 1097.264677 \nL 97.906905 1099.256056 \nL 101.673782 1093.281918 \nL 105.440659 1099.256056 \nL 109.207535 1095.273297 \nL 112.974412 1099.256056 \nL 116.741289 1095.273297 \nL 120.508166 1099.256056 \nL 124.275042 1097.264677 \nL 128.041919 1097.264677 \nL 131.808796 1095.273297 \nL 135.575672 1105.230194 \nL 139.342549 1097.264677 \nL 143.109426 1103.238815 \nL 146.876302 1097.264677 \nL 150.643179 1093.281918 \nL 154.410056 1095.273297 \nL 158.176932 1095.273297 \nL 161.943809 1097.264677 \nL 165.710686 1101.247435 \nL 169.477562 1099.256056 \nL 173.244439 1099.256056 \nL 177.011316 1101.247435 \nL 180.778193 1097.264677 \nL 184.545069 1099.256056 \nL 188.311946 1099.256056 \nL 192.078823 1099.256056 \nL 195.845699 1099.256056 \nL 199.612576 1101.247435 \nL 203.379453 1099.256056 \nL 207.146329 1099.256056 \nL 210.913206 1099.256056 \nL 214.680083 1099.256056 \nL 218.446959 1099.256056 \nL 222.213836 1099.256056 \nL 225.980713 1101.247435 \nL 229.747589 1097.264677 \nL 233.514466 1099.256056 \nL 237.281343 1095.273297 \nL 241.04822 1097.264677 \nL 244.815096 1097.264677 \nL 248.581973 1095.273297 \nL 252.34885 1101.247435 \nL 256.115726 1099.256056 \nL 259.882603 1099.256056 \nL 263.64948 1101.247435 \nL 267.416356 1099.256056 \nL 271.183233 1101.247435 \nL 274.95011 1101.247435 \nL 278.716986 1099.256056 \nL 282.483863 1099.256056 \nL 286.25074 1101.247435 \nL 290.017616 1101.247435 \nL 293.784493 1101.247435 \nL 297.55137 1101.247435 \nL 301.318247 1099.256056 \nL 305.085123 1101.247435 \nL 308.852 1099.256056 \nL 312.618877 1099.256056 \nL 316.385753 1101.247435 \nL 320.15263 1099.256056 \nL 323.919507 1101.247435 \nL 327.686383 1101.247435 \nL 331.45326 1099.256056 \nL 335.220137 1099.256056 \nL 338.987013 1099.256056 \nL 342.75389 1099.256056 \nL 346.520767 1099.256056 \nL 350.287643 1099.256056 \nL 354.05452 1101.247435 \nL 357.821397 1101.247435 \nL 361.588274 1099.256056 \nL 365.35515 1099.256056 \nL 369.122027 1099.256056 \nL 372.888904 1099.256056 \nL 376.65578 1099.256056 \nL 380.422657 1099.256056 \nL 384.189534 1099.256056 \nL 387.95641 1099.256056 \nL 391.723287 1099.256056 \nL 395.490164 1097.264677 \nL 399.25704 1099.256056 \nL 403.023917 1099.256056 \nL 406.790794 1099.256056 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_406\">\n    <path d=\"M 33.870002 1127.135366 \nL 37.636878 1127.135366 \nL 41.403755 1127.135366 \nL 45.170632 1131.118125 \nL 48.937508 1123.152608 \nL 52.704385 1111.204332 \nL 56.471262 1103.238815 \nL 60.238139 1093.281918 \nL 64.005015 1089.299159 \nL 67.771892 1093.281918 \nL 71.538769 1093.281918 \nL 75.305645 1095.273297 \nL 79.072522 1093.281918 \nL 82.839399 1095.273297 \nL 86.606275 1091.290539 \nL 90.373152 1093.281918 \nL 94.140029 1095.273297 \nL 97.906905 1099.256056 \nL 101.673782 1093.281918 \nL 105.440659 1099.256056 \nL 109.207535 1093.281918 \nL 112.974412 1099.256056 \nL 116.741289 1093.281918 \nL 120.508166 1097.264677 \nL 124.275042 1095.273297 \nL 128.041919 1095.273297 \nL 131.808796 1095.273297 \nL 135.575672 1101.247435 \nL 139.342549 1095.273297 \nL 143.109426 1101.247435 \nL 146.876302 1093.281918 \nL 150.643179 1093.281918 \nL 154.410056 1093.281918 \nL 158.176932 1091.290539 \nL 161.943809 1095.273297 \nL 165.710686 1097.264677 \nL 169.477562 1099.256056 \nL 173.244439 1095.273297 \nL 177.011316 1095.273297 \nL 180.778193 1093.281918 \nL 184.545069 1097.264677 \nL 188.311946 1093.281918 \nL 192.078823 1095.273297 \nL 195.845699 1093.281918 \nL 199.612576 1095.273297 \nL 203.379453 1095.273297 \nL 207.146329 1097.264677 \nL 210.913206 1097.264677 \nL 214.680083 1093.281918 \nL 218.446959 1095.273297 \nL 222.213836 1095.273297 \nL 225.980713 1097.264677 \nL 229.747589 1095.273297 \nL 233.514466 1095.273297 \nL 237.281343 1091.290539 \nL 241.04822 1095.273297 \nL 244.815096 1095.273297 \nL 248.581973 1093.281918 \nL 252.34885 1095.273297 \nL 256.115726 1093.281918 \nL 259.882603 1095.273297 \nL 263.64948 1095.273297 \nL 267.416356 1097.264677 \nL 271.183233 1095.273297 \nL 274.95011 1095.273297 \nL 278.716986 1095.273297 \nL 282.483863 1097.264677 \nL 286.25074 1099.256056 \nL 290.017616 1099.256056 \nL 293.784493 1097.264677 \nL 297.55137 1097.264677 \nL 301.318247 1097.264677 \nL 305.085123 1093.281918 \nL 308.852 1093.281918 \nL 312.618877 1095.273297 \nL 316.385753 1097.264677 \nL 320.15263 1097.264677 \nL 323.919507 1097.264677 \nL 327.686383 1097.264677 \nL 331.45326 1097.264677 \nL 335.220137 1099.256056 \nL 338.987013 1097.264677 \nL 342.75389 1097.264677 \nL 346.520767 1095.273297 \nL 350.287643 1097.264677 \nL 354.05452 1095.273297 \nL 357.821397 1095.273297 \nL 361.588274 1097.264677 \nL 365.35515 1095.273297 \nL 369.122027 1095.273297 \nL 372.888904 1095.273297 \nL 376.65578 1097.264677 \nL 380.422657 1093.281918 \nL 384.189534 1093.281918 \nL 387.95641 1095.273297 \nL 391.723287 1099.256056 \nL 395.490164 1097.264677 \nL 399.25704 1095.273297 \nL 403.023917 1095.273297 \nL 406.790794 1095.273297 \n\" clip-path=\"url(#paf85ef470a)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 30.103125 1131.118125 \nL 30.103125 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 410.55767 1131.118125 \nL 410.55767 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_53\">\n    <path d=\"M 30.103125 1131.118125 \nL 410.55767 1131.118125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_54\">\n    <path d=\"M 30.103125 939.945711 \nL 410.55767 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_217\">\n    <!-- Training result when p = 900 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(133.661335 933.945711)scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n    </g>\n   </g>\n   <g id=\"legend_9\">\n    <g id=\"patch_55\">\n     <path d=\"M 37.103125 1065.370711 \nL 149.8875 1065.370711 \nQ 151.8875 1065.370711 151.8875 1063.370711 \nL 151.8875 946.945711 \nQ 151.8875 944.945711 149.8875 944.945711 \nL 37.103125 944.945711 \nQ 35.103125 944.945711 35.103125 946.945711 \nL 35.103125 1063.370711 \nQ 35.103125 1065.370711 37.103125 1065.370711 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_407\">\n     <path d=\"M 39.103125 953.044149 \nL 49.103125 953.044149 \nL 59.103125 953.044149 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_218\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 956.544149)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_408\">\n     <path d=\"M 39.103125 967.722274 \nL 49.103125 967.722274 \nL 59.103125 967.722274 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_219\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 971.222274)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_409\">\n     <path d=\"M 39.103125 982.400399 \nL 49.103125 982.400399 \nL 59.103125 982.400399 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_220\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 985.900399)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_410\">\n     <path d=\"M 39.103125 997.078524 \nL 49.103125 997.078524 \nL 59.103125 997.078524 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_221\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 1000.578524)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_411\">\n     <path d=\"M 39.103125 1011.756649 \nL 49.103125 1011.756649 \nL 59.103125 1011.756649 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_222\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 1015.256649)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_412\">\n     <path d=\"M 39.103125 1026.434774 \nL 49.103125 1026.434774 \nL 59.103125 1026.434774 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_223\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 1029.934774)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_413\">\n     <path d=\"M 39.103125 1041.112899 \nL 49.103125 1041.112899 \nL 59.103125 1041.112899 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_224\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 1044.612899)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_414\">\n     <path d=\"M 39.103125 1055.791024 \nL 49.103125 1055.791024 \nL 59.103125 1055.791024 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_225\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(67.103125 1059.291024)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_10\">\n   <g id=\"patch_56\">\n    <path d=\"M 486.64858 1131.118125 \nL 867.103125 1131.118125 \nL 867.103125 939.945711 \nL 486.64858 939.945711 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_19\">\n    <g id=\"xtick_55\">\n     <g id=\"line2d_415\">\n      <path d=\"M 486.64858 1131.118125 \nL 486.64858 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_416\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"486.64858\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_226\">\n      <!-- 0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(483.46733 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_56\">\n     <g id=\"line2d_417\">\n      <path d=\"M 561.986113 1131.118125 \nL 561.986113 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_418\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"561.986113\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_227\">\n      <!-- 20 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(555.623613 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_57\">\n     <g id=\"line2d_419\">\n      <path d=\"M 637.323647 1131.118125 \nL 637.323647 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_420\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"637.323647\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_228\">\n      <!-- 40 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(630.961147 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_58\">\n     <g id=\"line2d_421\">\n      <path d=\"M 712.661181 1131.118125 \nL 712.661181 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_422\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"712.661181\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_229\">\n      <!-- 60 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(706.298681 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_59\">\n     <g id=\"line2d_423\">\n      <path d=\"M 787.998715 1131.118125 \nL 787.998715 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_424\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"787.998715\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_230\">\n      <!-- 80 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(781.636215 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_60\">\n     <g id=\"line2d_425\">\n      <path d=\"M 863.336248 1131.118125 \nL 863.336248 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_426\">\n      <g>\n       <use xlink:href=\"#m0b69f7a329\" x=\"863.336248\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_231\">\n      <!-- 100 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(853.792498 1145.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_232\">\n     <!-- Epochs -->\n     <g style=\"fill: #ffffff\" transform=\"translate(658.960227 1159.394688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_20\">\n    <g id=\"ytick_82\">\n     <g id=\"line2d_427\">\n      <path d=\"M 486.64858 1131.118125 \nL 867.103125 1131.118125 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_428\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1131.118125\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_233\">\n      <!-- 0.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1134.917344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_83\">\n     <g id=\"line2d_429\">\n      <path d=\"M 486.64858 1107.221573 \nL 867.103125 1107.221573 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_430\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1107.221573\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_234\">\n      <!-- 0.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1111.020792)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_84\">\n     <g id=\"line2d_431\">\n      <path d=\"M 486.64858 1083.325022 \nL 867.103125 1083.325022 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_432\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1083.325022\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_235\">\n      <!-- 1.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1087.12424)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_85\">\n     <g id=\"line2d_433\">\n      <path d=\"M 486.64858 1059.42847 \nL 867.103125 1059.42847 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_434\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1059.42847\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_236\">\n      <!-- 1.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1063.227689)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_86\">\n     <g id=\"line2d_435\">\n      <path d=\"M 486.64858 1035.531918 \nL 867.103125 1035.531918 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_436\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1035.531918\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_237\">\n      <!-- 2.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1039.331137)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_87\">\n     <g id=\"line2d_437\">\n      <path d=\"M 486.64858 1011.635366 \nL 867.103125 1011.635366 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_438\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"1011.635366\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_238\">\n      <!-- 2.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 1015.434585)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_88\">\n     <g id=\"line2d_439\">\n      <path d=\"M 486.64858 987.738815 \nL 867.103125 987.738815 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_440\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"987.738815\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_239\">\n      <!-- 3.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 991.538033)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_89\">\n     <g id=\"line2d_441\">\n      <path d=\"M 486.64858 963.842263 \nL 867.103125 963.842263 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_442\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"963.842263\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_240\">\n      <!-- 3.5 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 967.641482)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_90\">\n     <g id=\"line2d_443\">\n      <path d=\"M 486.64858 939.945711 \nL 867.103125 939.945711 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_444\">\n      <g>\n       <use xlink:href=\"#mdda734422f\" x=\"486.64858\" y=\"939.945711\" style=\"fill: #ffffff; stroke: #ffffff; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_241\">\n      <!-- 4.0 -->\n      <g style=\"fill: #ffffff\" transform=\"translate(463.745455 943.74493)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_445\">\n    <path d=\"M 490.415456 943.555949 \nL 494.182333 934.069888 \nL 497.94921 936.533965 \nL 501.716086 942.79562 \nL 505.482963 947.104831 \nL 509.24984 950.803251 \nL 513.016716 954.481094 \nL 516.783593 957.870757 \nL 520.55047 959.862319 \nL 524.317346 962.842992 \nL 528.084223 964.316314 \nL 531.8511 966.296842 \nL 535.617976 968.339691 \nL 539.384853 969.484008 \nL 543.15173 970.104947 \nL 546.918607 971.934371 \nL 550.685483 972.812039 \nL 554.45236 973.708558 \nL 558.219237 974.857196 \nL 561.986113 974.922131 \nL 565.75299 975.357466 \nL 569.519867 975.724013 \nL 573.286743 976.298899 \nL 577.05362 976.623136 \nL 580.820497 977.114227 \nL 584.587373 977.69684 \nL 588.35425 976.682207 \nL 592.121127 978.607096 \nL 595.888003 978.217297 \nL 599.65488 978.780873 \nL 603.421757 978.525531 \nL 607.188634 978.542419 \nL 610.95551 979.019409 \nL 614.722387 979.4365 \nL 618.489264 979.127553 \nL 622.25614 979.547271 \nL 626.023017 980.208081 \nL 629.789894 980.810393 \nL 633.55677 980.839557 \nL 637.323647 980.926774 \nL 641.090524 980.996851 \nL 644.8574 981.162902 \nL 648.624277 981.794635 \nL 652.391154 981.902237 \nL 656.15803 980.92852 \nL 659.924907 981.968388 \nL 663.691784 981.120962 \nL 667.458661 981.218087 \nL 671.225537 981.355112 \nL 674.992414 982.117275 \nL 678.759291 981.668632 \nL 682.526167 983.248965 \nL 686.293044 982.514013 \nL 690.059921 983.296805 \nL 693.826797 982.230573 \nL 697.593674 982.252004 \nL 701.360551 983.275942 \nL 705.127427 982.440564 \nL 708.894304 982.800427 \nL 712.661181 982.950068 \nL 716.428057 983.158484 \nL 720.194934 982.865477 \nL 723.961811 982.81372 \nL 727.728688 982.51054 \nL 731.495564 983.848629 \nL 735.262441 983.921479 \nL 739.029318 983.197328 \nL 742.796194 982.492014 \nL 746.563071 984.210511 \nL 750.329948 983.106851 \nL 754.096824 983.64309 \nL 757.863701 983.826069 \nL 761.630578 984.622253 \nL 765.397454 984.229943 \nL 769.164331 984.448446 \nL 772.931208 984.59849 \nL 776.698084 984.138861 \nL 780.464961 983.502313 \nL 784.231838 983.347452 \nL 787.998715 984.120904 \nL 791.765591 983.565309 \nL 795.532468 984.007371 \nL 799.299345 984.246174 \nL 803.066221 984.587538 \nL 806.833098 985.021068 \nL 810.599975 983.698694 \nL 814.366851 983.953631 \nL 818.133728 983.147094 \nL 821.900605 983.792904 \nL 825.667481 984.063223 \nL 829.434358 983.970045 \nL 833.201235 983.588711 \nL 836.968111 984.093904 \nL 840.734988 985.249636 \nL 844.501865 984.349513 \nL 848.268742 984.895243 \nL 852.035618 983.5488 \nL 855.802495 984.926242 \nL 859.569372 985.300915 \nL 863.336248 984.541822 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_446\">\n    <path d=\"M 490.415456 1129.027177 \nL 494.182333 1125.143987 \nL 497.94921 1126.040108 \nL 501.716086 1125.143987 \nL 505.482963 1125.741401 \nL 509.24984 1117.676315 \nL 513.016716 1103.935797 \nL 516.783593 1099.156487 \nL 520.55047 1096.169418 \nL 524.317346 1090.792694 \nL 528.084223 1091.091401 \nL 531.8511 1094.07847 \nL 535.617976 1090.493987 \nL 539.384853 1086.610797 \nL 543.15173 1086.312091 \nL 546.918607 1086.312091 \nL 550.685483 1087.506918 \nL 554.45236 1085.714677 \nL 558.219237 1085.714677 \nL 561.986113 1085.41597 \nL 565.75299 1085.714677 \nL 569.519867 1085.41597 \nL 573.286743 1085.41597 \nL 577.05362 1084.519849 \nL 580.820497 1084.221142 \nL 584.587373 1084.221142 \nL 588.35425 1083.922435 \nL 592.121127 1084.221142 \nL 595.888003 1083.922435 \nL 599.65488 1084.818556 \nL 603.421757 1083.623728 \nL 607.188634 1083.623728 \nL 610.95551 1083.922435 \nL 614.722387 1083.623728 \nL 618.489264 1083.922435 \nL 622.25614 1083.623728 \nL 626.023017 1083.623728 \nL 629.789894 1083.922435 \nL 633.55677 1083.922435 \nL 637.323647 1083.623728 \nL 641.090524 1083.623728 \nL 644.8574 1083.623728 \nL 648.624277 1083.325022 \nL 652.391154 1083.325022 \nL 656.15803 1083.325022 \nL 659.924907 1083.325022 \nL 663.691784 1083.623728 \nL 667.458661 1083.325022 \nL 671.225537 1083.325022 \nL 674.992414 1083.325022 \nL 678.759291 1083.623728 \nL 682.526167 1083.623728 \nL 686.293044 1083.325022 \nL 690.059921 1083.325022 \nL 693.826797 1083.325022 \nL 697.593674 1083.325022 \nL 701.360551 1083.325022 \nL 705.127427 1083.922435 \nL 708.894304 1083.325022 \nL 712.661181 1083.325022 \nL 716.428057 1083.325022 \nL 720.194934 1083.325022 \nL 723.961811 1083.325022 \nL 727.728688 1083.325022 \nL 731.495564 1083.623728 \nL 735.262441 1083.325022 \nL 739.029318 1083.325022 \nL 742.796194 1083.325022 \nL 746.563071 1083.325022 \nL 750.329948 1083.325022 \nL 754.096824 1083.325022 \nL 757.863701 1083.325022 \nL 761.630578 1083.325022 \nL 765.397454 1083.325022 \nL 769.164331 1083.325022 \nL 772.931208 1083.325022 \nL 776.698084 1083.325022 \nL 780.464961 1083.325022 \nL 784.231838 1083.325022 \nL 787.998715 1083.325022 \nL 791.765591 1083.325022 \nL 795.532468 1083.325022 \nL 799.299345 1083.325022 \nL 803.066221 1083.623728 \nL 806.833098 1083.325022 \nL 810.599975 1083.325022 \nL 814.366851 1083.325022 \nL 818.133728 1083.325022 \nL 821.900605 1083.325022 \nL 825.667481 1083.325022 \nL 829.434358 1083.325022 \nL 833.201235 1083.325022 \nL 836.968111 1083.325022 \nL 840.734988 1083.325022 \nL 844.501865 1083.325022 \nL 848.268742 1083.325022 \nL 852.035618 1083.325022 \nL 855.802495 1083.325022 \nL 859.569372 1083.325022 \nL 863.336248 1083.325022 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_447\">\n    <path d=\"M 490.415456 1126.936228 \nL 494.182333 1122.455625 \nL 497.94921 1122.156918 \nL 501.716086 1122.455625 \nL 505.482963 1123.351746 \nL 509.24984 1112.598297 \nL 513.016716 1098.85778 \nL 516.783593 1093.779763 \nL 520.55047 1091.688815 \nL 524.317346 1086.610797 \nL 528.084223 1086.909504 \nL 531.8511 1088.403039 \nL 535.617976 1086.909504 \nL 539.384853 1084.519849 \nL 543.15173 1083.922435 \nL 546.918607 1084.519849 \nL 550.685483 1084.818556 \nL 554.45236 1084.221142 \nL 558.219237 1084.221142 \nL 561.986113 1083.623728 \nL 565.75299 1083.623728 \nL 569.519867 1084.221142 \nL 573.286743 1083.325022 \nL 577.05362 1083.325022 \nL 580.820497 1083.325022 \nL 584.587373 1083.623728 \nL 588.35425 1083.325022 \nL 592.121127 1083.325022 \nL 595.888003 1083.623728 \nL 599.65488 1084.221142 \nL 603.421757 1083.325022 \nL 607.188634 1083.325022 \nL 610.95551 1083.325022 \nL 614.722387 1083.325022 \nL 618.489264 1083.325022 \nL 622.25614 1083.325022 \nL 626.023017 1083.325022 \nL 629.789894 1083.325022 \nL 633.55677 1083.623728 \nL 637.323647 1083.325022 \nL 641.090524 1083.623728 \nL 644.8574 1083.325022 \nL 648.624277 1083.325022 \nL 652.391154 1083.325022 \nL 656.15803 1083.325022 \nL 659.924907 1083.325022 \nL 663.691784 1083.325022 \nL 667.458661 1083.325022 \nL 671.225537 1083.325022 \nL 674.992414 1083.325022 \nL 678.759291 1083.623728 \nL 682.526167 1083.325022 \nL 686.293044 1083.325022 \nL 690.059921 1083.325022 \nL 693.826797 1083.325022 \nL 697.593674 1083.325022 \nL 701.360551 1083.325022 \nL 705.127427 1083.623728 \nL 708.894304 1083.325022 \nL 712.661181 1083.325022 \nL 716.428057 1083.325022 \nL 720.194934 1083.325022 \nL 723.961811 1083.325022 \nL 727.728688 1083.325022 \nL 731.495564 1083.325022 \nL 735.262441 1083.325022 \nL 739.029318 1083.325022 \nL 742.796194 1083.325022 \nL 746.563071 1083.325022 \nL 750.329948 1083.325022 \nL 754.096824 1083.325022 \nL 757.863701 1083.325022 \nL 761.630578 1083.325022 \nL 765.397454 1083.325022 \nL 769.164331 1083.325022 \nL 772.931208 1083.325022 \nL 776.698084 1083.325022 \nL 780.464961 1083.325022 \nL 784.231838 1083.325022 \nL 787.998715 1083.325022 \nL 791.765591 1083.325022 \nL 795.532468 1083.325022 \nL 799.299345 1083.325022 \nL 803.066221 1083.325022 \nL 806.833098 1083.325022 \nL 810.599975 1083.325022 \nL 814.366851 1083.325022 \nL 818.133728 1083.325022 \nL 821.900605 1083.325022 \nL 825.667481 1083.325022 \nL 829.434358 1083.325022 \nL 833.201235 1083.325022 \nL 836.968111 1083.325022 \nL 840.734988 1083.325022 \nL 844.501865 1083.325022 \nL 848.268742 1083.325022 \nL 852.035618 1083.325022 \nL 855.802495 1083.325022 \nL 859.569372 1083.325022 \nL 863.336248 1083.325022 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_448\">\n    <path d=\"M 490.415456 1122.754332 \nL 494.182333 1120.06597 \nL 497.94921 1120.06597 \nL 501.716086 1119.468556 \nL 505.482963 1119.468556 \nL 509.24984 1107.818987 \nL 513.016716 1094.07847 \nL 516.783593 1089.000453 \nL 520.55047 1088.104332 \nL 524.317346 1084.818556 \nL 528.084223 1085.714677 \nL 531.8511 1086.312091 \nL 535.617976 1084.519849 \nL 539.384853 1084.221142 \nL 543.15173 1083.922435 \nL 546.918607 1084.221142 \nL 550.685483 1084.221142 \nL 554.45236 1083.922435 \nL 558.219237 1083.922435 \nL 561.986113 1083.623728 \nL 565.75299 1083.325022 \nL 569.519867 1083.623728 \nL 573.286743 1083.325022 \nL 577.05362 1083.325022 \nL 580.820497 1083.325022 \nL 584.587373 1083.623728 \nL 588.35425 1083.325022 \nL 592.121127 1083.325022 \nL 595.888003 1083.325022 \nL 599.65488 1083.623728 \nL 603.421757 1083.325022 \nL 607.188634 1083.325022 \nL 610.95551 1083.325022 \nL 614.722387 1083.325022 \nL 618.489264 1083.325022 \nL 622.25614 1083.325022 \nL 626.023017 1083.325022 \nL 629.789894 1083.325022 \nL 633.55677 1083.325022 \nL 637.323647 1083.325022 \nL 641.090524 1083.623728 \nL 644.8574 1083.325022 \nL 648.624277 1083.325022 \nL 652.391154 1083.325022 \nL 656.15803 1083.325022 \nL 659.924907 1083.325022 \nL 663.691784 1083.325022 \nL 667.458661 1083.325022 \nL 671.225537 1083.325022 \nL 674.992414 1083.325022 \nL 678.759291 1083.325022 \nL 682.526167 1083.325022 \nL 686.293044 1083.325022 \nL 690.059921 1083.325022 \nL 693.826797 1083.325022 \nL 697.593674 1083.325022 \nL 701.360551 1083.325022 \nL 705.127427 1083.325022 \nL 708.894304 1083.325022 \nL 712.661181 1083.325022 \nL 716.428057 1083.325022 \nL 720.194934 1083.325022 \nL 723.961811 1083.325022 \nL 727.728688 1083.325022 \nL 731.495564 1083.325022 \nL 735.262441 1083.325022 \nL 739.029318 1083.325022 \nL 742.796194 1083.325022 \nL 746.563071 1083.325022 \nL 750.329948 1083.325022 \nL 754.096824 1083.325022 \nL 757.863701 1083.325022 \nL 761.630578 1083.325022 \nL 765.397454 1083.325022 \nL 769.164331 1083.325022 \nL 772.931208 1083.325022 \nL 776.698084 1083.325022 \nL 780.464961 1083.325022 \nL 784.231838 1083.325022 \nL 787.998715 1083.325022 \nL 791.765591 1083.325022 \nL 795.532468 1083.325022 \nL 799.299345 1083.325022 \nL 803.066221 1083.325022 \nL 806.833098 1083.325022 \nL 810.599975 1083.325022 \nL 814.366851 1083.325022 \nL 818.133728 1083.325022 \nL 821.900605 1083.325022 \nL 825.667481 1083.325022 \nL 829.434358 1083.325022 \nL 833.201235 1083.325022 \nL 836.968111 1083.325022 \nL 840.734988 1083.325022 \nL 844.501865 1083.325022 \nL 848.268742 1083.325022 \nL 852.035618 1083.325022 \nL 855.802495 1083.325022 \nL 859.569372 1083.325022 \nL 863.336248 1083.325022 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_449\">\n    <path d=\"M 490.415456 926.187459 \nL 494.182333 928.196831 \nL 497.94921 928.794854 \nL 501.716086 932.581962 \nL 505.482963 938.904039 \nL 509.24984 949.497108 \nL 513.016716 950.652895 \nL 516.783593 951.965042 \nL 520.55047 955.86606 \nL 524.317346 954.556022 \nL 528.084223 957.05303 \nL 531.8511 956.704368 \nL 535.617976 956.417484 \nL 539.384853 957.019459 \nL 543.15173 957.015878 \nL 546.918607 959.184956 \nL 550.685483 959.149238 \nL 554.45236 960.122646 \nL 558.219237 958.407519 \nL 561.986113 959.632988 \nL 565.75299 961.438637 \nL 569.519867 957.950096 \nL 573.286743 958.438589 \nL 577.05362 961.213226 \nL 580.820497 959.660832 \nL 584.587373 960.101499 \nL 588.35425 959.549492 \nL 592.121127 958.954215 \nL 595.888003 961.293021 \nL 599.65488 959.67307 \nL 603.421757 961.270429 \nL 607.188634 961.552265 \nL 610.95551 962.425593 \nL 614.722387 963.313549 \nL 618.489264 961.648234 \nL 622.25614 961.115164 \nL 626.023017 960.985171 \nL 629.789894 961.199075 \nL 633.55677 961.967305 \nL 637.323647 962.243727 \nL 641.090524 961.677261 \nL 644.8574 961.710241 \nL 648.624277 962.154391 \nL 652.391154 962.349785 \nL 656.15803 961.604141 \nL 659.924907 962.053624 \nL 663.691784 964.073461 \nL 667.458661 962.92762 \nL 671.225537 961.850242 \nL 674.992414 961.464916 \nL 678.759291 961.716475 \nL 682.526167 962.88178 \nL 686.293044 962.331449 \nL 690.059921 963.332979 \nL 693.826797 963.845659 \nL 697.593674 962.918714 \nL 701.360551 963.146183 \nL 705.127427 962.554996 \nL 708.894304 963.602532 \nL 712.661181 964.252424 \nL 716.428057 963.252517 \nL 720.194934 963.79571 \nL 723.961811 964.154984 \nL 727.728688 964.206851 \nL 731.495564 964.338046 \nL 735.262441 963.816465 \nL 739.029318 963.491356 \nL 742.796194 964.420352 \nL 746.563071 962.687493 \nL 750.329948 963.92919 \nL 754.096824 964.994611 \nL 757.863701 963.910758 \nL 761.630578 963.598277 \nL 765.397454 963.779424 \nL 769.164331 963.902711 \nL 772.931208 962.978458 \nL 776.698084 964.105632 \nL 780.464961 963.454839 \nL 784.231838 963.047317 \nL 787.998715 963.933719 \nL 791.765591 963.802347 \nL 795.532468 963.613334 \nL 799.299345 964.330416 \nL 803.066221 963.967255 \nL 806.833098 963.796012 \nL 810.599975 964.2375 \nL 814.366851 964.259617 \nL 818.133728 963.872446 \nL 821.900605 963.277633 \nL 825.667481 963.455259 \nL 829.434358 964.400603 \nL 833.201235 964.226229 \nL 836.968111 963.826803 \nL 840.734988 964.28011 \nL 844.501865 963.176009 \nL 848.268742 964.021556 \nL 852.035618 964.196422 \nL 855.802495 963.181251 \nL 859.569372 964.101455 \nL 863.336248 963.679798 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_450\">\n    <path d=\"M 490.415456 1129.126746 \nL 494.182333 1131.118125 \nL 497.94921 1131.118125 \nL 501.716086 1131.118125 \nL 505.482963 1123.152608 \nL 509.24984 1117.17847 \nL 513.016716 1111.204332 \nL 516.783593 1107.221573 \nL 520.55047 1105.230194 \nL 524.317346 1107.221573 \nL 528.084223 1109.212953 \nL 531.8511 1103.238815 \nL 535.617976 1107.221573 \nL 539.384853 1103.238815 \nL 543.15173 1101.247435 \nL 546.918607 1103.238815 \nL 550.685483 1101.247435 \nL 554.45236 1107.221573 \nL 558.219237 1101.247435 \nL 561.986113 1103.238815 \nL 565.75299 1103.238815 \nL 569.519867 1103.238815 \nL 573.286743 1107.221573 \nL 577.05362 1101.247435 \nL 580.820497 1103.238815 \nL 584.587373 1103.238815 \nL 588.35425 1099.256056 \nL 592.121127 1101.247435 \nL 595.888003 1101.247435 \nL 599.65488 1103.238815 \nL 603.421757 1105.230194 \nL 607.188634 1099.256056 \nL 610.95551 1099.256056 \nL 614.722387 1099.256056 \nL 618.489264 1105.230194 \nL 622.25614 1103.238815 \nL 626.023017 1105.230194 \nL 629.789894 1107.221573 \nL 633.55677 1103.238815 \nL 637.323647 1101.247435 \nL 641.090524 1099.256056 \nL 644.8574 1103.238815 \nL 648.624277 1099.256056 \nL 652.391154 1099.256056 \nL 656.15803 1101.247435 \nL 659.924907 1103.238815 \nL 663.691784 1103.238815 \nL 667.458661 1103.238815 \nL 671.225537 1101.247435 \nL 674.992414 1101.247435 \nL 678.759291 1099.256056 \nL 682.526167 1103.238815 \nL 686.293044 1101.247435 \nL 690.059921 1099.256056 \nL 693.826797 1103.238815 \nL 697.593674 1103.238815 \nL 701.360551 1099.256056 \nL 705.127427 1099.256056 \nL 708.894304 1101.247435 \nL 712.661181 1099.256056 \nL 716.428057 1101.247435 \nL 720.194934 1099.256056 \nL 723.961811 1101.247435 \nL 727.728688 1103.238815 \nL 731.495564 1099.256056 \nL 735.262441 1099.256056 \nL 739.029318 1099.256056 \nL 742.796194 1099.256056 \nL 746.563071 1103.238815 \nL 750.329948 1101.247435 \nL 754.096824 1099.256056 \nL 757.863701 1099.256056 \nL 761.630578 1099.256056 \nL 765.397454 1099.256056 \nL 769.164331 1103.238815 \nL 772.931208 1101.247435 \nL 776.698084 1101.247435 \nL 780.464961 1101.247435 \nL 784.231838 1099.256056 \nL 787.998715 1101.247435 \nL 791.765591 1101.247435 \nL 795.532468 1101.247435 \nL 799.299345 1101.247435 \nL 803.066221 1101.247435 \nL 806.833098 1101.247435 \nL 810.599975 1103.238815 \nL 814.366851 1103.238815 \nL 818.133728 1101.247435 \nL 821.900605 1103.238815 \nL 825.667481 1103.238815 \nL 829.434358 1101.247435 \nL 833.201235 1103.238815 \nL 836.968111 1101.247435 \nL 840.734988 1103.238815 \nL 844.501865 1103.238815 \nL 848.268742 1103.238815 \nL 852.035618 1101.247435 \nL 855.802495 1103.238815 \nL 859.569372 1105.230194 \nL 863.336248 1103.238815 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_451\">\n    <path d=\"M 490.415456 1127.135366 \nL 494.182333 1131.118125 \nL 497.94921 1131.118125 \nL 501.716086 1129.126746 \nL 505.482963 1121.161228 \nL 509.24984 1117.17847 \nL 513.016716 1105.230194 \nL 516.783593 1105.230194 \nL 520.55047 1101.247435 \nL 524.317346 1099.256056 \nL 528.084223 1105.230194 \nL 531.8511 1103.238815 \nL 535.617976 1103.238815 \nL 539.384853 1097.264677 \nL 543.15173 1097.264677 \nL 546.918607 1099.256056 \nL 550.685483 1097.264677 \nL 554.45236 1101.247435 \nL 558.219237 1097.264677 \nL 561.986113 1099.256056 \nL 565.75299 1101.247435 \nL 569.519867 1103.238815 \nL 573.286743 1101.247435 \nL 577.05362 1099.256056 \nL 580.820497 1101.247435 \nL 584.587373 1097.264677 \nL 588.35425 1095.273297 \nL 592.121127 1097.264677 \nL 595.888003 1099.256056 \nL 599.65488 1099.256056 \nL 603.421757 1103.238815 \nL 607.188634 1099.256056 \nL 610.95551 1093.281918 \nL 614.722387 1097.264677 \nL 618.489264 1101.247435 \nL 622.25614 1097.264677 \nL 626.023017 1097.264677 \nL 629.789894 1099.256056 \nL 633.55677 1097.264677 \nL 637.323647 1099.256056 \nL 641.090524 1097.264677 \nL 644.8574 1103.238815 \nL 648.624277 1099.256056 \nL 652.391154 1095.273297 \nL 656.15803 1097.264677 \nL 659.924907 1101.247435 \nL 663.691784 1101.247435 \nL 667.458661 1099.256056 \nL 671.225537 1099.256056 \nL 674.992414 1097.264677 \nL 678.759291 1099.256056 \nL 682.526167 1101.247435 \nL 686.293044 1099.256056 \nL 690.059921 1099.256056 \nL 693.826797 1097.264677 \nL 697.593674 1101.247435 \nL 701.360551 1099.256056 \nL 705.127427 1099.256056 \nL 708.894304 1099.256056 \nL 712.661181 1099.256056 \nL 716.428057 1099.256056 \nL 720.194934 1097.264677 \nL 723.961811 1097.264677 \nL 727.728688 1095.273297 \nL 731.495564 1097.264677 \nL 735.262441 1099.256056 \nL 739.029318 1099.256056 \nL 742.796194 1097.264677 \nL 746.563071 1097.264677 \nL 750.329948 1097.264677 \nL 754.096824 1097.264677 \nL 757.863701 1099.256056 \nL 761.630578 1099.256056 \nL 765.397454 1097.264677 \nL 769.164331 1095.273297 \nL 772.931208 1097.264677 \nL 776.698084 1099.256056 \nL 780.464961 1099.256056 \nL 784.231838 1097.264677 \nL 787.998715 1097.264677 \nL 791.765591 1097.264677 \nL 795.532468 1097.264677 \nL 799.299345 1097.264677 \nL 803.066221 1097.264677 \nL 806.833098 1097.264677 \nL 810.599975 1097.264677 \nL 814.366851 1099.256056 \nL 818.133728 1097.264677 \nL 821.900605 1097.264677 \nL 825.667481 1097.264677 \nL 829.434358 1097.264677 \nL 833.201235 1099.256056 \nL 836.968111 1099.256056 \nL 840.734988 1097.264677 \nL 844.501865 1099.256056 \nL 848.268742 1099.256056 \nL 852.035618 1097.264677 \nL 855.802495 1099.256056 \nL 859.569372 1097.264677 \nL 863.336248 1097.264677 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_452\">\n    <path d=\"M 490.415456 1127.135366 \nL 494.182333 1127.135366 \nL 497.94921 1127.135366 \nL 501.716086 1129.126746 \nL 505.482963 1121.161228 \nL 509.24984 1111.204332 \nL 513.016716 1101.247435 \nL 516.783593 1097.264677 \nL 520.55047 1099.256056 \nL 524.317346 1093.281918 \nL 528.084223 1101.247435 \nL 531.8511 1099.256056 \nL 535.617976 1099.256056 \nL 539.384853 1093.281918 \nL 543.15173 1095.273297 \nL 546.918607 1095.273297 \nL 550.685483 1093.281918 \nL 554.45236 1099.256056 \nL 558.219237 1095.273297 \nL 561.986113 1099.256056 \nL 565.75299 1097.264677 \nL 569.519867 1095.273297 \nL 573.286743 1099.256056 \nL 577.05362 1099.256056 \nL 580.820497 1097.264677 \nL 584.587373 1093.281918 \nL 588.35425 1095.273297 \nL 592.121127 1095.273297 \nL 595.888003 1099.256056 \nL 599.65488 1095.273297 \nL 603.421757 1097.264677 \nL 607.188634 1097.264677 \nL 610.95551 1093.281918 \nL 614.722387 1097.264677 \nL 618.489264 1099.256056 \nL 622.25614 1093.281918 \nL 626.023017 1097.264677 \nL 629.789894 1099.256056 \nL 633.55677 1097.264677 \nL 637.323647 1097.264677 \nL 641.090524 1097.264677 \nL 644.8574 1099.256056 \nL 648.624277 1097.264677 \nL 652.391154 1095.273297 \nL 656.15803 1097.264677 \nL 659.924907 1099.256056 \nL 663.691784 1095.273297 \nL 667.458661 1097.264677 \nL 671.225537 1095.273297 \nL 674.992414 1095.273297 \nL 678.759291 1097.264677 \nL 682.526167 1097.264677 \nL 686.293044 1097.264677 \nL 690.059921 1095.273297 \nL 693.826797 1097.264677 \nL 697.593674 1101.247435 \nL 701.360551 1099.256056 \nL 705.127427 1099.256056 \nL 708.894304 1099.256056 \nL 712.661181 1097.264677 \nL 716.428057 1097.264677 \nL 720.194934 1097.264677 \nL 723.961811 1095.273297 \nL 727.728688 1095.273297 \nL 731.495564 1097.264677 \nL 735.262441 1097.264677 \nL 739.029318 1097.264677 \nL 742.796194 1097.264677 \nL 746.563071 1097.264677 \nL 750.329948 1095.273297 \nL 754.096824 1097.264677 \nL 757.863701 1095.273297 \nL 761.630578 1097.264677 \nL 765.397454 1095.273297 \nL 769.164331 1095.273297 \nL 772.931208 1095.273297 \nL 776.698084 1095.273297 \nL 780.464961 1097.264677 \nL 784.231838 1097.264677 \nL 787.998715 1097.264677 \nL 791.765591 1097.264677 \nL 795.532468 1097.264677 \nL 799.299345 1097.264677 \nL 803.066221 1097.264677 \nL 806.833098 1097.264677 \nL 810.599975 1095.273297 \nL 814.366851 1095.273297 \nL 818.133728 1095.273297 \nL 821.900605 1097.264677 \nL 825.667481 1095.273297 \nL 829.434358 1095.273297 \nL 833.201235 1097.264677 \nL 836.968111 1095.273297 \nL 840.734988 1097.264677 \nL 844.501865 1097.264677 \nL 848.268742 1097.264677 \nL 852.035618 1097.264677 \nL 855.802495 1095.273297 \nL 859.569372 1097.264677 \nL 863.336248 1095.273297 \n\" clip-path=\"url(#p0f03c41d77)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 486.64858 1131.118125 \nL 486.64858 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 867.103125 1131.118125 \nL 867.103125 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 486.64858 1131.118125 \nL 867.103125 1131.118125 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 486.64858 939.945711 \nL 867.103125 939.945711 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_242\">\n    <!-- Training result when p = 1000 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(586.38929 933.945711)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"465.177734\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"526.701172\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"578.800781\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"642.179688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"669.962891\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"709.171875\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"740.958984\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"822.746094\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"886.125\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"947.648438\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1011.027344\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"1042.814453\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1106.291016\"/>\n     <use xlink:href=\"#DejaVuSans-3d\" x=\"1138.078125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1221.867188\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"1253.654297\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1317.277344\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1380.900391\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"1444.523438\"/>\n    </g>\n   </g>\n   <g id=\"legend_10\">\n    <g id=\"patch_61\">\n     <path d=\"M 493.64858 1065.370711 \nL 606.432955 1065.370711 \nQ 608.432955 1065.370711 608.432955 1063.370711 \nL 608.432955 946.945711 \nQ 608.432955 944.945711 606.432955 944.945711 \nL 493.64858 944.945711 \nQ 491.64858 944.945711 491.64858 946.945711 \nL 491.64858 1063.370711 \nQ 491.64858 1065.370711 493.64858 1065.370711 \nz\n\" style=\"opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_453\">\n     <path d=\"M 495.64858 953.044149 \nL 505.64858 953.044149 \nL 515.64858 953.044149 \n\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_243\">\n     <!-- Train Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 956.544149)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_454\">\n     <path d=\"M 495.64858 967.722274 \nL 505.64858 967.722274 \nL 515.64858 967.722274 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_244\">\n     <!-- Train Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 971.222274)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_455\">\n     <path d=\"M 495.64858 982.400399 \nL 505.64858 982.400399 \nL 515.64858 982.400399 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_245\">\n     <!-- Train Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 985.900399)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_456\">\n     <path d=\"M 495.64858 997.078524 \nL 505.64858 997.078524 \nL 515.64858 997.078524 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #0000ff; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_246\">\n     <!-- Train Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 1000.578524)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"338.333984\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"393.314453\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"448.294922\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"480.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"524.166016\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"585.347656\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"648.824219\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"680.611328\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"744.234375\"/>\n     </g>\n    </g>\n    <g id=\"line2d_457\">\n     <path d=\"M 495.64858 1011.756649 \nL 505.64858 1011.756649 \nL 515.64858 1011.756649 \n\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_247\">\n     <!-- Val Loss -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 1015.256649)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"235.470703\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"296.652344\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"348.751953\"/>\n     </g>\n    </g>\n    <g id=\"line2d_458\">\n     <path d=\"M 495.64858 1026.434774 \nL 505.64858 1026.434774 \nL 515.64858 1026.434774 \n\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_248\">\n     <!-- Val Acc Top 20 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 1029.934774)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_459\">\n     <path d=\"M 495.64858 1041.112899 \nL 505.64858 1041.112899 \nL 515.64858 1041.112899 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_249\">\n     <!-- Val Acc Top 30 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 1044.612899)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n    <g id=\"line2d_460\">\n     <path d=\"M 495.64858 1055.791024 \nL 505.64858 1055.791024 \nL 515.64858 1055.791024 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_250\">\n     <!-- Val Acc Top 40 -->\n     <g style=\"fill: #ffffff\" transform=\"translate(523.64858 1059.291024)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-41\" x=\"181.507812\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"248.166016\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"303.146484\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"358.126953\"/>\n      <use xlink:href=\"#DejaVuSans-54\" x=\"389.914062\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.998047\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"495.179688\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"558.65625\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"590.443359\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"654.066406\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb173291db9\">\n   <rect x=\"30.103125\" y=\"22.318125\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p1063115bc5\">\n   <rect x=\"486.64858\" y=\"22.318125\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p7487f6dc3e\">\n   <rect x=\"30.103125\" y=\"251.725022\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p3573166e8c\">\n   <rect x=\"486.64858\" y=\"251.725022\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"pf30be4b301\">\n   <rect x=\"30.103125\" y=\"481.131918\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p7ab555a4aa\">\n   <rect x=\"486.64858\" y=\"481.131918\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"pe6c35d5558\">\n   <rect x=\"30.103125\" y=\"710.538815\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p2894dc4dff\">\n   <rect x=\"486.64858\" y=\"710.538815\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"paf85ef470a\">\n   <rect x=\"30.103125\" y=\"939.945711\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n  <clipPath id=\"p0f03c41d77\">\n   <rect x=\"486.64858\" y=\"939.945711\" width=\"380.454545\" height=\"191.172414\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 1500x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) train loss mean 3.08605340208326\n",
      "(100,) val loss mean 3.6336542878832137\n",
      "(100,) 20 mean 0.6833333333333332\n",
      "(100,) 20 max 0.75\n",
      "(100,) 30 mean 0.75\n",
      "(100,) 30 max 0.8333333333333334\n",
      "(100,) 40 mean 0.75\n",
      "(100,) 40 max 0.875\n",
      "(200,) train loss mean 3.1032639946256366\n",
      "(200,) val loss mean 3.5687300818307057\n",
      "(200,) 20 mean 0.6458333333333333\n",
      "(200,) 20 max 0.7083333333333334\n",
      "(200,) 30 mean 0.7458333333333333\n",
      "(200,) 30 max 0.8333333333333334\n",
      "(200,) 40 mean 0.7625\n",
      "(200,) 40 max 0.875\n",
      "(300,) train loss mean 3.0943782431738716\n",
      "(300,) val loss mean 3.5672928605760847\n",
      "(300,) 20 mean 0.6583333333333334\n",
      "(300,) 20 max 0.7916666666666666\n",
      "(300,) 30 mean 0.7708333333333333\n",
      "(300,) 30 max 0.875\n",
      "(300,) 40 mean 0.8458333333333334\n",
      "(300,) 40 max 0.9166666666666666\n",
      "(400,) train loss mean 3.08684378692082\n",
      "(400,) val loss mean 3.543745313371931\n",
      "(400,) 20 mean 0.6625\n",
      "(400,) 20 max 0.7083333333333334\n",
      "(400,) 30 mean 0.7458333333333333\n",
      "(400,) 30 max 0.7916666666666666\n",
      "(400,) 40 mean 0.7708333333333333\n",
      "(400,) 40 max 0.8333333333333334\n",
      "(500,) train loss mean 3.087862127167838\n",
      "(500,) val loss mean 3.522768565586635\n",
      "(500,) 20 mean 0.6833333333333333\n",
      "(500,) 20 max 0.7083333333333334\n",
      "(500,) 30 mean 0.7583333333333333\n",
      "(500,) 30 max 0.8333333333333334\n",
      "(500,) 40 mean 0.7791666666666667\n",
      "(500,) 40 max 0.9166666666666666\n",
      "(600,) train loss mean 3.0902150528771535\n",
      "(600,) val loss mean 3.5150747980390276\n",
      "(600,) 20 mean 0.6875\n",
      "(600,) 20 max 0.75\n",
      "(600,) 30 mean 0.8208333333333334\n",
      "(600,) 30 max 0.875\n",
      "(600,) 40 mean 0.8333333333333334\n",
      "(600,) 40 max 0.875\n",
      "(700,) train loss mean 3.08742653301784\n",
      "(700,) val loss mean 3.527449437550136\n",
      "(700,) 20 mean 0.575\n",
      "(700,) 20 max 0.7083333333333334\n",
      "(700,) 30 mean 0.7208333333333333\n",
      "(700,) 30 max 0.8333333333333334\n",
      "(700,) 40 mean 0.8083333333333332\n",
      "(700,) 40 max 0.875\n",
      "(800,) train loss mean 3.077141397339957\n",
      "(800,) val loss mean 3.492772477013724\n",
      "(800,) 20 mean 0.7\n",
      "(800,) 20 max 0.7083333333333334\n",
      "(800,) 30 mean 0.75\n",
      "(800,) 30 max 0.875\n",
      "(800,) 40 mean 0.825\n",
      "(800,) 40 max 0.9583333333333334\n",
      "(900,) train loss mean 3.0879837819508142\n",
      "(900,) val loss mean 3.5004867144993375\n",
      "(900,) 20 mean 0.625\n",
      "(900,) 20 max 0.75\n",
      "(900,) 30 mean 0.6708333333333334\n",
      "(900,) 30 max 0.7916666666666666\n",
      "(900,) 40 mean 0.7416666666666667\n",
      "(900,) 40 max 0.875\n",
      "(1000,) train loss mean 3.0788559402738294\n",
      "(1000,) val loss mean 3.5008351802825928\n",
      "(1000,) 20 mean 0.5916666666666667\n",
      "(1000,) 20 max 0.6666666666666666\n",
      "(1000,) 30 mean 0.6874999999999999\n",
      "(1000,) 30 max 0.7916666666666666\n",
      "(1000,) 40 mean 0.725\n",
      "(1000,) 40 max 0.7916666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_graph(train_metrics.data, 100, ('pretrain_epochs'))\n",
    "for k, v in train_metrics.data.items():\n",
    "    print(f'{k} train loss mean {np.mean(v[0][-10])}')\n",
    "    print(f'{k} val loss mean {np.mean(v[2][-20])}')\n",
    "    for k1 in v[1].keys():\n",
    "        print(f'{k} {k1} mean {np.mean(v[3][k1][-10:])}')\n",
    "        print(f'{k} {k1} max {np.max(v[3][k1])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d4e980a27e930b9ff5731385d4bd44946951fe20aeacecd4aa5a8f48401c490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
